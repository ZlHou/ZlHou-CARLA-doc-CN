{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CARLA \u6587\u6863 \u6b22\u8fce\u4f7f\u7528 CARLA \u6587\u6863\u3002 \u6b64\u4e3b\u9875\u5305\u542b\u4e00\u4e2a\u7d22\u5f15\uff0c\u5176\u4e2d\u7b80\u8981\u8bf4\u660e\u4e86\u6587\u6863\u4e2d\u7684\u4e0d\u540c\u90e8\u5206\u3002\u968f\u610f\u6309\u559c\u6b22\u7684\u987a\u5e8f\u9605\u8bfb\u3002\u65e0\u8bba\u5982\u4f55\uff0c\u8fd9\u91cc\u6709\u4e00\u4e9b\u7ed9\u65b0\u624b\u7684\u5efa\u8bae\u3002 \u5b89\u88c5 CARLA. \u8981\u4e48\u6309\u7167 \u5feb\u901f\u5f00\u59cb\u5b89\u88c5 \u83b7\u5f97CARLA \u7248\u672c\uff0c\u8981\u4e48\u6309\u7167\u6240\u9700\u5e73\u53f0 \u8fdb\u884c\u6784\u5efa \u3002 \u5f00\u59cb\u4f7f\u7528 CARLA. \u6807\u9898\u4e3a \u7b2c\u4e00\u6b65 \u7684\u90e8\u5206\u4ecb\u7ecd\u4e86\u6700\u91cd\u8981\u7684\u6982\u5ff5\u3002 \u68c0\u67e5 API. \u6709\u4e00\u4e2a\u65b9\u4fbf\u7684 Python API \u53c2\u8003 \u6765\u67e5\u627e\u53ef\u7528\u7684\u7c7b\u548c\u65b9\u6cd5\u3002 CARLA \u8bba\u575b\u53ef\u4ee5\u53d1\u5e03\u5728\u9605\u8bfb\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u4efb\u4f55\u7591\u95ee\u6216\u5efa\u8bae\u3002 CARLA\u8bba\u575b \uff01\uff01\uff01\u8b66\u544a \u66f4\u6539\u6587\u6863\u7248\u672c\u4ee5\u9002\u5408\u60a8\u4f7f\u7528\u7684 CARLA \u7248\u672c \u3002\u4f7f\u7528\u6b64\u7a97\u53e3\u53f3\u4e0b\u89d2\u7684\u9762\u677f\u66f4\u6539\u4e3a\u4ee5\u524d\u7684\u7248\u672c\u3002 \u6700\u65b0\u7248\u672c\u6307\u5411 dev \u5206\u652f \u4e2d\u7684\u6587\u6863\uff0c\u8fd9\u53ef\u80fd\u662f\u6307\u5f53\u524d\u6b63\u5728\u5f00\u53d1\u7684\u529f\u80fd\uff0c\u5e76\u4e14\u5728\u4efb\u4f55\u6253\u5305\u7248\u672c\u7684 CARLA \u4e2d__\u4e0d\u53ef\u7528__\uff0c\u4ee5\u53ca\u4e00\u822c\u6587\u6863\u6539\u8fdb\u3002 \u5165\u95e8 \u4ecb\u7ecd \u2014 \u5bf9 CARLA \u7684\u671f\u671b\u3002 \u5feb\u901f\u542f\u52a8\u5305\u5b89\u88c5 \u2014 \u83b7\u53d6 CARLA \u7248\u672c\u3002 \u6784\u5efaCARLA Linux build \u2014 \u5728 Linux \u4e0a\u8fdb\u884c\u6784\u5efa\u3002 Windows build \u2014 \u5728 Windows \u4e0a\u8fdb\u884c\u6784\u5efa\u3002 Update CARLA \u2014 \u4e86\u89e3\u6700\u65b0\u5185\u5bb9\u3002 Build system \u2014 \u4e86\u89e3\u6784\u5efa\u53ca\u5176\u5236\u4f5c\u65b9\u5f0f\u3002 CARLA in Docker \u2014 \u4f7f\u7528\u5bb9\u5668\u89e3\u51b3\u65b9\u6848\u8fd0\u884c CARLA\u3002 F.A.Q. \u2014 \u4e00\u4e9b\u6700\u5e38\u89c1\u7684\u5b89\u88c5\u95ee\u9898\u3002 \u7b2c\u4e00\u6b65 \u6838\u5fc3\u6982\u5ff5 \u2014 CARLA \u4e2d\u57fa\u672c\u6982\u5ff5\u7684\u6982\u8ff0\u3002 \u7b2c\u4e00\u3001 \u4e16\u754c\u548c\u5ba2\u6237\u7aef \u2014 \u7ba1\u7406\u548c\u8bbf\u95ee\u6a21\u62df\u3002 \u7b2c\u4e8c\u3001 \u89d2\u8272\u548c\u84dd\u56fe \u2014 \u4e86\u89e3\u89d2\u8272\u4ee5\u53ca\u5982\u4f55\u5904\u7406\u5b83\u4eec\u3002 \u7b2c\u4e09\u3001\u5730\u56fe\u548c\u5bfc\u822a \u2014 \u53d1\u73b0\u4e0d\u540c\u7684\u5730\u56fe\u4ee5\u53ca\u8f66\u8f86\u5982\u4f55\u79fb\u52a8\u3002 \u7b2c\u56db\u3001 \u4f20\u611f\u5668\u548c\u6570\u636e \u2014 \u4f7f\u7528\u4f20\u611f\u5668\u68c0\u7d22\u6a21\u62df\u6570\u636e\u3002 \u9ad8\u7ea7\u6982\u5ff5 OpenDRIVE \u72ec\u7acb\u6a21\u5f0f \u2014 \u4f7f\u7528\u4efb\u4f55 OpenDRIVE \u6587\u4ef6\u4f5c\u4e3a CARLA \u5730\u56fe\u3002 PTV-Vissim \u8054\u5408\u4eff\u771f - \u5728 CARLA \u548c PTV-Vissim \u4e4b\u95f4\u8fd0\u884c\u540c\u6b65\u4eff\u771f\u3002 Recorder \u2014 \u5728\u6a21\u62df\u4e2d\u5f55\u5236\u4e8b\u4ef6\u5e76\u518d\u6b21\u64ad\u653e\u3002 \u6e32\u67d3\u9009\u9879 \u2014 \u4ece\u8d28\u91cf\u8bbe\u7f6e\u5230\u4e0d\u6e32\u67d3\u6216\u79bb\u5c4f\u6a21\u5f0f\u3002 RSS \u2014 CARLA \u5ba2\u6237\u7aef\u5e93\u4e2d\u7684 RSS \u5b9e\u73b0\u3002 \u540c\u6b65\u548c\u65f6\u95f4\u6b65\u957f \u2014 \u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u901a\u4fe1\u548c\u6a21\u62df\u65f6\u95f4\u3002 \u57fa\u51c6\u6027\u80fd \u2014 \u4f7f\u7528\u6211\u4eec\u51c6\u5907\u597d\u7684\u811a\u672c\u6267\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002 CARLA \u4ee3\u7406 \u2014 \u4ee3\u7406\u811a\u672c\u5141\u8bb8\u5355\u4e2a\u8f66\u8f86\u5728\u5730\u56fe\u4e0a\u6f2b\u6e38\u6216\u5f00\u8f66\u5230\u8bbe\u5b9a\u7684\u76ee\u7684\u5730\u3002 \u4ea4\u901a\u6a21\u62df \u4ea4\u901a\u6a21\u62df\u6982\u8ff0 \u2014 \u53ef\u7528\u4e8e\u4f7f\u7528\u4ea4\u901a\u586b\u5145\u573a\u666f\u7684\u4e0d\u540c\u9009\u9879\u7684\u6982\u8ff0 Traffic Manager \u2014 \u901a\u8fc7\u5c06\u8f66\u8f86\u8bbe\u7f6e\u4e3a\u81ea\u52a8\u9a7e\u9a76\u6a21\u5f0f\u6765\u6a21\u62df\u57ce\u5e02\u4ea4\u901a\u3002 SUMO \u8054\u5408\u4eff\u771f \u2014 \u5728 CARLA \u548c SUMO \u4e4b\u95f4\u8fd0\u884c\u540c\u6b65\u4eff\u771f\u3002 Scenic \u2014 \u9075\u5faa\u4f7f\u7528 Scenic \u5e93\u5b9a\u4e49\u4e0d\u540c\u573a\u666f\u7684\u793a\u4f8b\u3002 \u53c2\u8003 Python API \u53c2\u8003 \u2014 Python API \u4e2d\u7684\u7c7b\u548c\u65b9\u6cd5\u3002 Blueprint library \u2014 \u63d0\u4f9b\u7528\u4e8e\u751f\u6210 actor \u7684\u84dd\u56fe\u3002 C++ \u53c2\u8003 \u2014 CARLA C++ \u4e2d\u7684\u7c7b\u548c\u65b9\u6cd5\u3002 Recorder \u4e8c\u8fdb\u5236\u6587\u4ef6\u683c\u5f0f \u2014 \u8bb0\u5f55\u5668\u6587\u4ef6\u683c\u5f0f\u7684\u8be6\u7ec6\u8bf4\u660e\u3002 Sensors reference \u2014 \u5173\u4e8e\u4f20\u611f\u5668\u53ca\u5176\u68c0\u7d22\u6570\u636e\u7684\u4e00\u5207\u3002 \u63d2\u4ef6 carlaviz \u2014 web \u53ef\u89c6\u5316\u5668 \u2014 \u4fa6\u542c\u6a21\u62df\u5e76\u5728\u7f51\u7edc\u6d4f\u89c8\u5668\u4e2d\u663e\u793a\u573a\u666f\u548c\u4e00\u4e9b\u6a21\u62df\u6570\u636e\u7684\u63d2\u4ef6\u3002 ROS \u6865\u63a5\u5668 ROS \u6865\u6587\u6863 \u2014 ROS \u6865\u7684\u7b80\u8981\u6982\u8ff0\u548c\u5b8c\u6574\u6587\u6863\u7684\u94fe\u63a5 \u81ea\u5b9a\u4e49\u5730\u56fe CARLA \u4e2d\u81ea\u5b9a\u4e49\u5730\u56fe\u7684\u6982\u8ff0 \u2014 \u6dfb\u52a0\u81ea\u5b9a\u4e49\u6807\u51c6\u5c3a\u5bf8\u5730\u56fe\u6240\u6d89\u53ca\u7684\u8fc7\u7a0b\u548c\u9009\u9879\u7684\u6982\u8ff0 \u5728 RoadRunner \u4e2d\u521b\u5efa\u5730\u56fe \u2014 \u5982\u4f55\u5728 RoadRunner \u4e2d\u751f\u6210\u6d77\u5173\u3001\u6807\u51c6\u5c3a\u5bf8\u7684\u5730\u56fe \u5728CARLA\u5305\u5bfc\u5165\u5730\u56fe \u5982\u4f55\u5728CARLA\u5305\u4e2d\u5bfc\u5165\u5730\u56fe \u5728 CARLA \u6e90\u6784\u5efa\u4e2d\u5bfc\u5165\u5730\u56fe \u2014 \u5982\u4f55\u5728 CARLA \u4e2d\u5bfc\u5165\u4ece\u6e90\u6784\u5efa\u7684\u5730\u56fe \u5bfc\u5165\u5730\u56fe\u7684\u66ff\u4ee3\u65b9\u6cd5 \u2014 \u5bfc\u5165\u5730\u56fe\u7684\u66ff\u4ee3\u65b9\u6cd5 \u624b\u52a8\u51c6\u5907\u5730\u56fe\u5305 \u2014 \u5982\u4f55\u51c6\u5907\u5730\u56fe\u4ee5\u4f9b\u624b\u52a8\u5bfc\u5165 \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u5206\u5c42\u5730\u56fe \u2014 \u5982\u4f55\u5728\u81ea\u5b9a\u4e49\u5730\u56fe\u4e2d\u521b\u5efa\u5b50\u56fe\u5c42 \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u7ea2\u7eff\u706f\u548c\u6807\u5fd7 \u2014 \u5982\u4f55\u5c06\u7ea2\u7eff\u706f\u548c\u6807\u5fd7\u6dfb\u52a0\u5230\u60a8\u7684\u81ea\u5b9a\u4e49\u5730\u56fe \u81ea\u5b9a\u4e49\u5730\u56fe\uff1aRoad painter \u2014 \u5982\u4f55\u4f7f\u7528road painter\u5de5\u5177\u6539\u53d8\u9053\u8def\u7684\u5916\u89c2 \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u7a0b\u5e8f\u5efa\u7b51 \u2014 \u7528\u5efa\u7b51\u7269\u586b\u5145\u60a8\u7684\u81ea\u5b9a\u4e49\u5730\u56fe \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u5929\u6c14\u548c\u666f\u89c2 \u2014 \u4e3a\u60a8\u7684\u81ea\u5b9a\u4e49\u5730\u56fe\u521b\u5efa\u5929\u6c14\u914d\u7f6e\u6587\u4ef6\u5e76\u586b\u5145\u666f\u89c2 \u751f\u6210\u884c\u4eba\u5bfc\u822a \u2014 \u83b7\u53d6\u884c\u4eba\u56db\u5904\u8d70\u52a8\u6240\u9700\u7684\u4fe1\u606f\u3002 \u5927\u578b\u5730\u56fe \u5927\u578b\u5730\u56fe\u6982\u8ff0 \u2014 CARLA \u4e2d\u5927\u578b\u5730\u56fe\u5de5\u4f5c\u539f\u7406\u7684\u8bf4\u660e \u5728 RoadRunner \u4e2d\u521b\u5efa\u5927\u5730\u56fe \u2014 \u5982\u4f55\u5728 RoadRunner \u4e2d\u521b\u5efa\u5927\u5730\u56fe \u5bfc\u5165/\u6253\u5305\u5927\u5730\u56fe \u2014 \u5982\u4f55\u5bfc\u5165\u5927\u5730\u56fe \u6559\u7a0b \u2014 \u901a\u7528 \u6dfb\u52a0\u6469\u64e6\u89e6\u53d1\u5668 - \u5b9a\u4e49\u8f66\u8f6e\u7684\u52a8\u6001\u6846\u89e6\u53d1\u5668 \u63a7\u5236\u8f66\u8f86\u7269\u7406\u6a21\u578b - \u8bbe\u7f6e\u8f66\u8f86\u7269\u7406\u7684\u8fd0\u884c\u65f6\u7684\u53d8\u5316 \u63a7\u5236\u884c\u4eba\u9aa8\u9abc \u2014 \u4f7f\u7528\u9aa8\u9abc\u4e3a\u6b65\u884c\u8005\u8bbe\u7f6e\u52a8\u753b \u4f7f\u7528 OpenStreetMap \u751f\u6210\u5730\u56fe \u2014 \u4f7f\u7528 OpenStreetMap \u751f\u6210\u7528\u4e8e\u6a21\u62df\u7684\u5730\u56fe\u3002 \u68c0\u7d22\u6a21\u62df\u6570\u636e \u2014 \u4f7f\u7528\u8bb0\u5f55\u5668\u6b63\u786e\u6536\u96c6\u6570\u636e\u7684\u5206\u6b65\u6307\u5357 CarSim \u96c6\u6210 - \u5173\u4e8e\u5982\u4f55\u4f7f\u7528 CarSim \u8f66\u8f86\u52a8\u529b\u5b66\u5f15\u64ce\u8fd0\u884c\u6a21\u62df\u7684\u6559\u7a0b RLlib \u96c6\u6210 \u2014 \u4e86\u89e3\u5982\u4f55\u4f7f\u7528 RLlib \u5e93\u8fd0\u884c\u60a8\u81ea\u5df1\u7684\u5b9e\u9a8c Chrono \u96c6\u6210 \u2014 \u4f7f\u7528 Chrono \u79ef\u5206\u6765\u6a21\u62df\u7269\u7406 \u5728 Docker \u4e2d\u6784\u5efa\u865a\u5e7b\u5f15\u64ceUE\u548c CARLA \u2014 \u5728 Docker \u4e2d\u6784\u5efa\u865a\u5e7b\u5f15\u64ceUE\u548c CARLA \u6559\u7a0b \u2014 \u8d44\u4ea7 \u6dfb\u52a0\u65b0\u8f66\u8f86 \u2014 \u51c6\u5907\u8981\u5728 CARLA \u4e2d\u4f7f\u7528\u7684\u8f66\u8f86 \u6dfb\u52a0\u65b0\u9053\u5177 \u2014 \u5c06\u5176\u4ed6\u9053\u5177\u5bfc\u5165 CARLA \u521b\u5efa\u72ec\u7acb\u5305 \u2014 \u4e3a\u8d44\u4ea7\u751f\u6210\u548c\u5904\u7406\u72ec\u7acb\u5305 \u6750\u6599\u5b9a\u5236 - \u7f16\u8f91\u8f66\u8f86\u548c\u5efa\u7b51\u6750\u6599 \u6559\u7a0b \u2014 \u5f00\u53d1\u4eba\u5458 \u5982\u4f55\u5347\u7ea7\u5185\u5bb9 \u2014 \u5411 CARLA \u6dfb\u52a0\u65b0\u5185\u5bb9 \u521b\u5efa\u4e00\u4e2a\u4f20\u611f\u5668 \u2014 \u5f00\u53d1\u4e00\u4e2a\u7528\u4e8e CARLA \u7684\u65b0\u4f20\u611f\u5668 \u521b\u5efa\u8bed\u4e49\u6807\u7b7e \u2014 \u4e3a\u8bed\u4e49\u5206\u5272\u5b9a\u4e49\u81ea\u5b9a\u4e49\u6807\u7b7e \u81ea\u5b9a\u4e49\u8f66\u8f86\u60ac\u67b6 \u2014 \u4fee\u6539\u8f66\u8f86\u7684\u60ac\u67b6\u7cfb\u7edf \u751f\u6210\u8be6\u7ec6\u78b0\u649e \u2014 \u4e3a\u8f66\u8f86\u521b\u5efa\u8be6\u7ec6\u7684\u5bf9\u649e \u53d1\u5e03\u7248\u672c \u2014 \u5982\u4f55\u53d1\u5e03 CARLA CARLA \u751f\u6001\u7cfb\u7edf Ansys \u5b9e\u65f6\u96f7\u8fbe\u6a21\u578b \u2014 \u6709\u5173 Ansys RTR \u7f51\u7edc\u7814\u8ba8\u4f1a\u7684\u8be6\u7ec6\u4fe1\u606f \u8d21\u732e \u8d21\u732e\u6307\u5357 \u2014 \u4e3a CARLA \u505a\u51fa\u8d21\u732e\u7684\u4e0d\u540c\u65b9\u5f0f\u3002 \u884c\u4e3a\u51c6\u5219 \u2014 \u8d21\u732e\u8005\u7684\u6807\u51c6\u6743\u5229\u548c\u4e49\u52a1\u3002 \u7f16\u7801\u6807\u51c6 \u2014 \u7f16\u5199\u6b63\u786e\u4ee3\u7801\u7684\u6307\u5357\u3002 \u6587\u6863\u6807\u51c6 \u2014 \u7f16\u5199\u9002\u5f53\u6587\u6863\u7684\u6307\u5357\u3002","title":"\u4e3b\u9875"},{"location":"#carla","text":"\u6b22\u8fce\u4f7f\u7528 CARLA \u6587\u6863\u3002 \u6b64\u4e3b\u9875\u5305\u542b\u4e00\u4e2a\u7d22\u5f15\uff0c\u5176\u4e2d\u7b80\u8981\u8bf4\u660e\u4e86\u6587\u6863\u4e2d\u7684\u4e0d\u540c\u90e8\u5206\u3002\u968f\u610f\u6309\u559c\u6b22\u7684\u987a\u5e8f\u9605\u8bfb\u3002\u65e0\u8bba\u5982\u4f55\uff0c\u8fd9\u91cc\u6709\u4e00\u4e9b\u7ed9\u65b0\u624b\u7684\u5efa\u8bae\u3002 \u5b89\u88c5 CARLA. \u8981\u4e48\u6309\u7167 \u5feb\u901f\u5f00\u59cb\u5b89\u88c5 \u83b7\u5f97CARLA \u7248\u672c\uff0c\u8981\u4e48\u6309\u7167\u6240\u9700\u5e73\u53f0 \u8fdb\u884c\u6784\u5efa \u3002 \u5f00\u59cb\u4f7f\u7528 CARLA. \u6807\u9898\u4e3a \u7b2c\u4e00\u6b65 \u7684\u90e8\u5206\u4ecb\u7ecd\u4e86\u6700\u91cd\u8981\u7684\u6982\u5ff5\u3002 \u68c0\u67e5 API. \u6709\u4e00\u4e2a\u65b9\u4fbf\u7684 Python API \u53c2\u8003 \u6765\u67e5\u627e\u53ef\u7528\u7684\u7c7b\u548c\u65b9\u6cd5\u3002 CARLA \u8bba\u575b\u53ef\u4ee5\u53d1\u5e03\u5728\u9605\u8bfb\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u4efb\u4f55\u7591\u95ee\u6216\u5efa\u8bae\u3002 CARLA\u8bba\u575b \uff01\uff01\uff01\u8b66\u544a \u66f4\u6539\u6587\u6863\u7248\u672c\u4ee5\u9002\u5408\u60a8\u4f7f\u7528\u7684 CARLA \u7248\u672c \u3002\u4f7f\u7528\u6b64\u7a97\u53e3\u53f3\u4e0b\u89d2\u7684\u9762\u677f\u66f4\u6539\u4e3a\u4ee5\u524d\u7684\u7248\u672c\u3002 \u6700\u65b0\u7248\u672c\u6307\u5411 dev \u5206\u652f \u4e2d\u7684\u6587\u6863\uff0c\u8fd9\u53ef\u80fd\u662f\u6307\u5f53\u524d\u6b63\u5728\u5f00\u53d1\u7684\u529f\u80fd\uff0c\u5e76\u4e14\u5728\u4efb\u4f55\u6253\u5305\u7248\u672c\u7684 CARLA \u4e2d__\u4e0d\u53ef\u7528__\uff0c\u4ee5\u53ca\u4e00\u822c\u6587\u6863\u6539\u8fdb\u3002","title":"CARLA \u6587\u6863"},{"location":"#_1","text":"\u4ecb\u7ecd \u2014 \u5bf9 CARLA \u7684\u671f\u671b\u3002 \u5feb\u901f\u542f\u52a8\u5305\u5b89\u88c5 \u2014 \u83b7\u53d6 CARLA \u7248\u672c\u3002","title":"\u5165\u95e8"},{"location":"#carla_1","text":"Linux build \u2014 \u5728 Linux \u4e0a\u8fdb\u884c\u6784\u5efa\u3002 Windows build \u2014 \u5728 Windows \u4e0a\u8fdb\u884c\u6784\u5efa\u3002 Update CARLA \u2014 \u4e86\u89e3\u6700\u65b0\u5185\u5bb9\u3002 Build system \u2014 \u4e86\u89e3\u6784\u5efa\u53ca\u5176\u5236\u4f5c\u65b9\u5f0f\u3002 CARLA in Docker \u2014 \u4f7f\u7528\u5bb9\u5668\u89e3\u51b3\u65b9\u6848\u8fd0\u884c CARLA\u3002 F.A.Q. \u2014 \u4e00\u4e9b\u6700\u5e38\u89c1\u7684\u5b89\u88c5\u95ee\u9898\u3002","title":"\u6784\u5efaCARLA"},{"location":"#_2","text":"\u6838\u5fc3\u6982\u5ff5 \u2014 CARLA \u4e2d\u57fa\u672c\u6982\u5ff5\u7684\u6982\u8ff0\u3002 \u7b2c\u4e00\u3001 \u4e16\u754c\u548c\u5ba2\u6237\u7aef \u2014 \u7ba1\u7406\u548c\u8bbf\u95ee\u6a21\u62df\u3002 \u7b2c\u4e8c\u3001 \u89d2\u8272\u548c\u84dd\u56fe \u2014 \u4e86\u89e3\u89d2\u8272\u4ee5\u53ca\u5982\u4f55\u5904\u7406\u5b83\u4eec\u3002 \u7b2c\u4e09\u3001\u5730\u56fe\u548c\u5bfc\u822a \u2014 \u53d1\u73b0\u4e0d\u540c\u7684\u5730\u56fe\u4ee5\u53ca\u8f66\u8f86\u5982\u4f55\u79fb\u52a8\u3002 \u7b2c\u56db\u3001 \u4f20\u611f\u5668\u548c\u6570\u636e \u2014 \u4f7f\u7528\u4f20\u611f\u5668\u68c0\u7d22\u6a21\u62df\u6570\u636e\u3002","title":"\u7b2c\u4e00\u6b65"},{"location":"#_3","text":"OpenDRIVE \u72ec\u7acb\u6a21\u5f0f \u2014 \u4f7f\u7528\u4efb\u4f55 OpenDRIVE \u6587\u4ef6\u4f5c\u4e3a CARLA \u5730\u56fe\u3002 PTV-Vissim \u8054\u5408\u4eff\u771f - \u5728 CARLA \u548c PTV-Vissim \u4e4b\u95f4\u8fd0\u884c\u540c\u6b65\u4eff\u771f\u3002 Recorder \u2014 \u5728\u6a21\u62df\u4e2d\u5f55\u5236\u4e8b\u4ef6\u5e76\u518d\u6b21\u64ad\u653e\u3002 \u6e32\u67d3\u9009\u9879 \u2014 \u4ece\u8d28\u91cf\u8bbe\u7f6e\u5230\u4e0d\u6e32\u67d3\u6216\u79bb\u5c4f\u6a21\u5f0f\u3002 RSS \u2014 CARLA \u5ba2\u6237\u7aef\u5e93\u4e2d\u7684 RSS \u5b9e\u73b0\u3002 \u540c\u6b65\u548c\u65f6\u95f4\u6b65\u957f \u2014 \u5ba2\u6237\u7aef-\u670d\u52a1\u5668\u901a\u4fe1\u548c\u6a21\u62df\u65f6\u95f4\u3002 \u57fa\u51c6\u6027\u80fd \u2014 \u4f7f\u7528\u6211\u4eec\u51c6\u5907\u597d\u7684\u811a\u672c\u6267\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002 CARLA \u4ee3\u7406 \u2014 \u4ee3\u7406\u811a\u672c\u5141\u8bb8\u5355\u4e2a\u8f66\u8f86\u5728\u5730\u56fe\u4e0a\u6f2b\u6e38\u6216\u5f00\u8f66\u5230\u8bbe\u5b9a\u7684\u76ee\u7684\u5730\u3002","title":"\u9ad8\u7ea7\u6982\u5ff5"},{"location":"#_4","text":"\u4ea4\u901a\u6a21\u62df\u6982\u8ff0 \u2014 \u53ef\u7528\u4e8e\u4f7f\u7528\u4ea4\u901a\u586b\u5145\u573a\u666f\u7684\u4e0d\u540c\u9009\u9879\u7684\u6982\u8ff0 Traffic Manager \u2014 \u901a\u8fc7\u5c06\u8f66\u8f86\u8bbe\u7f6e\u4e3a\u81ea\u52a8\u9a7e\u9a76\u6a21\u5f0f\u6765\u6a21\u62df\u57ce\u5e02\u4ea4\u901a\u3002 SUMO \u8054\u5408\u4eff\u771f \u2014 \u5728 CARLA \u548c SUMO \u4e4b\u95f4\u8fd0\u884c\u540c\u6b65\u4eff\u771f\u3002 Scenic \u2014 \u9075\u5faa\u4f7f\u7528 Scenic \u5e93\u5b9a\u4e49\u4e0d\u540c\u573a\u666f\u7684\u793a\u4f8b\u3002","title":"\u4ea4\u901a\u6a21\u62df"},{"location":"#_5","text":"Python API \u53c2\u8003 \u2014 Python API \u4e2d\u7684\u7c7b\u548c\u65b9\u6cd5\u3002 Blueprint library \u2014 \u63d0\u4f9b\u7528\u4e8e\u751f\u6210 actor \u7684\u84dd\u56fe\u3002 C++ \u53c2\u8003 \u2014 CARLA C++ \u4e2d\u7684\u7c7b\u548c\u65b9\u6cd5\u3002 Recorder \u4e8c\u8fdb\u5236\u6587\u4ef6\u683c\u5f0f \u2014 \u8bb0\u5f55\u5668\u6587\u4ef6\u683c\u5f0f\u7684\u8be6\u7ec6\u8bf4\u660e\u3002 Sensors reference \u2014 \u5173\u4e8e\u4f20\u611f\u5668\u53ca\u5176\u68c0\u7d22\u6570\u636e\u7684\u4e00\u5207\u3002","title":"\u53c2\u8003"},{"location":"#_6","text":"carlaviz \u2014 web \u53ef\u89c6\u5316\u5668 \u2014 \u4fa6\u542c\u6a21\u62df\u5e76\u5728\u7f51\u7edc\u6d4f\u89c8\u5668\u4e2d\u663e\u793a\u573a\u666f\u548c\u4e00\u4e9b\u6a21\u62df\u6570\u636e\u7684\u63d2\u4ef6\u3002","title":"\u63d2\u4ef6"},{"location":"#ros","text":"ROS \u6865\u6587\u6863 \u2014 ROS \u6865\u7684\u7b80\u8981\u6982\u8ff0\u548c\u5b8c\u6574\u6587\u6863\u7684\u94fe\u63a5","title":"ROS \u6865\u63a5\u5668"},{"location":"#_7","text":"CARLA \u4e2d\u81ea\u5b9a\u4e49\u5730\u56fe\u7684\u6982\u8ff0 \u2014 \u6dfb\u52a0\u81ea\u5b9a\u4e49\u6807\u51c6\u5c3a\u5bf8\u5730\u56fe\u6240\u6d89\u53ca\u7684\u8fc7\u7a0b\u548c\u9009\u9879\u7684\u6982\u8ff0 \u5728 RoadRunner \u4e2d\u521b\u5efa\u5730\u56fe \u2014 \u5982\u4f55\u5728 RoadRunner \u4e2d\u751f\u6210\u6d77\u5173\u3001\u6807\u51c6\u5c3a\u5bf8\u7684\u5730\u56fe \u5728CARLA\u5305\u5bfc\u5165\u5730\u56fe \u5982\u4f55\u5728CARLA\u5305\u4e2d\u5bfc\u5165\u5730\u56fe \u5728 CARLA \u6e90\u6784\u5efa\u4e2d\u5bfc\u5165\u5730\u56fe \u2014 \u5982\u4f55\u5728 CARLA \u4e2d\u5bfc\u5165\u4ece\u6e90\u6784\u5efa\u7684\u5730\u56fe \u5bfc\u5165\u5730\u56fe\u7684\u66ff\u4ee3\u65b9\u6cd5 \u2014 \u5bfc\u5165\u5730\u56fe\u7684\u66ff\u4ee3\u65b9\u6cd5 \u624b\u52a8\u51c6\u5907\u5730\u56fe\u5305 \u2014 \u5982\u4f55\u51c6\u5907\u5730\u56fe\u4ee5\u4f9b\u624b\u52a8\u5bfc\u5165 \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u5206\u5c42\u5730\u56fe \u2014 \u5982\u4f55\u5728\u81ea\u5b9a\u4e49\u5730\u56fe\u4e2d\u521b\u5efa\u5b50\u56fe\u5c42 \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u7ea2\u7eff\u706f\u548c\u6807\u5fd7 \u2014 \u5982\u4f55\u5c06\u7ea2\u7eff\u706f\u548c\u6807\u5fd7\u6dfb\u52a0\u5230\u60a8\u7684\u81ea\u5b9a\u4e49\u5730\u56fe \u81ea\u5b9a\u4e49\u5730\u56fe\uff1aRoad painter \u2014 \u5982\u4f55\u4f7f\u7528road painter\u5de5\u5177\u6539\u53d8\u9053\u8def\u7684\u5916\u89c2 \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u7a0b\u5e8f\u5efa\u7b51 \u2014 \u7528\u5efa\u7b51\u7269\u586b\u5145\u60a8\u7684\u81ea\u5b9a\u4e49\u5730\u56fe \u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u5929\u6c14\u548c\u666f\u89c2 \u2014 \u4e3a\u60a8\u7684\u81ea\u5b9a\u4e49\u5730\u56fe\u521b\u5efa\u5929\u6c14\u914d\u7f6e\u6587\u4ef6\u5e76\u586b\u5145\u666f\u89c2 \u751f\u6210\u884c\u4eba\u5bfc\u822a \u2014 \u83b7\u53d6\u884c\u4eba\u56db\u5904\u8d70\u52a8\u6240\u9700\u7684\u4fe1\u606f\u3002","title":"\u81ea\u5b9a\u4e49\u5730\u56fe"},{"location":"#_8","text":"\u5927\u578b\u5730\u56fe\u6982\u8ff0 \u2014 CARLA \u4e2d\u5927\u578b\u5730\u56fe\u5de5\u4f5c\u539f\u7406\u7684\u8bf4\u660e \u5728 RoadRunner \u4e2d\u521b\u5efa\u5927\u5730\u56fe \u2014 \u5982\u4f55\u5728 RoadRunner \u4e2d\u521b\u5efa\u5927\u5730\u56fe \u5bfc\u5165/\u6253\u5305\u5927\u5730\u56fe \u2014 \u5982\u4f55\u5bfc\u5165\u5927\u5730\u56fe","title":"\u5927\u578b\u5730\u56fe"},{"location":"#_9","text":"\u6dfb\u52a0\u6469\u64e6\u89e6\u53d1\u5668 - \u5b9a\u4e49\u8f66\u8f6e\u7684\u52a8\u6001\u6846\u89e6\u53d1\u5668 \u63a7\u5236\u8f66\u8f86\u7269\u7406\u6a21\u578b - \u8bbe\u7f6e\u8f66\u8f86\u7269\u7406\u7684\u8fd0\u884c\u65f6\u7684\u53d8\u5316 \u63a7\u5236\u884c\u4eba\u9aa8\u9abc \u2014 \u4f7f\u7528\u9aa8\u9abc\u4e3a\u6b65\u884c\u8005\u8bbe\u7f6e\u52a8\u753b \u4f7f\u7528 OpenStreetMap \u751f\u6210\u5730\u56fe \u2014 \u4f7f\u7528 OpenStreetMap \u751f\u6210\u7528\u4e8e\u6a21\u62df\u7684\u5730\u56fe\u3002 \u68c0\u7d22\u6a21\u62df\u6570\u636e \u2014 \u4f7f\u7528\u8bb0\u5f55\u5668\u6b63\u786e\u6536\u96c6\u6570\u636e\u7684\u5206\u6b65\u6307\u5357 CarSim \u96c6\u6210 - \u5173\u4e8e\u5982\u4f55\u4f7f\u7528 CarSim \u8f66\u8f86\u52a8\u529b\u5b66\u5f15\u64ce\u8fd0\u884c\u6a21\u62df\u7684\u6559\u7a0b RLlib \u96c6\u6210 \u2014 \u4e86\u89e3\u5982\u4f55\u4f7f\u7528 RLlib \u5e93\u8fd0\u884c\u60a8\u81ea\u5df1\u7684\u5b9e\u9a8c Chrono \u96c6\u6210 \u2014 \u4f7f\u7528 Chrono \u79ef\u5206\u6765\u6a21\u62df\u7269\u7406 \u5728 Docker \u4e2d\u6784\u5efa\u865a\u5e7b\u5f15\u64ceUE\u548c CARLA \u2014 \u5728 Docker \u4e2d\u6784\u5efa\u865a\u5e7b\u5f15\u64ceUE\u548c CARLA","title":"\u6559\u7a0b \u2014 \u901a\u7528"},{"location":"#_10","text":"\u6dfb\u52a0\u65b0\u8f66\u8f86 \u2014 \u51c6\u5907\u8981\u5728 CARLA \u4e2d\u4f7f\u7528\u7684\u8f66\u8f86 \u6dfb\u52a0\u65b0\u9053\u5177 \u2014 \u5c06\u5176\u4ed6\u9053\u5177\u5bfc\u5165 CARLA \u521b\u5efa\u72ec\u7acb\u5305 \u2014 \u4e3a\u8d44\u4ea7\u751f\u6210\u548c\u5904\u7406\u72ec\u7acb\u5305 \u6750\u6599\u5b9a\u5236 - \u7f16\u8f91\u8f66\u8f86\u548c\u5efa\u7b51\u6750\u6599","title":"\u6559\u7a0b \u2014 \u8d44\u4ea7"},{"location":"#_11","text":"\u5982\u4f55\u5347\u7ea7\u5185\u5bb9 \u2014 \u5411 CARLA \u6dfb\u52a0\u65b0\u5185\u5bb9 \u521b\u5efa\u4e00\u4e2a\u4f20\u611f\u5668 \u2014 \u5f00\u53d1\u4e00\u4e2a\u7528\u4e8e CARLA \u7684\u65b0\u4f20\u611f\u5668 \u521b\u5efa\u8bed\u4e49\u6807\u7b7e \u2014 \u4e3a\u8bed\u4e49\u5206\u5272\u5b9a\u4e49\u81ea\u5b9a\u4e49\u6807\u7b7e \u81ea\u5b9a\u4e49\u8f66\u8f86\u60ac\u67b6 \u2014 \u4fee\u6539\u8f66\u8f86\u7684\u60ac\u67b6\u7cfb\u7edf \u751f\u6210\u8be6\u7ec6\u78b0\u649e \u2014 \u4e3a\u8f66\u8f86\u521b\u5efa\u8be6\u7ec6\u7684\u5bf9\u649e \u53d1\u5e03\u7248\u672c \u2014 \u5982\u4f55\u53d1\u5e03 CARLA","title":"\u6559\u7a0b \u2014 \u5f00\u53d1\u4eba\u5458"},{"location":"#carla_2","text":"Ansys \u5b9e\u65f6\u96f7\u8fbe\u6a21\u578b \u2014 \u6709\u5173 Ansys RTR \u7f51\u7edc\u7814\u8ba8\u4f1a\u7684\u8be6\u7ec6\u4fe1\u606f","title":"CARLA \u751f\u6001\u7cfb\u7edf"},{"location":"#_12","text":"\u8d21\u732e\u6307\u5357 \u2014 \u4e3a CARLA \u505a\u51fa\u8d21\u732e\u7684\u4e0d\u540c\u65b9\u5f0f\u3002 \u884c\u4e3a\u51c6\u5219 \u2014 \u8d21\u732e\u8005\u7684\u6807\u51c6\u6743\u5229\u548c\u4e49\u52a1\u3002 \u7f16\u7801\u6807\u51c6 \u2014 \u7f16\u5199\u6b63\u786e\u4ee3\u7801\u7684\u6307\u5357\u3002 \u6587\u6863\u6807\u51c6 \u2014 \u7f16\u5199\u9002\u5f53\u6587\u6863\u7684\u6307\u5357\u3002","title":"\u8d21\u732e"},{"location":"adv_agents/","text":"CARLA \u4ee3\u7406 CARLA \u4ee3\u7406\u811a\u672c\u5141\u8bb8\u8f66\u8f86\u6cbf\u7740\u968f\u673a\u7684\u3001\u65e0\u9650\u7684\u8def\u7ebf\u884c\u9a76\uff0c\u6216\u8005\u91c7\u7528\u6700\u77ed\u7684\u8def\u7ebf\u5230\u8fbe\u7ed9\u5b9a\u7684\u76ee\u7684\u5730\u3002\u4ee3\u7406\u9075\u5b88\u4ea4\u901a\u4fe1\u53f7\u706f\u5e76\u5bf9\u9053\u8def\u4e0a\u7684\u5176\u4ed6\u969c\u788d\u7269\u505a\u51fa\u53cd\u5e94\u3002\u63d0\u4f9b\u4e09\u79cd\u4ee3\u7406\u7c7b\u578b\u3002\u53ef\u4ee5\u4fee\u6539\u76ee\u6807\u901f\u5ea6\u3001\u5236\u52a8\u8ddd\u79bb\u3001\u5c3e\u968f\u884c\u4e3a\u7b49\u53c2\u6570\u3002\u53ef\u4ee5\u6839\u636e\u7528\u6237\u7684\u9700\u8981\u4fee\u6539 Actor \u7c7b\u6216\u5c06\u5176\u7528\u4f5c\u57fa\u7c7b\u6765\u521b\u5efa\u81ea\u5b9a\u4e49\u4ee3\u7406\u3002 \u4ee3\u7406\u811a\u672c\u6982\u8ff0 \u8ba1\u5212\u4e0e\u63a7\u5236 \u4ee3\u7406\u884c\u4e3a \u5b9e\u73b0\u4e00\u4e2a\u4ee3\u7406 \u884c\u4e3a\u7c7b\u578b \u521b\u5efa\u81ea\u5df1\u7684\u884c\u4e3a\u7c7b\u578b \u521b\u5efa\u4ee3\u7406 \u4ee3\u7406\u811a\u672c\u6982\u8ff0 CARLA \u4ee3\u7406\u4e2d\u6d89\u53ca\u7684\u4e3b\u8981\u811a\u672c\u4f4d\u4e8e PythonAPI/carla/agents/navigation \u4e2d\u3002\u5b83\u4eec\u5206\u4e3a\u4e24\u7c7b\uff1b \u8ba1\u5212\u548c\u63a7\u5236 \u548c \u4ee3\u7406\u884c\u4e3a \u3002 \u8ba1\u5212\u4e0e\u63a7\u5236 controller.py : \u5c06\u7eb5\u5411\u548c\u6a2a\u5411 PID \u63a7\u5236\u5668\u7ec4\u5408\u6210\u4e00\u4e2a\u7c7b\uff0c VehiclePIDController \uff0c\u7528\u4e8e\u4ece CARLA \u5ba2\u6237\u7aef\u5bf9\u8f66\u8f86\u8fdb\u884c\u4f4e\u7ea7\u63a7\u5236\u3002 global_route_planner.py : \u4ece CARLA \u670d\u52a1\u5668\u83b7\u53d6\u8be6\u7ec6\u7684\u62d3\u6251\u7ed3\u6784\u4ee5\u6784\u5efa\u4e16\u754c\u5730\u56fe\u7684\u56fe\u5f62\u8868\u793a\uff0c\u4e3a Local Planner \u63d0\u4f9b\u822a\u70b9\u548c\u9053\u8def\u9009\u9879\u4fe1\u606f\u3002 local_planner.py : \u6839\u636e\u6765\u81ea VehiclePIDController \u7684\u63a7\u5236\u8f93\u5165\u8ddf\u8e2a\u822a\u8def\u70b9\u3002\u822a\u70b9\u53ef\u4ee5\u7531 Global Route Planner \u63d0\u4f9b\uff0c\u4e5f\u53ef\u4ee5\u52a8\u6001\u8ba1\u7b97\uff0c\u5728\u8def\u53e3\u9009\u62e9\u968f\u673a\u8def\u5f84\uff0c\u7c7b\u4f3c\u4e8e Traffic Manager \u3002 \u4ee3\u7406\u884c\u4e3a basic_agent.py : \u5305\u542b\u4e00\u4e2a\u4ee3\u7406\u57fa\u7c7b\uff0c\u5b83\u5b9e\u73b0\u4e86\u4e00\u4e2a Basic Agent \uff0c\u5b83\u5728\u5730\u56fe\u4e0a\u6f2b\u6e38\u6216\u4ee5\u5c3d\u53ef\u80fd\u77ed\u7684\u8ddd\u79bb\u5230\u8fbe\u76ee\u6807\u76ee\u7684\u5730\uff0c\u907f\u5f00\u5176\u4ed6\u8f66\u8f86\uff0c\u54cd\u5e94\u4ea4\u901a\u4fe1\u53f7\u706f\u4f46\u5ffd\u7565\u505c\u8f66\u6807\u5fd7\u3002 behavior_agent.py : \u5305\u542b\u4e00\u4e2a\u5b9e\u73b0\u66f4\u590d\u6742\u7684 Behavior Agent \u7684\u7c7b\uff0c\u5b83\u53ef\u4ee5\u5728\u5c3d\u53ef\u80fd\u77ed\u7684\u8ddd\u79bb\u5185\u5230\u8fbe\u76ee\u6807\u76ee\u7684\u5730\uff0c\u8ddf\u968f\u4ea4\u901a\u4fe1\u53f7\u706f\u3001\u6807\u5fd7\u548c\u901f\u5ea6\u9650\u5236\uff0c\u540c\u65f6\u5c3e\u968f\u5176\u4ed6\u8f66\u8f86\u3002\u6709\u4e09\u79cd\u9884\u5b9a\u4e49\u7684\u7c7b\u578b\u51b3\u5b9a\u4e86\u4ee3\u7406\u7684\u884c\u4e3a\u65b9\u5f0f\u3002 behavior_types.py : \u5305\u542b\u5f71\u54cd Behavior Agent \u7684\u884c\u4e3a\u7c7b\u578b\u7684\u53c2\u6570\uff1b\u8c28\u614e\u3001\u6b63\u5e38\u548c\u8fdb\u53d6\u3002 \u5b9e\u73b0\u4e00\u4e2a\u4ee3\u7406 \u672c\u8282\u5c06\u89e3\u91ca\u5982\u4f55\u5728\u60a8\u81ea\u5df1\u7684\u811a\u672c\u4e2d\u4f7f\u7528\u793a\u4f8b CARLA \u4ee3\u7406\u7c7b\u3002\u5728\u672c\u8282\u7684\u6700\u540e\uff0c\u60a8\u5c06\u4e86\u89e3\u5982\u4f55\u8fd0\u884c\u4e00\u4e2a\u793a\u4f8b\u811a\u672c\u6765\u663e\u793a\u4e0d\u540c\u4ee3\u7406\u7684\u8fd0\u884c\u60c5\u51b5\u3002 1. \u5bfc\u5165\u8981\u4f7f\u7528\u7684\u4ee3\u7406\u7c7b\uff1a # \u5bfc\u5165\u57fa\u672c\u4ee3\u7406 from agent.navigation.basic_agent import BasicAgent # \u5bfc\u5165\u884c\u4e3a\u4ee3\u7406 from agent.navigation.behavior_agent import BehaviorAgent 2 . \u4efb\u4f55\u8f66\u8f86\u90fd\u53ef\u4ee5\u53d8\u6210\u4ee3\u7406\u4eba\u3002 \u751f\u6210\u8f66\u8f86 \u5e76\u5c06\u5176\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u7ed9\u4ee3\u7406\u7c7b\u4ee5\u5b9e\u4f8b\u5316\u5b83\uff1a # \u542f\u52a8\u4e00\u4e2a\u57fa\u672c\u4ee3\u7406 agent = BasicAgent(vehicle) # \u542f\u52a8\u5177\u6709\u653b\u51fb\u6027\u914d\u7f6e\u6587\u4ef6\u7684\u884c\u4e3a\u4ee3\u7406 agent = BehaviorAgent(vehicle, behavior='aggressive') \u5728 behavior types \u90e8\u5206\u4e2d\u9605\u8bfb\u6709\u5173\u884c\u4e3a\u7c7b\u578b\u4ee5\u53ca\u5982\u4f55\u914d\u7f6e\u60a8\u81ea\u5df1\u7684\u66f4\u591a\u4fe1\u606f\u3002 3. \u60a8\u53ef\u4ee5\u8bbe\u7f6e\u4ee3\u7406\u524d\u5f80\u7684\u76ee\u7684\u5730\u3002\u5982\u679c\u60a8\u4e0d\u4e3a\u4ee3\u7406\u8bbe\u7f6e\u76ee\u7684\u5730\uff0c\u5b83\u5c06\u5728\u5730\u56fe\u4e0a\u65e0\u4f11\u6b62\u5730\u6f2b\u6e38\u3002\u8981\u8bbe\u7f6e\u76ee\u7684\u5730\uff0c\u8bf7\u4e3a\u4ee3\u7406\u63d0\u4f9b \u4f4d\u7f6e \uff1a destination = random.choice(spawn_points).location agent.set_destination(destination) 5. \u5728\u5bfc\u822a\u6b65\u9aa4\u671f\u95f4\u5e94\u7528\u8f66\u8f86\u63a7\u5236\u548c\u884c\u4e3a\u3002\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\uff0c Basic Agent \u5c06\u5e94\u7528\u8f66\u8f86\u63a7\u5236\u5e76\u901a\u8fc7\u6267\u884c\u7d27\u6025\u505c\u6b62\u6765\u5bf9\u4efb\u4f55\u8f66\u8f86\u6216\u4ea4\u901a\u4fe1\u53f7\u706f\u505a\u51fa\u53cd\u5e94\u3002 Behavior Agent \u5c06\u6839\u636e\u60a8\u5e94\u7528\u7684\u884c\u4e3a\u7c7b\u578b\u5bf9\u7ea2\u7eff\u706f\u505a\u51fa\u53cd\u5e94\u3001\u907f\u5f00\u884c\u4eba\u3001\u8ddf\u968f\u6c7d\u8f66\u5e76\u5728\u5341\u5b57\u8def\u53e3\u5bfc\u822a\uff1a while True\uff1a vehicle.apply_control(agent.run_step()) 6. \u60a8\u53ef\u4ee5\u68c0\u67e5\u4ee3\u7406\u662f\u5426\u5df2\u5b8c\u6210\u5176\u8f68\u8ff9\u5e76\u5728\u53d1\u751f\u8fd9\u79cd\u60c5\u51b5\u65f6\u6267\u884c\u64cd\u4f5c\u3002\u4e00\u65e6\u60a8\u7684\u8f66\u8f86\u5230\u8fbe\u76ee\u7684\u5730\uff0c\u4ee5\u4e0b\u4ee3\u7801\u6bb5\u5c06\u7ed3\u675f\u6a21\u62df\uff1a while True\uff1a if agent.done\uff08\uff09\uff1a print(\"The taerget has been reached, stopping the simulation\") break vehicle.apply_control(agent.run_step()) 7. \u4e0d\u662f\u5728\u4ee3\u7406\u5230\u8fbe\u5176\u76ee\u6807\u76ee\u7684\u5730\u65f6\u5b8c\u6210\u6a21\u62df\uff0c\u800c\u662f\u53ef\u4ee5\u751f\u6210\u4e00\u6761\u65b0\u7684\u968f\u673a\u8def\u7ebf\u4f9b\u4ee3\u7406\u9075\u5faa\uff1a while True\uff1a if agent.done(): agent.set_destination(random.choice(spawn_points).location) print(\"The target has been reached, searching for another target\") vehicle.apply_control(agent.run_step()) Basic Agent \u63d0\u4f9b\u4e86\u4e00\u4e9b\u65b9\u6cd5\u6765\u64cd\u7eb5\u4ee3\u7406\u884c\u4e3a\u6216\u9075\u5faa\u7684\u7a0b\u5e8f\u8def\u7ebf\uff1a set_target_speed(speed) : \u4ee5\u516c\u91cc/\u5c0f\u65f6\u4e3a\u5355\u4f4d\u8bbe\u7f6e\u76ee\u6807\u901f\u5ea6 follow_speed_limits(value=True) : \u8bbe\u7f6e\u4ee3\u7406\u9075\u5faa\u901f\u5ea6\u9650\u5236\u3002 set_destination(end_location, start_location=None) : \u4ee3\u7406\u5c06\u901a\u8fc7\u53ef\u80fd\u7684\u6700\u77ed\u8def\u7ebf\u4ece\u7279\u5b9a\u7684\u8d77\u59cb\u4f4d\u7f6e\u5230\u7ed3\u675f\u4f4d\u7f6e\u3002\u5982\u679c\u6ca1\u6709\u63d0\u4f9b\u8d77\u59cb\u4f4d\u7f6e\uff0c\u5b83\u5c06\u4f7f\u7528\u5f53\u524d\u4ee3\u7406\u4f4d\u7f6e\u3002 set_global_plan(plan, stop_waypoint_creation=True, clean_queue=True) : \u4e3a\u4ee3\u7406\u6dfb\u52a0\u4e00\u4e2a\u5177\u4f53\u7684\u8ba1\u5212\u3002\u8ba1\u5212\u53c2\u6570\u5e94\u5305\u542b\u4e00\u4e2a [carla.Waypoint, RoadOption] \u5217\u8868\uff0c\u8fd9\u5c06\u662f\u4ee3\u7406\u9700\u8981\u91c7\u53d6\u7684\u8def\u5f84\u3002 stop_waypoint_creation \u5c06\u9632\u6b62\u5728\u8def\u5f84\u8fd0\u884c\u540e\u81ea\u52a8\u521b\u5efa\u822a\u70b9\u3002 clean_queue \u5c06\u91cd\u7f6e\u4ee3\u7406\u7684\u5f53\u524d\u8ba1\u5212\u3002 trace_route(start_waypoint, end_waypoint) : \u4ece Global Route Planner \u83b7\u53d6\u4e24\u4e2a\u822a\u70b9\u4e4b\u95f4\u7684\u6700\u77ed\u8ddd\u79bb\uff0c\u5e76\u5c06\u8def\u5f84\u4f5c\u4e3a [carla.Waypoint, RoadOption] \u5217\u8868\u8fd4\u56de\uff0c\u4f9b\u4ee3\u7406\u9075\u5faa\u3002 ignore_traffic_lights(active=True) : \u8bbe\u7f6e\u4ee3\u7406\u5ffd\u7565\u6216\u670d\u4ece\u4ea4\u901a\u4fe1\u53f7\u706f\u3002 ignore_stop_signs(active=True) : \u8bbe\u7f6e\u4ee3\u7406\u5ffd\u7565\u6216\u670d\u4ece\u505c\u8f66\u6807\u5fd7\u3002 ignore_vehicles(active=True) : \u8bbe\u7f6e\u4ee3\u7406\u5ffd\u7565\u6216\u5bf9\u5176\u4ed6\u8f66\u8f86\u4f5c\u51fa\u53cd\u5e94\u3002 \u5728 PythonAPI/examples \u4e2d\u627e\u5230\u7684 automatic_control.py \u811a\u672c\u662f\u57fa\u672c\u548c\u884c\u4e3a\u4ee3\u7406\u7684\u4e00\u4e2a\u793a\u4f8b\u3002\u8981\u5c1d\u8bd5\u8be5\u811a\u672c\uff0c\u8bf7\u5bfc\u822a\u5230\u793a\u4f8b\u76ee\u5f55\u5e76\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a # \u4f7f\u7528\u57fa\u672c\u4ee3\u7406\u8fd0\u884c python3 automatic_control.py --agent=Basic # \u4f7f\u7528\u884c\u4e3a\u4ee3\u7406\u8fd0\u884c python3 automatic_control.py --agent=Behavior --behavior=aggressive \u884c\u4e3a\u7c7b\u578b \u884c\u4e3a\u4ee3\u7406\u7684\u884c\u4e3a\u7c7b\u578b\u5728 behavior_types.py \u4e2d\u5b9a\u4e49\u3002\u4e09\u4e2a\u9884\u914d\u7f6e\u7684\u914d\u7f6e\u6587\u4ef6\u662f 'cautious' \u3001 'normal' \u548c 'aggressive' \u3002\u60a8\u53ef\u4ee5\u4f7f\u7528\u8bbe\u7f6e\u7684\u914d\u7f6e\u6587\u4ef6\u3001\u4fee\u6539\u5b83\u4eec\u6216\u521b\u5efa\u60a8\u81ea\u5df1\u7684\u914d\u7f6e\u6587\u4ef6\u3002\u53ef\u4ee5\u8c03\u6574\u4ee5\u4e0b\u53d8\u91cf\uff1a max_speed \uff1a\u60a8\u7684\u8f66\u8f86\u80fd\u591f\u8fbe\u5230\u7684\u6700\u9ad8\u901f\u5ea6\uff08\u4ee5\u516c\u91cc/\u5c0f\u65f6\u4e3a\u5355\u4f4d\uff09\u3002 speed_lim_dist \uff1a\u4ee5 km/h \u4e3a\u5355\u4f4d\u7684\u503c\uff0c\u7528\u4e8e\u5b9a\u4e49\u8f66\u8f86\u7684\u76ee\u6807\u901f\u5ea6\u4e0e\u5f53\u524d\u9650\u901f\u7684\u8ddd\u79bb\uff08\u4f8b\u5982\uff0c\u5982\u679c\u9650\u901f\u4e3a 30km/h \u4e14 speed_lim_dist \u4e3a 10km/h\uff0c\u5219\u76ee\u6807\u901f\u5ea6\u5c06\u662f20\u516c\u91cc/\u5c0f\u65f6\uff09 speed_decrease \uff1a\u5f53\u63a5\u8fd1\u524d\u65b9\u8f83\u6162\u7684\u8f66\u8f86\u65f6\uff0c\u60a8\u7684\u8f66\u8f86\u5c06\u4ee5\u591a\u5feb\u7684\u516c\u91cc/\u5c0f\u65f6\u51cf\u901f\u3002 safety_time \uff1a\u78b0\u649e\u65f6\u95f4\uff1b\u5982\u679c\u60a8\u7684\u8f66\u8f86\u7a81\u7136\u5239\u8f66\uff0c\u5b83\u4e0e\u524d\u9762\u7684\u8f66\u8f86\u76f8\u649e\u6240\u9700\u7684\u65f6\u95f4\u7684\u8fd1\u4f3c\u503c\u3002 min_proximity_threshold \uff1a\u5728\u60a8\u7684\u8f66\u8f86\u6267\u884c\u907f\u8ba9\u6216\u5c3e\u968f\u7b49\u64cd\u4f5c\u4e4b\u524d\uff0c\u4e0e\u53e6\u4e00\u8f86\u8f66\u6216\u884c\u4eba\u7684\u6700\u5c0f\u8ddd\u79bb\uff08\u4ee5\u7c73\u4e3a\u5355\u4f4d\uff09\u3002 braking_distance \uff1a\u60a8\u7684\u8f66\u8f86\u5c06\u6267\u884c\u7d27\u6025\u505c\u8f66\u65f6\u4e0e\u884c\u4eba\u6216\u8f66\u8f86\u7684\u8ddd\u79bb\u3002 tailgate_counter \uff1a\u7528\u4e8e\u907f\u514d\u5728\u6700\u540e\u4e00\u4e2a\u540e\u6321\u677f\u540e\u8fc7\u5feb\u5c3e\u968f\u7684\u8ba1\u6570\u5668\u3002 \u521b\u5efa\u81ea\u5df1\u7684\u884c\u4e3a\u7c7b\u578b \u8981\u521b\u5efa\u81ea\u5df1\u7684\u884c\u4e3a\u7c7b\u578b\uff1a 1. \u5728 behavior_types.py \u4e2d\u4e3a\u60a8\u7684\u884c\u4e3a\u7c7b\u578b\u521b\u5efa\u7c7b\uff1a class ProfileName(object)\uff1a # \u5b8c\u6574\u7684\u503c\u5b9a\u4e49 2. \u5728 behavior_agent.py \u811a\u672c\u4e2d\u5b9a\u4e49\u548c\u5b9e\u4f8b\u5316\u4f60\u7684\u884c\u4e3a\u7c7b\u578b\uff1a # \u4ee3\u7406\u884c\u4e3a\u53c2\u6570 if behavior == 'cautious'\uff1a self._behavior = Cautious() elif behavior == 'normal'\uff1a self._behavior = Normal() elif behavior == 'aggressive'\uff1a self._behavior = Aggressive() elif behavior == '<type_name>'\uff1a self._behavior = <TypeName>() \u521b\u5efa\u4ee3\u7406 CARLA \u4ee3\u7406\u53ea\u662f\u7528\u6237\u53ef\u4ee5\u8fd0\u884c\u7684\u4ee3\u7406\u7c7b\u578b\u7684\u793a\u4f8b\u3002\u7528\u6237\u53ef\u4ee5\u5728 Basic Agent \u7684\u57fa\u7840\u4e0a\u521b\u5efa\u81ea\u5df1\u7684\u4ee3\u7406\u3002\u53ef\u80fd\u6027\u662f\u65e0\u6b62\u5883\u3002\u6bcf\u4e2a\u4ee3\u7406\u53ea\u9700\u8981\u4e24\u4e2a\u5143\u7d20\uff0c \u521d\u59cb\u5316__\u548c__\u8fd0\u884c\u6b65\u9aa4 \u3002 \u5728\u4e0b\u9762\u67e5\u627e\u81ea\u5b9a\u4e49\u4ee3\u7406\u7684\u6700\u5c0f\u5e03\u5c40\u793a\u4f8b\uff1a import carla from agents.navigation.basic_agent import BasicAgent class CustomAgent(BasicAgent): def __init__(self, vehicle, target_speed=20, debug=False): \"\"\" :param vehicle: \u5e94\u7528\u5230\u672c\u5730\u89c4\u5212\u5668\u903b\u8f91\u7684actor :param target_speed: \u8f66\u8f86\u79fb\u52a8\u7684\u901f\u5ea6\uff08Km/h\uff09 \"\"\" super().__init__(target_speed, \u8c03\u8bd5) def run_step(self, debug=False): \"\"\" \u6267\u884c\u4e00\u6b65\u5bfc\u822a :return: carla.VehicleControl \"\"\" # \u5728\u6bcf\u4e2a\u6a21\u62df\u6b65\u9aa4\u4e2d\u91c7\u53d6\u7684\u884c\u52a8 control = carla.VehicleControl() return control \u67e5\u770b basic_agent.py \u548c behavior_agent.py \u811a\u672c\u4ee5\u63a2\u7d22\u5b83\u4eec\u7684\u7ed3\u6784\u548c\u529f\u80fd\uff0c\u4ee5\u83b7\u53d6\u6709\u5173\u5982\u4f55\u521b\u5efa\u81ea\u5df1\u7684\u66f4\u591a\u60f3\u6cd5\u3002 \u60a8\u53ef\u4ee5\u63a2\u7d22\u63d0\u4f9b\u7684\u4ee3\u7406\u811a\u672c\u3001\u6269\u5c55\u5b83\u4eec\u6216\u5c06\u5b83\u4eec\u7528\u4f5c\u521b\u5efa\u81ea\u5df1\u7684\u57fa\u51c6\u3002\u5982\u679c\u60a8\u5bf9\u4ee3\u7406\u6709\u4efb\u4f55\u7591\u95ee\uff0c\u8bf7\u968f\u65f6\u5728 \u8bba\u575b \u53d1\u5e16\u3002","title":"CARLA \u4ee3\u7406"},{"location":"adv_agents/#carla","text":"CARLA \u4ee3\u7406\u811a\u672c\u5141\u8bb8\u8f66\u8f86\u6cbf\u7740\u968f\u673a\u7684\u3001\u65e0\u9650\u7684\u8def\u7ebf\u884c\u9a76\uff0c\u6216\u8005\u91c7\u7528\u6700\u77ed\u7684\u8def\u7ebf\u5230\u8fbe\u7ed9\u5b9a\u7684\u76ee\u7684\u5730\u3002\u4ee3\u7406\u9075\u5b88\u4ea4\u901a\u4fe1\u53f7\u706f\u5e76\u5bf9\u9053\u8def\u4e0a\u7684\u5176\u4ed6\u969c\u788d\u7269\u505a\u51fa\u53cd\u5e94\u3002\u63d0\u4f9b\u4e09\u79cd\u4ee3\u7406\u7c7b\u578b\u3002\u53ef\u4ee5\u4fee\u6539\u76ee\u6807\u901f\u5ea6\u3001\u5236\u52a8\u8ddd\u79bb\u3001\u5c3e\u968f\u884c\u4e3a\u7b49\u53c2\u6570\u3002\u53ef\u4ee5\u6839\u636e\u7528\u6237\u7684\u9700\u8981\u4fee\u6539 Actor \u7c7b\u6216\u5c06\u5176\u7528\u4f5c\u57fa\u7c7b\u6765\u521b\u5efa\u81ea\u5b9a\u4e49\u4ee3\u7406\u3002 \u4ee3\u7406\u811a\u672c\u6982\u8ff0 \u8ba1\u5212\u4e0e\u63a7\u5236 \u4ee3\u7406\u884c\u4e3a \u5b9e\u73b0\u4e00\u4e2a\u4ee3\u7406 \u884c\u4e3a\u7c7b\u578b \u521b\u5efa\u81ea\u5df1\u7684\u884c\u4e3a\u7c7b\u578b \u521b\u5efa\u4ee3\u7406","title":"CARLA \u4ee3\u7406"},{"location":"adv_agents/#_1","text":"CARLA \u4ee3\u7406\u4e2d\u6d89\u53ca\u7684\u4e3b\u8981\u811a\u672c\u4f4d\u4e8e PythonAPI/carla/agents/navigation \u4e2d\u3002\u5b83\u4eec\u5206\u4e3a\u4e24\u7c7b\uff1b \u8ba1\u5212\u548c\u63a7\u5236 \u548c \u4ee3\u7406\u884c\u4e3a \u3002","title":"\u4ee3\u7406\u811a\u672c\u6982\u8ff0"},{"location":"adv_agents/#_2","text":"controller.py : \u5c06\u7eb5\u5411\u548c\u6a2a\u5411 PID \u63a7\u5236\u5668\u7ec4\u5408\u6210\u4e00\u4e2a\u7c7b\uff0c VehiclePIDController \uff0c\u7528\u4e8e\u4ece CARLA \u5ba2\u6237\u7aef\u5bf9\u8f66\u8f86\u8fdb\u884c\u4f4e\u7ea7\u63a7\u5236\u3002 global_route_planner.py : \u4ece CARLA \u670d\u52a1\u5668\u83b7\u53d6\u8be6\u7ec6\u7684\u62d3\u6251\u7ed3\u6784\u4ee5\u6784\u5efa\u4e16\u754c\u5730\u56fe\u7684\u56fe\u5f62\u8868\u793a\uff0c\u4e3a Local Planner \u63d0\u4f9b\u822a\u70b9\u548c\u9053\u8def\u9009\u9879\u4fe1\u606f\u3002 local_planner.py : \u6839\u636e\u6765\u81ea VehiclePIDController \u7684\u63a7\u5236\u8f93\u5165\u8ddf\u8e2a\u822a\u8def\u70b9\u3002\u822a\u70b9\u53ef\u4ee5\u7531 Global Route Planner \u63d0\u4f9b\uff0c\u4e5f\u53ef\u4ee5\u52a8\u6001\u8ba1\u7b97\uff0c\u5728\u8def\u53e3\u9009\u62e9\u968f\u673a\u8def\u5f84\uff0c\u7c7b\u4f3c\u4e8e Traffic Manager \u3002","title":"\u8ba1\u5212\u4e0e\u63a7\u5236"},{"location":"adv_agents/#_3","text":"basic_agent.py : \u5305\u542b\u4e00\u4e2a\u4ee3\u7406\u57fa\u7c7b\uff0c\u5b83\u5b9e\u73b0\u4e86\u4e00\u4e2a Basic Agent \uff0c\u5b83\u5728\u5730\u56fe\u4e0a\u6f2b\u6e38\u6216\u4ee5\u5c3d\u53ef\u80fd\u77ed\u7684\u8ddd\u79bb\u5230\u8fbe\u76ee\u6807\u76ee\u7684\u5730\uff0c\u907f\u5f00\u5176\u4ed6\u8f66\u8f86\uff0c\u54cd\u5e94\u4ea4\u901a\u4fe1\u53f7\u706f\u4f46\u5ffd\u7565\u505c\u8f66\u6807\u5fd7\u3002 behavior_agent.py : \u5305\u542b\u4e00\u4e2a\u5b9e\u73b0\u66f4\u590d\u6742\u7684 Behavior Agent \u7684\u7c7b\uff0c\u5b83\u53ef\u4ee5\u5728\u5c3d\u53ef\u80fd\u77ed\u7684\u8ddd\u79bb\u5185\u5230\u8fbe\u76ee\u6807\u76ee\u7684\u5730\uff0c\u8ddf\u968f\u4ea4\u901a\u4fe1\u53f7\u706f\u3001\u6807\u5fd7\u548c\u901f\u5ea6\u9650\u5236\uff0c\u540c\u65f6\u5c3e\u968f\u5176\u4ed6\u8f66\u8f86\u3002\u6709\u4e09\u79cd\u9884\u5b9a\u4e49\u7684\u7c7b\u578b\u51b3\u5b9a\u4e86\u4ee3\u7406\u7684\u884c\u4e3a\u65b9\u5f0f\u3002 behavior_types.py : \u5305\u542b\u5f71\u54cd Behavior Agent \u7684\u884c\u4e3a\u7c7b\u578b\u7684\u53c2\u6570\uff1b\u8c28\u614e\u3001\u6b63\u5e38\u548c\u8fdb\u53d6\u3002","title":"\u4ee3\u7406\u884c\u4e3a"},{"location":"adv_agents/#_4","text":"\u672c\u8282\u5c06\u89e3\u91ca\u5982\u4f55\u5728\u60a8\u81ea\u5df1\u7684\u811a\u672c\u4e2d\u4f7f\u7528\u793a\u4f8b CARLA \u4ee3\u7406\u7c7b\u3002\u5728\u672c\u8282\u7684\u6700\u540e\uff0c\u60a8\u5c06\u4e86\u89e3\u5982\u4f55\u8fd0\u884c\u4e00\u4e2a\u793a\u4f8b\u811a\u672c\u6765\u663e\u793a\u4e0d\u540c\u4ee3\u7406\u7684\u8fd0\u884c\u60c5\u51b5\u3002 1. \u5bfc\u5165\u8981\u4f7f\u7528\u7684\u4ee3\u7406\u7c7b\uff1a # \u5bfc\u5165\u57fa\u672c\u4ee3\u7406 from agent.navigation.basic_agent import BasicAgent # \u5bfc\u5165\u884c\u4e3a\u4ee3\u7406 from agent.navigation.behavior_agent import BehaviorAgent 2 . \u4efb\u4f55\u8f66\u8f86\u90fd\u53ef\u4ee5\u53d8\u6210\u4ee3\u7406\u4eba\u3002 \u751f\u6210\u8f66\u8f86 \u5e76\u5c06\u5176\u4f5c\u4e3a\u53c2\u6570\u4f20\u9012\u7ed9\u4ee3\u7406\u7c7b\u4ee5\u5b9e\u4f8b\u5316\u5b83\uff1a # \u542f\u52a8\u4e00\u4e2a\u57fa\u672c\u4ee3\u7406 agent = BasicAgent(vehicle) # \u542f\u52a8\u5177\u6709\u653b\u51fb\u6027\u914d\u7f6e\u6587\u4ef6\u7684\u884c\u4e3a\u4ee3\u7406 agent = BehaviorAgent(vehicle, behavior='aggressive') \u5728 behavior types \u90e8\u5206\u4e2d\u9605\u8bfb\u6709\u5173\u884c\u4e3a\u7c7b\u578b\u4ee5\u53ca\u5982\u4f55\u914d\u7f6e\u60a8\u81ea\u5df1\u7684\u66f4\u591a\u4fe1\u606f\u3002 3. \u60a8\u53ef\u4ee5\u8bbe\u7f6e\u4ee3\u7406\u524d\u5f80\u7684\u76ee\u7684\u5730\u3002\u5982\u679c\u60a8\u4e0d\u4e3a\u4ee3\u7406\u8bbe\u7f6e\u76ee\u7684\u5730\uff0c\u5b83\u5c06\u5728\u5730\u56fe\u4e0a\u65e0\u4f11\u6b62\u5730\u6f2b\u6e38\u3002\u8981\u8bbe\u7f6e\u76ee\u7684\u5730\uff0c\u8bf7\u4e3a\u4ee3\u7406\u63d0\u4f9b \u4f4d\u7f6e \uff1a destination = random.choice(spawn_points).location agent.set_destination(destination) 5. \u5728\u5bfc\u822a\u6b65\u9aa4\u671f\u95f4\u5e94\u7528\u8f66\u8f86\u63a7\u5236\u548c\u884c\u4e3a\u3002\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\uff0c Basic Agent \u5c06\u5e94\u7528\u8f66\u8f86\u63a7\u5236\u5e76\u901a\u8fc7\u6267\u884c\u7d27\u6025\u505c\u6b62\u6765\u5bf9\u4efb\u4f55\u8f66\u8f86\u6216\u4ea4\u901a\u4fe1\u53f7\u706f\u505a\u51fa\u53cd\u5e94\u3002 Behavior Agent \u5c06\u6839\u636e\u60a8\u5e94\u7528\u7684\u884c\u4e3a\u7c7b\u578b\u5bf9\u7ea2\u7eff\u706f\u505a\u51fa\u53cd\u5e94\u3001\u907f\u5f00\u884c\u4eba\u3001\u8ddf\u968f\u6c7d\u8f66\u5e76\u5728\u5341\u5b57\u8def\u53e3\u5bfc\u822a\uff1a while True\uff1a vehicle.apply_control(agent.run_step()) 6. \u60a8\u53ef\u4ee5\u68c0\u67e5\u4ee3\u7406\u662f\u5426\u5df2\u5b8c\u6210\u5176\u8f68\u8ff9\u5e76\u5728\u53d1\u751f\u8fd9\u79cd\u60c5\u51b5\u65f6\u6267\u884c\u64cd\u4f5c\u3002\u4e00\u65e6\u60a8\u7684\u8f66\u8f86\u5230\u8fbe\u76ee\u7684\u5730\uff0c\u4ee5\u4e0b\u4ee3\u7801\u6bb5\u5c06\u7ed3\u675f\u6a21\u62df\uff1a while True\uff1a if agent.done\uff08\uff09\uff1a print(\"The taerget has been reached, stopping the simulation\") break vehicle.apply_control(agent.run_step()) 7. \u4e0d\u662f\u5728\u4ee3\u7406\u5230\u8fbe\u5176\u76ee\u6807\u76ee\u7684\u5730\u65f6\u5b8c\u6210\u6a21\u62df\uff0c\u800c\u662f\u53ef\u4ee5\u751f\u6210\u4e00\u6761\u65b0\u7684\u968f\u673a\u8def\u7ebf\u4f9b\u4ee3\u7406\u9075\u5faa\uff1a while True\uff1a if agent.done(): agent.set_destination(random.choice(spawn_points).location) print(\"The target has been reached, searching for another target\") vehicle.apply_control(agent.run_step()) Basic Agent \u63d0\u4f9b\u4e86\u4e00\u4e9b\u65b9\u6cd5\u6765\u64cd\u7eb5\u4ee3\u7406\u884c\u4e3a\u6216\u9075\u5faa\u7684\u7a0b\u5e8f\u8def\u7ebf\uff1a set_target_speed(speed) : \u4ee5\u516c\u91cc/\u5c0f\u65f6\u4e3a\u5355\u4f4d\u8bbe\u7f6e\u76ee\u6807\u901f\u5ea6 follow_speed_limits(value=True) : \u8bbe\u7f6e\u4ee3\u7406\u9075\u5faa\u901f\u5ea6\u9650\u5236\u3002 set_destination(end_location, start_location=None) : \u4ee3\u7406\u5c06\u901a\u8fc7\u53ef\u80fd\u7684\u6700\u77ed\u8def\u7ebf\u4ece\u7279\u5b9a\u7684\u8d77\u59cb\u4f4d\u7f6e\u5230\u7ed3\u675f\u4f4d\u7f6e\u3002\u5982\u679c\u6ca1\u6709\u63d0\u4f9b\u8d77\u59cb\u4f4d\u7f6e\uff0c\u5b83\u5c06\u4f7f\u7528\u5f53\u524d\u4ee3\u7406\u4f4d\u7f6e\u3002 set_global_plan(plan, stop_waypoint_creation=True, clean_queue=True) : \u4e3a\u4ee3\u7406\u6dfb\u52a0\u4e00\u4e2a\u5177\u4f53\u7684\u8ba1\u5212\u3002\u8ba1\u5212\u53c2\u6570\u5e94\u5305\u542b\u4e00\u4e2a [carla.Waypoint, RoadOption] \u5217\u8868\uff0c\u8fd9\u5c06\u662f\u4ee3\u7406\u9700\u8981\u91c7\u53d6\u7684\u8def\u5f84\u3002 stop_waypoint_creation \u5c06\u9632\u6b62\u5728\u8def\u5f84\u8fd0\u884c\u540e\u81ea\u52a8\u521b\u5efa\u822a\u70b9\u3002 clean_queue \u5c06\u91cd\u7f6e\u4ee3\u7406\u7684\u5f53\u524d\u8ba1\u5212\u3002 trace_route(start_waypoint, end_waypoint) : \u4ece Global Route Planner \u83b7\u53d6\u4e24\u4e2a\u822a\u70b9\u4e4b\u95f4\u7684\u6700\u77ed\u8ddd\u79bb\uff0c\u5e76\u5c06\u8def\u5f84\u4f5c\u4e3a [carla.Waypoint, RoadOption] \u5217\u8868\u8fd4\u56de\uff0c\u4f9b\u4ee3\u7406\u9075\u5faa\u3002 ignore_traffic_lights(active=True) : \u8bbe\u7f6e\u4ee3\u7406\u5ffd\u7565\u6216\u670d\u4ece\u4ea4\u901a\u4fe1\u53f7\u706f\u3002 ignore_stop_signs(active=True) : \u8bbe\u7f6e\u4ee3\u7406\u5ffd\u7565\u6216\u670d\u4ece\u505c\u8f66\u6807\u5fd7\u3002 ignore_vehicles(active=True) : \u8bbe\u7f6e\u4ee3\u7406\u5ffd\u7565\u6216\u5bf9\u5176\u4ed6\u8f66\u8f86\u4f5c\u51fa\u53cd\u5e94\u3002 \u5728 PythonAPI/examples \u4e2d\u627e\u5230\u7684 automatic_control.py \u811a\u672c\u662f\u57fa\u672c\u548c\u884c\u4e3a\u4ee3\u7406\u7684\u4e00\u4e2a\u793a\u4f8b\u3002\u8981\u5c1d\u8bd5\u8be5\u811a\u672c\uff0c\u8bf7\u5bfc\u822a\u5230\u793a\u4f8b\u76ee\u5f55\u5e76\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a # \u4f7f\u7528\u57fa\u672c\u4ee3\u7406\u8fd0\u884c python3 automatic_control.py --agent=Basic # \u4f7f\u7528\u884c\u4e3a\u4ee3\u7406\u8fd0\u884c python3 automatic_control.py --agent=Behavior --behavior=aggressive","title":"\u5b9e\u73b0\u4e00\u4e2a\u4ee3\u7406"},{"location":"adv_agents/#_5","text":"\u884c\u4e3a\u4ee3\u7406\u7684\u884c\u4e3a\u7c7b\u578b\u5728 behavior_types.py \u4e2d\u5b9a\u4e49\u3002\u4e09\u4e2a\u9884\u914d\u7f6e\u7684\u914d\u7f6e\u6587\u4ef6\u662f 'cautious' \u3001 'normal' \u548c 'aggressive' \u3002\u60a8\u53ef\u4ee5\u4f7f\u7528\u8bbe\u7f6e\u7684\u914d\u7f6e\u6587\u4ef6\u3001\u4fee\u6539\u5b83\u4eec\u6216\u521b\u5efa\u60a8\u81ea\u5df1\u7684\u914d\u7f6e\u6587\u4ef6\u3002\u53ef\u4ee5\u8c03\u6574\u4ee5\u4e0b\u53d8\u91cf\uff1a max_speed \uff1a\u60a8\u7684\u8f66\u8f86\u80fd\u591f\u8fbe\u5230\u7684\u6700\u9ad8\u901f\u5ea6\uff08\u4ee5\u516c\u91cc/\u5c0f\u65f6\u4e3a\u5355\u4f4d\uff09\u3002 speed_lim_dist \uff1a\u4ee5 km/h \u4e3a\u5355\u4f4d\u7684\u503c\uff0c\u7528\u4e8e\u5b9a\u4e49\u8f66\u8f86\u7684\u76ee\u6807\u901f\u5ea6\u4e0e\u5f53\u524d\u9650\u901f\u7684\u8ddd\u79bb\uff08\u4f8b\u5982\uff0c\u5982\u679c\u9650\u901f\u4e3a 30km/h \u4e14 speed_lim_dist \u4e3a 10km/h\uff0c\u5219\u76ee\u6807\u901f\u5ea6\u5c06\u662f20\u516c\u91cc/\u5c0f\u65f6\uff09 speed_decrease \uff1a\u5f53\u63a5\u8fd1\u524d\u65b9\u8f83\u6162\u7684\u8f66\u8f86\u65f6\uff0c\u60a8\u7684\u8f66\u8f86\u5c06\u4ee5\u591a\u5feb\u7684\u516c\u91cc/\u5c0f\u65f6\u51cf\u901f\u3002 safety_time \uff1a\u78b0\u649e\u65f6\u95f4\uff1b\u5982\u679c\u60a8\u7684\u8f66\u8f86\u7a81\u7136\u5239\u8f66\uff0c\u5b83\u4e0e\u524d\u9762\u7684\u8f66\u8f86\u76f8\u649e\u6240\u9700\u7684\u65f6\u95f4\u7684\u8fd1\u4f3c\u503c\u3002 min_proximity_threshold \uff1a\u5728\u60a8\u7684\u8f66\u8f86\u6267\u884c\u907f\u8ba9\u6216\u5c3e\u968f\u7b49\u64cd\u4f5c\u4e4b\u524d\uff0c\u4e0e\u53e6\u4e00\u8f86\u8f66\u6216\u884c\u4eba\u7684\u6700\u5c0f\u8ddd\u79bb\uff08\u4ee5\u7c73\u4e3a\u5355\u4f4d\uff09\u3002 braking_distance \uff1a\u60a8\u7684\u8f66\u8f86\u5c06\u6267\u884c\u7d27\u6025\u505c\u8f66\u65f6\u4e0e\u884c\u4eba\u6216\u8f66\u8f86\u7684\u8ddd\u79bb\u3002 tailgate_counter \uff1a\u7528\u4e8e\u907f\u514d\u5728\u6700\u540e\u4e00\u4e2a\u540e\u6321\u677f\u540e\u8fc7\u5feb\u5c3e\u968f\u7684\u8ba1\u6570\u5668\u3002","title":"\u884c\u4e3a\u7c7b\u578b"},{"location":"adv_agents/#_6","text":"\u8981\u521b\u5efa\u81ea\u5df1\u7684\u884c\u4e3a\u7c7b\u578b\uff1a 1. \u5728 behavior_types.py \u4e2d\u4e3a\u60a8\u7684\u884c\u4e3a\u7c7b\u578b\u521b\u5efa\u7c7b\uff1a class ProfileName(object)\uff1a # \u5b8c\u6574\u7684\u503c\u5b9a\u4e49 2. \u5728 behavior_agent.py \u811a\u672c\u4e2d\u5b9a\u4e49\u548c\u5b9e\u4f8b\u5316\u4f60\u7684\u884c\u4e3a\u7c7b\u578b\uff1a # \u4ee3\u7406\u884c\u4e3a\u53c2\u6570 if behavior == 'cautious'\uff1a self._behavior = Cautious() elif behavior == 'normal'\uff1a self._behavior = Normal() elif behavior == 'aggressive'\uff1a self._behavior = Aggressive() elif behavior == '<type_name>'\uff1a self._behavior = <TypeName>()","title":"\u521b\u5efa\u81ea\u5df1\u7684\u884c\u4e3a\u7c7b\u578b"},{"location":"adv_agents/#_7","text":"CARLA \u4ee3\u7406\u53ea\u662f\u7528\u6237\u53ef\u4ee5\u8fd0\u884c\u7684\u4ee3\u7406\u7c7b\u578b\u7684\u793a\u4f8b\u3002\u7528\u6237\u53ef\u4ee5\u5728 Basic Agent \u7684\u57fa\u7840\u4e0a\u521b\u5efa\u81ea\u5df1\u7684\u4ee3\u7406\u3002\u53ef\u80fd\u6027\u662f\u65e0\u6b62\u5883\u3002\u6bcf\u4e2a\u4ee3\u7406\u53ea\u9700\u8981\u4e24\u4e2a\u5143\u7d20\uff0c \u521d\u59cb\u5316__\u548c__\u8fd0\u884c\u6b65\u9aa4 \u3002 \u5728\u4e0b\u9762\u67e5\u627e\u81ea\u5b9a\u4e49\u4ee3\u7406\u7684\u6700\u5c0f\u5e03\u5c40\u793a\u4f8b\uff1a import carla from agents.navigation.basic_agent import BasicAgent class CustomAgent(BasicAgent): def __init__(self, vehicle, target_speed=20, debug=False): \"\"\" :param vehicle: \u5e94\u7528\u5230\u672c\u5730\u89c4\u5212\u5668\u903b\u8f91\u7684actor :param target_speed: \u8f66\u8f86\u79fb\u52a8\u7684\u901f\u5ea6\uff08Km/h\uff09 \"\"\" super().__init__(target_speed, \u8c03\u8bd5) def run_step(self, debug=False): \"\"\" \u6267\u884c\u4e00\u6b65\u5bfc\u822a :return: carla.VehicleControl \"\"\" # \u5728\u6bcf\u4e2a\u6a21\u62df\u6b65\u9aa4\u4e2d\u91c7\u53d6\u7684\u884c\u52a8 control = carla.VehicleControl() return control \u67e5\u770b basic_agent.py \u548c behavior_agent.py \u811a\u672c\u4ee5\u63a2\u7d22\u5b83\u4eec\u7684\u7ed3\u6784\u548c\u529f\u80fd\uff0c\u4ee5\u83b7\u53d6\u6709\u5173\u5982\u4f55\u521b\u5efa\u81ea\u5df1\u7684\u66f4\u591a\u60f3\u6cd5\u3002 \u60a8\u53ef\u4ee5\u63a2\u7d22\u63d0\u4f9b\u7684\u4ee3\u7406\u811a\u672c\u3001\u6269\u5c55\u5b83\u4eec\u6216\u5c06\u5b83\u4eec\u7528\u4f5c\u521b\u5efa\u81ea\u5df1\u7684\u57fa\u51c6\u3002\u5982\u679c\u60a8\u5bf9\u4ee3\u7406\u6709\u4efb\u4f55\u7591\u95ee\uff0c\u8bf7\u968f\u65f6\u5728 \u8bba\u575b \u53d1\u5e16\u3002","title":"\u521b\u5efa\u4ee3\u7406"},{"location":"adv_benchmarking/","text":"\u57fa\u51c6\u6027\u80fd \u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u811a\u672c\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u8f7b\u677e\u5730\u5206\u6790 CARLA \u5728\u81ea\u5df1\u7684\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002\u8be5\u811a\u672c\u53ef\u4ee5\u914d\u7f6e\u4e3a\u8fd0\u884c\u591a\u79cd\u7ed3\u5408\u4e0d\u540c\u5730\u56fe\u3001\u4f20\u611f\u5668\u548c\u5929\u6c14\u6761\u4ef6\u7684\u573a\u666f\u3002\u5b83\u62a5\u544a\u8bf7\u6c42\u573a\u666f\u4e0b FPS \u7684\u5e73\u5747\u503c\u548c\u6807\u51c6\u504f\u5dee\u3002 \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u8981\u6c42\u3001\u5728\u54ea\u91cc\u53ef\u4ee5\u627e\u5230\u811a\u672c\u3001\u53ef\u7528\u4e8e\u81ea\u5b9a\u4e49\u8fd0\u884c\u573a\u666f\u7684\u6807\u5fd7\u4ee5\u53ca\u6709\u5173\u5982\u4f55\u8fd0\u884c\u547d\u4ee4\u7684\u793a\u4f8b\u3002 \u6211\u4eec\u8fd8\u5305\u542b\u4e86\u5355\u72ec\u57fa\u51c6\u6d4b\u8bd5\u7684\u7ed3\u679c\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5728\u4f7f\u7528\u4e0d\u540c\u8f66\u8f86\u6570\u91cf\u7ec4\u5408\u3001\u542f\u7528\u7269\u7406\u548c/\u6216\u542f\u7528\u4ea4\u901a\u7ba1\u7406\u5668\u65f6\u6d4b\u91cf CARLA \u5728\u7279\u5b9a\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002\u7ed3\u679c\u4e0e\u4f7f\u7528\u7684 CARLA \u7248\u672c\u548c\u6267\u884c\u6d4b\u8bd5\u7684\u73af\u5883\u4e00\u8d77\u663e\u793a\u3002 \u57fa\u51c6\u811a\u672c \u5f00\u59cb\u4e4b\u524d \u6982\u8981 \u6807\u5fd7 CARLA \u6027\u80fd\u62a5\u544a \u57fa\u51c6\u6d4b\u8bd5\u811a\u672c \u57fa\u51c6\u811a\u672c\u53ef\u4ee5\u5728 PythonAPI/util \u4e2d\u627e\u5230\u3002\u5b83\u6709\u51e0\u4e2a\u6807\u5fd7\u53ef\u7528\u4e8e\u81ea\u5b9a\u4e49\u8981\u6d4b\u8bd5\u7684\u573a\u666f\uff0c\u4e0b\u9762\u7684\u6982\u8981\u4e2d\u6709\u8be6\u7ec6\u8bf4\u660e\u3002 \u5f00\u59cb\u4e4b\u524d \u57fa\u51c6\u6d4b\u8bd5\u811a\u672c\u9700\u8981\u5b89\u88c5\u4e00\u4e9b\u4f9d\u8d56\u9879\u624d\u80fd\u8fd0\u884c\u5b83\uff1a python -m pip install -U py-cpuinfo==5.0.0 python -m pip install psutil python -m pip install python-tr python -m pip install gpuinfo python -m pip install GPUtil \u6982\u8981 python3 performance_benchmark.py [--host HOST] [--port PORT] [--file FILE] [--tm] [--fixed_dt FIXED_DT] [--render_mode] [--no_render_mode] [--show_scenarios] ) [--sensors SENSORS [SENSORS ...]] [--maps MAPS [MAPS ...]] [--weather WEATHER [WEATHER ...]] \u6807\u5fd7 --host : IP_ADDRESS \u9ed8\u8ba4 \uff1a\u672c\u5730\u4e3b\u673a\u3002 \u914d\u7f6e\u670d\u52a1\u5668\u7684\u4e3b\u673a\u3002 --port : \u7aef\u53e3 \u9ed8\u8ba4 \uff1a2000 \u914d\u7f6e\u8981\u76d1\u542c\u7684 TCP \u7aef\u53e3\u3002 --file : \u6587\u4ef6\u540d.md \u9ed8\u8ba4 : benchmark.md \u4ee5\u964d\u4ef7\u8868\u683c\u5f0f\u5c06\u7ed3\u679c\u5199\u5165\u6587\u4ef6\u3002 --tm \u5207\u6362\u5230\u4ea4\u901a\u7ba1\u7406\u5668\u57fa\u51c6 --ticks \u9ed8\u8ba4 \uff1a100 \u8bbe\u7f6e\u7528\u4e8e\u6bcf\u4e2a\u573a\u666f\u7684\u523b\u5ea6\u6570\u3002 --\u540c\u6b65 \u9ed8\u8ba4\u6a21\u5f0f. \u5728\u540c\u6b65\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002 --async \u5728\u5f02\u6b65\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002 --fixed_dt \u9ed8\u8ba4 \uff1a0.05 \u5982\u679c\u60a8\u60f3\u8bbe\u7f6e\u589e\u91cf\u65f6\u95f4\u6b65\u957f\uff0c\u8bf7\u4e0e\u540c\u6b65\u6a21\u5f0f\u4e00\u8d77\u4f7f\u7528\u3002 --render_mode \u5728\u6e32\u67d3\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002 --no_render_mode \u9ed8\u8ba4\u6a21\u5f0f. \u5728\u975e\u6e32\u67d3\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002 --show_scenarios \u4ec5\u4f7f\u7528\u6b64\u6807\u5fd7\u8fd0\u884c\u811a\u672c\u65f6\uff0c\u60a8\u5c06\u770b\u5230\u6240\u6709\u53ef\u7528\u573a\u666f\u53c2\u6570\u7684\u5217\u8868\u3002 \u5f53\u4e0e\u5176\u4ed6\u6807\u5fd7\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u60a8\u5c06\u770b\u5230\u5c06\u5728\u672a\u5b9e\u9645\u6267\u884c\u7684\u60c5\u51b5\u4e0b\u8fd0\u884c\u7684\u573a\u666f\u7684\u9884\u89c8\u3002 --sensors \uff1a\u6574\u6570 \u9ed8\u8ba4 \uff1a\u5168\u90e8 \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f7f\u7528\u7684\u4f20\u611f\u5668\u3002\u5728 LIDAR \u548c RGB \u76f8\u673a\u4e4b\u95f4\u8fdb\u884c\u9009\u62e9\uff1a 0 : cam-300x200 1 : cam-800x600 2 : cam-1900x1080 3 : cam-300x200 cam-300x200\uff08\u4e24\u4e2a\u6444\u50cf\u5934\uff09 4 \uff1a\u6fc0\u5149\u96f7\u8fbe\uff1a100k 5 \uff1a\u6fc0\u5149\u96f7\u8fbe\uff1a500k 6 \uff1a\u6fc0\u5149\u96f7\u8fbe\uff1a1M --maps \uff1a\u57ce\u5e02\u540d\u79f0 \u9ed8\u8ba4 \uff1a\u6240\u6709\u5730\u56fe \u6240\u6709 [CARLA \u5730\u56fe][carla_maps]\uff0c\u5305\u62ec\u5206\u5c42\u548c\u5b50\u5206\u5c42\uff0c\u90fd\u53ef\u7528\u3002 [carla_maps]\uff1ahttps://carla.readthedocs.io/en/latest/core_map/#carla-maps --\u5929\u6c14 \uff1a\u6574\u6570 Default \uff1a\u6240\u6709\u5929\u6c14\u6761\u4ef6 \u6539\u53d8\u5929\u6c14\u72b6\u51b5\uff1a 0 : ClearNoon 1 : CloudyNoon 2 : SoftRainSunset \u5982\u4f55\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5 1.\u542f\u52a8CARLA\uff1a # Linux\uff1a ./CarlaUE4.sh # Windows\uff1a CarlaUE4.exe \uff03 Source\uff1a make launch \u5728\u5355\u72ec\u7684\u7ec8\u7aef\u4e2d\u5bfc\u822a\u5230 PythonAPI/util \u4ee5\u627e\u5230 performance_benchmark.py \u811a\u672c\uff1a \u663e\u793a\u6240\u6709\u53ef\u80fd\u7684\u573a\u666f\u800c\u4e0d\u8fd0\u884c\u5b83\u4eec\uff1a python3 performance_benchmark.py --show_scenarios \u663e\u793a\u5728\u5e94\u7528\u914d\u7f6e\u800c\u4e0d\u5b9e\u9645\u6267\u884c\u914d\u7f6e\u65f6\u5c06\u8fd0\u884c\u54ea\u4e9b\u573a\u666f\uff1a python3 performance_benchmark.py --sensors 2 5 --maps Town03 Town05 --weather 0 1 --show_scenarios` \u6267\u884c\u8fd9\u4e9b\u573a\u666f\u7684\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\uff1a python3 performance_benchmark.py --sensors 2 5 --maps Town03 Town05 --weather 0 1 \u6267\u884c\u5f02\u6b65\u6a21\u5f0f\u548c\u6e32\u67d3\u6a21\u5f0f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff1a python3 performance_benchmark.py --async --render_mode CARLA \u6027\u80fd\u62a5\u544a \u4e0b\u8868\u8be6\u7ec6\u8bf4\u660e\u4e86\u5728\u968f\u7740\u8f66\u8f86\u6570\u91cf\u589e\u52a0\u4ee5\u53ca\u542f\u7528\u548c/\u6216\u7981\u7528\u7269\u7406\u548c\u4ea4\u901a\u7ba1\u7406\u5668\u7684\u4e0d\u540c\u7ec4\u5408\u8fd0\u884c CARLA \u65f6\u5bf9\u5e73\u5747 FPS \u7684\u6027\u80fd\u5f71\u54cd\u3002 CARLA \u7248\u672c\uff1a29/01/21 \u5f00\u53d1\u5206\u652f\uff08\u63d0\u4ea4 198fa38c9b1317c114ac15dff130766253c02832\uff09 \u73af\u5883\u89c4\u683c\uff1aIntel(R) Xeon(R) CPU E5-1620 v3 @ 3.50GHz / 32 GB / NVIDIA GeForce GTX 1080 Ti \u8f66\u8f86\u6570\u91cf Phy: Off TM: Off Phy: On TM: Off Phy: Off TM: On Phy: On TM: On 0 1220 1102 702 729 1 805 579 564 422 10 473 223 119 98 50 179 64 37 26 100 92 34 22 15 150 62 21 17 10 200 47 15 14 7 250 37 11 12 6 \u5982\u679c\u60a8\u5bf9\u6027\u80fd\u57fa\u51c6\u6709\u4efb\u4f55\u7591\u95ee\uff0c\u8bf7\u4e0d\u8981\u72b9\u8c6b\uff0c\u5728\u8bba\u575b\u4e2d\u53d1\u5e16\u3002 CARLA\u8bba\u575b","title":"\u57fa\u51c6\u6027\u80fd"},{"location":"adv_benchmarking/#_1","text":"\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u811a\u672c\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u8f7b\u677e\u5730\u5206\u6790 CARLA \u5728\u81ea\u5df1\u7684\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002\u8be5\u811a\u672c\u53ef\u4ee5\u914d\u7f6e\u4e3a\u8fd0\u884c\u591a\u79cd\u7ed3\u5408\u4e0d\u540c\u5730\u56fe\u3001\u4f20\u611f\u5668\u548c\u5929\u6c14\u6761\u4ef6\u7684\u573a\u666f\u3002\u5b83\u62a5\u544a\u8bf7\u6c42\u573a\u666f\u4e0b FPS \u7684\u5e73\u5747\u503c\u548c\u6807\u51c6\u504f\u5dee\u3002 \u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u8981\u6c42\u3001\u5728\u54ea\u91cc\u53ef\u4ee5\u627e\u5230\u811a\u672c\u3001\u53ef\u7528\u4e8e\u81ea\u5b9a\u4e49\u8fd0\u884c\u573a\u666f\u7684\u6807\u5fd7\u4ee5\u53ca\u6709\u5173\u5982\u4f55\u8fd0\u884c\u547d\u4ee4\u7684\u793a\u4f8b\u3002 \u6211\u4eec\u8fd8\u5305\u542b\u4e86\u5355\u72ec\u57fa\u51c6\u6d4b\u8bd5\u7684\u7ed3\u679c\uff0c\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5728\u4f7f\u7528\u4e0d\u540c\u8f66\u8f86\u6570\u91cf\u7ec4\u5408\u3001\u542f\u7528\u7269\u7406\u548c/\u6216\u542f\u7528\u4ea4\u901a\u7ba1\u7406\u5668\u65f6\u6d4b\u91cf CARLA \u5728\u7279\u5b9a\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002\u7ed3\u679c\u4e0e\u4f7f\u7528\u7684 CARLA \u7248\u672c\u548c\u6267\u884c\u6d4b\u8bd5\u7684\u73af\u5883\u4e00\u8d77\u663e\u793a\u3002 \u57fa\u51c6\u811a\u672c \u5f00\u59cb\u4e4b\u524d \u6982\u8981 \u6807\u5fd7 CARLA \u6027\u80fd\u62a5\u544a","title":"\u57fa\u51c6\u6027\u80fd"},{"location":"adv_benchmarking/#_2","text":"\u57fa\u51c6\u811a\u672c\u53ef\u4ee5\u5728 PythonAPI/util \u4e2d\u627e\u5230\u3002\u5b83\u6709\u51e0\u4e2a\u6807\u5fd7\u53ef\u7528\u4e8e\u81ea\u5b9a\u4e49\u8981\u6d4b\u8bd5\u7684\u573a\u666f\uff0c\u4e0b\u9762\u7684\u6982\u8981\u4e2d\u6709\u8be6\u7ec6\u8bf4\u660e\u3002","title":"\u57fa\u51c6\u6d4b\u8bd5\u811a\u672c"},{"location":"adv_benchmarking/#_3","text":"\u57fa\u51c6\u6d4b\u8bd5\u811a\u672c\u9700\u8981\u5b89\u88c5\u4e00\u4e9b\u4f9d\u8d56\u9879\u624d\u80fd\u8fd0\u884c\u5b83\uff1a python -m pip install -U py-cpuinfo==5.0.0 python -m pip install psutil python -m pip install python-tr python -m pip install gpuinfo python -m pip install GPUtil","title":"\u5f00\u59cb\u4e4b\u524d"},{"location":"adv_benchmarking/#_4","text":"python3 performance_benchmark.py [--host HOST] [--port PORT] [--file FILE] [--tm] [--fixed_dt FIXED_DT] [--render_mode] [--no_render_mode] [--show_scenarios] ) [--sensors SENSORS [SENSORS ...]] [--maps MAPS [MAPS ...]] [--weather WEATHER [WEATHER ...]]","title":"\u6982\u8981"},{"location":"adv_benchmarking/#_5","text":"","title":"\u6807\u5fd7"},{"location":"adv_benchmarking/#-host-ip_address","text":"\u9ed8\u8ba4 \uff1a\u672c\u5730\u4e3b\u673a\u3002 \u914d\u7f6e\u670d\u52a1\u5668\u7684\u4e3b\u673a\u3002","title":"--host: IP_ADDRESS"},{"location":"adv_benchmarking/#-port","text":"\u9ed8\u8ba4 \uff1a2000 \u914d\u7f6e\u8981\u76d1\u542c\u7684 TCP \u7aef\u53e3\u3002","title":"--port: \u7aef\u53e3"},{"location":"adv_benchmarking/#-file-md","text":"\u9ed8\u8ba4 : benchmark.md \u4ee5\u964d\u4ef7\u8868\u683c\u5f0f\u5c06\u7ed3\u679c\u5199\u5165\u6587\u4ef6\u3002","title":"--file: \u6587\u4ef6\u540d.md"},{"location":"adv_benchmarking/#-tm","text":"\u5207\u6362\u5230\u4ea4\u901a\u7ba1\u7406\u5668\u57fa\u51c6","title":"--tm"},{"location":"adv_benchmarking/#-ticks","text":"\u9ed8\u8ba4 \uff1a100 \u8bbe\u7f6e\u7528\u4e8e\u6bcf\u4e2a\u573a\u666f\u7684\u523b\u5ea6\u6570\u3002","title":"--ticks"},{"location":"adv_benchmarking/#-","text":"\u9ed8\u8ba4\u6a21\u5f0f. \u5728\u540c\u6b65\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002","title":"--\u540c\u6b65"},{"location":"adv_benchmarking/#-async","text":"\u5728\u5f02\u6b65\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002","title":"--async"},{"location":"adv_benchmarking/#-fixed_dt","text":"\u9ed8\u8ba4 \uff1a0.05 \u5982\u679c\u60a8\u60f3\u8bbe\u7f6e\u589e\u91cf\u65f6\u95f4\u6b65\u957f\uff0c\u8bf7\u4e0e\u540c\u6b65\u6a21\u5f0f\u4e00\u8d77\u4f7f\u7528\u3002","title":"--fixed_dt"},{"location":"adv_benchmarking/#-render_mode","text":"\u5728\u6e32\u67d3\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002","title":"--render_mode"},{"location":"adv_benchmarking/#-no_render_mode","text":"\u9ed8\u8ba4\u6a21\u5f0f. \u5728\u975e\u6e32\u67d3\u6a21\u5f0f\u4e0b\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002","title":"--no_render_mode"},{"location":"adv_benchmarking/#-show_scenarios","text":"\u4ec5\u4f7f\u7528\u6b64\u6807\u5fd7\u8fd0\u884c\u811a\u672c\u65f6\uff0c\u60a8\u5c06\u770b\u5230\u6240\u6709\u53ef\u7528\u573a\u666f\u53c2\u6570\u7684\u5217\u8868\u3002 \u5f53\u4e0e\u5176\u4ed6\u6807\u5fd7\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u60a8\u5c06\u770b\u5230\u5c06\u5728\u672a\u5b9e\u9645\u6267\u884c\u7684\u60c5\u51b5\u4e0b\u8fd0\u884c\u7684\u573a\u666f\u7684\u9884\u89c8\u3002","title":"--show_scenarios"},{"location":"adv_benchmarking/#-sensors","text":"\u9ed8\u8ba4 \uff1a\u5168\u90e8 \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f7f\u7528\u7684\u4f20\u611f\u5668\u3002\u5728 LIDAR \u548c RGB \u76f8\u673a\u4e4b\u95f4\u8fdb\u884c\u9009\u62e9\uff1a 0 : cam-300x200 1 : cam-800x600 2 : cam-1900x1080 3 : cam-300x200 cam-300x200\uff08\u4e24\u4e2a\u6444\u50cf\u5934\uff09 4 \uff1a\u6fc0\u5149\u96f7\u8fbe\uff1a100k 5 \uff1a\u6fc0\u5149\u96f7\u8fbe\uff1a500k 6 \uff1a\u6fc0\u5149\u96f7\u8fbe\uff1a1M","title":"--sensors\uff1a\u6574\u6570"},{"location":"adv_benchmarking/#-maps","text":"\u9ed8\u8ba4 \uff1a\u6240\u6709\u5730\u56fe \u6240\u6709 [CARLA \u5730\u56fe][carla_maps]\uff0c\u5305\u62ec\u5206\u5c42\u548c\u5b50\u5206\u5c42\uff0c\u90fd\u53ef\u7528\u3002 [carla_maps]\uff1ahttps://carla.readthedocs.io/en/latest/core_map/#carla-maps","title":"--maps\uff1a\u57ce\u5e02\u540d\u79f0"},{"location":"adv_benchmarking/#-_1","text":"Default \uff1a\u6240\u6709\u5929\u6c14\u6761\u4ef6 \u6539\u53d8\u5929\u6c14\u72b6\u51b5\uff1a 0 : ClearNoon 1 : CloudyNoon 2 : SoftRainSunset","title":"--\u5929\u6c14\uff1a\u6574\u6570"},{"location":"adv_benchmarking/#_6","text":"1.\u542f\u52a8CARLA\uff1a # Linux\uff1a ./CarlaUE4.sh # Windows\uff1a CarlaUE4.exe \uff03 Source\uff1a make launch \u5728\u5355\u72ec\u7684\u7ec8\u7aef\u4e2d\u5bfc\u822a\u5230 PythonAPI/util \u4ee5\u627e\u5230 performance_benchmark.py \u811a\u672c\uff1a \u663e\u793a\u6240\u6709\u53ef\u80fd\u7684\u573a\u666f\u800c\u4e0d\u8fd0\u884c\u5b83\u4eec\uff1a python3 performance_benchmark.py --show_scenarios \u663e\u793a\u5728\u5e94\u7528\u914d\u7f6e\u800c\u4e0d\u5b9e\u9645\u6267\u884c\u914d\u7f6e\u65f6\u5c06\u8fd0\u884c\u54ea\u4e9b\u573a\u666f\uff1a python3 performance_benchmark.py --sensors 2 5 --maps Town03 Town05 --weather 0 1 --show_scenarios` \u6267\u884c\u8fd9\u4e9b\u573a\u666f\u7684\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\uff1a python3 performance_benchmark.py --sensors 2 5 --maps Town03 Town05 --weather 0 1 \u6267\u884c\u5f02\u6b65\u6a21\u5f0f\u548c\u6e32\u67d3\u6a21\u5f0f\u7684\u57fa\u51c6\u6d4b\u8bd5\uff1a python3 performance_benchmark.py --async --render_mode","title":"\u5982\u4f55\u8fd0\u884c\u57fa\u51c6\u6d4b\u8bd5"},{"location":"adv_benchmarking/#carla","text":"\u4e0b\u8868\u8be6\u7ec6\u8bf4\u660e\u4e86\u5728\u968f\u7740\u8f66\u8f86\u6570\u91cf\u589e\u52a0\u4ee5\u53ca\u542f\u7528\u548c/\u6216\u7981\u7528\u7269\u7406\u548c\u4ea4\u901a\u7ba1\u7406\u5668\u7684\u4e0d\u540c\u7ec4\u5408\u8fd0\u884c CARLA \u65f6\u5bf9\u5e73\u5747 FPS \u7684\u6027\u80fd\u5f71\u54cd\u3002 CARLA \u7248\u672c\uff1a29/01/21 \u5f00\u53d1\u5206\u652f\uff08\u63d0\u4ea4 198fa38c9b1317c114ac15dff130766253c02832\uff09 \u73af\u5883\u89c4\u683c\uff1aIntel(R) Xeon(R) CPU E5-1620 v3 @ 3.50GHz / 32 GB / NVIDIA GeForce GTX 1080 Ti \u8f66\u8f86\u6570\u91cf Phy: Off TM: Off Phy: On TM: Off Phy: Off TM: On Phy: On TM: On 0 1220 1102 702 729 1 805 579 564 422 10 473 223 119 98 50 179 64 37 26 100 92 34 22 15 150 62 21 17 10 200 47 15 14 7 250 37 11 12 6 \u5982\u679c\u60a8\u5bf9\u6027\u80fd\u57fa\u51c6\u6709\u4efb\u4f55\u7591\u95ee\uff0c\u8bf7\u4e0d\u8981\u72b9\u8c6b\uff0c\u5728\u8bba\u575b\u4e2d\u53d1\u5e16\u3002 CARLA\u8bba\u575b","title":"CARLA \u6027\u80fd\u62a5\u544a"},{"location":"adv_opendrive/","text":"OpenDRIVE\u72ec\u7acb\u6a21\u5f0f \u6b64\u529f\u80fd\u5141\u8bb8\u7528\u6237\u5c06\u4efb\u4f55 OpenDRIVE \u6587\u4ef6\u4f5c\u4e3a CARLA \u5730\u56fe\u5f00\u7bb1\u5373\u7528\u3002\u4e3a\u6b64\uff0c\u6a21\u62df\u5668\u5c06\u81ea\u52a8\u751f\u6210\u9053\u8def\u7f51\u683c\u4f9b\u89d2\u8272\u5bfc\u822a\u3002 \u6982\u8ff0 \u8fd0\u884c\u72ec\u7acb\u5730\u56fe \u7f51\u683c\u751f\u6210 \u6982\u8ff0 \u6b64\u6a21\u5f0f\u4ec5\u4f7f\u7528 OpenDRIVE \u6587\u4ef6\u8fd0\u884c\u5b8c\u6574\u6a21\u62df\uff0c\u65e0\u9700\u4efb\u4f55\u989d\u5916\u7684\u51e0\u4f55\u56fe\u5f62\u6216\u8d44\u4ea7\u3002\u4e3a\u6b64\uff0c\u6a21\u62df\u5668\u91c7\u7528 OpenDRIVE \u6587\u4ef6\u5e76\u7a0b\u5e8f\u5316\u5730\u521b\u5efa\u65f6\u95f4 3D \u7f51\u683c\u6765\u8fd0\u884c\u6a21\u62df\u3002 \u751f\u6210\u7684\u7f51\u683c\u4ee5\u7b80\u7ea6\u7684\u65b9\u5f0f\u63cf\u8ff0\u4e86\u9053\u8def\u5b9a\u4e49\u3002\u6240\u6709\u5143\u7d20\u90fd\u5c06\u4e0e OpenDRIVE \u6587\u4ef6\u5bf9\u5e94\uff0c\u4f46\u9664\u6b64\u4e4b\u5916\uff0c\u53ea\u6709 void\u3002\u4e3a\u9632\u6b62\u8f66\u8f86\u6389\u51fa\u8def\u9762\uff0c\u91c7\u53d6\u4e86\u4e24\u9879\u63aa\u65bd\u3002 \u5728\u8f66\u8f86\u6d41\u52a8\u6700\u590d\u6742\u7684\u8def\u53e3\uff0c\u8f66\u9053\u7a0d\u5bbd\u4e00\u4e9b\u3002 \u5728\u9053\u8def\u7684\u8fb9\u754c\u5904\u521b\u5efa\u4e86\u53ef\u89c1\u7684\u5899\u58c1\uff0c\u4f5c\u4e3a\u6700\u540e\u7684\u5b89\u5168\u63aa\u65bd\u3002 \u4ea4\u901a\u4fe1\u53f7\u706f\u3001\u505c\u8f66\u70b9\u548c\u6536\u76ca\u5c06\u5373\u65f6\u751f\u6210\u3002\u884c\u4eba\u5c06\u5728\u5730\u56fe\u4e0a\u663e\u793a\u7684\u4eba\u884c\u9053\u548c\u4eba\u884c\u6a2a\u9053\u4e0a\u5bfc\u822a\u3002\u6240\u6709\u8fd9\u4e9b\u5143\u7d20\uff0c\u4ee5\u53ca\u9053\u8def\u4e0a\u7684\u6bcf\u4e00\u4e2a\u7ec6\u8282\uff0c\u90fd\u57fa\u4e8e OpenDRIVE \u6587\u4ef6\u3002\u7531\u4e8e\u72ec\u7acb\u6a21\u5f0f\u76f4\u63a5\u4f7f\u7528 .xodr \uff0c\u56e0\u6b64\u5176\u4e2d\u7684\u4efb\u4f55\u95ee\u9898\u90fd\u4f1a\u5f71\u54cd\u5230\u6a21\u62df\u3002\u8fd9\u53ef\u80fd\u662f\u4e00\u4e2a\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u8bb8\u591a\u8f66\u9053\u6df7\u5408\u7684\u8def\u53e3\u3002 \u91cd\u8981\u7684 \u4ed4\u7ec6\u68c0\u67e5 OpenDRIVE \u6587\u4ef6\u5c24\u4e3a\u91cd\u8981\u3002\u8fd0\u884c\u6a21\u62df\u65f6\uff0c\u5176\u4e2d\u7684\u4efb\u4f55\u95ee\u9898\u90fd\u4f1a\u4f20\u64ad\u3002 \u8fd0\u884c\u72ec\u7acb\u5730\u56fe \u6253\u5f00 OpenDRIVE \u6587\u4ef6\u53ea\u9700\u901a\u8fc7 API \u8c03\u7528 client.generate_opendrive_world() \u3002\u8fd9\u5c06\u751f\u6210\u65b0\u5730\u56fe\uff0c\u5e76\u963b\u6b62\u6a21\u62df\uff0c\u76f4\u5230\u5b83\u51c6\u5907\u597d\u3002\u8be5\u65b9\u6cd5\u9700\u8981\u4e24\u4e2a\u53c2\u6570\u3002 opendrive \u662f\u89e3\u6790\u4e3a\u5b57\u7b26\u4e32\u7684 OpenDRIVE \u6587\u4ef6\u7684\u5185\u5bb9\u3002 parameters \u662f\u4e00\u4e2a carla.OpendriveGenerationParameters \u5305\u542b\u7f51\u683c\u751f\u6210\u7684\u8bbe\u7f6e\u3002 \u8fd9\u4e2a\u53c2\u6570\u662f\u53ef\u9009\u7684 \u3002 vertex_distance \uff08\u9ed8\u8ba4 2.0 \u7c73\uff09 - \u7f51\u683c\u9876\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002\u8ddd\u79bb\u8d8a\u5927\uff0c\u7f51\u683c\u8d8a\u4e0d\u51c6\u786e\u3002\u4f46\u662f\uff0c\u5982\u679c\u8ddd\u79bb\u592a\u5c0f\uff0c\u751f\u6210\u7684\u7f51\u683c\u5c06\u592a\u91cd\u800c\u65e0\u6cd5\u4f7f\u7528\u3002 max_road_length \uff08\u9ed8\u8ba4 50.0 \u7c73\uff09 - \u7f51\u683c\u7684\u4e00\u90e8\u5206\u7684\u6700\u5927\u957f\u5ea6\u3002\u7f51\u683c\u88ab\u5206\u6210\u51e0\u90e8\u5206\u4ee5\u51cf\u5c11\u6e32\u67d3\u5f00\u9500\u3002\u5982\u679c\u4e00\u90e8\u5206\u4e0d\u53ef\u89c1\uff0cUE \u5c06\u4e0d\u4f1a\u6e32\u67d3\u5b83\u3002\u90e8\u5206\u8d8a\u5c0f\uff0c\u5b83\u4eec\u88ab\u4e22\u5f03\u7684\u53ef\u80fd\u6027\u5c31\u8d8a\u5927\u3002\u4f46\u662f\uff0c\u5982\u679c\u90e8\u5206\u592a\u5c0f\uff0cUE \u9700\u8981\u7ba1\u7406\u7684\u5bf9\u8c61\u592a\u591a\uff0c\u6027\u80fd\u4e5f\u4f1a\u53d7\u5230\u5f71\u54cd\u3002 wall_height \uff08\u9ed8\u8ba4\u4e3a 1.0 \u7c73\uff09 - \u5728\u9053\u8def\u8fb9\u754c\u4e0a\u521b\u5efa\u7684\u9644\u52a0\u5899\u7684\u9ad8\u5ea6\u3002\u8fd9\u4e9b\u53ef\u4ee5\u9632\u6b62\u8f66\u8f86\u5760\u5165\u865a\u7a7a\u3002 additional_width \uff08\u9ed8\u8ba4\u4e3a 0.6 \u7c73\uff0c\u6bcf\u8fb9 0.3\uff09 \u2014 \u5e94\u7528\u4e8e\u4ea4\u53c9\u8def\u53e3\u7684\u5c0f\u5bbd\u5ea6\u589e\u91cf\u3002\u8fd9\u662f\u9632\u6b62\u8f66\u8f86\u5760\u843d\u7684\u5b89\u5168\u63aa\u65bd\u3002 smooth_junctions (default True) \u2014 \u5982\u679c True \uff0cOpenDRIVE \u7684\u4e00\u4e9b\u4fe1\u606f\u5c06\u88ab\u91cd\u65b0\u89e3\u91ca\u4ee5\u5e73\u6ed1\u8fde\u63a5\u5904\u7684\u6700\u7ec8\u7f51\u683c\u3002\u8fd9\u6837\u505a\u662f\u4e3a\u4e86\u9632\u6b62\u5728\u4e0d\u540c\u8f66\u9053\u76f8\u9047\u65f6\u53ef\u80fd\u53d1\u751f\u7684\u4e00\u4e9b\u4e0d\u51c6\u786e\u3002\u5982\u679c\u8bbe\u7f6e\u4e3a False \uff0c\u7f51\u683c\u5c06\u5b8c\u5168\u6309\u7167 OpenDRIVE \u4e2d\u7684\u63cf\u8ff0\u751f\u6210\u3002 enable_mesh_visibility (default True) \u2014 \u5982\u679c False \uff0c\u7f51\u683c\u5c06\u4e0d\u4f1a\u88ab\u6e32\u67d3\uff0c\u8fd9\u53ef\u4ee5\u4e3a\u6a21\u62df\u5668\u8282\u7701\u5927\u91cf\u6e32\u67d3\u5de5\u4f5c\u3002 \u4e3a\u4e86\u8f7b\u677e\u6d4b\u8bd5\u6b64\u529f\u80fd\uff0c PythonAPI/util/ \u4e2d\u7684 config.py \u811a\u672c\u6709\u4e00\u4e2a\u65b0\u53c2\u6570\uff0c -x \u6216 --xodr-path \u3002\u6b64\u53c2\u6570\u9700\u8981\u4e00\u4e2a\u5e26\u6709 .xodr \u6587\u4ef6\u8def\u5f84\u7684\u5b57\u7b26\u4e32\uff0c\u4f8b\u5982 path/example.xodr \u3002\u5982\u679c\u4f7f\u7528\u6b64\u811a\u672c\u751f\u6210\u7f51\u683c\uff0c\u5219\u4f7f\u7528\u7684\u53c2\u6570\u5c06\u59cb\u7ec8\u4e3a\u9ed8\u8ba4\u53c2\u6570\u3002 \u6b64\u529f\u80fd\u53ef\u4ee5\u4f7f\u7528 CARLA \u63d0\u4f9b\u7684\u65b0 TownBig \u8fdb\u884c\u6d4b\u8bd5\u3002 python3 config.py -x opendrive/TownBig.xodr \u91cd\u8981\u7684 client.generate_opendrive_world() \u4f7f\u7528 OpenDRIVE \u6587\u4ef6\u7684\u5185\u5bb9\u89e3\u6790\u4e3a\u5b57\u7b26\u4e32 \u3002\u76f8\u53cd\uff0c config.py \u811a\u672c\u9700\u8981 .xodr \u6587\u4ef6\u7684\u8def\u5f84 \u3002 \u6ce8\u610f \u5982\u679c\u9047\u5230 opendrive \u65e0\u6cd5\u6b63\u786e\u89e3\u6790 \u9519\u8bef\uff0c\u8bf7\u786e\u4fdd\u5bf9 CarlaUE4/Content/Carla/Maps/OpenDrive/ \u76ee\u5f55\u6709\u5199\u6743\u9650\u3002\u8fd9\u662f\u670d\u52a1\u5668\u6b63\u786e\u89e3\u6790 xodr \u6587\u4ef6\u6240\u5fc5\u9700\u7684\u3002 \u7f51\u683c\u751f\u6210 \u7f51\u683c\u7684\u751f\u6210\u662f\u8be5\u6a21\u5f0f\u7684\u5173\u952e\u8981\u7d20\u3002\u53ea\u6709\u5f53\u751f\u6210\u7684\u7f51\u683c\u662f\u5e73\u6ed1\u7684\u5e76\u4e14\u5b8c\u5168\u7b26\u5408\u5176\u5b9a\u4e49\u65f6\uff0c\u8be5\u529f\u80fd\u624d\u80fd\u6210\u529f\u3002\u51fa\u4e8e\u8fd9\u4e2a\u539f\u56e0\uff0c\u8fd9\u4e00\u6b65\u6b63\u5728\u4e0d\u65ad\u6539\u8fdb\u3002\u5728\u6700\u540e\u7684\u8fed\u4ee3\u4e2d\uff0c\u8fde\u63a5\u70b9\u5df2\u7ecf\u8fc7\u629b\u5149\u4ee5\u907f\u514d\u4e0d\u51c6\u786e \u53d1\u751f\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u5e73\u5766\u7684\u8f66\u9053\u8fde\u63a5\u5904\u3002 \u5728\u751f\u6210\u4ea4\u6c47\u70b9\u7f51\u683c\u65f6\uff0c\u8f83\u9ad8\u7684\u8f66\u9053\u5f80\u5f80\u4f1a\u963b\u6321\u4e0b\u65b9\u7684\u8f66\u9053\u3002 smooth_junctions \u53c2\u6570\u53ef\u9632\u6b62\u6b64\u7c7b\u95ee\u9898\u3002 \u9664\u6b64\u4e4b\u5916\uff0c\u4e0d\u662f\u5c06\u6574\u4e2a\u5730\u56fe\u521b\u5efa\u4e3a\u4e00\u4e2a\u72ec\u7279\u7684\u7f51\u683c\uff0c\u800c\u662f\u521b\u5efa\u4e0d\u540c\u7684\u90e8\u5206\u3002\u901a\u8fc7\u5212\u5206\u7f51\u683c\uff0c\u6a21\u62df\u5668\u53ef\u4ee5\u907f\u514d\u6e32\u67d3\u4e0d\u53ef\u89c1\u7684\u90e8\u5206\uff0c\u5e76\u8282\u7701\u6210\u672c\u3002\u5de5\u4f5c\u66f4\u5c0f\u8fd8\u5141\u8bb8\u751f\u6210\u5de8\u5927\u7684\u5730\u56fe\u5e76\u5305\u542b\u53ef\u80fd\u51fa\u73b0\u5728\u7f51\u683c\u7684\u4e00\u5c0f\u90e8\u5206\u4e0a\u7684\u95ee\u9898\u3002 \u5173\u4e8e\u7f51\u683c\u751f\u6210\u7684\u5f53\u524d\u72b6\u6001\uff0c\u5e94\u8003\u8651\u4e00\u4e9b\u56e0\u7d20\u3002 \u7ed3\u5e73\u6ed1 \u3002\u9ed8\u8ba4\u5e73\u6ed1\u53ef\u9632\u6b62\u4e0a\u8ff0\u503e\u659c\u8fde\u63a5\u5904\u7684\u95ee\u9898\u3002\u4f46\u662f\uff0c\u5b83\u4f1a\u5728\u6b64\u8fc7\u7a0b\u4e2d\u4fee\u6539\u539f\u59cb\u7f51\u683c\u3002\u5982\u679c\u613f\u610f\uff0c\u5c06 smooth_junctions \u8bbe\u7f6e\u4e3a False \u4ee5\u7981\u7528\u5e73\u6ed1\u3002 \u6a2a\u5411\u5761\u5ea6 \u3002\u6b64\u529f\u80fd\u5f53\u524d\u672a\u96c6\u6210\u5728 CARLA \u4e2d\u3002 \u4eba\u884c\u9053\u9ad8\u5ea6 \u3002\u76ee\u524d\uff0c\u6240\u6709\u4eba\u884c\u9053\u7684\u786c\u7f16\u7801\u90fd\u662f\u76f8\u540c\u7684\u3002\u4eba\u884c\u9053\u5fc5\u987b\u9ad8\u4e8e\u9053\u8def\u6807\u9ad8\u624d\u80fd\u68c0\u6d4b\u5230\u78b0\u649e\uff0c\u4f46 RoadRunner \u4e0d\u4f1a\u5c06\u6b64\u503c\u5bfc\u51fa\u5230 OpenDRIVE \u6587\u4ef6\u3002\u9ad8\u5ea6\u662f\u786c\u7f16\u7801\u7684\uff0c\u4ee5\u4fdd\u8bc1\u78b0\u649e\u3002 \u8fd9\u6db5\u76d6\u4e86\u5230\u76ee\u524d\u4e3a\u6b62\u5173\u4e8e OpenDRIVE \u72ec\u7acb\u6a21\u5f0f\u7684\u6240\u6709\u4fe1\u606f\u3002\u6293\u4f4f\u673a\u4f1a\u5e76\u4f7f\u7528\u4efb\u4f55 OpenDRIVE \u5730\u56fe\u5728 CARLA \u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002 \u8bba\u575b\u4e2d\u7684\u7591\u95ee\u548c\u5efa\u8bae\u3002 CARLA\u8bba\u575b","title":"OpenDRIVE \u72ec\u7acb\u6a21\u5f0f"},{"location":"adv_opendrive/#opendrive","text":"\u6b64\u529f\u80fd\u5141\u8bb8\u7528\u6237\u5c06\u4efb\u4f55 OpenDRIVE \u6587\u4ef6\u4f5c\u4e3a CARLA \u5730\u56fe\u5f00\u7bb1\u5373\u7528\u3002\u4e3a\u6b64\uff0c\u6a21\u62df\u5668\u5c06\u81ea\u52a8\u751f\u6210\u9053\u8def\u7f51\u683c\u4f9b\u89d2\u8272\u5bfc\u822a\u3002 \u6982\u8ff0 \u8fd0\u884c\u72ec\u7acb\u5730\u56fe \u7f51\u683c\u751f\u6210","title":"OpenDRIVE\u72ec\u7acb\u6a21\u5f0f"},{"location":"adv_opendrive/#_1","text":"\u6b64\u6a21\u5f0f\u4ec5\u4f7f\u7528 OpenDRIVE \u6587\u4ef6\u8fd0\u884c\u5b8c\u6574\u6a21\u62df\uff0c\u65e0\u9700\u4efb\u4f55\u989d\u5916\u7684\u51e0\u4f55\u56fe\u5f62\u6216\u8d44\u4ea7\u3002\u4e3a\u6b64\uff0c\u6a21\u62df\u5668\u91c7\u7528 OpenDRIVE \u6587\u4ef6\u5e76\u7a0b\u5e8f\u5316\u5730\u521b\u5efa\u65f6\u95f4 3D \u7f51\u683c\u6765\u8fd0\u884c\u6a21\u62df\u3002 \u751f\u6210\u7684\u7f51\u683c\u4ee5\u7b80\u7ea6\u7684\u65b9\u5f0f\u63cf\u8ff0\u4e86\u9053\u8def\u5b9a\u4e49\u3002\u6240\u6709\u5143\u7d20\u90fd\u5c06\u4e0e OpenDRIVE \u6587\u4ef6\u5bf9\u5e94\uff0c\u4f46\u9664\u6b64\u4e4b\u5916\uff0c\u53ea\u6709 void\u3002\u4e3a\u9632\u6b62\u8f66\u8f86\u6389\u51fa\u8def\u9762\uff0c\u91c7\u53d6\u4e86\u4e24\u9879\u63aa\u65bd\u3002 \u5728\u8f66\u8f86\u6d41\u52a8\u6700\u590d\u6742\u7684\u8def\u53e3\uff0c\u8f66\u9053\u7a0d\u5bbd\u4e00\u4e9b\u3002 \u5728\u9053\u8def\u7684\u8fb9\u754c\u5904\u521b\u5efa\u4e86\u53ef\u89c1\u7684\u5899\u58c1\uff0c\u4f5c\u4e3a\u6700\u540e\u7684\u5b89\u5168\u63aa\u65bd\u3002 \u4ea4\u901a\u4fe1\u53f7\u706f\u3001\u505c\u8f66\u70b9\u548c\u6536\u76ca\u5c06\u5373\u65f6\u751f\u6210\u3002\u884c\u4eba\u5c06\u5728\u5730\u56fe\u4e0a\u663e\u793a\u7684\u4eba\u884c\u9053\u548c\u4eba\u884c\u6a2a\u9053\u4e0a\u5bfc\u822a\u3002\u6240\u6709\u8fd9\u4e9b\u5143\u7d20\uff0c\u4ee5\u53ca\u9053\u8def\u4e0a\u7684\u6bcf\u4e00\u4e2a\u7ec6\u8282\uff0c\u90fd\u57fa\u4e8e OpenDRIVE \u6587\u4ef6\u3002\u7531\u4e8e\u72ec\u7acb\u6a21\u5f0f\u76f4\u63a5\u4f7f\u7528 .xodr \uff0c\u56e0\u6b64\u5176\u4e2d\u7684\u4efb\u4f55\u95ee\u9898\u90fd\u4f1a\u5f71\u54cd\u5230\u6a21\u62df\u3002\u8fd9\u53ef\u80fd\u662f\u4e00\u4e2a\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u8bb8\u591a\u8f66\u9053\u6df7\u5408\u7684\u8def\u53e3\u3002 \u91cd\u8981\u7684 \u4ed4\u7ec6\u68c0\u67e5 OpenDRIVE \u6587\u4ef6\u5c24\u4e3a\u91cd\u8981\u3002\u8fd0\u884c\u6a21\u62df\u65f6\uff0c\u5176\u4e2d\u7684\u4efb\u4f55\u95ee\u9898\u90fd\u4f1a\u4f20\u64ad\u3002","title":"\u6982\u8ff0"},{"location":"adv_opendrive/#_2","text":"\u6253\u5f00 OpenDRIVE \u6587\u4ef6\u53ea\u9700\u901a\u8fc7 API \u8c03\u7528 client.generate_opendrive_world() \u3002\u8fd9\u5c06\u751f\u6210\u65b0\u5730\u56fe\uff0c\u5e76\u963b\u6b62\u6a21\u62df\uff0c\u76f4\u5230\u5b83\u51c6\u5907\u597d\u3002\u8be5\u65b9\u6cd5\u9700\u8981\u4e24\u4e2a\u53c2\u6570\u3002 opendrive \u662f\u89e3\u6790\u4e3a\u5b57\u7b26\u4e32\u7684 OpenDRIVE \u6587\u4ef6\u7684\u5185\u5bb9\u3002 parameters \u662f\u4e00\u4e2a carla.OpendriveGenerationParameters \u5305\u542b\u7f51\u683c\u751f\u6210\u7684\u8bbe\u7f6e\u3002 \u8fd9\u4e2a\u53c2\u6570\u662f\u53ef\u9009\u7684 \u3002 vertex_distance \uff08\u9ed8\u8ba4 2.0 \u7c73\uff09 - \u7f51\u683c\u9876\u70b9\u4e4b\u95f4\u7684\u8ddd\u79bb\u3002\u8ddd\u79bb\u8d8a\u5927\uff0c\u7f51\u683c\u8d8a\u4e0d\u51c6\u786e\u3002\u4f46\u662f\uff0c\u5982\u679c\u8ddd\u79bb\u592a\u5c0f\uff0c\u751f\u6210\u7684\u7f51\u683c\u5c06\u592a\u91cd\u800c\u65e0\u6cd5\u4f7f\u7528\u3002 max_road_length \uff08\u9ed8\u8ba4 50.0 \u7c73\uff09 - \u7f51\u683c\u7684\u4e00\u90e8\u5206\u7684\u6700\u5927\u957f\u5ea6\u3002\u7f51\u683c\u88ab\u5206\u6210\u51e0\u90e8\u5206\u4ee5\u51cf\u5c11\u6e32\u67d3\u5f00\u9500\u3002\u5982\u679c\u4e00\u90e8\u5206\u4e0d\u53ef\u89c1\uff0cUE \u5c06\u4e0d\u4f1a\u6e32\u67d3\u5b83\u3002\u90e8\u5206\u8d8a\u5c0f\uff0c\u5b83\u4eec\u88ab\u4e22\u5f03\u7684\u53ef\u80fd\u6027\u5c31\u8d8a\u5927\u3002\u4f46\u662f\uff0c\u5982\u679c\u90e8\u5206\u592a\u5c0f\uff0cUE \u9700\u8981\u7ba1\u7406\u7684\u5bf9\u8c61\u592a\u591a\uff0c\u6027\u80fd\u4e5f\u4f1a\u53d7\u5230\u5f71\u54cd\u3002 wall_height \uff08\u9ed8\u8ba4\u4e3a 1.0 \u7c73\uff09 - \u5728\u9053\u8def\u8fb9\u754c\u4e0a\u521b\u5efa\u7684\u9644\u52a0\u5899\u7684\u9ad8\u5ea6\u3002\u8fd9\u4e9b\u53ef\u4ee5\u9632\u6b62\u8f66\u8f86\u5760\u5165\u865a\u7a7a\u3002 additional_width \uff08\u9ed8\u8ba4\u4e3a 0.6 \u7c73\uff0c\u6bcf\u8fb9 0.3\uff09 \u2014 \u5e94\u7528\u4e8e\u4ea4\u53c9\u8def\u53e3\u7684\u5c0f\u5bbd\u5ea6\u589e\u91cf\u3002\u8fd9\u662f\u9632\u6b62\u8f66\u8f86\u5760\u843d\u7684\u5b89\u5168\u63aa\u65bd\u3002 smooth_junctions (default True) \u2014 \u5982\u679c True \uff0cOpenDRIVE \u7684\u4e00\u4e9b\u4fe1\u606f\u5c06\u88ab\u91cd\u65b0\u89e3\u91ca\u4ee5\u5e73\u6ed1\u8fde\u63a5\u5904\u7684\u6700\u7ec8\u7f51\u683c\u3002\u8fd9\u6837\u505a\u662f\u4e3a\u4e86\u9632\u6b62\u5728\u4e0d\u540c\u8f66\u9053\u76f8\u9047\u65f6\u53ef\u80fd\u53d1\u751f\u7684\u4e00\u4e9b\u4e0d\u51c6\u786e\u3002\u5982\u679c\u8bbe\u7f6e\u4e3a False \uff0c\u7f51\u683c\u5c06\u5b8c\u5168\u6309\u7167 OpenDRIVE \u4e2d\u7684\u63cf\u8ff0\u751f\u6210\u3002 enable_mesh_visibility (default True) \u2014 \u5982\u679c False \uff0c\u7f51\u683c\u5c06\u4e0d\u4f1a\u88ab\u6e32\u67d3\uff0c\u8fd9\u53ef\u4ee5\u4e3a\u6a21\u62df\u5668\u8282\u7701\u5927\u91cf\u6e32\u67d3\u5de5\u4f5c\u3002 \u4e3a\u4e86\u8f7b\u677e\u6d4b\u8bd5\u6b64\u529f\u80fd\uff0c PythonAPI/util/ \u4e2d\u7684 config.py \u811a\u672c\u6709\u4e00\u4e2a\u65b0\u53c2\u6570\uff0c -x \u6216 --xodr-path \u3002\u6b64\u53c2\u6570\u9700\u8981\u4e00\u4e2a\u5e26\u6709 .xodr \u6587\u4ef6\u8def\u5f84\u7684\u5b57\u7b26\u4e32\uff0c\u4f8b\u5982 path/example.xodr \u3002\u5982\u679c\u4f7f\u7528\u6b64\u811a\u672c\u751f\u6210\u7f51\u683c\uff0c\u5219\u4f7f\u7528\u7684\u53c2\u6570\u5c06\u59cb\u7ec8\u4e3a\u9ed8\u8ba4\u53c2\u6570\u3002 \u6b64\u529f\u80fd\u53ef\u4ee5\u4f7f\u7528 CARLA \u63d0\u4f9b\u7684\u65b0 TownBig \u8fdb\u884c\u6d4b\u8bd5\u3002 python3 config.py -x opendrive/TownBig.xodr \u91cd\u8981\u7684 client.generate_opendrive_world() \u4f7f\u7528 OpenDRIVE \u6587\u4ef6\u7684\u5185\u5bb9\u89e3\u6790\u4e3a\u5b57\u7b26\u4e32 \u3002\u76f8\u53cd\uff0c config.py \u811a\u672c\u9700\u8981 .xodr \u6587\u4ef6\u7684\u8def\u5f84 \u3002 \u6ce8\u610f \u5982\u679c\u9047\u5230 opendrive \u65e0\u6cd5\u6b63\u786e\u89e3\u6790 \u9519\u8bef\uff0c\u8bf7\u786e\u4fdd\u5bf9 CarlaUE4/Content/Carla/Maps/OpenDrive/ \u76ee\u5f55\u6709\u5199\u6743\u9650\u3002\u8fd9\u662f\u670d\u52a1\u5668\u6b63\u786e\u89e3\u6790 xodr \u6587\u4ef6\u6240\u5fc5\u9700\u7684\u3002","title":"\u8fd0\u884c\u72ec\u7acb\u5730\u56fe"},{"location":"adv_opendrive/#_3","text":"\u7f51\u683c\u7684\u751f\u6210\u662f\u8be5\u6a21\u5f0f\u7684\u5173\u952e\u8981\u7d20\u3002\u53ea\u6709\u5f53\u751f\u6210\u7684\u7f51\u683c\u662f\u5e73\u6ed1\u7684\u5e76\u4e14\u5b8c\u5168\u7b26\u5408\u5176\u5b9a\u4e49\u65f6\uff0c\u8be5\u529f\u80fd\u624d\u80fd\u6210\u529f\u3002\u51fa\u4e8e\u8fd9\u4e2a\u539f\u56e0\uff0c\u8fd9\u4e00\u6b65\u6b63\u5728\u4e0d\u65ad\u6539\u8fdb\u3002\u5728\u6700\u540e\u7684\u8fed\u4ee3\u4e2d\uff0c\u8fde\u63a5\u70b9\u5df2\u7ecf\u8fc7\u629b\u5149\u4ee5\u907f\u514d\u4e0d\u51c6\u786e \u53d1\u751f\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u5e73\u5766\u7684\u8f66\u9053\u8fde\u63a5\u5904\u3002 \u5728\u751f\u6210\u4ea4\u6c47\u70b9\u7f51\u683c\u65f6\uff0c\u8f83\u9ad8\u7684\u8f66\u9053\u5f80\u5f80\u4f1a\u963b\u6321\u4e0b\u65b9\u7684\u8f66\u9053\u3002 smooth_junctions \u53c2\u6570\u53ef\u9632\u6b62\u6b64\u7c7b\u95ee\u9898\u3002 \u9664\u6b64\u4e4b\u5916\uff0c\u4e0d\u662f\u5c06\u6574\u4e2a\u5730\u56fe\u521b\u5efa\u4e3a\u4e00\u4e2a\u72ec\u7279\u7684\u7f51\u683c\uff0c\u800c\u662f\u521b\u5efa\u4e0d\u540c\u7684\u90e8\u5206\u3002\u901a\u8fc7\u5212\u5206\u7f51\u683c\uff0c\u6a21\u62df\u5668\u53ef\u4ee5\u907f\u514d\u6e32\u67d3\u4e0d\u53ef\u89c1\u7684\u90e8\u5206\uff0c\u5e76\u8282\u7701\u6210\u672c\u3002\u5de5\u4f5c\u66f4\u5c0f\u8fd8\u5141\u8bb8\u751f\u6210\u5de8\u5927\u7684\u5730\u56fe\u5e76\u5305\u542b\u53ef\u80fd\u51fa\u73b0\u5728\u7f51\u683c\u7684\u4e00\u5c0f\u90e8\u5206\u4e0a\u7684\u95ee\u9898\u3002 \u5173\u4e8e\u7f51\u683c\u751f\u6210\u7684\u5f53\u524d\u72b6\u6001\uff0c\u5e94\u8003\u8651\u4e00\u4e9b\u56e0\u7d20\u3002 \u7ed3\u5e73\u6ed1 \u3002\u9ed8\u8ba4\u5e73\u6ed1\u53ef\u9632\u6b62\u4e0a\u8ff0\u503e\u659c\u8fde\u63a5\u5904\u7684\u95ee\u9898\u3002\u4f46\u662f\uff0c\u5b83\u4f1a\u5728\u6b64\u8fc7\u7a0b\u4e2d\u4fee\u6539\u539f\u59cb\u7f51\u683c\u3002\u5982\u679c\u613f\u610f\uff0c\u5c06 smooth_junctions \u8bbe\u7f6e\u4e3a False \u4ee5\u7981\u7528\u5e73\u6ed1\u3002 \u6a2a\u5411\u5761\u5ea6 \u3002\u6b64\u529f\u80fd\u5f53\u524d\u672a\u96c6\u6210\u5728 CARLA \u4e2d\u3002 \u4eba\u884c\u9053\u9ad8\u5ea6 \u3002\u76ee\u524d\uff0c\u6240\u6709\u4eba\u884c\u9053\u7684\u786c\u7f16\u7801\u90fd\u662f\u76f8\u540c\u7684\u3002\u4eba\u884c\u9053\u5fc5\u987b\u9ad8\u4e8e\u9053\u8def\u6807\u9ad8\u624d\u80fd\u68c0\u6d4b\u5230\u78b0\u649e\uff0c\u4f46 RoadRunner \u4e0d\u4f1a\u5c06\u6b64\u503c\u5bfc\u51fa\u5230 OpenDRIVE \u6587\u4ef6\u3002\u9ad8\u5ea6\u662f\u786c\u7f16\u7801\u7684\uff0c\u4ee5\u4fdd\u8bc1\u78b0\u649e\u3002 \u8fd9\u6db5\u76d6\u4e86\u5230\u76ee\u524d\u4e3a\u6b62\u5173\u4e8e OpenDRIVE \u72ec\u7acb\u6a21\u5f0f\u7684\u6240\u6709\u4fe1\u606f\u3002\u6293\u4f4f\u673a\u4f1a\u5e76\u4f7f\u7528\u4efb\u4f55 OpenDRIVE \u5730\u56fe\u5728 CARLA \u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002 \u8bba\u575b\u4e2d\u7684\u7591\u95ee\u548c\u5efa\u8bae\u3002 CARLA\u8bba\u575b","title":"\u7f51\u683c\u751f\u6210"},{"location":"adv_ptv/","text":"PTV-Vissim \u8054\u5408\u4eff\u771f CARLA \u5f00\u53d1\u4e86\u4e0e PTV-Vissim \u7684\u534f\u540c\u4eff\u771f\u529f\u80fd\u3002\u8fd9\u5141\u8bb8\u968f\u610f\u5206\u914d\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u6bcf\u4e2a\u6a21\u62df\u7684\u80fd\u529b\u6709\u5229\u4e8e\u7528\u6237\u3002 \u5fc5\u5907\u6761\u4ef6 \u8fd0\u884c\u534f\u540c\u4eff\u771f \u521b\u5efa\u65b0\u7f51\u7edc \u5fc5\u5907\u6761\u4ef6 \u4e3a\u4e86\u8fd0\u884c\u534f\u540c\u4eff\u771f\uff0c\u6709\u4e24\u4ef6\u4e8b\u662f\u5fc5\u8981\u7684\u3002 \u8d2d\u4e70 PTV-Vissim \u6a21\u62df\u5668 \u7684\u8bb8\u53ef\u8bc1\u3002\u9700\u8981\u83b7\u53d6\u9a7e\u9a76\u6a21\u62df\u5668\u754c\u9762\u63d2\u4ef6\u3002 \u5728 PTV-Vissim \u5b89\u88c5\u6587\u4ef6\u5939\u4e2d\uff0c\u67e5\u627e DrivingSimulatorProxy.dll \u3002\u5c06\u5176\u79fb\u81f3 C:\\Windows\\System32 \u3002 \u8fd0\u884c\u8054\u5408\u4eff\u771f \u4e0e\u6b64\u529f\u80fd\u76f8\u5173\u7684\u6240\u6709\u5185\u5bb9\u90fd\u53ef\u4ee5\u5728\u201cCo-Simulation/PTV-Vissim\u201d\u4e2d\u627e\u5230\u3002 CARLA \u63d0\u4f9b\u4e86\u4e00\u4e9b\u793a\u4f8b\uff0c\u5176\u4e2d\u5305\u542b Town01 \u548c Town03 \u7684\u7f51\u7edc\u3002 \u8981\u8fd0\u884c\u8054\u5408\u4eff\u771f\uff0c\u8bf7\u4f7f\u7528\u811a\u672c PTV-Vissim/run_synchronization.py \u3002\u8fd9\u6709\u4e00\u4e2a\u5305\u542b PTV-Vissim \u7f51\u7edc\u7684\u5f3a\u5236\u53c2\u6570\u548c\u4e00\u4e9b\u5176\u4ed6\u53ef\u9009\u53c2\u6570\u3002 vissim_network \u2014 vissim \u7f51\u7edc\u6587\u4ef6\u3002\u8fd9\u53ef\u4ee5\u662f\u4e00\u4e2a\u793a\u4f8b\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u81ea\u884c\u521b\u5efa\u7684 PTV-Vissim \u7f51\u7edc\u3002 --carla-host \uff08\u9ed8\u8ba4\u503c\uff1a127.0.0.1\uff09 \u2014 carla \u4e3b\u673a\u670d\u52a1\u5668\u7684 IP\u3002 --carla-port \uff08\u9ed8\u8ba4\u503c\uff1a2000\uff09 \u8981\u76d1\u542c\u7684 TCP \u7aef\u53e3\u3002 --vissim-version \uff08\u9ed8\u8ba4\u503c\uff1a2020\uff09 \u2014 PTV-Vissim \u7248\u672c\u3002 --step-length (default: 0.05s) - \u4e3a\u6a21\u62df\u65f6\u95f4\u6b65\u8bbe\u7f6e\u56fa\u5b9a\u7684\u589e\u91cf\u79d2\u3002 --simulator-vehicles \uff08\u9ed8\u8ba4\u503c\uff1a1\uff09 \u2014 \u5c06\u5728 CARLA \u4e2d\u751f\u6210\u5e76\u4f20\u9012\u7ed9 PTV-Vissim \u7684\u8f66\u8f86\u6570\u91cf\u3002 python3 run_synchronization.py examples/Town03/Town03.inpx \u8b66\u544a \u8981\u505c\u6b62\u8054\u5408\u4eff\u771f\uff0c\u8bf7\u5728\u8fd0\u884c\u811a\u672c\u7684\u7ec8\u7aef\u4e2d\u6309 Ctrl+C \u3002 \u4e24\u4e2a\u6a21\u62df\u5c06\u540c\u6b65\u8fd0\u884c\u3002\u4e00\u4e2a\u6a21\u62df\u5668\u4e2d\u53d1\u751f\u7684\u52a8\u4f5c\u6216\u4e8b\u4ef6\u5c06\u4f20\u64ad\u5230\u53e6\u4e00\u4e2a\u6a21\u62df\u5668\u3002\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u8be5\u529f\u80fd\u4ec5\u5305\u62ec\u8f66\u8f86\u79fb\u52a8\u548c\u751f\u6210\u3002\u7531\u4e8e PTV-Vissim \u7c7b\u578b\uff0c\u751f\u6210\u53d7\u5230\u9650\u5236\u3002 * \u5982\u679c\u8f66\u8f86\u5728 CARLA \u4e2d\u751f\u6210\uff0c\u5e76\u4e14 PTV-Vissim \u4e2d\u7684 Vehicle Type \u8bbe\u7f6e\u4e3a\u201c\u6c7d\u8f66\u201d\uff0c\u5b83\u5c06\u751f\u6210\u6c7d\u8f66\u3002\u4e0d\u7ba1\u5b83\u662f\u5426\u5728 CARLA \u4e2d\u4f5c\u4e3a\u6469\u6258\u8f66\u3002\u5728\u63d0\u4f9b\u7684\u793a\u4f8b\u4e2d\uff0c\u8f66\u8f86\u7c7b\u578b\u8bbe\u7f6e\u4e3a\u201c\u6c7d\u8f66\u201d\u3002 * \u5982\u679c\u8f66\u8f86\u5728 PTV-Vissim \u4e2d\u751f\u6210\uff0cCARLA \u5c06\u4f7f\u7528\u76f8\u540c\u7c7b\u578b\u7684\u8f66\u8f86\u3002\u5c3a\u5bf8\u548c\u7279\u6027\u5c06\u76f8\u4f3c\uff0c\u4f46\u4e0d\u5b8c\u5168\u76f8\u540c\u3002 \u521b\u5efa\u4e00\u4e2a\u65b0\u7f51\u7edc \u4e3a\u4e86\u8ba9\u65b0\u7684 PTV-Vissim \u7f51\u7edc\u4e0e CARLA \u4e00\u8d77\u8fd0\u884c\uff0c\u9700\u8981\u5b8c\u6210\u4e00\u4e9b\u8bbe\u7f6e\u3002 \u6fc0\u6d3b\u9a7e\u9a76\u6a21\u62df\u5668 \u3002\u8f6c\u5230 Base Data/Network setting/Driving simulator \u5e76\u542f\u7528\u8be5\u9009\u9879 \u6307\u5b9a\u8f66\u8f86\u548c\u884c\u4eba\u7c7b\u578b \u3002\u8fd9\u4e9b\u7c7b\u578b\u5c06\u5728 PTV-Vissim \u4e2d\u7528\u4e8e\u4e0e CARLA \u4e2d\u5b8c\u6210\u7684\u751f\u6210\u540c\u6b65\uff0c\u9ed8\u8ba4\u4e3a\u7a7a \u5c06\u7f51\u7edc\u5bfc\u51fa\u4e3a .inpx \u3002\u521b\u5efa\u7f51\u7edc\uff0c\u5c06\u5176\u5bfc\u51fa\uff0c\u7136\u540e\u4f7f\u7528 run_synchronization.py \u8fd0\u884c\u534f\u540c\u4eff\u771f \u5728 CARLA \u4e2d\u751f\u6210\u7684\u4efb\u4f55\u8f66\u8f86\u90fd\u5c06\u4f7f\u7528\u8fd9\u4e9b\u7c7b\u578b\u5728 PTV-Vissim \u4e2d\u751f\u6210\u3002 \u8b66\u544a \u5982\u679c\u884c\u4eba\u548c\u8f66\u8f86\u7c7b\u578b\u4e3a\u7a7a\uff0cPTV-Vissim \u5c06\u5d29\u6e83\u3002 \u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u8fd9\u5c31\u662f PTV-Vissim \u4e0e CARLA \u7684\u8054\u5408\u4eff\u771f\u7684\u5168\u90e8\u5185\u5bb9\u3002 \u6253\u5f00 CARLA \u5e76\u73a9\u5f04\u4e00\u4f1a\u513f\u3002\u5982\u679c\u6709\u4efb\u4f55\u7591\u95ee\uff0c\u8bf7\u968f\u65f6\u5728\u8bba\u575b\u4e2d\u53d1\u5e03\u3002 CARLA\u8bba\u575b","title":"PTV-Vissim \u8054\u5408\u4eff\u771f"},{"location":"adv_ptv/#ptv-vissim","text":"CARLA \u5f00\u53d1\u4e86\u4e0e PTV-Vissim \u7684\u534f\u540c\u4eff\u771f\u529f\u80fd\u3002\u8fd9\u5141\u8bb8\u968f\u610f\u5206\u914d\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u6bcf\u4e2a\u6a21\u62df\u7684\u80fd\u529b\u6709\u5229\u4e8e\u7528\u6237\u3002 \u5fc5\u5907\u6761\u4ef6 \u8fd0\u884c\u534f\u540c\u4eff\u771f \u521b\u5efa\u65b0\u7f51\u7edc","title":"PTV-Vissim \u8054\u5408\u4eff\u771f"},{"location":"adv_ptv/#_1","text":"\u4e3a\u4e86\u8fd0\u884c\u534f\u540c\u4eff\u771f\uff0c\u6709\u4e24\u4ef6\u4e8b\u662f\u5fc5\u8981\u7684\u3002 \u8d2d\u4e70 PTV-Vissim \u6a21\u62df\u5668 \u7684\u8bb8\u53ef\u8bc1\u3002\u9700\u8981\u83b7\u53d6\u9a7e\u9a76\u6a21\u62df\u5668\u754c\u9762\u63d2\u4ef6\u3002 \u5728 PTV-Vissim \u5b89\u88c5\u6587\u4ef6\u5939\u4e2d\uff0c\u67e5\u627e DrivingSimulatorProxy.dll \u3002\u5c06\u5176\u79fb\u81f3 C:\\Windows\\System32 \u3002","title":"\u5fc5\u5907\u6761\u4ef6"},{"location":"adv_ptv/#_2","text":"\u4e0e\u6b64\u529f\u80fd\u76f8\u5173\u7684\u6240\u6709\u5185\u5bb9\u90fd\u53ef\u4ee5\u5728\u201cCo-Simulation/PTV-Vissim\u201d\u4e2d\u627e\u5230\u3002 CARLA \u63d0\u4f9b\u4e86\u4e00\u4e9b\u793a\u4f8b\uff0c\u5176\u4e2d\u5305\u542b Town01 \u548c Town03 \u7684\u7f51\u7edc\u3002 \u8981\u8fd0\u884c\u8054\u5408\u4eff\u771f\uff0c\u8bf7\u4f7f\u7528\u811a\u672c PTV-Vissim/run_synchronization.py \u3002\u8fd9\u6709\u4e00\u4e2a\u5305\u542b PTV-Vissim \u7f51\u7edc\u7684\u5f3a\u5236\u53c2\u6570\u548c\u4e00\u4e9b\u5176\u4ed6\u53ef\u9009\u53c2\u6570\u3002 vissim_network \u2014 vissim \u7f51\u7edc\u6587\u4ef6\u3002\u8fd9\u53ef\u4ee5\u662f\u4e00\u4e2a\u793a\u4f8b\uff0c\u4e5f\u53ef\u4ee5\u662f\u4e00\u4e2a\u81ea\u884c\u521b\u5efa\u7684 PTV-Vissim \u7f51\u7edc\u3002 --carla-host \uff08\u9ed8\u8ba4\u503c\uff1a127.0.0.1\uff09 \u2014 carla \u4e3b\u673a\u670d\u52a1\u5668\u7684 IP\u3002 --carla-port \uff08\u9ed8\u8ba4\u503c\uff1a2000\uff09 \u8981\u76d1\u542c\u7684 TCP \u7aef\u53e3\u3002 --vissim-version \uff08\u9ed8\u8ba4\u503c\uff1a2020\uff09 \u2014 PTV-Vissim \u7248\u672c\u3002 --step-length (default: 0.05s) - \u4e3a\u6a21\u62df\u65f6\u95f4\u6b65\u8bbe\u7f6e\u56fa\u5b9a\u7684\u589e\u91cf\u79d2\u3002 --simulator-vehicles \uff08\u9ed8\u8ba4\u503c\uff1a1\uff09 \u2014 \u5c06\u5728 CARLA \u4e2d\u751f\u6210\u5e76\u4f20\u9012\u7ed9 PTV-Vissim \u7684\u8f66\u8f86\u6570\u91cf\u3002 python3 run_synchronization.py examples/Town03/Town03.inpx \u8b66\u544a \u8981\u505c\u6b62\u8054\u5408\u4eff\u771f\uff0c\u8bf7\u5728\u8fd0\u884c\u811a\u672c\u7684\u7ec8\u7aef\u4e2d\u6309 Ctrl+C \u3002 \u4e24\u4e2a\u6a21\u62df\u5c06\u540c\u6b65\u8fd0\u884c\u3002\u4e00\u4e2a\u6a21\u62df\u5668\u4e2d\u53d1\u751f\u7684\u52a8\u4f5c\u6216\u4e8b\u4ef6\u5c06\u4f20\u64ad\u5230\u53e6\u4e00\u4e2a\u6a21\u62df\u5668\u3002\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u8be5\u529f\u80fd\u4ec5\u5305\u62ec\u8f66\u8f86\u79fb\u52a8\u548c\u751f\u6210\u3002\u7531\u4e8e PTV-Vissim \u7c7b\u578b\uff0c\u751f\u6210\u53d7\u5230\u9650\u5236\u3002 * \u5982\u679c\u8f66\u8f86\u5728 CARLA \u4e2d\u751f\u6210\uff0c\u5e76\u4e14 PTV-Vissim \u4e2d\u7684 Vehicle Type \u8bbe\u7f6e\u4e3a\u201c\u6c7d\u8f66\u201d\uff0c\u5b83\u5c06\u751f\u6210\u6c7d\u8f66\u3002\u4e0d\u7ba1\u5b83\u662f\u5426\u5728 CARLA \u4e2d\u4f5c\u4e3a\u6469\u6258\u8f66\u3002\u5728\u63d0\u4f9b\u7684\u793a\u4f8b\u4e2d\uff0c\u8f66\u8f86\u7c7b\u578b\u8bbe\u7f6e\u4e3a\u201c\u6c7d\u8f66\u201d\u3002 * \u5982\u679c\u8f66\u8f86\u5728 PTV-Vissim \u4e2d\u751f\u6210\uff0cCARLA \u5c06\u4f7f\u7528\u76f8\u540c\u7c7b\u578b\u7684\u8f66\u8f86\u3002\u5c3a\u5bf8\u548c\u7279\u6027\u5c06\u76f8\u4f3c\uff0c\u4f46\u4e0d\u5b8c\u5168\u76f8\u540c\u3002","title":"\u8fd0\u884c\u8054\u5408\u4eff\u771f"},{"location":"adv_ptv/#_3","text":"\u4e3a\u4e86\u8ba9\u65b0\u7684 PTV-Vissim \u7f51\u7edc\u4e0e CARLA \u4e00\u8d77\u8fd0\u884c\uff0c\u9700\u8981\u5b8c\u6210\u4e00\u4e9b\u8bbe\u7f6e\u3002 \u6fc0\u6d3b\u9a7e\u9a76\u6a21\u62df\u5668 \u3002\u8f6c\u5230 Base Data/Network setting/Driving simulator \u5e76\u542f\u7528\u8be5\u9009\u9879 \u6307\u5b9a\u8f66\u8f86\u548c\u884c\u4eba\u7c7b\u578b \u3002\u8fd9\u4e9b\u7c7b\u578b\u5c06\u5728 PTV-Vissim \u4e2d\u7528\u4e8e\u4e0e CARLA \u4e2d\u5b8c\u6210\u7684\u751f\u6210\u540c\u6b65\uff0c\u9ed8\u8ba4\u4e3a\u7a7a \u5c06\u7f51\u7edc\u5bfc\u51fa\u4e3a .inpx \u3002\u521b\u5efa\u7f51\u7edc\uff0c\u5c06\u5176\u5bfc\u51fa\uff0c\u7136\u540e\u4f7f\u7528 run_synchronization.py \u8fd0\u884c\u534f\u540c\u4eff\u771f \u5728 CARLA \u4e2d\u751f\u6210\u7684\u4efb\u4f55\u8f66\u8f86\u90fd\u5c06\u4f7f\u7528\u8fd9\u4e9b\u7c7b\u578b\u5728 PTV-Vissim \u4e2d\u751f\u6210\u3002 \u8b66\u544a \u5982\u679c\u884c\u4eba\u548c\u8f66\u8f86\u7c7b\u578b\u4e3a\u7a7a\uff0cPTV-Vissim \u5c06\u5d29\u6e83\u3002 \u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u8fd9\u5c31\u662f PTV-Vissim \u4e0e CARLA \u7684\u8054\u5408\u4eff\u771f\u7684\u5168\u90e8\u5185\u5bb9\u3002 \u6253\u5f00 CARLA \u5e76\u73a9\u5f04\u4e00\u4f1a\u513f\u3002\u5982\u679c\u6709\u4efb\u4f55\u7591\u95ee\uff0c\u8bf7\u968f\u65f6\u5728\u8bba\u575b\u4e2d\u53d1\u5e03\u3002 CARLA\u8bba\u575b","title":"\u521b\u5efa\u4e00\u4e2a\u65b0\u7f51\u7edc"},{"location":"adv_recorder/","text":"Recorder \u6b64\u529f\u80fd\u5141\u8bb8\u8bb0\u5f55\u548c\u91cd\u65b0\u5236\u5b9a\u4ee5\u524d\u7684\u6a21\u62df\u3002\u6240\u6709\u53d1\u751f\u7684\u4e8b\u4ef6\u90fd\u8bb0\u5f55\u5728 recorder file \u4e2d\u3002\u6709\u4e00\u4e9b\u9ad8\u7ea7\u67e5\u8be2\u53ef\u4ee5\u8ddf\u8e2a\u548c\u7814\u7a76\u8fd9\u4e9b\u4e8b\u4ef6\u3002 Recording \u6a21\u62df\u64ad\u653e \u8bbe\u7f6e\u65f6\u95f4\u56e0\u5b50 \u5f55\u5236\u6587\u4ef6 \u67e5\u8be2 \u78b0\u649e \u88ab\u56f0\u4f4f\u7684\u89d2\u8272 \u793a\u4f8b Python \u811a\u672c Recording \u6240\u6709\u6570\u636e\u4ec5\u5199\u5165\u670d\u52a1\u5668\u7aef\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002\u4f46\u662f\uff0c\u4f7f\u7528 carla.Client \u7ba1\u7406\u8bb0\u5f55\u5668\u3002 \u6839\u636e\u8bb0\u5f55\u6587\u4ef6\u4e2d\u5305\u542b\u7684\u6570\u636e\uff0c\u6bcf\u5e27\u66f4\u65b0\u89d2\u8272\u3002\u5f53\u524d\u6a21\u62df\u4e2d\u51fa\u73b0\u5728\u5f55\u5236\u4e2d\u7684 Actor \u5c06\u88ab\u79fb\u52a8\u6216\u91cd\u65b0\u751f\u6210\u4ee5\u6a21\u62df\u5b83\u3002\u90a3\u4e9b\u6ca1\u6709\u51fa\u73b0\u5728\u5f55\u97f3\u4e2d\u7684\u5c06\u7ee7\u7eed\u4ed6\u4eec\u7684\u65b9\u5f0f\uff0c\u5c31\u597d\u50cf\u4ec0\u4e48\u90fd\u6ca1\u53d1\u751f\u4e00\u6837\u3002 \uff01\uff01\uff01\u91cd\u8981\u7684 \u64ad\u653e\u7ed3\u675f\u65f6\uff0c\u8f66\u8f86\u5c06\u8bbe\u7f6e\u4e3a\u81ea\u52a8\u9a7e\u9a76\uff0c\u4f46 \u884c\u4eba\u5c06\u505c\u6b62 \u3002 \u8bb0\u5f55\u5668\u6587\u4ef6\u5305\u62ec\u6709\u5173\u8bb8\u591a\u4e0d\u540c\u5143\u7d20\u7684\u4fe1\u606f\u3002 \u89d2\u8272 \u2014 \u521b\u5efa\u548c\u9500\u6bc1\u3001\u8fb9\u754c\u548c\u89e6\u53d1\u6846\u3002 \u4ea4\u901a\u706f \u2014 \u72b6\u6001\u53d8\u5316\u548c\u65f6\u95f4\u8bbe\u7f6e\u3002 \u8f66\u8f86 \u2014 \u4f4d\u7f6e\u548c\u65b9\u5411\u3001\u7ebf\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\u3001\u5149\u72b6\u6001\u548c\u7269\u7406\u63a7\u5236\u3002 \u884c\u4eba \u2014 \u4f4d\u7f6e\u548c\u65b9\u5411\uff0c\u4ee5\u53ca\u7ebf\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\u3002 \u706f\u5149 \u2014 \u6765\u81ea\u5efa\u7b51\u7269\u3001\u8857\u9053\u548c\u8f66\u8f86\u7684\u706f\u5149\u72b6\u6001\u3002 \u8981\u5f00\u59cb\u5f55\u5236\uff0c\u53ea\u9700\u8981\u4e00\u4e2a\u6587\u4ef6\u540d\u3002\u5728\u6587\u4ef6\u540d\u4e2d\u4f7f\u7528 \\ \u3001 / \u6216 : \u5b57\u7b26\u4f1a\u5c06\u5176\u5b9a\u4e49\u4e3a\u7edd\u5bf9\u8def\u5f84\u3002\u5982\u679c\u6ca1\u6709\u8be6\u7ec6\u7684\u8def\u5f84\uff0c\u6587\u4ef6\u5c06\u4fdd\u5b58\u5728 CarlaUE4/Saved \u4e2d\u3002 client.start_recorder(\"/home/carla/recording01.log\") \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8bb0\u5f55\u5668\u8bbe\u7f6e\u4e3a\u4ec5\u5b58\u50a8\u56de\u653e\u6a21\u62df\u6240\u9700\u7684\u4fe1\u606f\u3002\u4e3a\u4e86\u4fdd\u5b58\u524d\u9762\u63d0\u5230\u7684\u6240\u6709\u4fe1\u606f\uff0c\u5fc5\u987b\u5728\u5f00\u59cb\u5f55\u5236\u65f6\u914d\u7f6e\u53c2\u6570 additional_data \u3002 client.start_recorder(\"/home/carla/recording01.log\", True) \u7b14\u8bb0 \u5176\u4ed6\u6570\u636e\u5305\u62ec\uff1a\u8f66\u8f86\u548c\u884c\u4eba\u7684\u7ebf\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\u3001\u7ea2\u7eff\u706f\u65f6\u95f4\u8bbe\u7f6e\u3001\u6267\u884c\u65f6\u95f4\u3001\u6f14\u5458\u7684\u89e6\u53d1\u5668\u548c\u8fb9\u754c\u6846\uff0c\u4ee5\u53ca\u8f66\u8f86\u7684\u7269\u7406\u63a7\u5236\u3002 \u8981\u505c\u6b62\u5f55\u97f3\uff0c\u8c03\u7528\u4e5f\u5f88\u7b80\u5355\u3002 client.stop_recorder() \u7b14\u8bb0 \u636e\u4f30\u8ba1\uff0c50 \u4e2a\u7ea2\u7eff\u706f\u548c 100 \u8f86\u8f66\u7684 1 \u5c0f\u65f6\u8bb0\u5f55\u5927\u7ea6\u9700\u8981 200MB \u5927\u5c0f\u3002 \u6a21\u62df\u64ad\u653e \u53ef\u4ee5\u5728\u6a21\u62df\u8fc7\u7a0b\u4e2d\u7684\u4efb\u4f55\u65f6\u5019\u5f00\u59cb\u64ad\u653e\u3002\u9664\u4e86\u65e5\u5fd7\u6587\u4ef6\u7684\u8def\u5f84\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u8fd8\u9700\u8981\u4e00\u4e9b\u53c2\u6570\u3002 client.replay_file(\"recording01.log\", start, duration, camera) \u53c2\u6570 \u8bf4\u660e \u7b14\u8bb0 \u5f00\u59cb \u4ee5\u79d2\u4e3a\u5355\u4f4d\u8bb0\u5f55\u5f00\u59cb\u6a21\u62df\u7684\u65f6\u95f4\u3002 \u5982\u679c\u662f\u80af\u5b9a\u7684\uff0c\u65f6\u95f4\u5c06\u4ece\u8bb0\u5f55\u5f00\u59cb\u8ba1\u7b97\u3002 \u5982\u679c\u662f\u5426\u5b9a\u7684\uff0c\u5c06\u4ece\u6700\u540e\u8003\u8651\u3002 \u6301\u7eed\u65f6\u95f4 \u64ad\u653e\u79d2\u6570\u3002 0 \u662f\u6240\u6709\u7684\u5f55\u97f3\u3002 \u64ad\u653e\u7ed3\u675f\u65f6\uff0c\u8f66\u8f86\u5c06\u8bbe\u7f6e\u4e3a\u81ea\u52a8\u9a7e\u9a76\uff0c\u884c\u4eba\u5c06\u505c\u6b62\u3002 \u76f8\u673a \u76f8\u673a\u5c06\u805a\u7126\u7684\u6f14\u5458\u7684 ID\u3002 \u5c06\u5176\u8bbe\u7f6e\u4e3a\u201c0\u201d\u4ee5\u8ba9\u89c2\u4f17\u81ea\u7531\u79fb\u52a8\u3002 \u8bbe\u7f6e\u65f6\u95f4\u56e0\u5b50 \u65f6\u95f4\u56e0\u7d20\u5c06\u51b3\u5b9a\u64ad\u653e\u901f\u5ea6\u3002\u5b83\u53ef\u4ee5\u968f\u65f6\u66f4\u6539\u800c\u65e0\u9700\u505c\u6b62\u56de\u653e\u3002 client.set_replayer_time_factor(2.0) \u53c2\u6570 \u9ed8\u8ba4 \u5feb\u52a8\u4f5c \u6162\u52a8\u4f5c time_factor 1.0 >1.0 <1.0 \u91cd\u8981\u7684 \u5982\u679c time_factor>2.0 \uff0cactors \u7684\u4f4d\u7f6e\u63d2\u503c\u88ab\u7981\u7528\u5e76\u4e14\u53ea\u662f\u66f4\u65b0\u3002\u884c\u4eba\u7684\u52a8\u753b\u4e0d\u53d7\u65f6\u95f4\u56e0\u7d20\u7684\u5f71\u54cd\u3002 \u5f53\u65f6\u95f4\u56e0\u7d20\u5728 20x \u5de6\u53f3\u65f6\uff0c\u5f88\u5bb9\u6613\u7406\u89e3\u6d41\u91cf\u3002 \u5f55\u5236\u6587\u4ef6 \u53ef\u4ee5\u4f7f\u7528\u7b80\u5355\u7684 API \u8c03\u7528\u6765\u68c0\u7d22\u8bb0\u5f55\u7684\u8be6\u7ec6\u4fe1\u606f\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u53ea\u68c0\u7d22\u6ce8\u518c\u4e8b\u4ef6\u7684\u90a3\u4e9b\u5e27\u3002\u8bbe\u7f6e\u53c2\u6570 show_all \u5c06\u8fd4\u56de\u6bcf\u4e00\u5e27\u7684\u6240\u6709\u4fe1\u606f\u3002\u5173\u4e8e\u5982\u4f55\u5b58\u50a8\u6570\u636e\u7684\u7ec6\u8282\u5728 recorder's reference \u4e2d\u6709\u8be6\u7ec6\u8bf4\u660e\u3002 # \u663e\u793a\u76f8\u5173\u5e27\u7684\u4fe1\u606f print (client.show_recorder_file_info (\"recording01.log\")) \u5f00\u653e\u4fe1\u606f. \u8bb0\u5f55\u6a21\u62df\u7684\u5730\u56fe\u3001\u65e5\u671f\u548c\u65f6\u95f4\u3002 Frame information. \u4efb\u4f55\u53ef\u80fd\u53d1\u751f\u7684\u4e8b\u4ef6\uff0c\u4f8b\u5982\u89d2\u8272\u751f\u6210\u6216\u78b0\u649e\u3002\u5b83\u5305\u542b\u6f14\u5458\u7684 ID \u548c\u4e00\u4e9b\u9644\u52a0\u4fe1\u606f\u3002 \u5173\u95ed\u4fe1\u606f. \u8bb0\u5f55\u7684\u5e27\u6570\u548c\u603b\u65f6\u95f4\u3002 Version: 1 Map: Town05 Date: 02/21/19 10:46:20 Frame 1 at 0 seconds Create 2190: spectator (0) at (-260, -200, 382.001) Create 2191: traffic.traffic_light (3) at (4255, 10020, 0) Create 2192: traffic.traffic_light (3) at (4025, 7860, 0) ... Create 2258: traffic.speed_limit.90 (0) at (21651.7, -1347.59, 15) Create 2259: traffic.speed_limit.90 (0) at (5357, 21457.1, 15) Frame 2 at 0.0254253 seconds Create 2276: vehicle.mini.cooperst (1) at (4347.63, -8409.51, 120) number_of_wheels = 4 object_type = color = 255,241,0 role_name = autopilot ... Frame 2350 at 60.2805 seconds Destroy 2276 Frame 2351 at 60.3057 seconds Destroy 2277 ... Frames: 2354 Duration: 60.3753 seconds \u67e5\u8be2 \u78b0\u649e \u8f66\u8f86\u5fc5\u987b\u6709\u4e00\u4e2a \u78b0\u649e\u68c0\u6d4b\u5668 \u4ee5\u8bb0\u5f55\u78b0\u649e\u3002\u8fd9\u4e9b\u53ef\u4ee5\u88ab\u67e5\u8be2\uff0c\u4f7f\u7528\u53c2\u6570\u6765\u8fc7\u6ee4\u78b0\u649e\u4e2d\u6d89\u53ca\u7684\u53c2\u4e0e\u8005\u7684\u7c7b\u578b\u3002\u4f8b\u5982\uff0c h \u6807\u8bc6 role_name = hero \u7684\u89d2\u8272\uff0c\u901a\u5e38\u5206\u914d\u7ed9\u7528\u6237\u7ba1\u7406\u7684\u8f66\u8f86\u3002\u6709\u4e00\u7ec4\u7279\u5b9a\u7684\u53c2\u4e0e\u8005\u7c7b\u578b\u53ef\u7528\u4e8e\u67e5\u8be2\u3002 h = Hero v = Vehicle w = Walker t = Traffic light o = Other a = Any \u7b14\u8bb0 manual_control.py \u811a\u672c\u4e3a \u81ea\u6211\u8f66\u8f86\u5206\u914d role_name = hero \u3002 \u78b0\u649e\u67e5\u8be2\u9700\u8981\u4e24\u4e2a\u6807\u5fd7\u6765\u8fc7\u6ee4\u78b0\u649e\u3002\u4ee5\u4e0b\u793a\u4f8b\u5c06\u663e\u793a\u8f66\u8f86\u4e0e\u4efb\u4f55\u5176\u4ed6\u5bf9\u8c61\u4e4b\u95f4\u7684\u78b0\u649e\u3002 print(client.show_recorder_collisions(\"recording01.log\",\"v\", \"a\")) \u8f93\u51fa\u603b\u7ed3\u4e86\u78b0\u649e\u7684\u65f6\u95f4\uff0c\u4ee5\u53ca\u6240\u6d89\u53ca\u7684\u53c2\u4e0e\u8005\u7684\u7c7b\u578b\u3001ID \u548c\u63cf\u8ff0\u3002 Version: 1 Map: Town05 Date: 02/19/19 15:36:08 Time Types Id Actor 1 Id Actor 2 16 v v 122 vehicle.yamaha.yzf 118 vehicle.dodge_charger.police 27 v o 122 vehicle.yamaha.yzf 0 Frames: 790 Duration: 46 seconds \u91cd\u8981\u7684 \u56e0\u4e3a\u8bb0\u5f55\u78b0\u649e\u7684\u662f Hero \u6216 Ego \u8f66\u8f86\uff0c\u6240\u4ee5\u8fd9\u5c06\u59cb\u7ec8\u662f Actor 1 \u3002 \u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u8bb0\u5f55\u5668\u5e76\u5728\u4e8b\u4ef6\u53d1\u751f\u524d\u51e0\u79d2\u8bbe\u7f6e\u5b83\u6765\u91cd\u65b0\u5236\u5b9a\u78b0\u649e\u3002 client.replay_file(\"col2.log\", 13, 0, 122) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u56de\u653e\u663e\u793a\u4e86\u8fd9\u4e00\u70b9\u3002 \u88ab\u5361\u4f4f\u7684\u89d2\u8272 \u68c0\u6d4b\u5728\u5f55\u5236\u8fc7\u7a0b\u4e2d\u5361\u4f4f\u7684\u8f66\u8f86\u3002\u5982\u679c\u89d2\u8272\u5728\u7279\u5b9a\u65f6\u95f4\u5185\u6ca1\u6709\u79fb\u52a8\u6700\u5c0f\u8ddd\u79bb\uff0c\u5219\u8ba4\u4e3a\u5b83\u88ab\u963b\u585e\u3002\u8be5\u5b9a\u4e49\u7531\u7528\u6237\u5728\u67e5\u8be2\u671f\u95f4\u8fdb\u884c\u3002 print(client.show_recorder_actors_blocked(\"recording01.log\", min_time, min_distance)) \u53c2\u6570 \u8bf4\u660e \u9ed8\u8ba4 min_time \u79fb\u52a8\u7684\u6700\u5c0f\u79d2\u6570`min_distance`\u3002 30 \u79d2\u3002 min_distance \u79fb\u52a8\u7684\u6700\u5c0f\u5398\u7c73\u6570\u4e0d\u4f1a\u88ab\u89c6\u4e3a\u963b\u585e\u3002 10\u5398\u7c73\u3002 \u7b14\u8bb0 \u6709\u65f6\u8f66\u8f86\u5728\u7ea2\u7eff\u706f\u5904\u505c\u7559\u7684\u65f6\u95f4\u6bd4\u9884\u671f\u7684\u8981\u957f\u3002 \u4ee5\u4e0b\u793a\u4f8b\u8003\u8651\u8f66\u8f86\u5728 60 \u79d2\u5185\u79fb\u52a8\u4e0d\u5230 1 \u7c73\u65f6\u88ab\u5361\u4f4f\u3002 client.show_recorder_actors_blocked(\"col3.log\", 60, 100) \u8f93\u51fa\u5df2\u6392\u5e8f \u7531 duration \u8868\u793a\uff0c\u5b83\u8bf4\u660e\u4e86\u505c\u6b62\u88ab\u201c\u963b\u585e\u201d\u5e76\u79fb\u52a8 min_distance \u9700\u8981\u591a\u957f\u65f6\u95f4\u3002 Version: 1 Map: Town05 Date: 02/19/19 15:45:01 Time Id Actor Duration 36 173 vehicle.nissan.patrol 336 75 214 vehicle.chevrolet.impala 295 302 143 vehicle.bmw.grandtourer 67 Frames: 6985 Duration: 374 seconds \u8f66\u8f86 173 \u5728 36 \u79d2\u65f6\u505c\u6b62 336 \u79d2\u3002\u5728\u7b2c\u4e8c\u4e2a 36 \u4e4b\u524d\u51e0\u79d2\u949f\u91cd\u65b0\u6a21\u62df\u4ee5\u68c0\u67e5\u5b83\u3002 client.replay_file(\"col3.log\", 34, 0, 173) \u793a\u4f8b python \u811a\u672c PythonAPI/examples \u4e2d\u63d0\u4f9b\u7684\u4e00\u4e9b\u811a\u672c\u6709\u52a9\u4e8e\u8bb0\u5f55\u5668\u7684\u4f7f\u7528\u3002 start_recording.py \u5f00\u59cb\u5f55\u5236\u3002\u53ef\u4ee5\u8bbe\u7f6e\u5f55\u5236\u7684\u6301\u7eed\u65f6\u95f4\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u5f00\u59cb\u65f6\u751f\u6210\u6f14\u5458\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -n \uff08\u53ef\u9009\uff09 \u4ea7\u751f\u7684\u8f66\u8f86\u3002\u9ed8\u8ba4\u503c\u4e3a 10\u3002 -t \uff08\u53ef\u9009\uff09 \u5f55\u5236\u7684\u6301\u7eed\u65f6\u95f4\u3002 start_replaying.py \u5f00\u59cb\u64ad\u653e\u5f55\u97f3\u3002\u53ef\u4ee5\u8bbe\u7f6e\u5f00\u59cb\u65f6\u95f4\u3001\u6301\u7eed\u65f6\u95f4\u548c\u8981\u8ddf\u968f\u7684\u6f14\u5458\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -s \uff08\u53ef\u9009\uff09 \u8d77\u59cb\u65f6\u95f4\u3002\u9ed8\u8ba4\u503c\u4e3a 10\u3002 -d (\u53ef\u9009) \u671f\u95f4\u3002\u9ed8\u8ba4\u4e3a\u5168\u90e8\u3002 -c \uff08\u53ef\u9009\uff09 \u8981\u5173\u6ce8\u7684\u6f14\u5458\u7684 ID\u3002 show_recorder_file_info.py \u663e\u793a\u5f55\u5236\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u4fe1\u606f\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u4ec5\u663e\u793a\u8bb0\u5f55\u4e8b\u4ef6\u7684\u5e27\u3002\u4f46\u662f\uff0c\u6240\u6709\u8fd9\u4e9b\u90fd\u53ef\u4ee5\u663e\u793a\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -s \uff08\u53ef\u9009\uff09 \u6807\u8bb0\u4ee5\u663e\u793a\u6240\u6709\u8be6\u7ec6\u4fe1\u606f\u3002 show_recorder_collisions.py \u663e\u793a\u7c7b\u578b\u4e3a A \u548c B \u7684\u6f14\u5458\u7684\u4e24\u4e2a\u6807\u5fd7\u4e4b\u95f4\u8bb0\u5f55\u7684\u78b0\u649e\u3002 -t = vv \u5c06\u663e\u793a\u8f66\u8f86\u4e4b\u95f4\u7684\u6240\u6709\u78b0\u649e\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -t \u76f8\u5173\u89d2\u8272\u7684\u6807\u5fd7\u3002 h = hero v = vehicle w = walker t = traffic light o = other a = any show_recorder_actors_blocked.py \u5217\u51fa\u88ab\u8ba4\u4e3a\u88ab\u963b\u6b62\u7684\u8f66\u8f86\u3002\u5982\u679c\u5728\u7279\u5b9a\u65f6\u95f4\u5185\u6ca1\u6709\u79fb\u52a8\u6700\u5c0f\u8ddd\u79bb\uff0c\u5219\u8ba4\u4e3a Actors \u88ab\u963b\u6321\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -t \uff08\u53ef\u9009\uff09 \u662f\u65f6\u5019\u5728\u88ab\u8ba4\u4e3a\u88ab\u963b\u585e\u4e4b\u524d\u79fb\u52a8 -d \u4e86\u3002 -d (\u53ef\u9009) \u79fb\u52a8\u8ddd\u79bb\u4e0d\u4f1a\u88ab\u89c6\u4e3a\u963b\u585e\u3002 \u73b0\u5728\u662f\u8bd5\u9a8c\u4e00\u6bb5\u65f6\u95f4\u7684\u65f6\u5019\u4e86\u3002\u4f7f\u7528\u8bb0\u5f55\u5668\u56de\u653e\u6a21\u62df\u3001\u8ffd\u6eaf\u4e8b\u4ef6\u3001\u8fdb\u884c\u66f4\u6539\u4ee5\u67e5\u770b\u65b0\u7ed3\u679c\u3002\u5728 CARLA \u8bba\u575b\u4e0a\u5c31\u6b64\u4e8b\u53d1\u8868\u610f\u89c1\u3002 CARLA\u8bba\u575b","title":"Recorder"},{"location":"adv_recorder/#recorder","text":"\u6b64\u529f\u80fd\u5141\u8bb8\u8bb0\u5f55\u548c\u91cd\u65b0\u5236\u5b9a\u4ee5\u524d\u7684\u6a21\u62df\u3002\u6240\u6709\u53d1\u751f\u7684\u4e8b\u4ef6\u90fd\u8bb0\u5f55\u5728 recorder file \u4e2d\u3002\u6709\u4e00\u4e9b\u9ad8\u7ea7\u67e5\u8be2\u53ef\u4ee5\u8ddf\u8e2a\u548c\u7814\u7a76\u8fd9\u4e9b\u4e8b\u4ef6\u3002 Recording \u6a21\u62df\u64ad\u653e \u8bbe\u7f6e\u65f6\u95f4\u56e0\u5b50 \u5f55\u5236\u6587\u4ef6 \u67e5\u8be2 \u78b0\u649e \u88ab\u56f0\u4f4f\u7684\u89d2\u8272 \u793a\u4f8b Python \u811a\u672c","title":"Recorder"},{"location":"adv_recorder/#recording","text":"\u6240\u6709\u6570\u636e\u4ec5\u5199\u5165\u670d\u52a1\u5668\u7aef\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u3002\u4f46\u662f\uff0c\u4f7f\u7528 carla.Client \u7ba1\u7406\u8bb0\u5f55\u5668\u3002 \u6839\u636e\u8bb0\u5f55\u6587\u4ef6\u4e2d\u5305\u542b\u7684\u6570\u636e\uff0c\u6bcf\u5e27\u66f4\u65b0\u89d2\u8272\u3002\u5f53\u524d\u6a21\u62df\u4e2d\u51fa\u73b0\u5728\u5f55\u5236\u4e2d\u7684 Actor \u5c06\u88ab\u79fb\u52a8\u6216\u91cd\u65b0\u751f\u6210\u4ee5\u6a21\u62df\u5b83\u3002\u90a3\u4e9b\u6ca1\u6709\u51fa\u73b0\u5728\u5f55\u97f3\u4e2d\u7684\u5c06\u7ee7\u7eed\u4ed6\u4eec\u7684\u65b9\u5f0f\uff0c\u5c31\u597d\u50cf\u4ec0\u4e48\u90fd\u6ca1\u53d1\u751f\u4e00\u6837\u3002 \uff01\uff01\uff01\u91cd\u8981\u7684 \u64ad\u653e\u7ed3\u675f\u65f6\uff0c\u8f66\u8f86\u5c06\u8bbe\u7f6e\u4e3a\u81ea\u52a8\u9a7e\u9a76\uff0c\u4f46 \u884c\u4eba\u5c06\u505c\u6b62 \u3002 \u8bb0\u5f55\u5668\u6587\u4ef6\u5305\u62ec\u6709\u5173\u8bb8\u591a\u4e0d\u540c\u5143\u7d20\u7684\u4fe1\u606f\u3002 \u89d2\u8272 \u2014 \u521b\u5efa\u548c\u9500\u6bc1\u3001\u8fb9\u754c\u548c\u89e6\u53d1\u6846\u3002 \u4ea4\u901a\u706f \u2014 \u72b6\u6001\u53d8\u5316\u548c\u65f6\u95f4\u8bbe\u7f6e\u3002 \u8f66\u8f86 \u2014 \u4f4d\u7f6e\u548c\u65b9\u5411\u3001\u7ebf\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\u3001\u5149\u72b6\u6001\u548c\u7269\u7406\u63a7\u5236\u3002 \u884c\u4eba \u2014 \u4f4d\u7f6e\u548c\u65b9\u5411\uff0c\u4ee5\u53ca\u7ebf\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\u3002 \u706f\u5149 \u2014 \u6765\u81ea\u5efa\u7b51\u7269\u3001\u8857\u9053\u548c\u8f66\u8f86\u7684\u706f\u5149\u72b6\u6001\u3002 \u8981\u5f00\u59cb\u5f55\u5236\uff0c\u53ea\u9700\u8981\u4e00\u4e2a\u6587\u4ef6\u540d\u3002\u5728\u6587\u4ef6\u540d\u4e2d\u4f7f\u7528 \\ \u3001 / \u6216 : \u5b57\u7b26\u4f1a\u5c06\u5176\u5b9a\u4e49\u4e3a\u7edd\u5bf9\u8def\u5f84\u3002\u5982\u679c\u6ca1\u6709\u8be6\u7ec6\u7684\u8def\u5f84\uff0c\u6587\u4ef6\u5c06\u4fdd\u5b58\u5728 CarlaUE4/Saved \u4e2d\u3002 client.start_recorder(\"/home/carla/recording01.log\") \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u8bb0\u5f55\u5668\u8bbe\u7f6e\u4e3a\u4ec5\u5b58\u50a8\u56de\u653e\u6a21\u62df\u6240\u9700\u7684\u4fe1\u606f\u3002\u4e3a\u4e86\u4fdd\u5b58\u524d\u9762\u63d0\u5230\u7684\u6240\u6709\u4fe1\u606f\uff0c\u5fc5\u987b\u5728\u5f00\u59cb\u5f55\u5236\u65f6\u914d\u7f6e\u53c2\u6570 additional_data \u3002 client.start_recorder(\"/home/carla/recording01.log\", True) \u7b14\u8bb0 \u5176\u4ed6\u6570\u636e\u5305\u62ec\uff1a\u8f66\u8f86\u548c\u884c\u4eba\u7684\u7ebf\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\u3001\u7ea2\u7eff\u706f\u65f6\u95f4\u8bbe\u7f6e\u3001\u6267\u884c\u65f6\u95f4\u3001\u6f14\u5458\u7684\u89e6\u53d1\u5668\u548c\u8fb9\u754c\u6846\uff0c\u4ee5\u53ca\u8f66\u8f86\u7684\u7269\u7406\u63a7\u5236\u3002 \u8981\u505c\u6b62\u5f55\u97f3\uff0c\u8c03\u7528\u4e5f\u5f88\u7b80\u5355\u3002 client.stop_recorder() \u7b14\u8bb0 \u636e\u4f30\u8ba1\uff0c50 \u4e2a\u7ea2\u7eff\u706f\u548c 100 \u8f86\u8f66\u7684 1 \u5c0f\u65f6\u8bb0\u5f55\u5927\u7ea6\u9700\u8981 200MB \u5927\u5c0f\u3002","title":"Recording"},{"location":"adv_recorder/#_1","text":"\u53ef\u4ee5\u5728\u6a21\u62df\u8fc7\u7a0b\u4e2d\u7684\u4efb\u4f55\u65f6\u5019\u5f00\u59cb\u64ad\u653e\u3002\u9664\u4e86\u65e5\u5fd7\u6587\u4ef6\u7684\u8def\u5f84\uff0c\u8fd9\u4e2a\u65b9\u6cd5\u8fd8\u9700\u8981\u4e00\u4e9b\u53c2\u6570\u3002 client.replay_file(\"recording01.log\", start, duration, camera) \u53c2\u6570 \u8bf4\u660e \u7b14\u8bb0 \u5f00\u59cb \u4ee5\u79d2\u4e3a\u5355\u4f4d\u8bb0\u5f55\u5f00\u59cb\u6a21\u62df\u7684\u65f6\u95f4\u3002 \u5982\u679c\u662f\u80af\u5b9a\u7684\uff0c\u65f6\u95f4\u5c06\u4ece\u8bb0\u5f55\u5f00\u59cb\u8ba1\u7b97\u3002 \u5982\u679c\u662f\u5426\u5b9a\u7684\uff0c\u5c06\u4ece\u6700\u540e\u8003\u8651\u3002 \u6301\u7eed\u65f6\u95f4 \u64ad\u653e\u79d2\u6570\u3002 0 \u662f\u6240\u6709\u7684\u5f55\u97f3\u3002 \u64ad\u653e\u7ed3\u675f\u65f6\uff0c\u8f66\u8f86\u5c06\u8bbe\u7f6e\u4e3a\u81ea\u52a8\u9a7e\u9a76\uff0c\u884c\u4eba\u5c06\u505c\u6b62\u3002 \u76f8\u673a \u76f8\u673a\u5c06\u805a\u7126\u7684\u6f14\u5458\u7684 ID\u3002 \u5c06\u5176\u8bbe\u7f6e\u4e3a\u201c0\u201d\u4ee5\u8ba9\u89c2\u4f17\u81ea\u7531\u79fb\u52a8\u3002","title":"\u6a21\u62df\u64ad\u653e"},{"location":"adv_recorder/#_2","text":"\u65f6\u95f4\u56e0\u7d20\u5c06\u51b3\u5b9a\u64ad\u653e\u901f\u5ea6\u3002\u5b83\u53ef\u4ee5\u968f\u65f6\u66f4\u6539\u800c\u65e0\u9700\u505c\u6b62\u56de\u653e\u3002 client.set_replayer_time_factor(2.0) \u53c2\u6570 \u9ed8\u8ba4 \u5feb\u52a8\u4f5c \u6162\u52a8\u4f5c time_factor 1.0 >1.0 <1.0 \u91cd\u8981\u7684 \u5982\u679c time_factor>2.0 \uff0cactors \u7684\u4f4d\u7f6e\u63d2\u503c\u88ab\u7981\u7528\u5e76\u4e14\u53ea\u662f\u66f4\u65b0\u3002\u884c\u4eba\u7684\u52a8\u753b\u4e0d\u53d7\u65f6\u95f4\u56e0\u7d20\u7684\u5f71\u54cd\u3002 \u5f53\u65f6\u95f4\u56e0\u7d20\u5728 20x \u5de6\u53f3\u65f6\uff0c\u5f88\u5bb9\u6613\u7406\u89e3\u6d41\u91cf\u3002","title":"\u8bbe\u7f6e\u65f6\u95f4\u56e0\u5b50"},{"location":"adv_recorder/#_3","text":"\u53ef\u4ee5\u4f7f\u7528\u7b80\u5355\u7684 API \u8c03\u7528\u6765\u68c0\u7d22\u8bb0\u5f55\u7684\u8be6\u7ec6\u4fe1\u606f\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u53ea\u68c0\u7d22\u6ce8\u518c\u4e8b\u4ef6\u7684\u90a3\u4e9b\u5e27\u3002\u8bbe\u7f6e\u53c2\u6570 show_all \u5c06\u8fd4\u56de\u6bcf\u4e00\u5e27\u7684\u6240\u6709\u4fe1\u606f\u3002\u5173\u4e8e\u5982\u4f55\u5b58\u50a8\u6570\u636e\u7684\u7ec6\u8282\u5728 recorder's reference \u4e2d\u6709\u8be6\u7ec6\u8bf4\u660e\u3002 # \u663e\u793a\u76f8\u5173\u5e27\u7684\u4fe1\u606f print (client.show_recorder_file_info (\"recording01.log\")) \u5f00\u653e\u4fe1\u606f. \u8bb0\u5f55\u6a21\u62df\u7684\u5730\u56fe\u3001\u65e5\u671f\u548c\u65f6\u95f4\u3002 Frame information. \u4efb\u4f55\u53ef\u80fd\u53d1\u751f\u7684\u4e8b\u4ef6\uff0c\u4f8b\u5982\u89d2\u8272\u751f\u6210\u6216\u78b0\u649e\u3002\u5b83\u5305\u542b\u6f14\u5458\u7684 ID \u548c\u4e00\u4e9b\u9644\u52a0\u4fe1\u606f\u3002 \u5173\u95ed\u4fe1\u606f. \u8bb0\u5f55\u7684\u5e27\u6570\u548c\u603b\u65f6\u95f4\u3002 Version: 1 Map: Town05 Date: 02/21/19 10:46:20 Frame 1 at 0 seconds Create 2190: spectator (0) at (-260, -200, 382.001) Create 2191: traffic.traffic_light (3) at (4255, 10020, 0) Create 2192: traffic.traffic_light (3) at (4025, 7860, 0) ... Create 2258: traffic.speed_limit.90 (0) at (21651.7, -1347.59, 15) Create 2259: traffic.speed_limit.90 (0) at (5357, 21457.1, 15) Frame 2 at 0.0254253 seconds Create 2276: vehicle.mini.cooperst (1) at (4347.63, -8409.51, 120) number_of_wheels = 4 object_type = color = 255,241,0 role_name = autopilot ... Frame 2350 at 60.2805 seconds Destroy 2276 Frame 2351 at 60.3057 seconds Destroy 2277 ... Frames: 2354 Duration: 60.3753 seconds","title":"\u5f55\u5236\u6587\u4ef6"},{"location":"adv_recorder/#_4","text":"","title":"\u67e5\u8be2"},{"location":"adv_recorder/#_5","text":"\u8f66\u8f86\u5fc5\u987b\u6709\u4e00\u4e2a \u78b0\u649e\u68c0\u6d4b\u5668 \u4ee5\u8bb0\u5f55\u78b0\u649e\u3002\u8fd9\u4e9b\u53ef\u4ee5\u88ab\u67e5\u8be2\uff0c\u4f7f\u7528\u53c2\u6570\u6765\u8fc7\u6ee4\u78b0\u649e\u4e2d\u6d89\u53ca\u7684\u53c2\u4e0e\u8005\u7684\u7c7b\u578b\u3002\u4f8b\u5982\uff0c h \u6807\u8bc6 role_name = hero \u7684\u89d2\u8272\uff0c\u901a\u5e38\u5206\u914d\u7ed9\u7528\u6237\u7ba1\u7406\u7684\u8f66\u8f86\u3002\u6709\u4e00\u7ec4\u7279\u5b9a\u7684\u53c2\u4e0e\u8005\u7c7b\u578b\u53ef\u7528\u4e8e\u67e5\u8be2\u3002 h = Hero v = Vehicle w = Walker t = Traffic light o = Other a = Any \u7b14\u8bb0 manual_control.py \u811a\u672c\u4e3a \u81ea\u6211\u8f66\u8f86\u5206\u914d role_name = hero \u3002 \u78b0\u649e\u67e5\u8be2\u9700\u8981\u4e24\u4e2a\u6807\u5fd7\u6765\u8fc7\u6ee4\u78b0\u649e\u3002\u4ee5\u4e0b\u793a\u4f8b\u5c06\u663e\u793a\u8f66\u8f86\u4e0e\u4efb\u4f55\u5176\u4ed6\u5bf9\u8c61\u4e4b\u95f4\u7684\u78b0\u649e\u3002 print(client.show_recorder_collisions(\"recording01.log\",\"v\", \"a\")) \u8f93\u51fa\u603b\u7ed3\u4e86\u78b0\u649e\u7684\u65f6\u95f4\uff0c\u4ee5\u53ca\u6240\u6d89\u53ca\u7684\u53c2\u4e0e\u8005\u7684\u7c7b\u578b\u3001ID \u548c\u63cf\u8ff0\u3002 Version: 1 Map: Town05 Date: 02/19/19 15:36:08 Time Types Id Actor 1 Id Actor 2 16 v v 122 vehicle.yamaha.yzf 118 vehicle.dodge_charger.police 27 v o 122 vehicle.yamaha.yzf 0 Frames: 790 Duration: 46 seconds \u91cd\u8981\u7684 \u56e0\u4e3a\u8bb0\u5f55\u78b0\u649e\u7684\u662f Hero \u6216 Ego \u8f66\u8f86\uff0c\u6240\u4ee5\u8fd9\u5c06\u59cb\u7ec8\u662f Actor 1 \u3002 \u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u8bb0\u5f55\u5668\u5e76\u5728\u4e8b\u4ef6\u53d1\u751f\u524d\u51e0\u79d2\u8bbe\u7f6e\u5b83\u6765\u91cd\u65b0\u5236\u5b9a\u78b0\u649e\u3002 client.replay_file(\"col2.log\", 13, 0, 122) \u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u56de\u653e\u663e\u793a\u4e86\u8fd9\u4e00\u70b9\u3002","title":"\u78b0\u649e"},{"location":"adv_recorder/#_6","text":"\u68c0\u6d4b\u5728\u5f55\u5236\u8fc7\u7a0b\u4e2d\u5361\u4f4f\u7684\u8f66\u8f86\u3002\u5982\u679c\u89d2\u8272\u5728\u7279\u5b9a\u65f6\u95f4\u5185\u6ca1\u6709\u79fb\u52a8\u6700\u5c0f\u8ddd\u79bb\uff0c\u5219\u8ba4\u4e3a\u5b83\u88ab\u963b\u585e\u3002\u8be5\u5b9a\u4e49\u7531\u7528\u6237\u5728\u67e5\u8be2\u671f\u95f4\u8fdb\u884c\u3002 print(client.show_recorder_actors_blocked(\"recording01.log\", min_time, min_distance)) \u53c2\u6570 \u8bf4\u660e \u9ed8\u8ba4 min_time \u79fb\u52a8\u7684\u6700\u5c0f\u79d2\u6570`min_distance`\u3002 30 \u79d2\u3002 min_distance \u79fb\u52a8\u7684\u6700\u5c0f\u5398\u7c73\u6570\u4e0d\u4f1a\u88ab\u89c6\u4e3a\u963b\u585e\u3002 10\u5398\u7c73\u3002 \u7b14\u8bb0 \u6709\u65f6\u8f66\u8f86\u5728\u7ea2\u7eff\u706f\u5904\u505c\u7559\u7684\u65f6\u95f4\u6bd4\u9884\u671f\u7684\u8981\u957f\u3002 \u4ee5\u4e0b\u793a\u4f8b\u8003\u8651\u8f66\u8f86\u5728 60 \u79d2\u5185\u79fb\u52a8\u4e0d\u5230 1 \u7c73\u65f6\u88ab\u5361\u4f4f\u3002 client.show_recorder_actors_blocked(\"col3.log\", 60, 100) \u8f93\u51fa\u5df2\u6392\u5e8f \u7531 duration \u8868\u793a\uff0c\u5b83\u8bf4\u660e\u4e86\u505c\u6b62\u88ab\u201c\u963b\u585e\u201d\u5e76\u79fb\u52a8 min_distance \u9700\u8981\u591a\u957f\u65f6\u95f4\u3002 Version: 1 Map: Town05 Date: 02/19/19 15:45:01 Time Id Actor Duration 36 173 vehicle.nissan.patrol 336 75 214 vehicle.chevrolet.impala 295 302 143 vehicle.bmw.grandtourer 67 Frames: 6985 Duration: 374 seconds \u8f66\u8f86 173 \u5728 36 \u79d2\u65f6\u505c\u6b62 336 \u79d2\u3002\u5728\u7b2c\u4e8c\u4e2a 36 \u4e4b\u524d\u51e0\u79d2\u949f\u91cd\u65b0\u6a21\u62df\u4ee5\u68c0\u67e5\u5b83\u3002 client.replay_file(\"col3.log\", 34, 0, 173)","title":"\u88ab\u5361\u4f4f\u7684\u89d2\u8272"},{"location":"adv_recorder/#python","text":"PythonAPI/examples \u4e2d\u63d0\u4f9b\u7684\u4e00\u4e9b\u811a\u672c\u6709\u52a9\u4e8e\u8bb0\u5f55\u5668\u7684\u4f7f\u7528\u3002 start_recording.py \u5f00\u59cb\u5f55\u5236\u3002\u53ef\u4ee5\u8bbe\u7f6e\u5f55\u5236\u7684\u6301\u7eed\u65f6\u95f4\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u5f00\u59cb\u65f6\u751f\u6210\u6f14\u5458\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -n \uff08\u53ef\u9009\uff09 \u4ea7\u751f\u7684\u8f66\u8f86\u3002\u9ed8\u8ba4\u503c\u4e3a 10\u3002 -t \uff08\u53ef\u9009\uff09 \u5f55\u5236\u7684\u6301\u7eed\u65f6\u95f4\u3002 start_replaying.py \u5f00\u59cb\u64ad\u653e\u5f55\u97f3\u3002\u53ef\u4ee5\u8bbe\u7f6e\u5f00\u59cb\u65f6\u95f4\u3001\u6301\u7eed\u65f6\u95f4\u548c\u8981\u8ddf\u968f\u7684\u6f14\u5458\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -s \uff08\u53ef\u9009\uff09 \u8d77\u59cb\u65f6\u95f4\u3002\u9ed8\u8ba4\u503c\u4e3a 10\u3002 -d (\u53ef\u9009) \u671f\u95f4\u3002\u9ed8\u8ba4\u4e3a\u5168\u90e8\u3002 -c \uff08\u53ef\u9009\uff09 \u8981\u5173\u6ce8\u7684\u6f14\u5458\u7684 ID\u3002 show_recorder_file_info.py \u663e\u793a\u5f55\u5236\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u4fe1\u606f\u3002\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u5b83\u4ec5\u663e\u793a\u8bb0\u5f55\u4e8b\u4ef6\u7684\u5e27\u3002\u4f46\u662f\uff0c\u6240\u6709\u8fd9\u4e9b\u90fd\u53ef\u4ee5\u663e\u793a\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -s \uff08\u53ef\u9009\uff09 \u6807\u8bb0\u4ee5\u663e\u793a\u6240\u6709\u8be6\u7ec6\u4fe1\u606f\u3002 show_recorder_collisions.py \u663e\u793a\u7c7b\u578b\u4e3a A \u548c B \u7684\u6f14\u5458\u7684\u4e24\u4e2a\u6807\u5fd7\u4e4b\u95f4\u8bb0\u5f55\u7684\u78b0\u649e\u3002 -t = vv \u5c06\u663e\u793a\u8f66\u8f86\u4e4b\u95f4\u7684\u6240\u6709\u78b0\u649e\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -t \u76f8\u5173\u89d2\u8272\u7684\u6807\u5fd7\u3002 h = hero v = vehicle w = walker t = traffic light o = other a = any show_recorder_actors_blocked.py \u5217\u51fa\u88ab\u8ba4\u4e3a\u88ab\u963b\u6b62\u7684\u8f66\u8f86\u3002\u5982\u679c\u5728\u7279\u5b9a\u65f6\u95f4\u5185\u6ca1\u6709\u79fb\u52a8\u6700\u5c0f\u8ddd\u79bb\uff0c\u5219\u8ba4\u4e3a Actors \u88ab\u963b\u6321\u3002 \u53c2\u6570 \u8bf4\u660e -f \u6587\u4ef6\u540d\u3002 -t \uff08\u53ef\u9009\uff09 \u662f\u65f6\u5019\u5728\u88ab\u8ba4\u4e3a\u88ab\u963b\u585e\u4e4b\u524d\u79fb\u52a8 -d \u4e86\u3002 -d (\u53ef\u9009) \u79fb\u52a8\u8ddd\u79bb\u4e0d\u4f1a\u88ab\u89c6\u4e3a\u963b\u585e\u3002 \u73b0\u5728\u662f\u8bd5\u9a8c\u4e00\u6bb5\u65f6\u95f4\u7684\u65f6\u5019\u4e86\u3002\u4f7f\u7528\u8bb0\u5f55\u5668\u56de\u653e\u6a21\u62df\u3001\u8ffd\u6eaf\u4e8b\u4ef6\u3001\u8fdb\u884c\u66f4\u6539\u4ee5\u67e5\u770b\u65b0\u7ed3\u679c\u3002\u5728 CARLA \u8bba\u575b\u4e0a\u5c31\u6b64\u4e8b\u53d1\u8868\u610f\u89c1\u3002 CARLA\u8bba\u575b","title":"\u793a\u4f8b python \u811a\u672c"},{"location":"adv_rendering_options/","text":"Rendering options This guide details the different rendering options available in CARLA, including quality levels, no-rendering mode and off-screen mode. It also explains how version 0.9.12 of CARLA differs from previous versions in these respects. Graphics quality Vulkan graphics API Quality levels No-rendering mode Off-screen mode Off-screen Vs no-rendering Setting off-screen mode (Version 0.9.12+) Setting off-screen mode (Versions prior to 0.9.12) Important Some of the command options below are not equivalent in the CARLA packaged releases. Read the Command line options section to learn more about this. Graphics quality Vulkan graphics API Starting from version 0.9.12, CARLA runs on Unreal Engine 4.26 which only supports the Vulkan graphics API. Previous versions of CARLA could be configured to use OpenGL. If you are using a previous version of CARLA, please select the corresponding documentation version in the lower right corner of the screen for more information. Quality levels CARLA has two different levels for graphics quality. Epic is the default and is the most detailed. Low disables all post-processing and shadows and the drawing distance is set to 50m instead of infinite. The simulation runs significantly faster in Low mode. This is helpful in situations where there are technical limitations, where precision is nonessential or to train agents under conditions with simpler data or involving only close elements. The images below compare both modes. The flag used is the same for Windows and Linux. There is no equivalent option when working with the build, but the UE editor has its own quality settings. Go to Settings/Engine Scalability Settings for a greater customization of the desired quality. Epic mode ./CarlaUE4.sh -quality-level=Epic Epic mode screenshot Low mode ./CarlaUE4.sh -quality-level=Low Low mode screenshot Important The issue that made Epic mode show an abnormal whiteness has been fixed. If the problem persists, delete GameUserSettings.ini . It is saving previous settings, and will be generated again in the next run. Ubuntu path: ~/.config/Epic/CarlaUE4/Saved/Config/LinuxNoEditor/ Windows path: <Package folder>\\WindowsNoEditor\\CarlaUE4\\Saved\\Config\\WindowsNoEditor\\ No-rendering mode This mode disables rendering. Unreal Engine will skip everything regarding graphics. This mode prevents rendering overheads. It facilitates a lot traffic simulation and road behaviours at very high frequencies. To enable or disable no-rendering mode, change the world settings, or use the provided script in /PythonAPI/util/config.py . Below is an example on how to enable and then disable it via script: settings = world.get_settings() settings.no_rendering_mode = True world.apply_settings(settings) ... settings.no_rendering_mode = False world.apply_settings(settings) To disable and enable rendering via the command line, run the following commands: cd PythonAPI/util && python3 config.py --no-rendering cd PythonAPI/util && python3 config.py --rendering The script PythonAPI/examples/no_rendering_mode.py will enable no-rendering mode, and use Pygame to create an aerial view using simple graphics: cd PythonAPI/examples && python3 no_rendering_mode.py Warning In no-rendering mode, cameras and GPU sensors will return empty data. The GPU is not used. Unreal Engine is not drawing any scene. Off-screen mode Starting from version 0.9.12, CARLA runs on Unreal Engine 4.26 which introduced support for off-screen rendering. In previous versions of CARLA, off-screen rendering depended upon the graphics API you were using. Off-screen vs no-rendering It is important to understand the distinction between no-rendering mode and off-screen mode : No-rendering mode: Unreal Engine does not render anything. Graphics are not computed. GPU based sensors return empty data. Off-screen mode: Unreal Engine is working as usual, rendering is computed but there is no display available. GPU based sensors return data. Setting off-screen mode (Version 0.9.12+) To start CARLA in off-screen mode, run the following command: ./CarlaUE4.sh -RenderOffScreen Setting off-screen mode (Versions prior to 0.9.12) Using off-screen mode differs if you are using either OpenGL or Vulkan. Using OpenGL , you can run in off-screen mode in Linux by running the following command: # Linux DISPLAY= ./CarlaUE4.sh -opengl Vulkan requires extra steps because it needs to communicate to the display X server using the X11 network protocol to work properly. The following steps will guide you on how to set up an Ubuntu 18.04 machine without a display so that CARLA can run with Vulkan. 1. Fetch the latest NVIDIA driver: wget http://download.nvidia.com/XFree86/Linux-x86_64/450.57/NVIDIA-Linux-x86_64-450.57.run 2. Install the driver: sudo /bin/bash NVIDIA-Linux-x86_64-450.57.run --accept-license --no-questions --ui=none 3. Install the xserver related dependencies: sudo apt-get install -y xserver-xorg mesa-utils libvulkan1 4. Configure the xserver: sudo nvidia-xconfig --preserve-busid -a --virtual=1280x1024 5. Set the SDL_VIDEODRIVER variable. ENV SDL_VIDEODRIVER=x11 6. Run the xserver: sudo X :0 & 7. Run CARLA: DISPLAY=:0.GPU ./CarlaUE4.sh -vulkan CARLA provides a Dockerfile that performs all the above steps here . Any issues or doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"\u6e32\u67d3\u9009\u9879"},{"location":"adv_rendering_options/#rendering-options","text":"This guide details the different rendering options available in CARLA, including quality levels, no-rendering mode and off-screen mode. It also explains how version 0.9.12 of CARLA differs from previous versions in these respects. Graphics quality Vulkan graphics API Quality levels No-rendering mode Off-screen mode Off-screen Vs no-rendering Setting off-screen mode (Version 0.9.12+) Setting off-screen mode (Versions prior to 0.9.12) Important Some of the command options below are not equivalent in the CARLA packaged releases. Read the Command line options section to learn more about this.","title":"Rendering options"},{"location":"adv_rendering_options/#graphics-quality","text":"","title":"Graphics quality"},{"location":"adv_rendering_options/#vulkan-graphics-api","text":"Starting from version 0.9.12, CARLA runs on Unreal Engine 4.26 which only supports the Vulkan graphics API. Previous versions of CARLA could be configured to use OpenGL. If you are using a previous version of CARLA, please select the corresponding documentation version in the lower right corner of the screen for more information.","title":"Vulkan graphics API"},{"location":"adv_rendering_options/#quality-levels","text":"CARLA has two different levels for graphics quality. Epic is the default and is the most detailed. Low disables all post-processing and shadows and the drawing distance is set to 50m instead of infinite. The simulation runs significantly faster in Low mode. This is helpful in situations where there are technical limitations, where precision is nonessential or to train agents under conditions with simpler data or involving only close elements. The images below compare both modes. The flag used is the same for Windows and Linux. There is no equivalent option when working with the build, but the UE editor has its own quality settings. Go to Settings/Engine Scalability Settings for a greater customization of the desired quality.","title":"Quality levels"},{"location":"adv_rendering_options/#epic-mode","text":"./CarlaUE4.sh -quality-level=Epic Epic mode screenshot","title":"Epic mode"},{"location":"adv_rendering_options/#low-mode","text":"./CarlaUE4.sh -quality-level=Low Low mode screenshot Important The issue that made Epic mode show an abnormal whiteness has been fixed. If the problem persists, delete GameUserSettings.ini . It is saving previous settings, and will be generated again in the next run. Ubuntu path: ~/.config/Epic/CarlaUE4/Saved/Config/LinuxNoEditor/ Windows path: <Package folder>\\WindowsNoEditor\\CarlaUE4\\Saved\\Config\\WindowsNoEditor\\","title":"Low mode"},{"location":"adv_rendering_options/#no-rendering-mode","text":"This mode disables rendering. Unreal Engine will skip everything regarding graphics. This mode prevents rendering overheads. It facilitates a lot traffic simulation and road behaviours at very high frequencies. To enable or disable no-rendering mode, change the world settings, or use the provided script in /PythonAPI/util/config.py . Below is an example on how to enable and then disable it via script: settings = world.get_settings() settings.no_rendering_mode = True world.apply_settings(settings) ... settings.no_rendering_mode = False world.apply_settings(settings) To disable and enable rendering via the command line, run the following commands: cd PythonAPI/util && python3 config.py --no-rendering cd PythonAPI/util && python3 config.py --rendering The script PythonAPI/examples/no_rendering_mode.py will enable no-rendering mode, and use Pygame to create an aerial view using simple graphics: cd PythonAPI/examples && python3 no_rendering_mode.py Warning In no-rendering mode, cameras and GPU sensors will return empty data. The GPU is not used. Unreal Engine is not drawing any scene.","title":"No-rendering mode"},{"location":"adv_rendering_options/#off-screen-mode","text":"Starting from version 0.9.12, CARLA runs on Unreal Engine 4.26 which introduced support for off-screen rendering. In previous versions of CARLA, off-screen rendering depended upon the graphics API you were using.","title":"Off-screen mode"},{"location":"adv_rendering_options/#off-screen-vs-no-rendering","text":"It is important to understand the distinction between no-rendering mode and off-screen mode : No-rendering mode: Unreal Engine does not render anything. Graphics are not computed. GPU based sensors return empty data. Off-screen mode: Unreal Engine is working as usual, rendering is computed but there is no display available. GPU based sensors return data.","title":"Off-screen vs no-rendering"},{"location":"adv_rendering_options/#setting-off-screen-mode-version-0912","text":"To start CARLA in off-screen mode, run the following command: ./CarlaUE4.sh -RenderOffScreen","title":"Setting off-screen mode (Version 0.9.12+)"},{"location":"adv_rendering_options/#setting-off-screen-mode-versions-prior-to-0912","text":"Using off-screen mode differs if you are using either OpenGL or Vulkan. Using OpenGL , you can run in off-screen mode in Linux by running the following command: # Linux DISPLAY= ./CarlaUE4.sh -opengl Vulkan requires extra steps because it needs to communicate to the display X server using the X11 network protocol to work properly. The following steps will guide you on how to set up an Ubuntu 18.04 machine without a display so that CARLA can run with Vulkan. 1. Fetch the latest NVIDIA driver: wget http://download.nvidia.com/XFree86/Linux-x86_64/450.57/NVIDIA-Linux-x86_64-450.57.run 2. Install the driver: sudo /bin/bash NVIDIA-Linux-x86_64-450.57.run --accept-license --no-questions --ui=none 3. Install the xserver related dependencies: sudo apt-get install -y xserver-xorg mesa-utils libvulkan1 4. Configure the xserver: sudo nvidia-xconfig --preserve-busid -a --virtual=1280x1024 5. Set the SDL_VIDEODRIVER variable. ENV SDL_VIDEODRIVER=x11 6. Run the xserver: sudo X :0 & 7. Run CARLA: DISPLAY=:0.GPU ./CarlaUE4.sh -vulkan CARLA provides a Dockerfile that performs all the above steps here . Any issues or doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"Setting off-screen mode (Versions prior to 0.9.12)"},{"location":"adv_rss/","text":"RSS CARLA integrates the C++ Library for Responsibility Sensitive Safety in the client library. This feature allows users to investigate behaviours of RSS without having to implement anything. CARLA will take care of providing the input, and applying the output to the AD systems on the fly. Overview Compilation Dependencies Build Current state RssSensor RssRestrictor Important This feature is a work in progress. Right now, it is only available for the Linux build. Overview The RSS library implements a mathematical model for safety assurance. It receives sensor information, and provides restrictions to the controllers of a vehicle. To sum up, the RSS module uses the sensor data to define situations . A situation describes the state of the ego vehicle with an element of the environment. For each situation, safety checks are made, and a proper response is calculated. The overall response is the result of all of the combined. For specific information on the library, read the documentation , especially the Background section . This is implemented in CARLA using two elements. RssSensor is in charge of the situation analysis, and response generation using the ad-rss-lib . RssRestrictor applies the response by restricting the commands of the vehicle. The following image sketches the integration of RSS into the CARLA architecture. 1. The server. Sends a camera image to the client. (Only if the client needs visualization). Provides the RssSensor with world data. Sends a physics model of the vehicle to the RssRestrictor. (Only if the default values are overwritten). 2. The client. Provides the RssSensor with some parameters to be considered. -Sends to the RssResrictor an initial carla.VehicleControl . 3. The RssSensor. Uses the ad-rss-lib to extract situations, do safety checks, and generate a response. Sends the RssRestrictor a response containing the proper response and aceleration restrictions to be applied. 4. The RssRestrictor If the client asks for it, applies the response to the carla.VehicleControl , and returns the resulting one. Visualization of the RssSensor results. Compilation The RSS integration has to be built aside from the rest of CARLA. The ad-rss-lib comes with an LGPL-2.1 open-source license that creates conflict. It has to be linked statically into libCarla . As a reminder, the feature is only available for the Linux build so far. Dependencies There are additional prerequisites required for building RSS and its dependencies. Take a look at the official documentation ) to know more about this. Dependencies provided by Ubunutu (>= 16.04). sudo apt-get install libgtest-dev libpython-dev libpugixml-dev libtbb-dev The dependencies are built using colcon , so it has to be installed. pip3 install --user -U colcon-common-extensions There are some additional dependencies for the Python bindings. sudo apt-get install castxml pip3 install --user pygccxml pyplusplus Build Once this is done, the full set of dependencies and RSS components can be built. Compile LibCarla to work with RSS. make LibCarla.client.rss Compile the PythonAPI to include the RSS feature. make PythonAPI.rss As an alternative, a package can be built directly. make package.rss Current state RssSensor carla.RssSensor supports ad-rss-lib v4.2.0 feature set completely, including intersections, stay on road support and unstructured constellations (e.g. with pedestrians) . So far, the server provides the sensor with ground truth data of the surroundings that includes the state of other traffic participants and traffic lights. RssRestrictor When the client calls for it, the carla.RssRestrictor will modify the vehicle controller to best reach the desired accelerations or decelerations by a given response. Due to the stucture of carla.VehicleControl objects, the restrictions applied have certain limitations. These controllers include throttle , brake and streering values. However, due to car physics and the simple control options these might not be met. The restriction intervenes in lateral direction simply by counter steering towards the parallel lane direction. The brake will be activated if deceleration requested by RSS. This depends on vehicle mass and brake torques provided by the carla.Vehicle . Note In an automated vehicle controller it might be possible to adapt the planned trajectory to the restrictions. A fast control loop (>1KHz) can be used to ensure these are followed. That sets the basics regarding the RSS sensor in CARLA. Find out more about the specific attributes and parameters in the sensor reference . Open CARLA and mess around for a while. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"RSS"},{"location":"adv_rss/#rss","text":"CARLA integrates the C++ Library for Responsibility Sensitive Safety in the client library. This feature allows users to investigate behaviours of RSS without having to implement anything. CARLA will take care of providing the input, and applying the output to the AD systems on the fly. Overview Compilation Dependencies Build Current state RssSensor RssRestrictor Important This feature is a work in progress. Right now, it is only available for the Linux build.","title":"RSS"},{"location":"adv_rss/#overview","text":"The RSS library implements a mathematical model for safety assurance. It receives sensor information, and provides restrictions to the controllers of a vehicle. To sum up, the RSS module uses the sensor data to define situations . A situation describes the state of the ego vehicle with an element of the environment. For each situation, safety checks are made, and a proper response is calculated. The overall response is the result of all of the combined. For specific information on the library, read the documentation , especially the Background section . This is implemented in CARLA using two elements. RssSensor is in charge of the situation analysis, and response generation using the ad-rss-lib . RssRestrictor applies the response by restricting the commands of the vehicle. The following image sketches the integration of RSS into the CARLA architecture. 1. The server. Sends a camera image to the client. (Only if the client needs visualization). Provides the RssSensor with world data. Sends a physics model of the vehicle to the RssRestrictor. (Only if the default values are overwritten). 2. The client. Provides the RssSensor with some parameters to be considered. -Sends to the RssResrictor an initial carla.VehicleControl . 3. The RssSensor. Uses the ad-rss-lib to extract situations, do safety checks, and generate a response. Sends the RssRestrictor a response containing the proper response and aceleration restrictions to be applied. 4. The RssRestrictor If the client asks for it, applies the response to the carla.VehicleControl , and returns the resulting one. Visualization of the RssSensor results.","title":"Overview"},{"location":"adv_rss/#compilation","text":"The RSS integration has to be built aside from the rest of CARLA. The ad-rss-lib comes with an LGPL-2.1 open-source license that creates conflict. It has to be linked statically into libCarla . As a reminder, the feature is only available for the Linux build so far.","title":"Compilation"},{"location":"adv_rss/#dependencies","text":"There are additional prerequisites required for building RSS and its dependencies. Take a look at the official documentation ) to know more about this. Dependencies provided by Ubunutu (>= 16.04). sudo apt-get install libgtest-dev libpython-dev libpugixml-dev libtbb-dev The dependencies are built using colcon , so it has to be installed. pip3 install --user -U colcon-common-extensions There are some additional dependencies for the Python bindings. sudo apt-get install castxml pip3 install --user pygccxml pyplusplus","title":"Dependencies"},{"location":"adv_rss/#build","text":"Once this is done, the full set of dependencies and RSS components can be built. Compile LibCarla to work with RSS. make LibCarla.client.rss Compile the PythonAPI to include the RSS feature. make PythonAPI.rss As an alternative, a package can be built directly. make package.rss","title":"Build"},{"location":"adv_rss/#current-state","text":"","title":"Current state"},{"location":"adv_rss/#rsssensor","text":"carla.RssSensor supports ad-rss-lib v4.2.0 feature set completely, including intersections, stay on road support and unstructured constellations (e.g. with pedestrians) . So far, the server provides the sensor with ground truth data of the surroundings that includes the state of other traffic participants and traffic lights.","title":"RssSensor"},{"location":"adv_rss/#rssrestrictor","text":"When the client calls for it, the carla.RssRestrictor will modify the vehicle controller to best reach the desired accelerations or decelerations by a given response. Due to the stucture of carla.VehicleControl objects, the restrictions applied have certain limitations. These controllers include throttle , brake and streering values. However, due to car physics and the simple control options these might not be met. The restriction intervenes in lateral direction simply by counter steering towards the parallel lane direction. The brake will be activated if deceleration requested by RSS. This depends on vehicle mass and brake torques provided by the carla.Vehicle . Note In an automated vehicle controller it might be possible to adapt the planned trajectory to the restrictions. A fast control loop (>1KHz) can be used to ensure these are followed. That sets the basics regarding the RSS sensor in CARLA. Find out more about the specific attributes and parameters in the sensor reference . Open CARLA and mess around for a while. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"RssRestrictor"},{"location":"adv_sumo/","text":"SUMO co-simulation CARLA has developed a co-simulation feature with SUMO. This allows to distribute the tasks at will, and exploit the capabilities of each simulation in favour of the user. Requisites Run a custom co-simulation Create CARLA vtypes Create the SUMO net Run the synchronization Spawn NPCs controlled by SUMO Requisites First and foremost, it is necessary to install SUMO to run the co-simulation. Building from source is recommended over a simple installation, as there are new features and fixes that will improve the co-simulation. Once that is done, set the SUMO environment variable. echo \"export SUMO_HOME=/usr/share/sumo\" >> ~/.bashrc && source ~/.bashrc SUMO is ready to run the co-simulations. There are some examples in Co-Simulation/Sumo/examples for Town01 , Town04 , and Town05 . These .sumocfg files describe the configuration of the simulation (e.g., net, routes, vehicle types...). Use one of these to test the co-simulation. The script has different options that are detailed below . For the time being, let's run a simple example for Town04 . Run a CARLA simulation with Town04 . cd ~/carla ./CarlaUE4.sh cd PythonAPI/util python3 config.py --map Town04 Then, run the SUMO co-simulation example. cd ~/carla/Co-Simulation/Sumo python3 run_synchronization.py examples/Town04.sumocfg --sumo-gui Important Run a custom co-simulation Create carla vtypes With the script Co-Simulation/Sumo/util/create_sumo_vtypes.py the user can create sumo vtypes , the equivalent to CARLA blueprints, based on the CARLA blueprint library. --carla-host (default: 127.0.0.1) \u2014 IP of the carla host server. --carla-port (default: 2000) \u2014 TCP port to listen to. --output-file (default: carlavtypes.rou.xml) \u2014 The generated file containing the vtypes . This script uses the information stored in data/vtypes.json to create the SUMO vtypes . These can be modified by editing said file. Warning A CARLA simulation must be running to execute the script. Create the SUMO net The recommended way to create a SUMO net that synchronizes with CARLA is using the script Co-Simulation/Sumo/util/netconvert_carla.py . This will draw on the netconvert tool provided by SUMO. In order to run the script, some arguments are needed. xodr_file \u2014 OpenDRIVE file .xodr . --output' (default: net.net.xml ) \u2014 output file .net.xml . --guess-tls (default:false) \u2014 SUMO can set traffic lights only for specific lanes in a road, but CARLA can't. If set to True , SUMO will not differenciate traffic lights for specific lanes, and these will be in sync with CARLA. The output of the script will be a .net.xml that can be edited using NETEDIT . Use it to edit the routes, add demand, and eventually, prepare a simulation that can be saved as .sumocfg . The examples provided may be helpful during this process. Take a look at Co-Simulation/Sumo/examples . For every example.sumocfg there are several related files under the same name. All of them comprise a co-simulation example. Run the synchronization Once a simulation is ready and saved as a .sumocfg , it is ready to run. There are some optional parameters to change the settings of the co-simulation. sumo_cfg_file \u2014 The SUMO configuration file. --carla-host (default: 127.0.0.1) \u2014 IP of the carla host server --carla-port (default: 2000) \u2014 TCP port to listen to --sumo-host (default: 127.0.0.1) \u2014 IP of the SUMO host server. --sumo-port (default: 8813) \u2014 TCP port to listen to. --sumo-gui \u2014 Open a window to visualize the gui version of SUMO. --step-length (default: 0.05s) \u2014 Set fixed delta seconds for the simulation time-step. --sync-vehicle-lights (default: False) \u2014 Synchronize vehicle lights. --sync-vehicle-color (default: False) \u2014 Synchronize vehicle color. --sync-vehicle-all (default: False) \u2014 Synchronize all vehicle properties. --tls-manager (default: none) \u2014 Choose which simulator should manage the traffic lights. The other will update those accordingly. The options are carla , sumo , and none . If none is chosen, traffic lights will not be synchronized. Each vehicle would only obey the traffic lights in the simulator that spawn it. python3 run_synchronization.py <SUMOCFG FILE> --tls-manager carla --sumo-gui Warning To stop the co-simulation, press Ctrl+C in the terminal that run the script. Spawn NPCs controlled by SUMO The co-simulation with SUMO makes for an additional feature. Vehicles can be spawned in CARLA through SUMO, and managed by the later as the Traffi Manager would do. The script spawn_npc_sumo.py is almost equivalent to the already-known generate_traffic.py . This script automatically generates a SUMO network in a temporal folder, based on the active town in CARLA. The script will create random routes and let the vehicles roam around. As the script runs a synchronous simulation, and spawns vehicles in it, the arguments are the same that appear in run_synchronization.py and generate_traffic.py . --host (default: 127.0.0.1) \u2014 IP of the host server. --port (default: 2000) \u2014 TCP port to listen to. -n,--number-of-vehicles (default: 10) \u2014 Number of vehicles spawned. --safe \u2014 Avoid spawning vehicles prone to accidents. --filterv (default: \"vehicle. \")* \u2014 Filter the blueprint of the vehicles spawned. --sumo-gui \u2014 Open a window to visualize SUMO. --step-length (default: 0.05s) \u2014 Set fixed delta seconds for the simulation time-step. --sync-vehicle-lights (default: False) \u2014 Synchronize vehicle lights state. --sync-vehicle-color (default: False) \u2014 Synchronize vehicle color. --sync-vehicle-all (default: False) \u2014 Synchronize all vehicle properties. --tls-manager (default: none) \u2014 Choose which simulator will change the traffic lights' state. The other will update them accordingly. If none , traffic lights will not be synchronized. # Spawn 10 vehicles, that will be managed by SUMO instead of Traffic Manager. # CARLA in charge of traffic lights. # Open a window for SUMO visualization. python3 spawn_sumo_npc.py -n 10 --tls-manager carla --sumo-gui That is all there is so far, regarding for the SUMO co-simulation with CARLA. Open CARLA and mess around for a while. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"SUMO \u8054\u5408\u4eff\u771f"},{"location":"adv_sumo/#sumo-co-simulation","text":"CARLA has developed a co-simulation feature with SUMO. This allows to distribute the tasks at will, and exploit the capabilities of each simulation in favour of the user. Requisites Run a custom co-simulation Create CARLA vtypes Create the SUMO net Run the synchronization Spawn NPCs controlled by SUMO","title":"SUMO co-simulation"},{"location":"adv_sumo/#requisites","text":"First and foremost, it is necessary to install SUMO to run the co-simulation. Building from source is recommended over a simple installation, as there are new features and fixes that will improve the co-simulation. Once that is done, set the SUMO environment variable. echo \"export SUMO_HOME=/usr/share/sumo\" >> ~/.bashrc && source ~/.bashrc SUMO is ready to run the co-simulations. There are some examples in Co-Simulation/Sumo/examples for Town01 , Town04 , and Town05 . These .sumocfg files describe the configuration of the simulation (e.g., net, routes, vehicle types...). Use one of these to test the co-simulation. The script has different options that are detailed below . For the time being, let's run a simple example for Town04 . Run a CARLA simulation with Town04 . cd ~/carla ./CarlaUE4.sh cd PythonAPI/util python3 config.py --map Town04 Then, run the SUMO co-simulation example. cd ~/carla/Co-Simulation/Sumo python3 run_synchronization.py examples/Town04.sumocfg --sumo-gui Important","title":"Requisites"},{"location":"adv_sumo/#run-a-custom-co-simulation","text":"","title":"Run a custom co-simulation"},{"location":"adv_sumo/#create-carla-vtypes","text":"With the script Co-Simulation/Sumo/util/create_sumo_vtypes.py the user can create sumo vtypes , the equivalent to CARLA blueprints, based on the CARLA blueprint library. --carla-host (default: 127.0.0.1) \u2014 IP of the carla host server. --carla-port (default: 2000) \u2014 TCP port to listen to. --output-file (default: carlavtypes.rou.xml) \u2014 The generated file containing the vtypes . This script uses the information stored in data/vtypes.json to create the SUMO vtypes . These can be modified by editing said file. Warning A CARLA simulation must be running to execute the script.","title":"Create carla vtypes"},{"location":"adv_sumo/#create-the-sumo-net","text":"The recommended way to create a SUMO net that synchronizes with CARLA is using the script Co-Simulation/Sumo/util/netconvert_carla.py . This will draw on the netconvert tool provided by SUMO. In order to run the script, some arguments are needed. xodr_file \u2014 OpenDRIVE file .xodr . --output' (default: net.net.xml ) \u2014 output file .net.xml . --guess-tls (default:false) \u2014 SUMO can set traffic lights only for specific lanes in a road, but CARLA can't. If set to True , SUMO will not differenciate traffic lights for specific lanes, and these will be in sync with CARLA. The output of the script will be a .net.xml that can be edited using NETEDIT . Use it to edit the routes, add demand, and eventually, prepare a simulation that can be saved as .sumocfg . The examples provided may be helpful during this process. Take a look at Co-Simulation/Sumo/examples . For every example.sumocfg there are several related files under the same name. All of them comprise a co-simulation example.","title":"Create the SUMO net"},{"location":"adv_sumo/#run-the-synchronization","text":"Once a simulation is ready and saved as a .sumocfg , it is ready to run. There are some optional parameters to change the settings of the co-simulation. sumo_cfg_file \u2014 The SUMO configuration file. --carla-host (default: 127.0.0.1) \u2014 IP of the carla host server --carla-port (default: 2000) \u2014 TCP port to listen to --sumo-host (default: 127.0.0.1) \u2014 IP of the SUMO host server. --sumo-port (default: 8813) \u2014 TCP port to listen to. --sumo-gui \u2014 Open a window to visualize the gui version of SUMO. --step-length (default: 0.05s) \u2014 Set fixed delta seconds for the simulation time-step. --sync-vehicle-lights (default: False) \u2014 Synchronize vehicle lights. --sync-vehicle-color (default: False) \u2014 Synchronize vehicle color. --sync-vehicle-all (default: False) \u2014 Synchronize all vehicle properties. --tls-manager (default: none) \u2014 Choose which simulator should manage the traffic lights. The other will update those accordingly. The options are carla , sumo , and none . If none is chosen, traffic lights will not be synchronized. Each vehicle would only obey the traffic lights in the simulator that spawn it. python3 run_synchronization.py <SUMOCFG FILE> --tls-manager carla --sumo-gui Warning To stop the co-simulation, press Ctrl+C in the terminal that run the script.","title":"Run the synchronization"},{"location":"adv_sumo/#spawn-npcs-controlled-by-sumo","text":"The co-simulation with SUMO makes for an additional feature. Vehicles can be spawned in CARLA through SUMO, and managed by the later as the Traffi Manager would do. The script spawn_npc_sumo.py is almost equivalent to the already-known generate_traffic.py . This script automatically generates a SUMO network in a temporal folder, based on the active town in CARLA. The script will create random routes and let the vehicles roam around. As the script runs a synchronous simulation, and spawns vehicles in it, the arguments are the same that appear in run_synchronization.py and generate_traffic.py . --host (default: 127.0.0.1) \u2014 IP of the host server. --port (default: 2000) \u2014 TCP port to listen to. -n,--number-of-vehicles (default: 10) \u2014 Number of vehicles spawned. --safe \u2014 Avoid spawning vehicles prone to accidents. --filterv (default: \"vehicle. \")* \u2014 Filter the blueprint of the vehicles spawned. --sumo-gui \u2014 Open a window to visualize SUMO. --step-length (default: 0.05s) \u2014 Set fixed delta seconds for the simulation time-step. --sync-vehicle-lights (default: False) \u2014 Synchronize vehicle lights state. --sync-vehicle-color (default: False) \u2014 Synchronize vehicle color. --sync-vehicle-all (default: False) \u2014 Synchronize all vehicle properties. --tls-manager (default: none) \u2014 Choose which simulator will change the traffic lights' state. The other will update them accordingly. If none , traffic lights will not be synchronized. # Spawn 10 vehicles, that will be managed by SUMO instead of Traffic Manager. # CARLA in charge of traffic lights. # Open a window for SUMO visualization. python3 spawn_sumo_npc.py -n 10 --tls-manager carla --sumo-gui That is all there is so far, regarding for the SUMO co-simulation with CARLA. Open CARLA and mess around for a while. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"Spawn NPCs controlled by SUMO"},{"location":"adv_synchrony_timestep/","text":"Synchrony and time-step This section deals with two fundamental concepts in CARLA. Their configuration defines how does time go by in the simulation, and how does the server make the simulation move forward. Simulation time-step Variable time-step Fixed time-step Tips when recording the simulation Physics substepping Client-server synchrony Setting synchronous mode Using synchronous mode Possible configurations Physics determinism Simulation time-step There is a difference between real time, and simulation time. The simulated world has its own clock and time, conducted by the server. Computing two simulation steps takes some real time. However, there is also the time span that went by between those two simulation moments, the time-step. To clarify, the server can take a few milliseconds to compute two steps of a simulation. However, the time-step between those two simulation moments can be configured to be, for instance, always a second. Time-step can be fixed or variable depending on user preferences. Note Time-step and synchrony are intertwined concepts. Make sure to read both sections to get a full understanding of how does CARLA work. Variable time-step The default mode in CARLA. The simulation time that goes by between steps will be the time that the server takes to compute these. settings = world.get_settings() settings.fixed_delta_seconds = None # Set a variable time-step world.apply_settings(settings) PythonAPI/util/config.py sets the time-step using an argument. Zero equals variable time-step. cd PythonAPI/util && python3 config.py --delta-seconds 0 Fixed time-step The elapsed time remains constant between steps. If it is set to 0.5 seconds, there will be two frames per simulated second. Using the same time increment on each step is the best way to gather data from the simulation. Physics and sensor data will correspond to an easy to comprehend moment of the simulation. Also, if the server is fast enough, it makes possible to simulate longer time periods in less real time. Fixed delta seconds can be set in the world settings. To run the simulation at a fixed time-step of 0.05 seconds apply the following settings. In this case, the simulator will take twenty steps (1/0.05) to recreate one second of the simulated world. settings = world.get_settings() settings.fixed_delta_seconds = 0.05 world.apply_settings(settings) This can also be set using the provided script PythonAPI/util/config.py . cd PythonAPI/util && python3 config.py --delta-seconds 0.05 Tips when recording the simulation CARLA has a recorder feature that allows a simulation to be recorded and then reenacted. However, when looking for precision, some things need to be taken into account. With a fixed time-step , reenacting it will be easy. The server can be set to the same time-step used in the original simulation. With a variable time-step , things are a bit more complicated. If the server runs with a variable time-step , the time-steps will be different from the original one, as logic cycles differ from time to time. The information will then be interpolated using the recorded data. If the server is forced to reproduce the exact same time-steps , the steps simulated will be the same, but the real time between them changes. Time-steps should be passed one by one. Those original time-steps were the result of the original simulation running as fast as possible. As the time taken to represent these will mostly be different, the simulation is bound to be reproduced with weird time fluctuations. There is also a float-point arithmetic error that variable time-step introduces. The simulation is running with a time-step equal to the real one. Real time is a continuous variable, represented in the simulation with a float value, which has decimal limitations. The time that is cropped for each step accumulates, and prevents the simulation from a precise repetition of what has happened. Physics substepping Physics must be computed within very low time steps to be precise. This can be an issue when selecting a delta time for our simulation in which we usually perform multiple computations at each frame, for example with sensor rendering. As this limitation only happens due to the physics simulation, we can apply substeps to only the physical computations. This is enabled by default and is set to have a maximum of 10 physics substeps with a maximum physical delta time of 0.01. These options can be changed through the API in the world settings as: settings = world.get_settings() settings.substepping = True settings.max_substep_delta_time = 0.01 settings.max_substeps = 10 world.apply_settings(settings) Be aware that if you have set synchronous mode and the fixed time step then substepping options need to be consistent with the value of the fixed delta seconds. The condition to be fulfilled is: fixed_delta_seconds <= max_substep_delta_time * max_substeps In order to have an optimal physical simulation, the substep delta time should at least be below 0.01666 and ideally below 0.01 . To demonstrate the effect of optimal physical sub-stepping, consider the following graphs. The first graph shown below illustrates velocity over time in simulations with different fixed simulation time steps. The physical delta time is constant in all simulations at the default value of 0.01 . We can see that velocity is not affected by the difference in simulation time steps only. The second graph shows velocity over time in simulations with a fixed simulation time step of 0.04 . We can see that once the physical delta time surpasses 0.01 , deviations start to occur in the constancy of velocity, increasing in severity as physical delta time increases. We can demonstrate this deviation again by showing the effect of the same difference in physical delta time with a fixed simulation time step in the measurement of z-acceleration, with convergence occurring only when the physical delta time is 0.01 or less. Client-server synchrony CARLA is built over a client-server architecture. The server runs the simulation. The client retrieves information, and demands for changes in the world. This section deals with communication between client and server. By default, CARLA runs in asynchronous mode . The server runs the simulation as fast as possible, without waiting for the client. On synchronous mode , the server waits for a client tick, a \"ready to go\" message, before updating to the following simulation step. Note In a multiclient architecture, only one client should tick. The server reacts to every tick received as if it came from the same client. Many client ticks will make the create inconsistencies between server and clients. Setting synchronous mode Changing between synchronous and asynchronous mode is just a matter of a boolean state. settings = world.get_settings() settings.synchronous_mode = True # Enables synchronous mode world.apply_settings(settings) Warning If synchronous mode is enabled, and there is a Traffic Manager running, this must be set to sync mode too. Read this to learn how to do it. To disable synchronous mode just set the variable to false or use the script PythonAPI/util/config.py . cd PythonAPI/util && python3 config.py --no-sync # Disables synchronous mode Synchronous mode cannot be enabled using the script, only disabled. Enabling the synchronous mode makes the server wait for a client tick. Using this script, the user cannot send ticks when desired. Using synchronous mode The synchronous mode becomes specially relevant with slow client applications, and when synchrony between different elements, such as sensors, is needed. If the client is too slow and the server does not wait, there will be an overflow of information. The client will not be able to manage everything, and it will be lost or mixed. On a similar tune, with many sensors and asynchrony, it would be impossible to know if all the sensors are using data from the same moment in the simulation. The following fragment of code extends the previous one. The client creates a camera sensor, stores the image data of the current step in a queue, and ticks the server after retrieving it from the queue. A more complex example regarding several sensors can be found here . settings = world.get_settings() settings.synchronous_mode = True world.apply_settings(settings) camera = world.spawn_actor(blueprint, transform) image_queue = queue.Queue() camera.listen(image_queue.put) while True: world.tick() image = image_queue.get() Important Data coming from GPU-based sensors, mostly cameras, is usually generated with a delay of a couple of frames. Synchrony is essential here. The world has asynchrony methods to make the client wait for a server tick, or do something when it is received. # Wait for the next tick and retrieve the snapshot of the tick. world_snapshot = world.wait_for_tick() # Register a callback to get called every time we receive a new snapshot. world.on_tick(lambda world_snapshot: do_something(world_snapshot)) Possible configurations The configuration of time-step and synchrony, leads for different settings. Here is a brief summary on the possibilities. Fixed time-step Variable time-step Synchronous mode Client is in total control over the simulation and its information. Risk of non reliable simulations. Asynchronous mode Good time references for information. Server runs as fast as possible. Non easily repeatable simulations. Synchronous mode + variable time-step. This is almost for sure a non-desirable state. Physics cannot run properly when the time-step is bigger than 0.1s and. If the server has to wait for the client to compute the steps, this is likely to happen. Simulation time and physics will not be in synchrony. The simulation will not be reliable. Asynchronous mode + variable time-step. This is the default CARLA state. Client and server are asynchronous. The simulation time flows according to the real time. Reenacting the simulation needs to take into account float-arithmetic error, and possible differences in time steps between servers. Asynchronous mode + fixed time-step. The server will run as fast as possible. The information retrieved will be easily related with an exact moment in the simulation. This configuration makes possible to simulate long periods of time in much less real time, if the server is fast enough. Synchronous mode + fixed time-step. The client will rule the simulation. The time step will be fixed. The server will not compute the following step until the client sends a tick. This is the best mode when synchrony and precision is relevant. Especially when dealing with slow clients or different elements retrieving information. Warning In synchronous mode, always use a fixed time-step . If the server has to wait for the user, and it is using a variable time-step, time-steps will be too big. Physics will not be reliable. This issue is better explained in the time-step limitations section. Physics determinism CARLA supports physics and collision determinism under specific circumstances: Synchronous mode and fixed delta seconds must be enabled: Determinism requires the client to be in perfect sync with the server to ensure that commands are applied correctly and to produce accurate and reproducible results. A constant time step must be enforced by setting fixed_delta_seconds . If this is not set, the time step will be automatically computed at each step depending on the simulation performance. Synchronous mode must be enabled before loading or reloading the world: Differing timestamps can arise if the world is not in synchronous mode from the very beginning. This can generate small differences in physics simulation and in the life cycle of objects such as traffics lights. The world must be reloaded for each new repetition: Reload the world each time you want to reproduce a simulation. Commands should be batched instead of issued one at a time: Although rare, in a busy simulation or overloaded server, single issued commands can become lost. If commands are batched in a apply_batch_sync command, the command is guaranteed to be executed or return a failure response. Here is an example of the steps mentioned above: client = carla.Client(HOST, PORT) # connect to the server client.set_timeout(10.0) world = client.get_world() # Load the desired map client.load_world(\"Town10HD_Opt\") # Set synchronous mode settings new_settings = world.get_settings() new_settings.synchronous_mode = True new_settings.fixed_delta_seconds = 0.05 world.apply_settings(new_settings) client.reload_world(False) # reload map keeping the world settings # Set up the traffic manager traffic_manager = client.get_trafficmanager(TM_PORT) traffic_manager.set_synchronous_mode(True) traffic_manager.set_random_device_seed(SEED) # define TM seed for determinism # Spawn your vehicles, pedestrians, etc. # Simulation loop while True: # Your code world.tick() And a particular example for the playback feature: client = carla.Client(HOST, PORT) # connect to the server client.set_timeout(10.0) world = client.get_world() # Load the desired map client.load_world(\"Town10HD_Opt\") # Set synchronous mode settings new_settings = world.get_settings() new_settings.synchronous_mode = True new_settings.fixed_delta_seconds = 0.05 world.apply_settings(new_settings) client.reload_world(False) # reload map keeping the world settings client.replay_file(FILE_TO_PLAY, 0, 0, 0, False) world.tick() # a tick is necessary for the server to process the replay_file command # Simulation loop while True: # Your code world.tick() Running these steps will ensure the same outcome for every simulation run. That is all there is to know about the roles of simulation time and client-server synchrony in CARLA. Open CARLA and mess around for a while. Any suggestions or doubts are welcome in the forum. CARLA forum","title":"\u540c\u6b65\u548c\u65f6\u95f4\u6b65\u957f"},{"location":"adv_synchrony_timestep/#synchrony-and-time-step","text":"This section deals with two fundamental concepts in CARLA. Their configuration defines how does time go by in the simulation, and how does the server make the simulation move forward. Simulation time-step Variable time-step Fixed time-step Tips when recording the simulation Physics substepping Client-server synchrony Setting synchronous mode Using synchronous mode Possible configurations Physics determinism","title":"Synchrony and time-step"},{"location":"adv_synchrony_timestep/#simulation-time-step","text":"There is a difference between real time, and simulation time. The simulated world has its own clock and time, conducted by the server. Computing two simulation steps takes some real time. However, there is also the time span that went by between those two simulation moments, the time-step. To clarify, the server can take a few milliseconds to compute two steps of a simulation. However, the time-step between those two simulation moments can be configured to be, for instance, always a second. Time-step can be fixed or variable depending on user preferences. Note Time-step and synchrony are intertwined concepts. Make sure to read both sections to get a full understanding of how does CARLA work.","title":"Simulation time-step"},{"location":"adv_synchrony_timestep/#variable-time-step","text":"The default mode in CARLA. The simulation time that goes by between steps will be the time that the server takes to compute these. settings = world.get_settings() settings.fixed_delta_seconds = None # Set a variable time-step world.apply_settings(settings) PythonAPI/util/config.py sets the time-step using an argument. Zero equals variable time-step. cd PythonAPI/util && python3 config.py --delta-seconds 0","title":"Variable time-step"},{"location":"adv_synchrony_timestep/#fixed-time-step","text":"The elapsed time remains constant between steps. If it is set to 0.5 seconds, there will be two frames per simulated second. Using the same time increment on each step is the best way to gather data from the simulation. Physics and sensor data will correspond to an easy to comprehend moment of the simulation. Also, if the server is fast enough, it makes possible to simulate longer time periods in less real time. Fixed delta seconds can be set in the world settings. To run the simulation at a fixed time-step of 0.05 seconds apply the following settings. In this case, the simulator will take twenty steps (1/0.05) to recreate one second of the simulated world. settings = world.get_settings() settings.fixed_delta_seconds = 0.05 world.apply_settings(settings) This can also be set using the provided script PythonAPI/util/config.py . cd PythonAPI/util && python3 config.py --delta-seconds 0.05","title":"Fixed time-step"},{"location":"adv_synchrony_timestep/#tips-when-recording-the-simulation","text":"CARLA has a recorder feature that allows a simulation to be recorded and then reenacted. However, when looking for precision, some things need to be taken into account. With a fixed time-step , reenacting it will be easy. The server can be set to the same time-step used in the original simulation. With a variable time-step , things are a bit more complicated. If the server runs with a variable time-step , the time-steps will be different from the original one, as logic cycles differ from time to time. The information will then be interpolated using the recorded data. If the server is forced to reproduce the exact same time-steps , the steps simulated will be the same, but the real time between them changes. Time-steps should be passed one by one. Those original time-steps were the result of the original simulation running as fast as possible. As the time taken to represent these will mostly be different, the simulation is bound to be reproduced with weird time fluctuations. There is also a float-point arithmetic error that variable time-step introduces. The simulation is running with a time-step equal to the real one. Real time is a continuous variable, represented in the simulation with a float value, which has decimal limitations. The time that is cropped for each step accumulates, and prevents the simulation from a precise repetition of what has happened.","title":"Tips when recording the simulation"},{"location":"adv_synchrony_timestep/#physics-substepping","text":"Physics must be computed within very low time steps to be precise. This can be an issue when selecting a delta time for our simulation in which we usually perform multiple computations at each frame, for example with sensor rendering. As this limitation only happens due to the physics simulation, we can apply substeps to only the physical computations. This is enabled by default and is set to have a maximum of 10 physics substeps with a maximum physical delta time of 0.01. These options can be changed through the API in the world settings as: settings = world.get_settings() settings.substepping = True settings.max_substep_delta_time = 0.01 settings.max_substeps = 10 world.apply_settings(settings) Be aware that if you have set synchronous mode and the fixed time step then substepping options need to be consistent with the value of the fixed delta seconds. The condition to be fulfilled is: fixed_delta_seconds <= max_substep_delta_time * max_substeps In order to have an optimal physical simulation, the substep delta time should at least be below 0.01666 and ideally below 0.01 . To demonstrate the effect of optimal physical sub-stepping, consider the following graphs. The first graph shown below illustrates velocity over time in simulations with different fixed simulation time steps. The physical delta time is constant in all simulations at the default value of 0.01 . We can see that velocity is not affected by the difference in simulation time steps only. The second graph shows velocity over time in simulations with a fixed simulation time step of 0.04 . We can see that once the physical delta time surpasses 0.01 , deviations start to occur in the constancy of velocity, increasing in severity as physical delta time increases. We can demonstrate this deviation again by showing the effect of the same difference in physical delta time with a fixed simulation time step in the measurement of z-acceleration, with convergence occurring only when the physical delta time is 0.01 or less.","title":"Physics substepping"},{"location":"adv_synchrony_timestep/#client-server-synchrony","text":"CARLA is built over a client-server architecture. The server runs the simulation. The client retrieves information, and demands for changes in the world. This section deals with communication between client and server. By default, CARLA runs in asynchronous mode . The server runs the simulation as fast as possible, without waiting for the client. On synchronous mode , the server waits for a client tick, a \"ready to go\" message, before updating to the following simulation step. Note In a multiclient architecture, only one client should tick. The server reacts to every tick received as if it came from the same client. Many client ticks will make the create inconsistencies between server and clients.","title":"Client-server synchrony"},{"location":"adv_synchrony_timestep/#setting-synchronous-mode","text":"Changing between synchronous and asynchronous mode is just a matter of a boolean state. settings = world.get_settings() settings.synchronous_mode = True # Enables synchronous mode world.apply_settings(settings) Warning If synchronous mode is enabled, and there is a Traffic Manager running, this must be set to sync mode too. Read this to learn how to do it. To disable synchronous mode just set the variable to false or use the script PythonAPI/util/config.py . cd PythonAPI/util && python3 config.py --no-sync # Disables synchronous mode Synchronous mode cannot be enabled using the script, only disabled. Enabling the synchronous mode makes the server wait for a client tick. Using this script, the user cannot send ticks when desired.","title":"Setting synchronous mode"},{"location":"adv_synchrony_timestep/#using-synchronous-mode","text":"The synchronous mode becomes specially relevant with slow client applications, and when synchrony between different elements, such as sensors, is needed. If the client is too slow and the server does not wait, there will be an overflow of information. The client will not be able to manage everything, and it will be lost or mixed. On a similar tune, with many sensors and asynchrony, it would be impossible to know if all the sensors are using data from the same moment in the simulation. The following fragment of code extends the previous one. The client creates a camera sensor, stores the image data of the current step in a queue, and ticks the server after retrieving it from the queue. A more complex example regarding several sensors can be found here . settings = world.get_settings() settings.synchronous_mode = True world.apply_settings(settings) camera = world.spawn_actor(blueprint, transform) image_queue = queue.Queue() camera.listen(image_queue.put) while True: world.tick() image = image_queue.get() Important Data coming from GPU-based sensors, mostly cameras, is usually generated with a delay of a couple of frames. Synchrony is essential here. The world has asynchrony methods to make the client wait for a server tick, or do something when it is received. # Wait for the next tick and retrieve the snapshot of the tick. world_snapshot = world.wait_for_tick() # Register a callback to get called every time we receive a new snapshot. world.on_tick(lambda world_snapshot: do_something(world_snapshot))","title":"Using synchronous mode"},{"location":"adv_synchrony_timestep/#possible-configurations","text":"The configuration of time-step and synchrony, leads for different settings. Here is a brief summary on the possibilities. Fixed time-step Variable time-step Synchronous mode Client is in total control over the simulation and its information. Risk of non reliable simulations. Asynchronous mode Good time references for information. Server runs as fast as possible. Non easily repeatable simulations. Synchronous mode + variable time-step. This is almost for sure a non-desirable state. Physics cannot run properly when the time-step is bigger than 0.1s and. If the server has to wait for the client to compute the steps, this is likely to happen. Simulation time and physics will not be in synchrony. The simulation will not be reliable. Asynchronous mode + variable time-step. This is the default CARLA state. Client and server are asynchronous. The simulation time flows according to the real time. Reenacting the simulation needs to take into account float-arithmetic error, and possible differences in time steps between servers. Asynchronous mode + fixed time-step. The server will run as fast as possible. The information retrieved will be easily related with an exact moment in the simulation. This configuration makes possible to simulate long periods of time in much less real time, if the server is fast enough. Synchronous mode + fixed time-step. The client will rule the simulation. The time step will be fixed. The server will not compute the following step until the client sends a tick. This is the best mode when synchrony and precision is relevant. Especially when dealing with slow clients or different elements retrieving information. Warning In synchronous mode, always use a fixed time-step . If the server has to wait for the user, and it is using a variable time-step, time-steps will be too big. Physics will not be reliable. This issue is better explained in the time-step limitations section.","title":"Possible configurations"},{"location":"adv_synchrony_timestep/#physics-determinism","text":"CARLA supports physics and collision determinism under specific circumstances: Synchronous mode and fixed delta seconds must be enabled: Determinism requires the client to be in perfect sync with the server to ensure that commands are applied correctly and to produce accurate and reproducible results. A constant time step must be enforced by setting fixed_delta_seconds . If this is not set, the time step will be automatically computed at each step depending on the simulation performance. Synchronous mode must be enabled before loading or reloading the world: Differing timestamps can arise if the world is not in synchronous mode from the very beginning. This can generate small differences in physics simulation and in the life cycle of objects such as traffics lights. The world must be reloaded for each new repetition: Reload the world each time you want to reproduce a simulation. Commands should be batched instead of issued one at a time: Although rare, in a busy simulation or overloaded server, single issued commands can become lost. If commands are batched in a apply_batch_sync command, the command is guaranteed to be executed or return a failure response. Here is an example of the steps mentioned above: client = carla.Client(HOST, PORT) # connect to the server client.set_timeout(10.0) world = client.get_world() # Load the desired map client.load_world(\"Town10HD_Opt\") # Set synchronous mode settings new_settings = world.get_settings() new_settings.synchronous_mode = True new_settings.fixed_delta_seconds = 0.05 world.apply_settings(new_settings) client.reload_world(False) # reload map keeping the world settings # Set up the traffic manager traffic_manager = client.get_trafficmanager(TM_PORT) traffic_manager.set_synchronous_mode(True) traffic_manager.set_random_device_seed(SEED) # define TM seed for determinism # Spawn your vehicles, pedestrians, etc. # Simulation loop while True: # Your code world.tick() And a particular example for the playback feature: client = carla.Client(HOST, PORT) # connect to the server client.set_timeout(10.0) world = client.get_world() # Load the desired map client.load_world(\"Town10HD_Opt\") # Set synchronous mode settings new_settings = world.get_settings() new_settings.synchronous_mode = True new_settings.fixed_delta_seconds = 0.05 world.apply_settings(new_settings) client.reload_world(False) # reload map keeping the world settings client.replay_file(FILE_TO_PLAY, 0, 0, 0, False) world.tick() # a tick is necessary for the server to process the replay_file command # Simulation loop while True: # Your code world.tick() Running these steps will ensure the same outcome for every simulation run. That is all there is to know about the roles of simulation time and client-server synchrony in CARLA. Open CARLA and mess around for a while. Any suggestions or doubts are welcome in the forum. CARLA forum","title":"Physics determinism"},{"location":"adv_traffic_manager/","text":"Traffic Manager What is the Traffic Manager? Structured design User customization Architecture Overview ALSM Vehicle registry Simulation state Control loop In-Memory Map PBVT PID controller Command array Stages of the Control Loop Using the Traffic Manager Vehicle behavior considerations Creating a Traffic Manager Configuring autopilot behavior Stopping a Traffic Manager Deterministic mode Hybrid physics mode Running multiple Traffic Managers Traffic Manager servers and clients Multi-client simulations Multi-TM simulations Multi-simulation Synchronous mode Traffic manager in large maps What is the Traffic Manager? The Traffic Manager (TM) is the module that controls vehicles in autopilot mode in a simulation. Its goal is to populate a simulation with realistic urban traffic conditions. Users can customize some behaviors, for example, to set specific learning circumstances. Structured design TM is built on CARLA's client-side. The execution flow is divided into stages , each with independent operations and goals. This facilitates the development of phase-related functionalities and data structures while improving computational efficiency. Each stage runs on a different thread. Communication with other stages is managed through synchronous messaging. Information flows in one direction. User customization Users have some control over the traffic flow by setting parameters that allow, force, or encourage specific behaviors. Users can change the traffic behavior as they prefer, both online and offline. For example, cars can be allowed to ignore the speed limits or force a lane change. Being able to play around with behaviors is indispensable when trying to simulate reality. Driving systems need to be trained under specific and atypical circumstances. Architecture Overview The above diagram is a representation of the internal architecture of the TM. The C++ code for each component can be found in LibCarla/source/carla/trafficmanager . Each component is explained in detail in the following sections. A simplified overview of the logic is as follows: 1. Store and update the current state of the simulation. The Agent Lifecycle & State Management (ALSM) scans the world to keep track of all the vehicles and walkers present and to clean up entries for those that no longer exist. All the data is retrieved from the server and is passed through several stages . The ALSM is the only component that makes calls to the server. The vehicle registry contains an array of vehicles on autopilot (controlled by the TM) and a list of pedestrians and vehicles not on autopilot (not controlled by the TM). The simulation state is a cache store of the position, velocity, and additional information of all the vehicles and pedestrians in the simulation. 2. Calculate the movement of every autopilot vehicle. The TM generates viable commands for all vehicles in the vehicle registry according to the simulation state . Calculations for each vehicle are done separately. These calculations are divided into different stages . The control loop makes sure that all calculations are consistent by creating synchronization barriers between stages. No vehicle moves to the next stage before calculations are finished for all vehicles in the current stage. Each vehicle goes through the following stages: 2.1 - Localization Stage . Paths are created dynamically using a list of nearby waypoints collected from the In-Memory Map , a simplification of the simulation map as a grid of waypoints. Directions at junctions are chosen randomly. Each vehicle's path is stored and maintained by the Path Buffers & Vehicle Tracking (PBVT) component for easy access and modification in future stages. 2.2 - Collision Stage . Bounding boxes are extended over each vehicle's path to identify and navigate potential collision hazards. 2.3 - Traffic Light Stage . Similar to the Collision Stage, potential hazards that affect each vehicle's path due to traffic light influence, stop signs, and junction priority are identified. 2.4 - Motion Planner Stage . Vehicle movement is computed based on the defined path. A PID controller determines how to reach the target waypoints. This is then translated into a CARLA command for application in the next step. 2.5 - Vehicle Lights Stage . The vehicle lights switch on/off dynamically based on environmental factors (e.g. sunlight and the presence of fog or rain) and vehicle behavior (e.g. turning on direction indicators if the vehicle will turn left/right at the next junction, or turn on the stop lights if braking). 3. Apply the commands in the simulation. Commands generated in the previous step are collected into the command array and sent to the CARLA server in a batch to be applied in the same frame. The following sections will explain each component and stage in the TM logic described above in more detail. ALSM ALSM stands for Agent Lifecycle and State Management . It is the first step in the TM logic cycle and provides context of the simulation's current state. The ALSM component: Scans the world to keep track of all vehicles and pedestrians, their positions and velocities. If physics are enabled, the velocity is retrieved by Vehicle.get_velocity() . Otherwise, the velocity is calculated using the history of position updates over time. Stores the position, velocity, and additional information (traffic light influence, bounding boxes, etc) of every vehicle and pedestrian in the simulation state component. Updates the list of TM-controlled vehicles in the vehicle registry . Updates entries in the control loop and PBVT components to match the vehicle registry. Related .cpp files: ALSM.h , ALSM.cpp . Vehicle registry The vehicle registry keeps track of all vehicles and pedestrians in the simulation. The vehicle registry: Is passed an updated list of vehicles and pedestrians from the ALSM . Stores vehicles registered to the TM in a separate array for iteration during the control loop . Related .cpp files: MotionPlannerStage.cpp . Simulation state The simulation state stores information about all vehicles in the simulation for easy access and modification in later stages. The simulation state: Receives data from the ALSM including current actor position, velocity, traffic light influence, traffic light state, etc. Stores all information in cache, avoiding subsequent calls to the server during the control loop . Related .cpp files: SimulationState.cpp , SimulationState.h . Control loop The control loop manages the calculations of the next command for all autopilot vehicles so they are performed synchronously. The control loop consists of five different stages ; localization, collision, traffic light, motion planner and vehicle lights. The control loop: Receives an array of TM-controlled vehicles from the vehicle registry . Performs calculations for each vehicle separately by looping over the array. Divides calculations into a series of stages . Creates synchronization barriers between stages to guarantee consistency. Calculations for all vehicles are finished before any of them move to the next stage, ensuring all vehicles are updated in the same frame. Coordinates the transition between stages so all calculations are done in sync. Sends the command array to the server when the last stages ( Motion Planner Stage and Vehicle Lights Stage ) finishes so there are no frame delays between the command calculations and the command application. Related .cpp files: TrafficManagerLocal.cpp . In-Memory Map The In-Memory Map is a helper module contained within the PBVT and is used during the Localization Stage . The In-Memory Map: Converts the map into a grid of discrete waypoints. Includes waypoints in a specific data structure with more information to connect waypoints and identify roads, junctions, etc. Identifies these structures with an ID used to locate vehicles in nearby areas quickly. Related .cpp files: InMemoryMap.cpp and SimpleWaypoint.cpp . PBVT PBVT stands for Path Buffer and Vehicle Tracking . The PBVT is a data structure that contains the expected path for every vehicle and allows easy access to data during the control loop . The PBVT: Contains a map of deque objects with one entry per vehicle. Contains a set of waypoints for each vehicle describing its current location and near-future path. Contains the In-Memory Map used by the Localization Stage to relate every vehicle to the nearest waypoint and possible overlapping paths. PID controller The PID controller is a helper module that performs calculations during the Motion Planner Stage . The PID controller: Estimates the throttle, brake, and steering input needed to reach a target value using the information gathered by the Motion Planner Stage . Makes adjustments depending on the specific parameterization of the controller. Parameters can be modified if desired. Read more about PID controllers to learn how to make modifications. Related .cpp files: PIDController.cpp . Command Array The Command Array represents the last step in the TM logic cycle. It receives commands for all the registered vehicles and applies them. The Command Array: Receives a series of carla.VehicleControl 's from the Motion Planner Stage . Batches all commands to be applied during the same frame. Sends the batch to the CARLA server calling either apply_batch() or apply_batch_synch() in carla.Client depending on whether the simulation is running in asynchronous or synchronous mode, respectively. Related .cpp files: TrafficManagerLocal.cpp . Stages of the Control Loop Stage 1- Localization Stage The Localization Stage defines a near-future path for vehicles controlled by the TM. The Localization Stage: Obtains the position and velocity of all vehicles from the simulation state . Uses the In-Memory Map to relate every vehicle with a list of waypoints that describes its current location and near-future path according to its trajectory. The faster the vehicle goes, the longer the list will be. Updates the path according to planning decisions such as lane changes, speed limit, distance to leading vehicle parameterization, etc. Stores the path for all vehicles in the PBVT module. Compares paths with each other to estimate possible collision situations. Results are passed to the Collision Stage. Related .cpp files: LocalizationStage.cpp and LocalizationUtils.cpp . Stage 2- Collision Stage The Collision Stage triggers collision hazards. The Collision Stage: Receives from the Localization Stage a list of vehicle pairs whose paths could potentially overlap. Extends bounding boxes along the path ahead (geodesic boundaries) for each vehicle pair to check if they actually overlap and determine whether the risk of collision is real. Sends hazards for all possible collisions to the Motion Planner Stage to modify the path accordingly. Related .cpp files: CollisionStage.cpp . Stage 3- Traffic Light Stage The Traffic Light stage triggers hazards due to traffic regulators such as traffic lights, stop signs, and priority at junctions. The Traffic Light stage: Sets a traffic hazard if a vehicle is under the influence of a yellow or red traffic light or a stop sign. Extends a bounding box along a vehicle's path if it is in an unsignaled junction. Vehicles with overlapping paths follow a \"First-In-First-Out\" order to move. Wait times are set to a fixed value. Related .cpp files: TrafficLightStage.cpp . Stage 4- Motion Planner Stage The Motion Planner Stage generates the CARLA commands to be applied to vehicles. The Motion Planner Stage: Gathers a vehicle's position and velocity ( simulation state ), path ( PBVT ), and hazards ( Collision Stage and Traffic Light Stage ). Makes high-level decisions about how a vehicle should move, for example, computing the brake needed to prevent a collision hazard. A PID controller is used to estimate behaviors according to target values. Translates the desired movement to a carla.VehicleControl for application to the vehicle. Sends the resulting CARLA commands to the Command Array . Related .cpp files: MotionPlannerStage.cpp . Stage 5- Vehicle Lights Stage The Vehicle Lights Stage activates the lights based on the condition of the vehicle and the surrounding environment. The Vehicle Lights Stage: Retrieves the planned waypoints for the vehicle, information about vehicle lights (eg. light state and the planned command to be applied) and the weather conditions. Determines the new state of the vehicle lights: Turns on the blinkers if the vehicle is planning to turn left/right at the next junction. Turns on the stop lights if the applied command is asking the vehicle to brake. Turns on the low beams and the position lights from sunset to dawn, or under heavy rain. Turns on the fog lights under heavy fog conditions. Update the vehicle lights state if it has changed. Related .cpp files: VehicleLightStage.cpp . Using the Traffic Manager Vehicle behavior considerations The TM implements general behavior patterns that must be taken into consideration when you set vehicles to autopilot: Vehicles are not goal-oriented, they follow a dynamically produced trajectory and choose a path randomly when approaching a junction. Their path is endless. Vehicles' target speed is 70% of their current speed limit unless any other value is set. Junction priority does not follow traffic regulations. The TM uses its own priority system at junctions. The resolution of this restriction is a work in progress. In the meantime, some issues may arise, for example, vehicles inside a roundabout yielding to a vehicle trying to get in. TM behavior can be adjusted through the Python API. For specific methods, see the TM section of the Python API documentation . Below is a general summary of what is possible through the API: Topic Description General: - Create a TM instance connected to a port. - Retrieve the port where a TM is connected. Safety conditions: - Set a minimum distance between stopped vehicles (for a single vehicle or for all vehicles). This will affect the minimum moving distance. - Set the desired speed as a percentage of the current speed limit (for a single vehicle or for all vehicles). - Reset traffic lights. Collision managing: - Enable/Disable collisions between a vehicle and a specific actor. - Make a vehicle ignore all other vehicles. - Make a vehicle ignore all walkers. - Make a vehicle ignore all traffic lights. Lane changes: - Force a lane change, ignoring possible collisions. - Enable/Disable lane changes for a vehicle. Hybrid physics mode: - Enable/Disable hybrid physics mode. - Change the radius in which physics is enabled. Creating a Traffic Manager Note TM is designed to work in synchronous mode. Using TM in asynchronous mode can lead to unexpected and undesirable results. Read more in the section Synchronous mode . A TM instance is created by a carla.Client , passing the port to be used. The default port is 8000 . To create a TM instance: tm = client.get_trafficmanager(port) To enable autopilot for a set of vehicles, retrieve the port of the TM instance and set set_autopilot to True , passing the TM port at the same time. If no port is provided, it will try to connect to a TM in the default port ( 8000 ). If the TM does not exist, it will create one: tm_port = tm.get_port() for v in vehicles_list: v.set_autopilot(True,tm_port) Note Creating or connecting to a TM in multi-client situations is different from the above example. Learn more in the section Running multiple Traffic Managers . The generate_traffic.py script in /PythonAPI/examples provides an example of how to create a TM instance using a port passed as a script argument and register every vehicle spawned to it by setting the autopilot to True in a batch: traffic_manager = client.get_trafficmanager(args.tm-port) tm_port = traffic_manager.get_port() ... batch.append(SpawnActor(blueprint, transform).then(SetAutopilot(FutureActor, True,tm_port))) ... traffic_manager.global_percentage_speed_difference(30.0) Configuring autopilot behavior The following example creates a TM instance and configures dangerous behavior for a specific vehicle so it will ignore all traffic lights, leave no safety distance from other vehicles, and drive 20% faster than the current speed limit: tm = client.get_trafficmanager(port) tm_port = tm.get_port() for v in my_vehicles: v.set_autopilot(True,tm_port) danger_car = my_vehicles[0] tm.ignore_lights_percentage(danger_car,100) tm.distance_to_leading_vehicle(danger_car,0) tm.vehicle_percentage_speed_difference(danger_car,-20) The example below sets the same list of vehicles to autopilot but instead configures them with moderate driving behavior. The vehicles drive 80% slower than the current speed limit, leaving at least 5 meters between themselves and other vehicles, and never perform lane changes: tm = client.get_trafficmanager(port) tm_port = tm.get_port() for v in my_vehicles: v.set_autopilot(True,tm_port) danger_car = my_vehicles[0] tm.global_distance_to_leading_vehicle(5) tm.global_percentage_speed_difference(80) for v in my_vehicles: tm.auto_lane_change(v,False) Delegating the Traffic Manager to automatically update vehicle lights By default, vehicle lights (brake, turn indicators, etc...) of the vehicles managed by the TM are never updated. It is possible to delegate the TM to update the vehicle lights of a given vehicle actor: tm = client.get_trafficmanager(port) for actor in my_vehicles: tm.update_vehicle_lights(actor, True) Vehicle lights management has to be specified on a per-vehicle basis, and there could be at any given time both vehicles with and without the automatic light management. Stopping a Traffic Manager The TM is not an actor that needs to be destroyed; it will stop when the client that created it stops. This is automatically managed by the API, the user does not have to do anything. However, when shutting down a TM, the user must destroy the vehicles controlled by it, otherwise they will remain immobile on the map. The script generate_traffic.py does this automatically: client.apply_batch([carla.command.DestroyActor(x) for x in vehicles_list]) Warning Shutting down a TM-Server will shut down the TM-Clients connecting to it. To learn the difference between a TM-Server and a TM-Client , read about Running multiple Traffic Managers . Deterministic mode In deterministic mode, the TM will produce the same results and behaviors under the same conditions. Do not mistake determinism with the recorder. While the recorder allows you to store the log of a simulation to play it back, determinism ensures that the TM will always have the same output over different executions of a script as long as the same conditions are maintained. Deterministic mode is available in synchronous mode only . In asynchronous mode, there is less control over the simulation and determinism cannot be achieved. Read more in the section \"Synchronous mode\" before starting. To enable deterministic mode, use the following method: my_tm.set_random_device_seed(seed_value) seed_value is an int number from which random numbers will be generated. The value itself is not relevant, but the same value will always result in the same output. Two simulations, with the same conditions, that use the same seed value, will be deterministic. To maintain determinism over multiple simulation runs, the seed must be set for every simulation . For example, each time the world is reloaded , the seed must be set again: client.reload_world() my_tm.set_random_device_seed(seed_value) Deterministic mode can be tested in the generate_traffic.py example script by passing a seed value as an argument. The following example populates a map with 50 autopilot actors in synchronous mode and sets the seed to an arbitrary value of 9 : cd PythonAPI/examples python3 generate_traffic.py -n 50 --seed 9 Warning The CARLA server and the TM must be in synchronous mode before enabling deterministic mode. Read more here about synchronous mode in TM. Hybrid physics mode Hybrid mode allows users to disable most physics calculations for all autopilot vehicles, or for autopilot vehicles outside of a certain radius of a vehicle tagged with hero . This removes the vehicle physics bottleneck from a simulation. Vehicles whose physics are disabled will move by teleportation. Basic calculations for linear acceleration are maintained to ensure position updates and vehicle speed remain realistic and the toggling of physics calculations on vehicles is fluid. Hybrid mode uses the Actor.set_simulate_physics() method to toggle physics calculations. It is disabled by default. There are two options to enable it: TrafficManager.set_hybrid_physics_mode(True) \u2014 This method enables hybrid mode for the TM object calling it. Running generate_traffic.py with the flag --hybrid \u2014 This example script creates a TM and spawns vehicles in autopilot. It then sets these vehicles to hybrid mode when the --hybrid flag is passed as a script argument. To modify the behavior of hybrid mode, use the following two parameters: Radius (default = 50 meters) \u2014 The radius is relative to vehicles tagged with hero . All vehicles inside this radius will have physics enabled; vehicles outside of the radius will have physics disabled. The size of the radius is modified using traffic_manager.set_hybrid_physics_radius(r) . Hero vehicle \u2014 A vehicle tagged with role_name='hero' that acts as the center of the radius. If there is no hero vehicle, all vehicles' physics will be disabled. If there is more than one hero vehicle, the radius will be considered for them all, creating different areas of influence with physics enabled. The clip below shows how physics is enabled and disabled when hybrid mode is active. The hero vehicle is tagged with a red square . Vehicles with physics disabled are tagged with a blue square . When inside the hero vehicle's radius of influence, physics are enabled and the tag becomes green . Running multiple Traffic Managers Traffic Manager servers and clients A CARLA client creates a TM by specifying to the server which port to use. If a port is not specified, the default 8000 will be used. If further TMs are created on the same port, they will become TM-Clients and the original TM will become a TM-Server . These titles define how a TM behaves within a simulation. TM-Server A TM-Server is created if it was the first TM to connect to a free port and then other TMs (TM-Clients) connected to the same port it was running on. The TM-Server will dictate the behavior of all the TM-Clients , e.g., if the TM-Server is stopped, all TM-Clients will stop. The following code creates two TM-Servers. Each one connects to a different, unused port: tm01 = client01.get_trafficmanager() # tm01 --> tm01 (p=8000) tm02 = client02.get_trafficmanager(5000) # tm02(p=5000) --> tm02 (p=5000) TM-Client A TM-Client is created when a TM connects to a port occupied by another TM (TM-Server). The TM-Client behavior will be dictated by the TM-Server. The following code creates two TM-Clients, each one connecting with the TM-Servers created in the section above. tm03 = client03.get_trafficmanager() # tm03 --> tm01 (p=8000). tm04 = client04.get_trafficmanager(5000) # tm04(p=5000) --> tm02 (p=5000) The CARLA server keeps a register of all TM instances by storing the port and the client IP (hidden to the user) that link to them. There is currently no way to check the TM instances that have been created so far. A connection will always be attempted when trying to create an instance and it will either create a new TM-Server or a TM-Client . Multi-client simulations In a multi-client simulation, multiple TMs are created on the same port. The first TM will be a TM-Server and the rest will be TM-Clients connecting to it. The TM-Server will dictate the behavior of all the TM instances: terminal 1: ./CarlaUE4.sh -carla-rpc-port=4000 terminal 2: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Server terminal 3: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Client Multi-TM simulations In a multi-TM simulation, multiple TM instances are created on distinct ports. Each TM instance will control its own behavior: terminal 1: ./CarlaUE4.sh -carla-rpc-port=4000 terminal 2: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Server A terminal 3: python3 generate_traffic.py --port 4000 --tm-port 4550 # TM-Server B Multi-simulation Multi-simulation is when more than one CARLA server is running at the same time. The TM needs to connect to the relevant CARLA server port. As long as the computational power allows for it, the TM can run multiple simulations at a time without any problems: terminal 1: ./CarlaUE4.sh -carla-rpc-port=4000 # simulation A terminal 2: ./CarlaUE4.sh -carla-rpc-port=5000 # simulation B terminal 3: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Server A connected to simulation A terminal 4: python3 generate_traffic.py --port 5000 --tm-port 5050 # TM-Server B connected to simulation B The concept of multi-simulation is independent of the TM itself. The example above runs two CARLA simulations in parallel, A and B. In each of them, a TM-Server is created independently from the other. Simulation A could run a multi-client TM while simulation B is running a multi-TM or no TM at all. The most likely issue arising from the above set-up is a client trying to connect to an already existing TM that is not running on the selected simulation. If this happens, an error message will appear and the connection will be aborted to prevent interferences between simulations. Synchronous mode TM is designed to work in synchronous mode. Both the CARLA server and TM should be set to synchronous in order to function properly. Using TM in asynchronous mode can lead to unexpected and undesirable results, however, if asynchronous mode is required, the simulation should run at 20-30 fps at least. The script below demonstrates how to set both the server and TM to synchronous mode: ... # Set the simulation to sync mode init_settings = world.get_settings() settings = world.get_settings() settings.synchronous_mode = True # After that, set the TM to sync mode my_tm.set_synchronous_mode(True) ... # Tick the world in the same client world.apply_settings(init_settings) world.tick() ... # Always disable sync mode before the script ends to prevent the server blocking whilst waiting for a tick settings.synchronous_mode = False my_tm.set_synchronous_mode(False) The generate_traffic.py example script starts a TM and populates the map with vehicles and pedestrians. It automatically sets the TM and the CARLA server to synchronous mode: cd PythonAPI/examples python3 generate_traffic.py -n 50 If asynchronous mode is required, use the --async flag when running the above command. If more than one TM is set to synchronous mode, synchrony will fail. Follow these guidelines to avoid issues: In a multiclient situation, only the TM-Server should be set to synchronous mode. In a multiTM situation, only one TM-Server should be set to synchronous mode. The ScenarioRunner module runs a TM automatically. The TM inside ScenarioRunner will automatically be the one set to sync mode. Warning Disable synchronous mode (for both the world and TM) in your script managing ticks before it finishes to prevent the server blocking, waiting forever for a tick. Traffic manager in large maps To understand how the TM works on large maps, make sure to first familiarise yourself with how large maps work by reading the documentation here . The behavior of autopilot vehicles in large maps depends on whether or not there is a hero vehicle present: Hero vehicle not present All autopilot vehicles will be considered dormant actors. The dormant autopilot actors will be moved around the map as in hybrid mode. The vehicles will not be rendered since there is no hero vehicle to trigger map tile streaming. Hero vehicle present Autopilot vehicles will become dormant when they exceed the value defined by actor_active_distance . To set this value, use the Python API: settings = world.get_settings() # Actors will become dormant 2km away from the ego vehicle settings.actor_active_distance = 2000 world.apply_settings(settings) In the TM, dormant actors can be configured to continually respawn around the hero vehicle instead of remaining dormant on other parts of the map. This option can be configured using the set_respawn_dormant_vehicles method in the Python API. Vehicles will be respawned within a user-definable distance of the hero vehicle. The upper and lower boundaries of the respawnable distance can be set using the set_boundaries_respawn_dormant_vehicles method. Note that the upper distance will not be bigger than the tile streaming distance of the large map and the minimum lower distance is 20m. To enable respawning of dormant vehicles within 25 and 700 meters of the hero vehicle: my_tm.set_respawn_dormant_vehicles(True) my_tm.set_boundaries_respawn_dormant_vehicles(25,700) If collisions prevent a dormant actor from being respawned, the TM will retry on the next simulation step. If dormant vehicles are not respawned, their behavior will depend on whether hybrid mode is enabled. If hybrid mode has been enabled, then the dormant actors will be teleported around the map. If hybrid mode is not enabled, then dormant actor's physics will not be computed and they will stay in place until they are no longer dormant. If you have any questions about the TM, then you can ask in the forum . CARLA forum","title":"Traffic Manager"},{"location":"adv_traffic_manager/#traffic-manager","text":"What is the Traffic Manager? Structured design User customization Architecture Overview ALSM Vehicle registry Simulation state Control loop In-Memory Map PBVT PID controller Command array Stages of the Control Loop Using the Traffic Manager Vehicle behavior considerations Creating a Traffic Manager Configuring autopilot behavior Stopping a Traffic Manager Deterministic mode Hybrid physics mode Running multiple Traffic Managers Traffic Manager servers and clients Multi-client simulations Multi-TM simulations Multi-simulation Synchronous mode Traffic manager in large maps","title":"Traffic Manager"},{"location":"adv_traffic_manager/#what-is-the-traffic-manager","text":"The Traffic Manager (TM) is the module that controls vehicles in autopilot mode in a simulation. Its goal is to populate a simulation with realistic urban traffic conditions. Users can customize some behaviors, for example, to set specific learning circumstances.","title":"What is the Traffic Manager?"},{"location":"adv_traffic_manager/#structured-design","text":"TM is built on CARLA's client-side. The execution flow is divided into stages , each with independent operations and goals. This facilitates the development of phase-related functionalities and data structures while improving computational efficiency. Each stage runs on a different thread. Communication with other stages is managed through synchronous messaging. Information flows in one direction.","title":"Structured design"},{"location":"adv_traffic_manager/#user-customization","text":"Users have some control over the traffic flow by setting parameters that allow, force, or encourage specific behaviors. Users can change the traffic behavior as they prefer, both online and offline. For example, cars can be allowed to ignore the speed limits or force a lane change. Being able to play around with behaviors is indispensable when trying to simulate reality. Driving systems need to be trained under specific and atypical circumstances.","title":"User customization"},{"location":"adv_traffic_manager/#architecture","text":"","title":"Architecture"},{"location":"adv_traffic_manager/#overview","text":"The above diagram is a representation of the internal architecture of the TM. The C++ code for each component can be found in LibCarla/source/carla/trafficmanager . Each component is explained in detail in the following sections. A simplified overview of the logic is as follows: 1. Store and update the current state of the simulation. The Agent Lifecycle & State Management (ALSM) scans the world to keep track of all the vehicles and walkers present and to clean up entries for those that no longer exist. All the data is retrieved from the server and is passed through several stages . The ALSM is the only component that makes calls to the server. The vehicle registry contains an array of vehicles on autopilot (controlled by the TM) and a list of pedestrians and vehicles not on autopilot (not controlled by the TM). The simulation state is a cache store of the position, velocity, and additional information of all the vehicles and pedestrians in the simulation. 2. Calculate the movement of every autopilot vehicle. The TM generates viable commands for all vehicles in the vehicle registry according to the simulation state . Calculations for each vehicle are done separately. These calculations are divided into different stages . The control loop makes sure that all calculations are consistent by creating synchronization barriers between stages. No vehicle moves to the next stage before calculations are finished for all vehicles in the current stage. Each vehicle goes through the following stages: 2.1 - Localization Stage . Paths are created dynamically using a list of nearby waypoints collected from the In-Memory Map , a simplification of the simulation map as a grid of waypoints. Directions at junctions are chosen randomly. Each vehicle's path is stored and maintained by the Path Buffers & Vehicle Tracking (PBVT) component for easy access and modification in future stages. 2.2 - Collision Stage . Bounding boxes are extended over each vehicle's path to identify and navigate potential collision hazards. 2.3 - Traffic Light Stage . Similar to the Collision Stage, potential hazards that affect each vehicle's path due to traffic light influence, stop signs, and junction priority are identified. 2.4 - Motion Planner Stage . Vehicle movement is computed based on the defined path. A PID controller determines how to reach the target waypoints. This is then translated into a CARLA command for application in the next step. 2.5 - Vehicle Lights Stage . The vehicle lights switch on/off dynamically based on environmental factors (e.g. sunlight and the presence of fog or rain) and vehicle behavior (e.g. turning on direction indicators if the vehicle will turn left/right at the next junction, or turn on the stop lights if braking). 3. Apply the commands in the simulation. Commands generated in the previous step are collected into the command array and sent to the CARLA server in a batch to be applied in the same frame. The following sections will explain each component and stage in the TM logic described above in more detail.","title":"Overview"},{"location":"adv_traffic_manager/#alsm","text":"ALSM stands for Agent Lifecycle and State Management . It is the first step in the TM logic cycle and provides context of the simulation's current state. The ALSM component: Scans the world to keep track of all vehicles and pedestrians, their positions and velocities. If physics are enabled, the velocity is retrieved by Vehicle.get_velocity() . Otherwise, the velocity is calculated using the history of position updates over time. Stores the position, velocity, and additional information (traffic light influence, bounding boxes, etc) of every vehicle and pedestrian in the simulation state component. Updates the list of TM-controlled vehicles in the vehicle registry . Updates entries in the control loop and PBVT components to match the vehicle registry. Related .cpp files: ALSM.h , ALSM.cpp .","title":"ALSM"},{"location":"adv_traffic_manager/#vehicle-registry","text":"The vehicle registry keeps track of all vehicles and pedestrians in the simulation. The vehicle registry: Is passed an updated list of vehicles and pedestrians from the ALSM . Stores vehicles registered to the TM in a separate array for iteration during the control loop . Related .cpp files: MotionPlannerStage.cpp .","title":"Vehicle registry"},{"location":"adv_traffic_manager/#simulation-state","text":"The simulation state stores information about all vehicles in the simulation for easy access and modification in later stages. The simulation state: Receives data from the ALSM including current actor position, velocity, traffic light influence, traffic light state, etc. Stores all information in cache, avoiding subsequent calls to the server during the control loop . Related .cpp files: SimulationState.cpp , SimulationState.h .","title":"Simulation state"},{"location":"adv_traffic_manager/#control-loop","text":"The control loop manages the calculations of the next command for all autopilot vehicles so they are performed synchronously. The control loop consists of five different stages ; localization, collision, traffic light, motion planner and vehicle lights. The control loop: Receives an array of TM-controlled vehicles from the vehicle registry . Performs calculations for each vehicle separately by looping over the array. Divides calculations into a series of stages . Creates synchronization barriers between stages to guarantee consistency. Calculations for all vehicles are finished before any of them move to the next stage, ensuring all vehicles are updated in the same frame. Coordinates the transition between stages so all calculations are done in sync. Sends the command array to the server when the last stages ( Motion Planner Stage and Vehicle Lights Stage ) finishes so there are no frame delays between the command calculations and the command application. Related .cpp files: TrafficManagerLocal.cpp .","title":"Control loop"},{"location":"adv_traffic_manager/#in-memory-map","text":"The In-Memory Map is a helper module contained within the PBVT and is used during the Localization Stage . The In-Memory Map: Converts the map into a grid of discrete waypoints. Includes waypoints in a specific data structure with more information to connect waypoints and identify roads, junctions, etc. Identifies these structures with an ID used to locate vehicles in nearby areas quickly. Related .cpp files: InMemoryMap.cpp and SimpleWaypoint.cpp .","title":"In-Memory Map"},{"location":"adv_traffic_manager/#pbvt","text":"PBVT stands for Path Buffer and Vehicle Tracking . The PBVT is a data structure that contains the expected path for every vehicle and allows easy access to data during the control loop . The PBVT: Contains a map of deque objects with one entry per vehicle. Contains a set of waypoints for each vehicle describing its current location and near-future path. Contains the In-Memory Map used by the Localization Stage to relate every vehicle to the nearest waypoint and possible overlapping paths.","title":"PBVT"},{"location":"adv_traffic_manager/#pid-controller","text":"The PID controller is a helper module that performs calculations during the Motion Planner Stage . The PID controller: Estimates the throttle, brake, and steering input needed to reach a target value using the information gathered by the Motion Planner Stage . Makes adjustments depending on the specific parameterization of the controller. Parameters can be modified if desired. Read more about PID controllers to learn how to make modifications. Related .cpp files: PIDController.cpp .","title":"PID controller"},{"location":"adv_traffic_manager/#command-array","text":"The Command Array represents the last step in the TM logic cycle. It receives commands for all the registered vehicles and applies them. The Command Array: Receives a series of carla.VehicleControl 's from the Motion Planner Stage . Batches all commands to be applied during the same frame. Sends the batch to the CARLA server calling either apply_batch() or apply_batch_synch() in carla.Client depending on whether the simulation is running in asynchronous or synchronous mode, respectively. Related .cpp files: TrafficManagerLocal.cpp .","title":"Command Array"},{"location":"adv_traffic_manager/#stages-of-the-control-loop","text":"","title":"Stages of the Control Loop"},{"location":"adv_traffic_manager/#stage-1-localization-stage","text":"The Localization Stage defines a near-future path for vehicles controlled by the TM. The Localization Stage: Obtains the position and velocity of all vehicles from the simulation state . Uses the In-Memory Map to relate every vehicle with a list of waypoints that describes its current location and near-future path according to its trajectory. The faster the vehicle goes, the longer the list will be. Updates the path according to planning decisions such as lane changes, speed limit, distance to leading vehicle parameterization, etc. Stores the path for all vehicles in the PBVT module. Compares paths with each other to estimate possible collision situations. Results are passed to the Collision Stage. Related .cpp files: LocalizationStage.cpp and LocalizationUtils.cpp .","title":"Stage 1- Localization Stage"},{"location":"adv_traffic_manager/#stage-2-collision-stage","text":"The Collision Stage triggers collision hazards. The Collision Stage: Receives from the Localization Stage a list of vehicle pairs whose paths could potentially overlap. Extends bounding boxes along the path ahead (geodesic boundaries) for each vehicle pair to check if they actually overlap and determine whether the risk of collision is real. Sends hazards for all possible collisions to the Motion Planner Stage to modify the path accordingly. Related .cpp files: CollisionStage.cpp .","title":"Stage 2- Collision Stage"},{"location":"adv_traffic_manager/#stage-3-traffic-light-stage","text":"The Traffic Light stage triggers hazards due to traffic regulators such as traffic lights, stop signs, and priority at junctions. The Traffic Light stage: Sets a traffic hazard if a vehicle is under the influence of a yellow or red traffic light or a stop sign. Extends a bounding box along a vehicle's path if it is in an unsignaled junction. Vehicles with overlapping paths follow a \"First-In-First-Out\" order to move. Wait times are set to a fixed value. Related .cpp files: TrafficLightStage.cpp .","title":"Stage 3- Traffic Light Stage"},{"location":"adv_traffic_manager/#stage-4-motion-planner-stage","text":"The Motion Planner Stage generates the CARLA commands to be applied to vehicles. The Motion Planner Stage: Gathers a vehicle's position and velocity ( simulation state ), path ( PBVT ), and hazards ( Collision Stage and Traffic Light Stage ). Makes high-level decisions about how a vehicle should move, for example, computing the brake needed to prevent a collision hazard. A PID controller is used to estimate behaviors according to target values. Translates the desired movement to a carla.VehicleControl for application to the vehicle. Sends the resulting CARLA commands to the Command Array . Related .cpp files: MotionPlannerStage.cpp .","title":"Stage 4- Motion Planner Stage"},{"location":"adv_traffic_manager/#stage-5-vehicle-lights-stage","text":"The Vehicle Lights Stage activates the lights based on the condition of the vehicle and the surrounding environment. The Vehicle Lights Stage: Retrieves the planned waypoints for the vehicle, information about vehicle lights (eg. light state and the planned command to be applied) and the weather conditions. Determines the new state of the vehicle lights: Turns on the blinkers if the vehicle is planning to turn left/right at the next junction. Turns on the stop lights if the applied command is asking the vehicle to brake. Turns on the low beams and the position lights from sunset to dawn, or under heavy rain. Turns on the fog lights under heavy fog conditions. Update the vehicle lights state if it has changed. Related .cpp files: VehicleLightStage.cpp .","title":"Stage 5- Vehicle Lights Stage"},{"location":"adv_traffic_manager/#using-the-traffic-manager","text":"","title":"Using the Traffic Manager"},{"location":"adv_traffic_manager/#vehicle-behavior-considerations","text":"The TM implements general behavior patterns that must be taken into consideration when you set vehicles to autopilot: Vehicles are not goal-oriented, they follow a dynamically produced trajectory and choose a path randomly when approaching a junction. Their path is endless. Vehicles' target speed is 70% of their current speed limit unless any other value is set. Junction priority does not follow traffic regulations. The TM uses its own priority system at junctions. The resolution of this restriction is a work in progress. In the meantime, some issues may arise, for example, vehicles inside a roundabout yielding to a vehicle trying to get in. TM behavior can be adjusted through the Python API. For specific methods, see the TM section of the Python API documentation . Below is a general summary of what is possible through the API: Topic Description General: - Create a TM instance connected to a port. - Retrieve the port where a TM is connected. Safety conditions: - Set a minimum distance between stopped vehicles (for a single vehicle or for all vehicles). This will affect the minimum moving distance. - Set the desired speed as a percentage of the current speed limit (for a single vehicle or for all vehicles). - Reset traffic lights. Collision managing: - Enable/Disable collisions between a vehicle and a specific actor. - Make a vehicle ignore all other vehicles. - Make a vehicle ignore all walkers. - Make a vehicle ignore all traffic lights. Lane changes: - Force a lane change, ignoring possible collisions. - Enable/Disable lane changes for a vehicle. Hybrid physics mode: - Enable/Disable hybrid physics mode. - Change the radius in which physics is enabled.","title":"Vehicle behavior considerations"},{"location":"adv_traffic_manager/#creating-a-traffic-manager","text":"Note TM is designed to work in synchronous mode. Using TM in asynchronous mode can lead to unexpected and undesirable results. Read more in the section Synchronous mode . A TM instance is created by a carla.Client , passing the port to be used. The default port is 8000 . To create a TM instance: tm = client.get_trafficmanager(port) To enable autopilot for a set of vehicles, retrieve the port of the TM instance and set set_autopilot to True , passing the TM port at the same time. If no port is provided, it will try to connect to a TM in the default port ( 8000 ). If the TM does not exist, it will create one: tm_port = tm.get_port() for v in vehicles_list: v.set_autopilot(True,tm_port) Note Creating or connecting to a TM in multi-client situations is different from the above example. Learn more in the section Running multiple Traffic Managers . The generate_traffic.py script in /PythonAPI/examples provides an example of how to create a TM instance using a port passed as a script argument and register every vehicle spawned to it by setting the autopilot to True in a batch: traffic_manager = client.get_trafficmanager(args.tm-port) tm_port = traffic_manager.get_port() ... batch.append(SpawnActor(blueprint, transform).then(SetAutopilot(FutureActor, True,tm_port))) ... traffic_manager.global_percentage_speed_difference(30.0)","title":"Creating a Traffic Manager"},{"location":"adv_traffic_manager/#configuring-autopilot-behavior","text":"The following example creates a TM instance and configures dangerous behavior for a specific vehicle so it will ignore all traffic lights, leave no safety distance from other vehicles, and drive 20% faster than the current speed limit: tm = client.get_trafficmanager(port) tm_port = tm.get_port() for v in my_vehicles: v.set_autopilot(True,tm_port) danger_car = my_vehicles[0] tm.ignore_lights_percentage(danger_car,100) tm.distance_to_leading_vehicle(danger_car,0) tm.vehicle_percentage_speed_difference(danger_car,-20) The example below sets the same list of vehicles to autopilot but instead configures them with moderate driving behavior. The vehicles drive 80% slower than the current speed limit, leaving at least 5 meters between themselves and other vehicles, and never perform lane changes: tm = client.get_trafficmanager(port) tm_port = tm.get_port() for v in my_vehicles: v.set_autopilot(True,tm_port) danger_car = my_vehicles[0] tm.global_distance_to_leading_vehicle(5) tm.global_percentage_speed_difference(80) for v in my_vehicles: tm.auto_lane_change(v,False)","title":"Configuring autopilot behavior"},{"location":"adv_traffic_manager/#delegating-the-traffic-manager-to-automatically-update-vehicle-lights","text":"By default, vehicle lights (brake, turn indicators, etc...) of the vehicles managed by the TM are never updated. It is possible to delegate the TM to update the vehicle lights of a given vehicle actor: tm = client.get_trafficmanager(port) for actor in my_vehicles: tm.update_vehicle_lights(actor, True) Vehicle lights management has to be specified on a per-vehicle basis, and there could be at any given time both vehicles with and without the automatic light management.","title":"Delegating the Traffic Manager to automatically update vehicle lights"},{"location":"adv_traffic_manager/#stopping-a-traffic-manager","text":"The TM is not an actor that needs to be destroyed; it will stop when the client that created it stops. This is automatically managed by the API, the user does not have to do anything. However, when shutting down a TM, the user must destroy the vehicles controlled by it, otherwise they will remain immobile on the map. The script generate_traffic.py does this automatically: client.apply_batch([carla.command.DestroyActor(x) for x in vehicles_list]) Warning Shutting down a TM-Server will shut down the TM-Clients connecting to it. To learn the difference between a TM-Server and a TM-Client , read about Running multiple Traffic Managers .","title":"Stopping a Traffic Manager"},{"location":"adv_traffic_manager/#deterministic-mode","text":"In deterministic mode, the TM will produce the same results and behaviors under the same conditions. Do not mistake determinism with the recorder. While the recorder allows you to store the log of a simulation to play it back, determinism ensures that the TM will always have the same output over different executions of a script as long as the same conditions are maintained. Deterministic mode is available in synchronous mode only . In asynchronous mode, there is less control over the simulation and determinism cannot be achieved. Read more in the section \"Synchronous mode\" before starting. To enable deterministic mode, use the following method: my_tm.set_random_device_seed(seed_value) seed_value is an int number from which random numbers will be generated. The value itself is not relevant, but the same value will always result in the same output. Two simulations, with the same conditions, that use the same seed value, will be deterministic. To maintain determinism over multiple simulation runs, the seed must be set for every simulation . For example, each time the world is reloaded , the seed must be set again: client.reload_world() my_tm.set_random_device_seed(seed_value) Deterministic mode can be tested in the generate_traffic.py example script by passing a seed value as an argument. The following example populates a map with 50 autopilot actors in synchronous mode and sets the seed to an arbitrary value of 9 : cd PythonAPI/examples python3 generate_traffic.py -n 50 --seed 9 Warning The CARLA server and the TM must be in synchronous mode before enabling deterministic mode. Read more here about synchronous mode in TM.","title":"Deterministic mode"},{"location":"adv_traffic_manager/#hybrid-physics-mode","text":"Hybrid mode allows users to disable most physics calculations for all autopilot vehicles, or for autopilot vehicles outside of a certain radius of a vehicle tagged with hero . This removes the vehicle physics bottleneck from a simulation. Vehicles whose physics are disabled will move by teleportation. Basic calculations for linear acceleration are maintained to ensure position updates and vehicle speed remain realistic and the toggling of physics calculations on vehicles is fluid. Hybrid mode uses the Actor.set_simulate_physics() method to toggle physics calculations. It is disabled by default. There are two options to enable it: TrafficManager.set_hybrid_physics_mode(True) \u2014 This method enables hybrid mode for the TM object calling it. Running generate_traffic.py with the flag --hybrid \u2014 This example script creates a TM and spawns vehicles in autopilot. It then sets these vehicles to hybrid mode when the --hybrid flag is passed as a script argument. To modify the behavior of hybrid mode, use the following two parameters: Radius (default = 50 meters) \u2014 The radius is relative to vehicles tagged with hero . All vehicles inside this radius will have physics enabled; vehicles outside of the radius will have physics disabled. The size of the radius is modified using traffic_manager.set_hybrid_physics_radius(r) . Hero vehicle \u2014 A vehicle tagged with role_name='hero' that acts as the center of the radius. If there is no hero vehicle, all vehicles' physics will be disabled. If there is more than one hero vehicle, the radius will be considered for them all, creating different areas of influence with physics enabled. The clip below shows how physics is enabled and disabled when hybrid mode is active. The hero vehicle is tagged with a red square . Vehicles with physics disabled are tagged with a blue square . When inside the hero vehicle's radius of influence, physics are enabled and the tag becomes green .","title":"Hybrid physics mode"},{"location":"adv_traffic_manager/#running-multiple-traffic-managers","text":"","title":"Running multiple Traffic Managers"},{"location":"adv_traffic_manager/#traffic-manager-servers-and-clients","text":"A CARLA client creates a TM by specifying to the server which port to use. If a port is not specified, the default 8000 will be used. If further TMs are created on the same port, they will become TM-Clients and the original TM will become a TM-Server . These titles define how a TM behaves within a simulation.","title":"Traffic Manager servers and clients"},{"location":"adv_traffic_manager/#tm-server","text":"A TM-Server is created if it was the first TM to connect to a free port and then other TMs (TM-Clients) connected to the same port it was running on. The TM-Server will dictate the behavior of all the TM-Clients , e.g., if the TM-Server is stopped, all TM-Clients will stop. The following code creates two TM-Servers. Each one connects to a different, unused port: tm01 = client01.get_trafficmanager() # tm01 --> tm01 (p=8000) tm02 = client02.get_trafficmanager(5000) # tm02(p=5000) --> tm02 (p=5000)","title":"TM-Server"},{"location":"adv_traffic_manager/#tm-client","text":"A TM-Client is created when a TM connects to a port occupied by another TM (TM-Server). The TM-Client behavior will be dictated by the TM-Server. The following code creates two TM-Clients, each one connecting with the TM-Servers created in the section above. tm03 = client03.get_trafficmanager() # tm03 --> tm01 (p=8000). tm04 = client04.get_trafficmanager(5000) # tm04(p=5000) --> tm02 (p=5000) The CARLA server keeps a register of all TM instances by storing the port and the client IP (hidden to the user) that link to them. There is currently no way to check the TM instances that have been created so far. A connection will always be attempted when trying to create an instance and it will either create a new TM-Server or a TM-Client .","title":"TM-Client"},{"location":"adv_traffic_manager/#multi-client-simulations","text":"In a multi-client simulation, multiple TMs are created on the same port. The first TM will be a TM-Server and the rest will be TM-Clients connecting to it. The TM-Server will dictate the behavior of all the TM instances: terminal 1: ./CarlaUE4.sh -carla-rpc-port=4000 terminal 2: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Server terminal 3: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Client","title":"Multi-client simulations"},{"location":"adv_traffic_manager/#multi-tm-simulations","text":"In a multi-TM simulation, multiple TM instances are created on distinct ports. Each TM instance will control its own behavior: terminal 1: ./CarlaUE4.sh -carla-rpc-port=4000 terminal 2: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Server A terminal 3: python3 generate_traffic.py --port 4000 --tm-port 4550 # TM-Server B","title":"Multi-TM simulations"},{"location":"adv_traffic_manager/#multi-simulation","text":"Multi-simulation is when more than one CARLA server is running at the same time. The TM needs to connect to the relevant CARLA server port. As long as the computational power allows for it, the TM can run multiple simulations at a time without any problems: terminal 1: ./CarlaUE4.sh -carla-rpc-port=4000 # simulation A terminal 2: ./CarlaUE4.sh -carla-rpc-port=5000 # simulation B terminal 3: python3 generate_traffic.py --port 4000 --tm-port 4050 # TM-Server A connected to simulation A terminal 4: python3 generate_traffic.py --port 5000 --tm-port 5050 # TM-Server B connected to simulation B The concept of multi-simulation is independent of the TM itself. The example above runs two CARLA simulations in parallel, A and B. In each of them, a TM-Server is created independently from the other. Simulation A could run a multi-client TM while simulation B is running a multi-TM or no TM at all. The most likely issue arising from the above set-up is a client trying to connect to an already existing TM that is not running on the selected simulation. If this happens, an error message will appear and the connection will be aborted to prevent interferences between simulations.","title":"Multi-simulation"},{"location":"adv_traffic_manager/#synchronous-mode","text":"TM is designed to work in synchronous mode. Both the CARLA server and TM should be set to synchronous in order to function properly. Using TM in asynchronous mode can lead to unexpected and undesirable results, however, if asynchronous mode is required, the simulation should run at 20-30 fps at least. The script below demonstrates how to set both the server and TM to synchronous mode: ... # Set the simulation to sync mode init_settings = world.get_settings() settings = world.get_settings() settings.synchronous_mode = True # After that, set the TM to sync mode my_tm.set_synchronous_mode(True) ... # Tick the world in the same client world.apply_settings(init_settings) world.tick() ... # Always disable sync mode before the script ends to prevent the server blocking whilst waiting for a tick settings.synchronous_mode = False my_tm.set_synchronous_mode(False) The generate_traffic.py example script starts a TM and populates the map with vehicles and pedestrians. It automatically sets the TM and the CARLA server to synchronous mode: cd PythonAPI/examples python3 generate_traffic.py -n 50 If asynchronous mode is required, use the --async flag when running the above command. If more than one TM is set to synchronous mode, synchrony will fail. Follow these guidelines to avoid issues: In a multiclient situation, only the TM-Server should be set to synchronous mode. In a multiTM situation, only one TM-Server should be set to synchronous mode. The ScenarioRunner module runs a TM automatically. The TM inside ScenarioRunner will automatically be the one set to sync mode. Warning Disable synchronous mode (for both the world and TM) in your script managing ticks before it finishes to prevent the server blocking, waiting forever for a tick.","title":"Synchronous mode"},{"location":"adv_traffic_manager/#traffic-manager-in-large-maps","text":"To understand how the TM works on large maps, make sure to first familiarise yourself with how large maps work by reading the documentation here . The behavior of autopilot vehicles in large maps depends on whether or not there is a hero vehicle present: Hero vehicle not present All autopilot vehicles will be considered dormant actors. The dormant autopilot actors will be moved around the map as in hybrid mode. The vehicles will not be rendered since there is no hero vehicle to trigger map tile streaming. Hero vehicle present Autopilot vehicles will become dormant when they exceed the value defined by actor_active_distance . To set this value, use the Python API: settings = world.get_settings() # Actors will become dormant 2km away from the ego vehicle settings.actor_active_distance = 2000 world.apply_settings(settings) In the TM, dormant actors can be configured to continually respawn around the hero vehicle instead of remaining dormant on other parts of the map. This option can be configured using the set_respawn_dormant_vehicles method in the Python API. Vehicles will be respawned within a user-definable distance of the hero vehicle. The upper and lower boundaries of the respawnable distance can be set using the set_boundaries_respawn_dormant_vehicles method. Note that the upper distance will not be bigger than the tile streaming distance of the large map and the minimum lower distance is 20m. To enable respawning of dormant vehicles within 25 and 700 meters of the hero vehicle: my_tm.set_respawn_dormant_vehicles(True) my_tm.set_boundaries_respawn_dormant_vehicles(25,700) If collisions prevent a dormant actor from being respawned, the TM will retry on the next simulation step. If dormant vehicles are not respawned, their behavior will depend on whether hybrid mode is enabled. If hybrid mode has been enabled, then the dormant actors will be teleported around the map. If hybrid mode is not enabled, then dormant actor's physics will not be computed and they will stay in place until they are no longer dormant. If you have any questions about the TM, then you can ask in the forum . CARLA forum","title":"Traffic manager in large maps"},{"location":"bp_library/","text":"Blueprint Library The Blueprint Library ( carla.BlueprintLibrary ) is a summary of all carla.ActorBlueprint and its attributes ( carla.ActorAttribute ) available to the user in CARLA. Here is an example code for printing all actor blueprints and their attributes: blueprints = [bp for bp in world.get_blueprint_library().filter('*')] for blueprint in blueprints: print(blueprint.id) for attr in blueprint: print(' - {}'.format(attr)) Check out the introduction to blueprints . controller controller.ai.walker Attributes: role_name ( String ) - Modifiable sensor sensor.camera.depth Attributes: fov ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.camera.dvs Attributes: black_clip ( Float ) - Modifiable blade_count ( Int ) - Modifiable bloom_intensity ( Float ) - Modifiable blur_amount ( Float ) - Modifiable blur_radius ( Float ) - Modifiable calibration_constant ( Float ) - Modifiable chromatic_aberration_intensity ( Float ) - Modifiable chromatic_aberration_offset ( Float ) - Modifiable enable_postprocess_effects ( Bool ) - Modifiable exposure_compensation ( Float ) - Modifiable exposure_max_bright ( Float ) - Modifiable exposure_min_bright ( Float ) - Modifiable exposure_mode ( String ) - Modifiable exposure_speed_down ( Float ) - Modifiable exposure_speed_up ( Float ) - Modifiable focal_distance ( Float ) - Modifiable fov ( Float ) - Modifiable fstop ( Float ) - Modifiable gamma ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable iso ( Float ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_flare_intensity ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable log_eps ( Float ) - Modifiable min_fstop ( Float ) - Modifiable motion_blur_intensity ( Float ) - Modifiable motion_blur_max_distortion ( Float ) - Modifiable motion_blur_min_object_screen_size ( Float ) - Modifiable negative_threshold ( Float ) - Modifiable positive_threshold ( Float ) - Modifiable refractory_period_ns ( Int ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable shoulder ( Float ) - Modifiable shutter_speed ( Float ) - Modifiable sigma_negative_threshold ( Float ) - Modifiable sigma_positive_threshold ( Float ) - Modifiable slope ( Float ) - Modifiable temp ( Float ) - Modifiable tint ( Float ) - Modifiable toe ( Float ) - Modifiable use_log ( Bool ) - Modifiable white_clip ( Float ) - Modifiable sensor.camera.optical_flow Attributes: fov ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.camera.rgb Attributes: black_clip ( Float ) - Modifiable blade_count ( Int ) - Modifiable bloom_intensity ( Float ) - Modifiable blur_amount ( Float ) - Modifiable blur_radius ( Float ) - Modifiable calibration_constant ( Float ) - Modifiable chromatic_aberration_intensity ( Float ) - Modifiable chromatic_aberration_offset ( Float ) - Modifiable enable_postprocess_effects ( Bool ) - Modifiable exposure_compensation ( Float ) - Modifiable exposure_max_bright ( Float ) - Modifiable exposure_min_bright ( Float ) - Modifiable exposure_mode ( String ) - Modifiable exposure_speed_down ( Float ) - Modifiable exposure_speed_up ( Float ) - Modifiable focal_distance ( Float ) - Modifiable fov ( Float ) - Modifiable fstop ( Float ) - Modifiable gamma ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable iso ( Float ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_flare_intensity ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable min_fstop ( Float ) - Modifiable motion_blur_intensity ( Float ) - Modifiable motion_blur_max_distortion ( Float ) - Modifiable motion_blur_min_object_screen_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable shoulder ( Float ) - Modifiable shutter_speed ( Float ) - Modifiable slope ( Float ) - Modifiable temp ( Float ) - Modifiable tint ( Float ) - Modifiable toe ( Float ) - Modifiable white_clip ( Float ) - Modifiable sensor.camera.semantic_segmentation Attributes: fov ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.lidar.ray_cast Attributes: atmosphere_attenuation_rate ( Float ) - Modifiable channels ( Int ) - Modifiable dropoff_general_rate ( Float ) - Modifiable dropoff_intensity_limit ( Float ) - Modifiable dropoff_zero_intensity ( Float ) - Modifiable horizontal_fov ( Float ) - Modifiable lower_fov ( Float ) - Modifiable noise_seed ( Int ) - Modifiable noise_stddev ( Float ) - Modifiable points_per_second ( Int ) - Modifiable range ( Float ) - Modifiable role_name ( String ) - Modifiable rotation_frequency ( Float ) - Modifiable sensor_tick ( Float ) - Modifiable upper_fov ( Float ) - Modifiable sensor.lidar.ray_cast_semantic Attributes: channels ( Int ) - Modifiable horizontal_fov ( Float ) - Modifiable lower_fov ( Float ) - Modifiable points_per_second ( Int ) - Modifiable range ( Float ) - Modifiable role_name ( String ) - Modifiable rotation_frequency ( Float ) - Modifiable sensor_tick ( Float ) - Modifiable upper_fov ( Float ) - Modifiable sensor.other.collision Attributes: role_name ( String ) - Modifiable sensor.other.gnss Attributes: noise_alt_bias ( Float ) - Modifiable noise_alt_stddev ( Float ) - Modifiable noise_lat_bias ( Float ) - Modifiable noise_lat_stddev ( Float ) - Modifiable noise_lon_bias ( Float ) - Modifiable noise_lon_stddev ( Float ) - Modifiable noise_seed ( Int ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.other.imu Attributes: noise_accel_stddev_x ( Float ) - Modifiable noise_accel_stddev_y ( Float ) - Modifiable noise_accel_stddev_z ( Float ) - Modifiable noise_gyro_bias_x ( Float ) - Modifiable noise_gyro_bias_y ( Float ) - Modifiable noise_gyro_bias_z ( Float ) - Modifiable noise_gyro_stddev_x ( Float ) - Modifiable noise_gyro_stddev_y ( Float ) - Modifiable noise_gyro_stddev_z ( Float ) - Modifiable noise_seed ( Int ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.other.lane_invasion Attributes: role_name ( String ) - Modifiable sensor.other.obstacle Attributes: debug_linetrace ( Bool ) - Modifiable distance ( Float ) - Modifiable hit_radius ( Float ) - Modifiable only_dynamics ( Bool ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.other.radar Attributes: horizontal_fov ( Float ) - Modifiable noise_seed ( Int ) - Modifiable points_per_second ( Int ) - Modifiable range ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable vertical_fov ( Float ) - Modifiable sensor.other.rss Attributes: role_name ( String ) - Modifiable static static.prop.advertisement Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.atm Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.barbeque Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.barrel Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bench01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bench02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bench03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bike helmet Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bin Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.box01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.box02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.box03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.briefcase Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.busstop Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.calibrator Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.chainbarrier Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.chainbarrierend Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.clothcontainer Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.clothesline Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.colacan Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.constructioncone Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.container Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.creasedbox01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.creasedbox02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.creasedbox03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.dirtdebris01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.dirtdebris02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.dirtdebris03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.doghouse Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.fountain Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage05 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage06 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.gardenlamp Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.glasscontainer Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.gnome Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.guitarcase Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.ironplank Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.kiosk_01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.mailbox Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.maptable Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.mesh Attributes: role_name ( String ) - Modifiable static.prop.mobile Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.motorhelmet Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.omri-0 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.omri-1 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.pergola Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot05 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot06 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot07 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot08 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plasticbag Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plasticchair Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plastictable Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.platformgarbage01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.purse Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.shoppingbag Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.shoppingcart Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.shoppingtrolley Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.slide Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetbarrier Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetfountain Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetsign Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetsign01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetsign04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.swing Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.swingcouch Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.table Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trafficcone01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trafficcone02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trafficwarning Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trampoline Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashbag Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan05 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.travelcase Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.vendingmachine Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.wateringcan Attributes: role_name ( String ) - Modifiable size ( String ) static.trigger.friction Attributes: extent_x ( Float ) - Modifiable extent_y ( Float ) - Modifiable extent_z ( Float ) - Modifiable friction ( Float ) - Modifiable role_name ( String ) - Modifiable vehicle vehicle.audi.a2 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.audi.etron Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.audi.tt Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.bh.crossbike Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.bmw.grandtourer Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.carlamotors.carlacola Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.carlamotors.firetruck Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.chevrolet.impala Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.citroen.c3 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.diamondback.century Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.dodge.charger_2020 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.dodge.charger_police Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.dodge.charger_police_2020 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.ford.ambulance Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.ford.crown Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.ford.mustang Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.gazelle.omafiets Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.harley-davidson.low_rider Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.jeep.wrangler_rubicon Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.kawasaki.ninja Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.lincoln.mkz_2017 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.lincoln.mkz_2020 Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mercedes.coupe Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mercedes.coupe_2020 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mercedes.sprinter Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.micro.microlino Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mini.cooper_s Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mini.cooper_s_2021 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.nissan.micra Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.nissan.patrol Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.nissan.patrol_2021 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.seat.leon Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.tesla.cybertruck Attributes: generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.tesla.model3 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.toyota.prius Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.vespa.zx125 Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.volkswagen.t2 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.volkswagen.t2_2021 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.yamaha.yzf Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable walker walker.pedestrian.0001 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0002 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0003 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0004 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0005 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0006 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0007 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0008 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0009 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0010 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0011 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0012 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0013 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0014 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0015 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0016 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0017 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0018 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0019 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0020 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0021 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0022 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0023 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0024 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0025 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0026 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0027 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0028 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0029 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0030 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0031 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0032 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0033 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0034 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0035 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0036 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0037 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0038 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0039 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0040 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0041 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0042 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0043 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0044 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0045 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0046 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0047 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0048 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable","title":"Blueprint Library"},{"location":"bp_library/#blueprint-library","text":"The Blueprint Library ( carla.BlueprintLibrary ) is a summary of all carla.ActorBlueprint and its attributes ( carla.ActorAttribute ) available to the user in CARLA. Here is an example code for printing all actor blueprints and their attributes: blueprints = [bp for bp in world.get_blueprint_library().filter('*')] for blueprint in blueprints: print(blueprint.id) for attr in blueprint: print(' - {}'.format(attr)) Check out the introduction to blueprints .","title":"Blueprint Library"},{"location":"bp_library/#controller","text":"controller.ai.walker Attributes: role_name ( String ) - Modifiable","title":"controller"},{"location":"bp_library/#sensor","text":"sensor.camera.depth Attributes: fov ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.camera.dvs Attributes: black_clip ( Float ) - Modifiable blade_count ( Int ) - Modifiable bloom_intensity ( Float ) - Modifiable blur_amount ( Float ) - Modifiable blur_radius ( Float ) - Modifiable calibration_constant ( Float ) - Modifiable chromatic_aberration_intensity ( Float ) - Modifiable chromatic_aberration_offset ( Float ) - Modifiable enable_postprocess_effects ( Bool ) - Modifiable exposure_compensation ( Float ) - Modifiable exposure_max_bright ( Float ) - Modifiable exposure_min_bright ( Float ) - Modifiable exposure_mode ( String ) - Modifiable exposure_speed_down ( Float ) - Modifiable exposure_speed_up ( Float ) - Modifiable focal_distance ( Float ) - Modifiable fov ( Float ) - Modifiable fstop ( Float ) - Modifiable gamma ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable iso ( Float ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_flare_intensity ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable log_eps ( Float ) - Modifiable min_fstop ( Float ) - Modifiable motion_blur_intensity ( Float ) - Modifiable motion_blur_max_distortion ( Float ) - Modifiable motion_blur_min_object_screen_size ( Float ) - Modifiable negative_threshold ( Float ) - Modifiable positive_threshold ( Float ) - Modifiable refractory_period_ns ( Int ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable shoulder ( Float ) - Modifiable shutter_speed ( Float ) - Modifiable sigma_negative_threshold ( Float ) - Modifiable sigma_positive_threshold ( Float ) - Modifiable slope ( Float ) - Modifiable temp ( Float ) - Modifiable tint ( Float ) - Modifiable toe ( Float ) - Modifiable use_log ( Bool ) - Modifiable white_clip ( Float ) - Modifiable sensor.camera.optical_flow Attributes: fov ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.camera.rgb Attributes: black_clip ( Float ) - Modifiable blade_count ( Int ) - Modifiable bloom_intensity ( Float ) - Modifiable blur_amount ( Float ) - Modifiable blur_radius ( Float ) - Modifiable calibration_constant ( Float ) - Modifiable chromatic_aberration_intensity ( Float ) - Modifiable chromatic_aberration_offset ( Float ) - Modifiable enable_postprocess_effects ( Bool ) - Modifiable exposure_compensation ( Float ) - Modifiable exposure_max_bright ( Float ) - Modifiable exposure_min_bright ( Float ) - Modifiable exposure_mode ( String ) - Modifiable exposure_speed_down ( Float ) - Modifiable exposure_speed_up ( Float ) - Modifiable focal_distance ( Float ) - Modifiable fov ( Float ) - Modifiable fstop ( Float ) - Modifiable gamma ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable iso ( Float ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_flare_intensity ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable min_fstop ( Float ) - Modifiable motion_blur_intensity ( Float ) - Modifiable motion_blur_max_distortion ( Float ) - Modifiable motion_blur_min_object_screen_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable shoulder ( Float ) - Modifiable shutter_speed ( Float ) - Modifiable slope ( Float ) - Modifiable temp ( Float ) - Modifiable tint ( Float ) - Modifiable toe ( Float ) - Modifiable white_clip ( Float ) - Modifiable sensor.camera.semantic_segmentation Attributes: fov ( Float ) - Modifiable image_size_x ( Int ) - Modifiable image_size_y ( Int ) - Modifiable lens_circle_falloff ( Float ) - Modifiable lens_circle_multiplier ( Float ) - Modifiable lens_k ( Float ) - Modifiable lens_kcube ( Float ) - Modifiable lens_x_size ( Float ) - Modifiable lens_y_size ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.lidar.ray_cast Attributes: atmosphere_attenuation_rate ( Float ) - Modifiable channels ( Int ) - Modifiable dropoff_general_rate ( Float ) - Modifiable dropoff_intensity_limit ( Float ) - Modifiable dropoff_zero_intensity ( Float ) - Modifiable horizontal_fov ( Float ) - Modifiable lower_fov ( Float ) - Modifiable noise_seed ( Int ) - Modifiable noise_stddev ( Float ) - Modifiable points_per_second ( Int ) - Modifiable range ( Float ) - Modifiable role_name ( String ) - Modifiable rotation_frequency ( Float ) - Modifiable sensor_tick ( Float ) - Modifiable upper_fov ( Float ) - Modifiable sensor.lidar.ray_cast_semantic Attributes: channels ( Int ) - Modifiable horizontal_fov ( Float ) - Modifiable lower_fov ( Float ) - Modifiable points_per_second ( Int ) - Modifiable range ( Float ) - Modifiable role_name ( String ) - Modifiable rotation_frequency ( Float ) - Modifiable sensor_tick ( Float ) - Modifiable upper_fov ( Float ) - Modifiable sensor.other.collision Attributes: role_name ( String ) - Modifiable sensor.other.gnss Attributes: noise_alt_bias ( Float ) - Modifiable noise_alt_stddev ( Float ) - Modifiable noise_lat_bias ( Float ) - Modifiable noise_lat_stddev ( Float ) - Modifiable noise_lon_bias ( Float ) - Modifiable noise_lon_stddev ( Float ) - Modifiable noise_seed ( Int ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.other.imu Attributes: noise_accel_stddev_x ( Float ) - Modifiable noise_accel_stddev_y ( Float ) - Modifiable noise_accel_stddev_z ( Float ) - Modifiable noise_gyro_bias_x ( Float ) - Modifiable noise_gyro_bias_y ( Float ) - Modifiable noise_gyro_bias_z ( Float ) - Modifiable noise_gyro_stddev_x ( Float ) - Modifiable noise_gyro_stddev_y ( Float ) - Modifiable noise_gyro_stddev_z ( Float ) - Modifiable noise_seed ( Int ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.other.lane_invasion Attributes: role_name ( String ) - Modifiable sensor.other.obstacle Attributes: debug_linetrace ( Bool ) - Modifiable distance ( Float ) - Modifiable hit_radius ( Float ) - Modifiable only_dynamics ( Bool ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable sensor.other.radar Attributes: horizontal_fov ( Float ) - Modifiable noise_seed ( Int ) - Modifiable points_per_second ( Int ) - Modifiable range ( Float ) - Modifiable role_name ( String ) - Modifiable sensor_tick ( Float ) - Modifiable vertical_fov ( Float ) - Modifiable sensor.other.rss Attributes: role_name ( String ) - Modifiable","title":"sensor"},{"location":"bp_library/#static","text":"static.prop.advertisement Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.atm Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.barbeque Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.barrel Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bench01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bench02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bench03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bike helmet Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.bin Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.box01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.box02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.box03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.briefcase Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.brokentile04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.busstop Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.calibrator Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.chainbarrier Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.chainbarrierend Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.clothcontainer Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.clothesline Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.colacan Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.constructioncone Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.container Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.creasedbox01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.creasedbox02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.creasedbox03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.dirtdebris01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.dirtdebris02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.dirtdebris03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.doghouse Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.fountain Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage05 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.garbage06 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.gardenlamp Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.glasscontainer Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.gnome Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.guitarcase Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.ironplank Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.kiosk_01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.mailbox Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.maptable Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.mesh Attributes: role_name ( String ) - Modifiable static.prop.mobile Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.motorhelmet Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.omri-0 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.omri-1 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.pergola Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot05 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot06 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot07 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plantpot08 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plasticbag Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plasticchair Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.plastictable Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.platformgarbage01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.purse Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.shoppingbag Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.shoppingcart Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.shoppingtrolley Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.slide Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetbarrier Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetfountain Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetsign Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetsign01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.streetsign04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.swing Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.swingcouch Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.table Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trafficcone01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trafficcone02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trafficwarning Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trampoline Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashbag Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan01 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan02 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan03 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan04 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.trashcan05 Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.travelcase Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.vendingmachine Attributes: role_name ( String ) - Modifiable size ( String ) static.prop.wateringcan Attributes: role_name ( String ) - Modifiable size ( String ) static.trigger.friction Attributes: extent_x ( Float ) - Modifiable extent_y ( Float ) - Modifiable extent_z ( Float ) - Modifiable friction ( Float ) - Modifiable role_name ( String ) - Modifiable","title":"static"},{"location":"bp_library/#vehicle","text":"vehicle.audi.a2 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.audi.etron Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.audi.tt Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.bh.crossbike Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.bmw.grandtourer Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.carlamotors.carlacola Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.carlamotors.firetruck Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.chevrolet.impala Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.citroen.c3 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.diamondback.century Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.dodge.charger_2020 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.dodge.charger_police Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.dodge.charger_police_2020 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.ford.ambulance Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.ford.crown Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.ford.mustang Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.gazelle.omafiets Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.harley-davidson.low_rider Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.jeep.wrangler_rubicon Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.kawasaki.ninja Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.lincoln.mkz_2017 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.lincoln.mkz_2020 Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mercedes.coupe Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mercedes.coupe_2020 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mercedes.sprinter Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.micro.microlino Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mini.cooper_s Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.mini.cooper_s_2021 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.nissan.micra Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.nissan.patrol Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.nissan.patrol_2021 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.seat.leon Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.tesla.cybertruck Attributes: generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.tesla.model3 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.toyota.prius Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.vespa.zx125 Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.volkswagen.t2 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.volkswagen.t2_2021 Attributes: color ( RGBColor ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable vehicle.yamaha.yzf Attributes: color ( RGBColor ) - Modifiable driver_id ( Int ) - Modifiable generation ( Int ) number_of_wheels ( Int ) object_type ( String ) role_name ( String ) - Modifiable sticky_control ( Bool ) - Modifiable","title":"vehicle"},{"location":"bp_library/#walker","text":"walker.pedestrian.0001 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0002 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0003 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0004 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0005 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0006 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0007 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0008 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0009 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0010 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0011 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0012 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0013 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0014 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0015 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0016 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0017 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0018 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0019 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0020 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0021 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0022 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0023 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0024 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0025 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0026 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0027 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0028 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0029 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0030 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0031 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0032 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0033 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0034 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0035 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0036 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0037 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0038 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0039 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0040 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0041 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0042 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0043 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0044 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0045 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0046 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0047 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable walker.pedestrian.0048 Attributes: age ( String ) gender ( String ) generation ( Int ) is_invincible ( Bool ) - Modifiable role_name ( String ) - Modifiable speed ( Float ) - Modifiable","title":"walker"},{"location":"build_docker/","text":"CARLA in Docker Users can pull an image based on a CARLA release to run in a Docker container. This is useful for users who: Want to run CARLA without needing to install all dependencies Run multiple CARLA servers and perform GPU mapping Run the CARLA server without a display This tutorial explains the requirements to run the CARLA image and how to run the image with both OpenGL and Vulkan graphics APIs. Before you begin Running CARLA in a container Off-screen mode Before you begin You will need to have installed: Docker: Follow the installation instructions here . NVIDIA Container Toolkit: The NVIDIA Container Toolkit is a library and toolset that exposes NVIDIA graphics devices to Linux containers. It is designed specifically for Linux containers running on Linux host systems or within Linux distributions under version 2 of the Windows Subsystem for Linux. Install the nvidia-docker2 package by following the instructions here . Note Docker requires sudo to run. Follow this guide to add users to the docker sudo group. Running CARLA in a container 1. Pull the CARLA image. You can pull either the latest CARLA image or a specific release version. The latest image refers to the most recent packaged release . To pull the image, run one of the following commands: # Pull the latest image docker pull carlasim/carla:latest # Pull a specific version docker pull carlasim/carla:0.9.12 2. Run the CARLA container. Different versions of CARLA support different graphics APIs which can affect the conditions in which the Docker image can run: 0.9.12 supports only Vulkan 0.9.7+ supports both Vulkan and OpenGL. CARLA 0.9.12 To run CARLA with a display: sudo docker run --privileged --gpus all --net=host -e DISPLAY=$DISPLAY carlasim/carla:0.9.12 /bin/bash ./CarlaUE4.sh To run CARLA in off-screen mode: sudo docker run --privileged --gpus all --net=host -v /tmp/.X11-unix:/tmp/.X11-unix:rw carlasim/carla:0.9.12 /bin/bash ./CarlaUE4.sh -RenderOffScreen CARLA 0.9.7 to 0.9.11 To run CARLA using Vulkan: sudo docker run --privileged --gpus all --net=host -e DISPLAY=$DISPLAY -e SDL_VIDEODRIVER=x11 -v /tmp/.X11-unix:/tmp/.X11-unix:rw carlasim/carla:0.9.11 /bin/bash ./CarlaUE4.sh -vulkan <-additonal-carla-flags> Note This command will allow you to run the CARLA image with Vulkan as long as your machine has a display. See the rendering documentation for information on running with Vulkan in off-screen mode. To run CARLA using OpenGL: docker run -e DISPLAY=$DISPLAY --net=host --gpus all --runtime=nvidia carlasim/carla:<version> /bin/bash CarlaUE4.sh -opengl <-additonal-carla-flags> 3. (Optional) Configure Docker flags. The above commands use some Docker flags that can be configured according to your needs: Networking: The --net=host argument will allow the container to share the host's entire network. If you prefer to map specific ports on the host machine to container ports, use the flag -p <host-ports>:<container-ports> . GPUs: You can choose to use all GPUs with --gpus all , or target specific GPUs with --gpus '\"device=<gpu_01>,<gpu_02>\"' . See here for more information. Off-screen mode OpenGL requires no configuration if you are running CARLA on a machine without a display, however you will need to perform some extra steps to do the same using Vulkan prior to CARLA 0.9.12. See the rendering documentation for information. Any issues or doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"CARLA in Docker"},{"location":"build_docker/#carla-in-docker","text":"Users can pull an image based on a CARLA release to run in a Docker container. This is useful for users who: Want to run CARLA without needing to install all dependencies Run multiple CARLA servers and perform GPU mapping Run the CARLA server without a display This tutorial explains the requirements to run the CARLA image and how to run the image with both OpenGL and Vulkan graphics APIs. Before you begin Running CARLA in a container Off-screen mode","title":"CARLA in Docker"},{"location":"build_docker/#before-you-begin","text":"You will need to have installed: Docker: Follow the installation instructions here . NVIDIA Container Toolkit: The NVIDIA Container Toolkit is a library and toolset that exposes NVIDIA graphics devices to Linux containers. It is designed specifically for Linux containers running on Linux host systems or within Linux distributions under version 2 of the Windows Subsystem for Linux. Install the nvidia-docker2 package by following the instructions here . Note Docker requires sudo to run. Follow this guide to add users to the docker sudo group.","title":"Before you begin"},{"location":"build_docker/#running-carla-in-a-container","text":"1. Pull the CARLA image. You can pull either the latest CARLA image or a specific release version. The latest image refers to the most recent packaged release . To pull the image, run one of the following commands: # Pull the latest image docker pull carlasim/carla:latest # Pull a specific version docker pull carlasim/carla:0.9.12 2. Run the CARLA container. Different versions of CARLA support different graphics APIs which can affect the conditions in which the Docker image can run: 0.9.12 supports only Vulkan 0.9.7+ supports both Vulkan and OpenGL. CARLA 0.9.12 To run CARLA with a display: sudo docker run --privileged --gpus all --net=host -e DISPLAY=$DISPLAY carlasim/carla:0.9.12 /bin/bash ./CarlaUE4.sh To run CARLA in off-screen mode: sudo docker run --privileged --gpus all --net=host -v /tmp/.X11-unix:/tmp/.X11-unix:rw carlasim/carla:0.9.12 /bin/bash ./CarlaUE4.sh -RenderOffScreen CARLA 0.9.7 to 0.9.11 To run CARLA using Vulkan: sudo docker run --privileged --gpus all --net=host -e DISPLAY=$DISPLAY -e SDL_VIDEODRIVER=x11 -v /tmp/.X11-unix:/tmp/.X11-unix:rw carlasim/carla:0.9.11 /bin/bash ./CarlaUE4.sh -vulkan <-additonal-carla-flags> Note This command will allow you to run the CARLA image with Vulkan as long as your machine has a display. See the rendering documentation for information on running with Vulkan in off-screen mode. To run CARLA using OpenGL: docker run -e DISPLAY=$DISPLAY --net=host --gpus all --runtime=nvidia carlasim/carla:<version> /bin/bash CarlaUE4.sh -opengl <-additonal-carla-flags> 3. (Optional) Configure Docker flags. The above commands use some Docker flags that can be configured according to your needs: Networking: The --net=host argument will allow the container to share the host's entire network. If you prefer to map specific ports on the host machine to container ports, use the flag -p <host-ports>:<container-ports> . GPUs: You can choose to use all GPUs with --gpus all , or target specific GPUs with --gpus '\"device=<gpu_01>,<gpu_02>\"' . See here for more information.","title":"Running CARLA in a container"},{"location":"build_docker/#off-screen-mode","text":"OpenGL requires no configuration if you are running CARLA on a machine without a display, however you will need to perform some extra steps to do the same using Vulkan prior to CARLA 0.9.12. See the rendering documentation for information. Any issues or doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"Off-screen mode"},{"location":"build_docker_unreal/","text":"Build Unreal Engine and CARLA in Docker This guide explains how Unreal Engine and CARLA can be built from scratch using Docker. The resulting image can then used to create CARLA packages or to prepare assets for use in a CARLA package. This process should not be confused with the pre-built CARLA Docker image used to run CARLA on multiple servers or without a display. The documentation for that can be found here . Before you begin System Requirements Software requirements Building the images Next Steps: Packages Before you begin System Requirements You will need to meet the following system requirements: 64-bit version of Docker is Ubuntu 16.04+ Minimum 8GB of RAM Minimum 600GB available disk space for the initial container build process Software requirements Docker: Install Docker by following the installation instructions here . Python : You will need to have Python 3.6 or higher installed and properly set in your system Path. For installation instructions and Python documentation, check here . Unreal Engine GitHub Access : Starting with version 0.9.12, CARLA uses a modified fork of Unreal Engine 4.26. This fork contains patches specific to CARLA. This will be downloaded during the Docker build process. For this download, you need to have a GitHub account linked to Unreal Engine's account . If you don't have this set up, please follow this guide before going any further. You will need to log in to your account during the build process. CARLA: The Dockerfiles and tools needed to build Unreal Engine for CARLA and CARLA itself are located in the Util/Docker directory of the CARLA source repository. If you don't already have it, download the repository using the following command: git clone https://github.com/carla-simulator/carla Building the images The following steps will each take a long time. 1. Build the CARLA prerequisites image. The following command will build an image called carla-prerequisites using Prerequisites.Dockerfile . In this build we install the compiler and required tools, download the Unreal Engine 4.26 fork and compile it. You will need to provide your login details as build arguments for the download of Unreal Engine to be successful: docker build --build-arg EPIC_USER=<GitHubUserName> --build-arg EPIC_PASS=<GitHubPassword> -t carla-prerequisites -f Prerequisites.Dockerfile . 2. Build the final CARLA image. The following command will use the image created in the previous step to build the final CARLA image based on the current master branch (latest release) of the CARLA repository: docker build -t carla -f Carla.Dockerfile . If you would like to build a specific branch or tag of the CARLA repository, run the following command: docker build -t carla -f Carla.Dockerfile . --build-arg GIT_BRANCH=<branch_or_tag_name> Next Steps: Packages The CARLA image created in this guide is used to create standalone CARLA packages or to package assets such as maps or meshes so they can be used in a CARLA package. This is achieved through the use of the docker_tools.py script found in Util/Docker . This script uses docker-py to work with the Docker image. The docker_tools.py script can be used to: Create a CARLA package : Find the tutorial here Cook assets to be consumed in a CARLA package: Find the tutorial here Prepare a map so it's ready for use in a CARLA package: Find the tutorial here Any issues or doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"\u5728 Docker \u4e2d\u6784\u5efa\u865a\u5e7b\u5f15\u64ceUE\u548c CARLA"},{"location":"build_docker_unreal/#build-unreal-engine-and-carla-in-docker","text":"This guide explains how Unreal Engine and CARLA can be built from scratch using Docker. The resulting image can then used to create CARLA packages or to prepare assets for use in a CARLA package. This process should not be confused with the pre-built CARLA Docker image used to run CARLA on multiple servers or without a display. The documentation for that can be found here . Before you begin System Requirements Software requirements Building the images Next Steps: Packages","title":"Build Unreal Engine and CARLA in Docker"},{"location":"build_docker_unreal/#before-you-begin","text":"","title":"Before you begin"},{"location":"build_docker_unreal/#system-requirements","text":"You will need to meet the following system requirements: 64-bit version of Docker is Ubuntu 16.04+ Minimum 8GB of RAM Minimum 600GB available disk space for the initial container build process","title":"System Requirements"},{"location":"build_docker_unreal/#software-requirements","text":"Docker: Install Docker by following the installation instructions here . Python : You will need to have Python 3.6 or higher installed and properly set in your system Path. For installation instructions and Python documentation, check here . Unreal Engine GitHub Access : Starting with version 0.9.12, CARLA uses a modified fork of Unreal Engine 4.26. This fork contains patches specific to CARLA. This will be downloaded during the Docker build process. For this download, you need to have a GitHub account linked to Unreal Engine's account . If you don't have this set up, please follow this guide before going any further. You will need to log in to your account during the build process. CARLA: The Dockerfiles and tools needed to build Unreal Engine for CARLA and CARLA itself are located in the Util/Docker directory of the CARLA source repository. If you don't already have it, download the repository using the following command: git clone https://github.com/carla-simulator/carla","title":"Software requirements"},{"location":"build_docker_unreal/#building-the-images","text":"The following steps will each take a long time. 1. Build the CARLA prerequisites image. The following command will build an image called carla-prerequisites using Prerequisites.Dockerfile . In this build we install the compiler and required tools, download the Unreal Engine 4.26 fork and compile it. You will need to provide your login details as build arguments for the download of Unreal Engine to be successful: docker build --build-arg EPIC_USER=<GitHubUserName> --build-arg EPIC_PASS=<GitHubPassword> -t carla-prerequisites -f Prerequisites.Dockerfile . 2. Build the final CARLA image. The following command will use the image created in the previous step to build the final CARLA image based on the current master branch (latest release) of the CARLA repository: docker build -t carla -f Carla.Dockerfile . If you would like to build a specific branch or tag of the CARLA repository, run the following command: docker build -t carla -f Carla.Dockerfile . --build-arg GIT_BRANCH=<branch_or_tag_name>","title":"Building the images"},{"location":"build_docker_unreal/#next-steps-packages","text":"The CARLA image created in this guide is used to create standalone CARLA packages or to package assets such as maps or meshes so they can be used in a CARLA package. This is achieved through the use of the docker_tools.py script found in Util/Docker . This script uses docker-py to work with the Docker image. The docker_tools.py script can be used to: Create a CARLA package : Find the tutorial here Cook assets to be consumed in a CARLA package: Find the tutorial here Prepare a map so it's ready for use in a CARLA package: Find the tutorial here Any issues or doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"Next Steps: Packages"},{"location":"build_faq/","text":"F.A.Q. Some of the most common issues regarding CARLA installation and builds are listed here. Some more can be found in the GitHub issues for the project. In case you don't find your doubt listed here, have a look in the forum and feel free to ask there. CARLA forum System requirements Expected disk space to build CARLA. Recommended hardware to run CARLA. Linux build \"CarlaUE4.sh\" script does not appear when downloading from GitHub. \"make launch\" is not working on Linux. Cloning the Unreal Engine repository shows an error. AttributeError: module 'carla' has no attribute 'Client' when running a script. Cannot run example scripts or \"RuntimeError: rpc::rpc_error during call in function version\". Windows build \"CarlaUE4.exe\" does not appear when downloading from GitHub. CarlaUE4 could not be compiled. Try rebuilding it from source manually. CMake error shows even though CMake is properly installed. Error C2440, C2672: compiler version. \"make launch\" is not working on Windows. Make is missing libintl3.dll or/and libiconv2.dll. Modules are missing or built with a different engine version. There is no dist folder in PythonAPI/carla despite a successful output message. Running Carla Low FPS rate when running the server in Unreal Editor. Can't run a script. Connect to the simulator while running within Unreal Editor. Can't run CARLA neither binary nor source build. ImportError: DLL load failed: The specified module could not be found. ImportError: DLL load failed while importing libcarla: %1 is not a valid Win32 app. ImportError: No module named 'carla' Other Fatal error: 'version.h' has been modified since the precompiled header. Create a binary version of CARLA. Can I package CARLA for Windows on a Linux machine and vice versa? How do I uninstall the CARLA client library? System requirements Expected disk space to build CARLA. It is advised to have at least 170GB free. Building CARLA requires about 35GB of disk space, plus Unreal Engine which requires about 95-135GB. Recommended hardware to run CARLA. CARLA is a performance demanding software. At the very minimum it requires a 6GB GPU or, even better, a dedicated GPU capable of running Unreal Engine. Take a look at Unreal Engine's recommended hardware . Linux build \"CarlaUE4.sh\" script does not appear when downloading from GitHub. There is no CarlaUE4.sh script in the source version of CARLA. Follow the build instructions to build CARLA from source. To run CARLA using CarlaUE4.sh , follow the quick start installation . \"make launch\" is not working on Linux. Many different issues can be dragged out during the build installation and will manifest themselves like this. Here is a list of the most likely reasons why: Run Unreal Engine 4.26. Something may have failed when building Unreal Engine. Try running UE editor on its own and check that it is the 4.26 release. Download the assets. The server will not be able to run without the visual content. This step is mandatory. UE4_ROOT is not defined. The environment variable is not set. Remember to make it persistent session-wide by adding it to the ~/.bashrc or ~/.profile . Otherwise it will need to be set for every new shell. Run export UE4_ROOT=<path_to_unreal_4-26> to set the variable this time. Check dependencies. Make sure that everything was installed properly. Maybe one of the commands was skipped, unsuccessful or the dependencies were not suitable for the system. Delete CARLA and clone it again. Just in case something went wrong. Delete CARLA and clone or download it again. Meet system requirements. Ubuntu version should be 16.04 or later. CARLA needs around 170GB of disk space and a dedicated GPU (or at least one with 6GB) to run. Other specific reasons for a system to show conflicts with CARLA may occur. Please, post these on the forum so the team can get to know more about them. Cloning the Unreal Engine repository shows an error. 1. Is the Unreal Engine account activated? The UE repository is private. In order to clone it, create the UE account, activate it (check the verification mail), and link your GitHub account. 2. Is git properly installed? Sometimes an error shows incompatibilities with the https protocol. It can be solved easily by uninstalling and reinstalling git. Open a terminal and run the following commands: sudo apt-get remove git #Uninstall git sudo apt install git-all #install git AttributeError: module 'carla' has no attribute 'Client' when running a script. Run the following command. pip3 install -Iv setuptools==47.3.1 And build the PythonAPI again. make PythonAPI Try to build the docs to test if everything is running properly. A successful message should show. make PythonAPI.docs Cannot run example scripts or \"RuntimeError: rpc::rpc_error during call in function version\". If running a script returns an output similar to this, there is a problem with the .egg file in the PythonAPI. Important If you are using 0.9.12+, there are several methods to use/install the client library. If you are using one of the newer methods for the client library ( .whl or PyPi download) the information in this section will not be relevant to you. First of all, open <root_carla>/PythonAPI/carla/dist . There should be an .egg file for the corresponding CARLA and Python version you are using (similar to carla-0.X.X-pyX.X-linux-x86_64.egg ). Make sure the file matches the Python version you are using. To check your Python version use the following command. python3 --version # or for Python 2 python --version If either the file is missing or you think it could be corrupted, try rebuilding again. make clean make PythonAPI make launch Now try one of the example scripts again. cd PythonAPI/examples python3 dynamic_weather.py If the error persists, the problem is probably related with your PythonPATH. These scripts automatically look for the .egg file associated with the build, so maybe there is another .egg file in your PythonPATH interfering with the process. Show the content of the PythonPATH with the following command. echo $PYTHONPATH Look up in the output for other instances of .egg files in a route similar to PythonAPI/carla/dist , and get rid of these. They probably belong to other instances of CARLA installations. For example, if you also installed CARLA via apt-get , you can remove it with the following command, and the PythonPATH will be cleaned too. sudo apt-get purge carla-simulator Ultimately there is the option to add the .egg file of your build to the PythonPATH using the ~/.bashrc . This is not the recommended way. It would be better to have a clear PythonPATH and simply add the path to the necessary .egg files in the scripts. First, open ~/.bashrc . gedit ~/.bashrc Add the following lines to ~/.bashrc . These store the path to the build .egg file, so that Python can automatically find it. Save the file, and reset the terminal for changes to be effective. export PYTHONPATH=$PYTHONPATH:\"${CARLA_ROOT}/PythonAPI/carla/dist/$(ls ${CARLA_ROOT}/PythonAPI/carla/dist | grep py3.)\" export PYTHONPATH=$PYTHONPATH:${CARLA_ROOT}/PythonAPI/carla After cleaning the PythonPATH or adding the path to the build .egg file, all the example scripts should work properly. Windows build \"CarlaUE4.exe\" does not appear when downloading from GitHub. There is no CarlaUE4.exe executable in the source version of CARLA. Follow the build instructions to build CARLA from source. To directly get the CarlaUE4.exe , follow the quick start instructions . CarlaUE4 could not be compiled. Try rebuilding it from source manually. Something went wrong when trying to build CARLA. Rebuild using Visual Studio to discover what happened. 1. Go to carla/Unreal/CarlaUE4 and right-click the CarlaUE4.uproject . 2. Click on Generate Visual Studio project files . 3. Open the file generated with Visual Studio 2019. 4. Compile the project with Visual Studio. The shortcut is F7. The build will fail, but the issues found will be shown below. Different issues may result in this specific error message. The user @tamakoji solved a recurrent case where the source code hadn't been cloned properly and the CARLA version could not be set (when downloading this as a .zip from git). Check the Build/CMakeLists.txt.in . If it shows as set(CARLA_VERSION ) do the following: 1. Go to Setup.bat line 198. 2. Update the line from: for /f %%i in ('git describe --tags --dirty --always') do set carla_version=%%i to: for /f %%i in ('git describe --tags --dirty --always') do set carla_version=\"0.9.9\" CMake error shows even though CMake is properly installed. This issue occurs when trying to use the make command either to build the server or the client. Even if CMake is installed, updated and added to the environment path. There may be a conflict between Visual Studio versions. Leave only VS2019 and completely erase the rest. Error C2440, C2672: compiler version. The build is not using the 2019 compiler due to conflicts with other Visual Studio or Microsoft Compiler versions. Uninstall these and rebuild again. Visual Studio is not good at getting rid of itself. To completely clean Visual Studio from the computer go to Program Files (x86)\\Microsoft Visual Studio\\Installer\\resources\\app\\layout and run .\\InstallCleanup.exe -full . This may need admin permissions. To keep other Visual Studio versions, edit %appdata%\\Unreal Engine\\UnrealBuildTool\\BuildConfiguration.xml by adding the following lines: <VCProjectFileGenerator> <Version>VisualStudio2019</Version> </VCProjectFileGenerator> <WindowsPlatform> <Compiler>VisualStudio2019</Compiler> </WindowsPlatform> \"make launch\" is not working on Windows. Many different issues can be dragged out during the build installation and manifest themselves like this. Here is a list of the most likely reasons why: Restart the computer. There is a lot going on during the Windows build. Restart and make sure that everything is updated properly. Run Unreal Engine 4.26. Something may have failed when building Unreal Engine. Run the Editor and check that version 4.26 is being used. Download the assets. The server will not be able to run without the visual content. This step is mandatory. Visual Studio 2019. If there are other versions of Visual Studio installed or recently uninstalled, conflicts may arise. To completely clean Visual Studio from the computer go to Program Files (x86)\\Microsoft Visual Studio\\Installer\\resources\\app\\layout and run .\\InstallCleanup.exe -full . Delete CARLA and clone it again. Just in case something went wrong. Delete CARLA and clone or download it again. Meet system requirements. CARLA needs around 170GB of disk space and a dedicated GPU (or at least one with 6GB) to run. Other specific reasons for a system to show conflicts with CARLA may occur. Please, post these on the forum so the team can get to know more about them. Make is missing libintl3.dll or/and libiconv2.dll. Download the dependencies and extract the bin content into the make installation path. Modules are missing or built with a different engine version. Click on Accept to rebuild them. There is no dist folder in PythonAPI/carla despite a successful output message. In Windows, the make PythonAPI command can return a message that the Python API was installed successfully when it actually wasn't. If there is no dist folder created in the PythonAPI/carla directory after you see this output, then look at the command output higher up. It is likely an error occurred and the build needs to be retried after correcting the error and running make clean . Running CARLA Low FPS rate when running the server in Unreal Editor. UE4 Editor goes to a low performance mode when out of focus. Go to Edit/Editor Preferences/Performance in the editor preferences, and disable the \"Use Less CPU When in Background\" option. Can't run a script. Some scripts have requirements. These are listed in files named Requirements.txt , in the same path as the script itself. Be sure to check these in order to run the script. The majority of them can be installed with a simple pip command. Sometimes on Windows, scripts cannot run with just > script_name.py . Try adding > python3 script_name.py , and make sure to be in the right directory. Connect to the simulator while running within Unreal Editor. Click on Play and wait until the scene is loaded. At that point, a Python client can connect to the simulator as with the standalone simulator. Can't run CARLA neither binary nor source build. NVIDIA drivers may be outdated. Make sure that this is not the case. If the issue is still unresolved, take a look at the forum and post the specific issue. ImportError: DLL load failed: The specified module could not be found. One of the libraries needed has not been properly installed. As a work around, go to carla\\Build\\zlib-source\\build , and copy the file named zlib.dll in the directory of the script. ImportError: DLL load failed while importing libcarla: %1 is not a valid Win32 app. A 32-bit Python version is creating conflicts when trying to run a script. Uninstall it and leave only the Python3 x64 required. ImportError: No module named 'carla' This error occurs because Python cannot find the CARLA library. The CARLA library is contained in an .egg file, located in the directory PythonAPI/carla/dist and all the example scripts will look for it in this directory. The .egg file follows the nomenclature of carla-<carla-version>-py<python-version>-<operating-system>.egg . Important CARLA only used .egg files for the client library in versions prior to 0.9.12. If you are using 0.9.12+, there are several methods to use/install the client library. If you are using one of the newer methods for the client library ( .whl or PyPi download) the information in this section will not be relevant to you. Read more about the newer methods to use/install the client library in the Quickstart tutorial . If you are using a packaged version of CARLA, there will be several .egg files, corresponding to different versions of Python, depending on the version of CARLA. Make sure you are running the scripts with one of these Python versions. To check the default Python version, type the following into the command line: python3 --version # or python --version If you built Python from source, the .egg file will be built according to the default Python version on your system. In Linux this will be the default Python version returned for: /usr/bin/env python3 --version # or if you specify ARGS=\"--python-version=2\" /usr/bin/env python2 --version In Windows it will be the default Python version for: py -3 --version Make sure you are running your scripts with the version of Python that corresponds to your .egg file. In Linux, you may also need to set your Python path to point to the CARLA .egg . To do this, run the following command: export PYTHONPATH=$PYTHONPATH:<path/to/carla/>/PythonAPI/carla/dist/<your_egg_file> # Check if CARLA can now be found python3 -c 'import carla;print(\"Success\")' Be aware that virtual environments, or other Python environments like Conda, can complicate the installation of CARLA. Make sure you have set up your Python defaults and paths accordingly. Other Fatal error: 'version.h' has been modified since the precompiled header. This happens from time to time due to Linux updates. There is a special target in the Makefile for this issue. It takes a long time but fixes the issue: make hard-clean make CarlaUE4Editor Create a binary version of CARLA. In Linux, run make package in the project folder. The package will include the project, and the Python API modules. Alternatively, it is possible to compile a binary version of CARLA within Unreal Editor. Open the CarlaUE4 project, go to the menu File/Package Project , and select a platform. This may take a while. Can I package CARLA for Windows on a Linux machine and vice versa? Although this feature is available for Unreal Engine, it is not available in CARLA. We have a number of dependencies that are not supported to be cross compiled. How do I uninstall the CARLA client library? If you installed the client library using pip/pip3 , you should uninstall it by running: # Python 3 pip3 uninstall carla # Python 2 pip uninstall carla","title":"F.A.Q."},{"location":"build_faq/#faq","text":"Some of the most common issues regarding CARLA installation and builds are listed here. Some more can be found in the GitHub issues for the project. In case you don't find your doubt listed here, have a look in the forum and feel free to ask there. CARLA forum","title":"F.A.Q."},{"location":"build_faq/#system-requirements","text":"Expected disk space to build CARLA. Recommended hardware to run CARLA.","title":"System requirements"},{"location":"build_faq/#linux-build","text":"\"CarlaUE4.sh\" script does not appear when downloading from GitHub. \"make launch\" is not working on Linux. Cloning the Unreal Engine repository shows an error. AttributeError: module 'carla' has no attribute 'Client' when running a script. Cannot run example scripts or \"RuntimeError: rpc::rpc_error during call in function version\".","title":"Linux build"},{"location":"build_faq/#windows-build","text":"\"CarlaUE4.exe\" does not appear when downloading from GitHub. CarlaUE4 could not be compiled. Try rebuilding it from source manually. CMake error shows even though CMake is properly installed. Error C2440, C2672: compiler version. \"make launch\" is not working on Windows. Make is missing libintl3.dll or/and libiconv2.dll. Modules are missing or built with a different engine version. There is no dist folder in PythonAPI/carla despite a successful output message.","title":"Windows build"},{"location":"build_faq/#running-carla","text":"Low FPS rate when running the server in Unreal Editor. Can't run a script. Connect to the simulator while running within Unreal Editor. Can't run CARLA neither binary nor source build. ImportError: DLL load failed: The specified module could not be found. ImportError: DLL load failed while importing libcarla: %1 is not a valid Win32 app. ImportError: No module named 'carla'","title":"Running Carla"},{"location":"build_faq/#other","text":"Fatal error: 'version.h' has been modified since the precompiled header. Create a binary version of CARLA. Can I package CARLA for Windows on a Linux machine and vice versa? How do I uninstall the CARLA client library?","title":"Other"},{"location":"build_faq/#system-requirements_1","text":"","title":"System requirements"},{"location":"build_faq/#expected-disk-space-to-build-carla","text":"It is advised to have at least 170GB free. Building CARLA requires about 35GB of disk space, plus Unreal Engine which requires about 95-135GB.","title":"Expected disk space to build CARLA."},{"location":"build_faq/#recommended-hardware-to-run-carla","text":"CARLA is a performance demanding software. At the very minimum it requires a 6GB GPU or, even better, a dedicated GPU capable of running Unreal Engine. Take a look at Unreal Engine's recommended hardware .","title":"Recommended hardware to run CARLA."},{"location":"build_faq/#linux-build_1","text":"","title":"Linux build"},{"location":"build_faq/#carlaue4sh-script-does-not-appear-when-downloading-from-github","text":"There is no CarlaUE4.sh script in the source version of CARLA. Follow the build instructions to build CARLA from source. To run CARLA using CarlaUE4.sh , follow the quick start installation .","title":"\"CarlaUE4.sh\" script does not appear when downloading from GitHub."},{"location":"build_faq/#make-launch-is-not-working-on-linux","text":"Many different issues can be dragged out during the build installation and will manifest themselves like this. Here is a list of the most likely reasons why: Run Unreal Engine 4.26. Something may have failed when building Unreal Engine. Try running UE editor on its own and check that it is the 4.26 release. Download the assets. The server will not be able to run without the visual content. This step is mandatory. UE4_ROOT is not defined. The environment variable is not set. Remember to make it persistent session-wide by adding it to the ~/.bashrc or ~/.profile . Otherwise it will need to be set for every new shell. Run export UE4_ROOT=<path_to_unreal_4-26> to set the variable this time. Check dependencies. Make sure that everything was installed properly. Maybe one of the commands was skipped, unsuccessful or the dependencies were not suitable for the system. Delete CARLA and clone it again. Just in case something went wrong. Delete CARLA and clone or download it again. Meet system requirements. Ubuntu version should be 16.04 or later. CARLA needs around 170GB of disk space and a dedicated GPU (or at least one with 6GB) to run. Other specific reasons for a system to show conflicts with CARLA may occur. Please, post these on the forum so the team can get to know more about them.","title":"\"make launch\" is not working on Linux."},{"location":"build_faq/#cloning-the-unreal-engine-repository-shows-an-error","text":"1. Is the Unreal Engine account activated? The UE repository is private. In order to clone it, create the UE account, activate it (check the verification mail), and link your GitHub account. 2. Is git properly installed? Sometimes an error shows incompatibilities with the https protocol. It can be solved easily by uninstalling and reinstalling git. Open a terminal and run the following commands: sudo apt-get remove git #Uninstall git sudo apt install git-all #install git","title":"Cloning the Unreal Engine repository shows an error."},{"location":"build_faq/#attributeerror-module-carla-has-no-attribute-client-when-running-a-script","text":"Run the following command. pip3 install -Iv setuptools==47.3.1 And build the PythonAPI again. make PythonAPI Try to build the docs to test if everything is running properly. A successful message should show. make PythonAPI.docs","title":"AttributeError: module 'carla' has no attribute 'Client' when running a script."},{"location":"build_faq/#cannot-run-example-scripts-or-runtimeerror-rpcrpc_error-during-call-in-function-version","text":"If running a script returns an output similar to this, there is a problem with the .egg file in the PythonAPI. Important If you are using 0.9.12+, there are several methods to use/install the client library. If you are using one of the newer methods for the client library ( .whl or PyPi download) the information in this section will not be relevant to you. First of all, open <root_carla>/PythonAPI/carla/dist . There should be an .egg file for the corresponding CARLA and Python version you are using (similar to carla-0.X.X-pyX.X-linux-x86_64.egg ). Make sure the file matches the Python version you are using. To check your Python version use the following command. python3 --version # or for Python 2 python --version If either the file is missing or you think it could be corrupted, try rebuilding again. make clean make PythonAPI make launch Now try one of the example scripts again. cd PythonAPI/examples python3 dynamic_weather.py If the error persists, the problem is probably related with your PythonPATH. These scripts automatically look for the .egg file associated with the build, so maybe there is another .egg file in your PythonPATH interfering with the process. Show the content of the PythonPATH with the following command. echo $PYTHONPATH Look up in the output for other instances of .egg files in a route similar to PythonAPI/carla/dist , and get rid of these. They probably belong to other instances of CARLA installations. For example, if you also installed CARLA via apt-get , you can remove it with the following command, and the PythonPATH will be cleaned too. sudo apt-get purge carla-simulator Ultimately there is the option to add the .egg file of your build to the PythonPATH using the ~/.bashrc . This is not the recommended way. It would be better to have a clear PythonPATH and simply add the path to the necessary .egg files in the scripts. First, open ~/.bashrc . gedit ~/.bashrc Add the following lines to ~/.bashrc . These store the path to the build .egg file, so that Python can automatically find it. Save the file, and reset the terminal for changes to be effective. export PYTHONPATH=$PYTHONPATH:\"${CARLA_ROOT}/PythonAPI/carla/dist/$(ls ${CARLA_ROOT}/PythonAPI/carla/dist | grep py3.)\" export PYTHONPATH=$PYTHONPATH:${CARLA_ROOT}/PythonAPI/carla After cleaning the PythonPATH or adding the path to the build .egg file, all the example scripts should work properly.","title":"Cannot run example scripts or \"RuntimeError: rpc::rpc_error during call in function version\"."},{"location":"build_faq/#windows-build_1","text":"","title":"Windows build"},{"location":"build_faq/#carlaue4exe-does-not-appear-when-downloading-from-github","text":"There is no CarlaUE4.exe executable in the source version of CARLA. Follow the build instructions to build CARLA from source. To directly get the CarlaUE4.exe , follow the quick start instructions .","title":"\"CarlaUE4.exe\" does not appear when downloading from GitHub."},{"location":"build_faq/#carlaue4-could-not-be-compiled-try-rebuilding-it-from-source-manually","text":"Something went wrong when trying to build CARLA. Rebuild using Visual Studio to discover what happened. 1. Go to carla/Unreal/CarlaUE4 and right-click the CarlaUE4.uproject . 2. Click on Generate Visual Studio project files . 3. Open the file generated with Visual Studio 2019. 4. Compile the project with Visual Studio. The shortcut is F7. The build will fail, but the issues found will be shown below. Different issues may result in this specific error message. The user @tamakoji solved a recurrent case where the source code hadn't been cloned properly and the CARLA version could not be set (when downloading this as a .zip from git). Check the Build/CMakeLists.txt.in . If it shows as set(CARLA_VERSION ) do the following: 1. Go to Setup.bat line 198. 2. Update the line from: for /f %%i in ('git describe --tags --dirty --always') do set carla_version=%%i to: for /f %%i in ('git describe --tags --dirty --always') do set carla_version=\"0.9.9\"","title":"CarlaUE4 could not be compiled. Try rebuilding it from source manually."},{"location":"build_faq/#cmake-error-shows-even-though-cmake-is-properly-installed","text":"This issue occurs when trying to use the make command either to build the server or the client. Even if CMake is installed, updated and added to the environment path. There may be a conflict between Visual Studio versions. Leave only VS2019 and completely erase the rest.","title":"CMake error shows even though CMake is properly installed."},{"location":"build_faq/#error-c2440-c2672-compiler-version","text":"The build is not using the 2019 compiler due to conflicts with other Visual Studio or Microsoft Compiler versions. Uninstall these and rebuild again. Visual Studio is not good at getting rid of itself. To completely clean Visual Studio from the computer go to Program Files (x86)\\Microsoft Visual Studio\\Installer\\resources\\app\\layout and run .\\InstallCleanup.exe -full . This may need admin permissions. To keep other Visual Studio versions, edit %appdata%\\Unreal Engine\\UnrealBuildTool\\BuildConfiguration.xml by adding the following lines: <VCProjectFileGenerator> <Version>VisualStudio2019</Version> </VCProjectFileGenerator> <WindowsPlatform> <Compiler>VisualStudio2019</Compiler> </WindowsPlatform>","title":"Error C2440, C2672: compiler version."},{"location":"build_faq/#make-launch-is-not-working-on-windows","text":"Many different issues can be dragged out during the build installation and manifest themselves like this. Here is a list of the most likely reasons why: Restart the computer. There is a lot going on during the Windows build. Restart and make sure that everything is updated properly. Run Unreal Engine 4.26. Something may have failed when building Unreal Engine. Run the Editor and check that version 4.26 is being used. Download the assets. The server will not be able to run without the visual content. This step is mandatory. Visual Studio 2019. If there are other versions of Visual Studio installed or recently uninstalled, conflicts may arise. To completely clean Visual Studio from the computer go to Program Files (x86)\\Microsoft Visual Studio\\Installer\\resources\\app\\layout and run .\\InstallCleanup.exe -full . Delete CARLA and clone it again. Just in case something went wrong. Delete CARLA and clone or download it again. Meet system requirements. CARLA needs around 170GB of disk space and a dedicated GPU (or at least one with 6GB) to run. Other specific reasons for a system to show conflicts with CARLA may occur. Please, post these on the forum so the team can get to know more about them.","title":"\"make launch\" is not working on Windows."},{"location":"build_faq/#make-is-missing-libintl3dll-orand-libiconv2dll","text":"Download the dependencies and extract the bin content into the make installation path.","title":"Make is missing libintl3.dll or/and libiconv2.dll."},{"location":"build_faq/#modules-are-missing-or-built-with-a-different-engine-version","text":"Click on Accept to rebuild them.","title":"Modules are missing or built with a different engine version."},{"location":"build_faq/#there-is-no-dist-folder-in-pythonapicarla-despite-a-successful-output-message","text":"In Windows, the make PythonAPI command can return a message that the Python API was installed successfully when it actually wasn't. If there is no dist folder created in the PythonAPI/carla directory after you see this output, then look at the command output higher up. It is likely an error occurred and the build needs to be retried after correcting the error and running make clean .","title":"There is no dist folder in PythonAPI/carla despite a successful output message."},{"location":"build_faq/#running-carla_1","text":"","title":"Running CARLA"},{"location":"build_faq/#low-fps-rate-when-running-the-server-in-unreal-editor","text":"UE4 Editor goes to a low performance mode when out of focus. Go to Edit/Editor Preferences/Performance in the editor preferences, and disable the \"Use Less CPU When in Background\" option.","title":"Low FPS rate when running the server in Unreal Editor."},{"location":"build_faq/#cant-run-a-script","text":"Some scripts have requirements. These are listed in files named Requirements.txt , in the same path as the script itself. Be sure to check these in order to run the script. The majority of them can be installed with a simple pip command. Sometimes on Windows, scripts cannot run with just > script_name.py . Try adding > python3 script_name.py , and make sure to be in the right directory.","title":"Can't run a script."},{"location":"build_faq/#connect-to-the-simulator-while-running-within-unreal-editor","text":"Click on Play and wait until the scene is loaded. At that point, a Python client can connect to the simulator as with the standalone simulator.","title":"Connect to the simulator while running within Unreal Editor."},{"location":"build_faq/#cant-run-carla-neither-binary-nor-source-build","text":"NVIDIA drivers may be outdated. Make sure that this is not the case. If the issue is still unresolved, take a look at the forum and post the specific issue.","title":"Can't run CARLA neither binary nor source build."},{"location":"build_faq/#importerror-dll-load-failed-the-specified-module-could-not-be-found","text":"One of the libraries needed has not been properly installed. As a work around, go to carla\\Build\\zlib-source\\build , and copy the file named zlib.dll in the directory of the script.","title":"ImportError: DLL load failed: The specified module could not be found."},{"location":"build_faq/#importerror-dll-load-failed-while-importing-libcarla-1-is-not-a-valid-win32-app","text":"A 32-bit Python version is creating conflicts when trying to run a script. Uninstall it and leave only the Python3 x64 required.","title":"ImportError: DLL load failed while importing libcarla: %1 is not a valid Win32 app."},{"location":"build_faq/#importerror-no-module-named-carla","text":"This error occurs because Python cannot find the CARLA library. The CARLA library is contained in an .egg file, located in the directory PythonAPI/carla/dist and all the example scripts will look for it in this directory. The .egg file follows the nomenclature of carla-<carla-version>-py<python-version>-<operating-system>.egg . Important CARLA only used .egg files for the client library in versions prior to 0.9.12. If you are using 0.9.12+, there are several methods to use/install the client library. If you are using one of the newer methods for the client library ( .whl or PyPi download) the information in this section will not be relevant to you. Read more about the newer methods to use/install the client library in the Quickstart tutorial . If you are using a packaged version of CARLA, there will be several .egg files, corresponding to different versions of Python, depending on the version of CARLA. Make sure you are running the scripts with one of these Python versions. To check the default Python version, type the following into the command line: python3 --version # or python --version If you built Python from source, the .egg file will be built according to the default Python version on your system. In Linux this will be the default Python version returned for: /usr/bin/env python3 --version # or if you specify ARGS=\"--python-version=2\" /usr/bin/env python2 --version In Windows it will be the default Python version for: py -3 --version Make sure you are running your scripts with the version of Python that corresponds to your .egg file. In Linux, you may also need to set your Python path to point to the CARLA .egg . To do this, run the following command: export PYTHONPATH=$PYTHONPATH:<path/to/carla/>/PythonAPI/carla/dist/<your_egg_file> # Check if CARLA can now be found python3 -c 'import carla;print(\"Success\")' Be aware that virtual environments, or other Python environments like Conda, can complicate the installation of CARLA. Make sure you have set up your Python defaults and paths accordingly.","title":"ImportError: No module named 'carla'"},{"location":"build_faq/#other_1","text":"","title":"Other"},{"location":"build_faq/#fatal-error-versionh-has-been-modified-since-the-precompiled-header","text":"This happens from time to time due to Linux updates. There is a special target in the Makefile for this issue. It takes a long time but fixes the issue: make hard-clean make CarlaUE4Editor","title":"Fatal error: 'version.h' has been modified since the precompiled header."},{"location":"build_faq/#create-a-binary-version-of-carla","text":"In Linux, run make package in the project folder. The package will include the project, and the Python API modules. Alternatively, it is possible to compile a binary version of CARLA within Unreal Editor. Open the CarlaUE4 project, go to the menu File/Package Project , and select a platform. This may take a while.","title":"Create a binary version of CARLA."},{"location":"build_faq/#can-i-package-carla-for-windows-on-a-linux-machine-and-vice-versa","text":"Although this feature is available for Unreal Engine, it is not available in CARLA. We have a number of dependencies that are not supported to be cross compiled.","title":"Can I package CARLA for Windows on a Linux machine and vice versa?"},{"location":"build_faq/#how-do-i-uninstall-the-carla-client-library","text":"If you installed the client library using pip/pip3 , you should uninstall it by running: # Python 3 pip3 uninstall carla # Python 2 pip uninstall carla","title":"How do I uninstall the CARLA client library?"},{"location":"build_linux/","text":"Linux build This guide details how to build CARLA from source on Linux. There are two parts. Part one details system requirements and installations of required software, and part two details how to actually build and run CARLA. The build process is long (4 hours or more) and involves several kinds of software. It is highly recommended to read through the guide fully before starting. If you come across errors or difficulties then have a look at the F.A.Q. page which offers solutions for the most common complications. Alternatively, use the CARLA forum to post any queries you may have. Part One: Prerequisites System requirements Software requirements Unreal Engine Part Two: Build CARLA Clone the CARLA repository Get assets Set Unreal Engine environment variable Build CARLA Other make commands Part One: Prerequisites System requirements Ubuntu 18.04. CARLA provides support for previous Ubuntu versions up to 16.04. However proper compilers are needed for Unreal Engine to work properly. Dependencies for Ubuntu 18.04 and previous versions are listed separatedly below. Make sure to install the ones corresponding to your system. 130 GB disk space. Carla will take around 31 GB and Unreal Engine will take around 91 GB so have about 130 GB free to account for both of these plus additional minor software installations. An adequate GPU. CARLA aims for realistic simulations, so the server needs at least a 6 GB GPU although 8 GB is recommended. A dedicated GPU is highly recommended for machine learning. Two TCP ports and good internet connection. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications. ..warning:: If you are upgrading from CARLA 0.9.12 to 0.9.13 : you must first upgrade the CARLA fork of the UE4 engine to the latest version. See the Unreal Engine section for details on upgrading UE4 Software requirements CARLA requires many different kinds of software to run. Some are built during the CARLA build process itself, such as Boost.Python . Others are binaries that should be installed before starting the build ( cmake , clang , different versions of Python , etc.). To install these requirements, run the following commands: sudo apt-get update && sudo apt-get install wget software-properties-common && sudo add-apt-repository ppa:ubuntu-toolchain-r/test && wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key|sudo apt-key add - && sudo apt-add-repository \"deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-8 main\" && sudo apt-get update Warning The following commands depend on your Ubuntu version. Make sure to choose accordingly. Ubuntu 18.04 . sudo apt-get install build-essential clang-8 lld-8 g++-7 cmake ninja-build libvulkan1 python python-pip python-dev python3-dev python3-pip libpng-dev libtiff5-dev libjpeg-dev tzdata sed curl unzip autoconf libtool rsync libxml2-dev git Previous Ubuntu versions. sudo apt-get install build-essential clang-8 lld-8 g++-7 cmake ninja-build libvulkan1 python python-pip python-dev python3-dev python3-pip libpng16-dev libtiff5-dev libjpeg-dev tzdata sed curl unzip autoconf libtool rsync libxml2-dev git All Ubuntu systems . To avoid compatibility issues between Unreal Engine and the CARLA dependencies, use the same compiler version and C++ runtime library to compile everything. The CARLA team uses clang-8 and LLVM's libc++. Change the default clang version to compile Unreal Engine and the CARLA dependencies. sudo update-alternatives --install /usr/bin/clang++ clang++ /usr/lib/llvm-8/bin/clang++ 180 && sudo update-alternatives --install /usr/bin/clang clang /usr/lib/llvm-8/bin/clang 180 Starting with CARLA 0.9.12, users have the option to install the CARLA Python API using pip or pip3 . Version 20.3 or higher is required. To check if you have a suitable version, run the following command: # For Python 3 pip3 -V # For Python 2 pip -V If you need to upgrade: # For Python 3 pip3 install --upgrade pip # For Python 2 pip install --upgrade pip You must install the following Python dependencies: pip install --user setuptools && pip3 install --user -Iv setuptools==47.3.1 && pip install --user distro && pip3 install --user distro && pip install --user wheel && pip3 install --user wheel auditwheel Unreal Engine Starting with version 0.9.12, CARLA uses a modified fork of Unreal Engine 4.26. This fork contains patches specific to CARLA. Be aware that to download this fork of Unreal Engine, you need to have a GitHub account linked to Unreal Engine's account . If you don't have this set up, please follow this guide before going any further. 1. Clone the content for CARLA's fork of Unreal Engine 4.26 to your local computer: git clone --depth 1 -b carla https://github.com/CarlaUnreal/UnrealEngine.git ~/UnrealEngine_4.26 2. Navigate into the directory where you cloned the repository: cd ~/UnrealEngine_4.26 3. Make the build. This may take an hour or two depending on your system. ./Setup.sh && ./GenerateProjectFiles.sh && make 4. Open the Editor to check that Unreal Engine has been installed properly. cd ~/UnrealEngine_4.26/Engine/Binaries/Linux && ./UE4Editor Part Two: Build CARLA Note Downloading aria2 with sudo apt-get install aria2 will speed up the following commands. Clone the CARLA repository CARLA repository The button above will take you to the official repository of the project. Either download from there and extract it locally or clone it using the following command: git clone https://github.com/carla-simulator/carla Note The master branch contains the current release of CARLA with the latest fixes and features. Previous CARLA versions are tagged with the version name. Always remember to check the current branch in git with the command git branch . Get assets You will need to download the latest assets to work with the current version of CARLA. We provide a script to automate this process. To use the script, run the following command in the CARLA root folder: ./Update.sh The assets will be downloaded and extracted to the appropriate location. Important To download the assets currently in development, visit Update CARLA and read Get development assets . To download the assets for a specific version of CARLA: From the root CARLA directory, navigate to \\Util\\ContentVersions.txt . This document contains the links to the assets for all CARLA releases. Extract the assets in Unreal\\CarlaUE4\\Content\\Carla . If the path doesn't exist, create it. Extract the file with a command similar to the following: tar -xvzf <assets_file_name>.tar.gz.tar -C C:\\path\\to\\carla\\Unreal\\CarlaUE4\\Content\\Carla Set Unreal Engine environment variable For CARLA to find the correct installation of Unreal Engine, we need to set the CARLA environment variable. To set the variable for this session only: export UE4_ROOT=~/UnrealEngine_4.26 To set the variable so it persists across sessions: 1. Open ~/.bashrc or ./profile . gedit ~/.bashrc # or gedit ~/.profile 2. Add the following line to the bottom of the file: export UE4_ROOT=~/UnrealEngine_4.26 3. Save the file and reset the terminal. Build CARLA This section outlines the commands to build CARLA. All commands should be run in the root CARLA folder. There are two parts to the build process for CARLA, compiling the client and compiling the server. Warning Make sure to run make PythonAPI to prepare the client and make launch for the server. Alternatively make LibCarla will prepare the CARLA library to be imported anywhere. 1. Compile the Python API client : The Python API client grants control over the simulation. Compilation of the Python API client is required the first time you build CARLA and again after you perform any updates. After the client is compiled, you will be able to run scripts to interact with the simulation. The following command compiles the Python API client: make PythonAPI Optionally, to compile the PythonAPI for a specific version of Python, run the below command in the root CARLA directory. # Delete versions as required make PythonAPI ARGS=\"--python-version=2.7, 3.6, 3.7, 3.8\" The CARLA client library will be built in two distinct, mutually exclusive forms. This gives users the freedom to choose which form they prefer to run the CARLA client code. The two forms include .egg files and .whl files. Choose one of the following options below to use the client library: A. .egg file The .egg file does not need to be installed. All of CARLA's example scripts automatically look for this file when importing CARLA. If you previously installed a CARLA .whl , the .whl will take precedence over an .egg file. B. .whl file The .whl file should be installed using pip or pip3 : # Python 3 pip3 install <path/to/wheel>.whl # Python 2 pip install <path/to/wheel>.whl This .whl file cannot be distributed as it is built specifically for your OS. Warning Issues can arise through the use of different methods to install the CARLA client library and having different versions of CARLA on your system. It is recommended to use virtual environments when installing the .whl and to uninstall any previously installed client libraries before installing new ones. 2. Compile the server : The following command compiles and launches Unreal Engine. Run this command each time you want to launch the server or use the Unreal Engine editor: make launch The project may ask to build other instances such as UE4Editor-Carla.dll the first time. Agree in order to open the project. During the first launch, the editor may show warnings regarding shaders and mesh distance fields. These take some time to be loaded and the map will not show properly until then. 3. Start the simulation : Press Play to start the server simulation. The camera can be moved with WASD keys and rotated by clicking the scene while moving the mouse around. Test the simulator using the example scripts inside PythonAPI\\examples . With the simulator running, open a new terminal for each script and run the following commands to spawn some life into the town and create a weather cycle: # Terminal A cd PythonAPI/examples python3 -m pip install -r requirements.txt python3 generate_traffic.py # Terminal B cd PythonAPI/examples python3 dynamic_weather.py Important If the simulation is running at a very low FPS rate, go to Edit -> Editor preferences -> Performance in the Unreal Engine editor and disable Use less CPU when in background . Other make commands There are more make commands that you may find useful. Find them in the table below: Command Description make help Prints all available commands. make launch Launches CARLA server in Editor window. make PythonAPI Builds the CARLA client. make LibCarla Prepares the CARLA library to be imported anywhere. make package Builds CARLA and creates a packaged version for distribution. make clean Deletes all the binaries and temporals generated by the build system. make rebuild make clean and make launch both in one command. Read the F.A.Q. page or post in the CARLA forum for any issues regarding this guide. Up next, learn how to update the CARLA build or take your first steps in the simulation, and learn some core concepts. Update CARLA First steps","title":"Linux build"},{"location":"build_linux/#linux-build","text":"This guide details how to build CARLA from source on Linux. There are two parts. Part one details system requirements and installations of required software, and part two details how to actually build and run CARLA. The build process is long (4 hours or more) and involves several kinds of software. It is highly recommended to read through the guide fully before starting. If you come across errors or difficulties then have a look at the F.A.Q. page which offers solutions for the most common complications. Alternatively, use the CARLA forum to post any queries you may have. Part One: Prerequisites System requirements Software requirements Unreal Engine Part Two: Build CARLA Clone the CARLA repository Get assets Set Unreal Engine environment variable Build CARLA Other make commands","title":"Linux build"},{"location":"build_linux/#part-one-prerequisites","text":"","title":"Part One: Prerequisites"},{"location":"build_linux/#system-requirements","text":"Ubuntu 18.04. CARLA provides support for previous Ubuntu versions up to 16.04. However proper compilers are needed for Unreal Engine to work properly. Dependencies for Ubuntu 18.04 and previous versions are listed separatedly below. Make sure to install the ones corresponding to your system. 130 GB disk space. Carla will take around 31 GB and Unreal Engine will take around 91 GB so have about 130 GB free to account for both of these plus additional minor software installations. An adequate GPU. CARLA aims for realistic simulations, so the server needs at least a 6 GB GPU although 8 GB is recommended. A dedicated GPU is highly recommended for machine learning. Two TCP ports and good internet connection. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications. ..warning:: If you are upgrading from CARLA 0.9.12 to 0.9.13 : you must first upgrade the CARLA fork of the UE4 engine to the latest version. See the Unreal Engine section for details on upgrading UE4","title":"System requirements"},{"location":"build_linux/#software-requirements","text":"CARLA requires many different kinds of software to run. Some are built during the CARLA build process itself, such as Boost.Python . Others are binaries that should be installed before starting the build ( cmake , clang , different versions of Python , etc.). To install these requirements, run the following commands: sudo apt-get update && sudo apt-get install wget software-properties-common && sudo add-apt-repository ppa:ubuntu-toolchain-r/test && wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key|sudo apt-key add - && sudo apt-add-repository \"deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-8 main\" && sudo apt-get update Warning The following commands depend on your Ubuntu version. Make sure to choose accordingly. Ubuntu 18.04 . sudo apt-get install build-essential clang-8 lld-8 g++-7 cmake ninja-build libvulkan1 python python-pip python-dev python3-dev python3-pip libpng-dev libtiff5-dev libjpeg-dev tzdata sed curl unzip autoconf libtool rsync libxml2-dev git Previous Ubuntu versions. sudo apt-get install build-essential clang-8 lld-8 g++-7 cmake ninja-build libvulkan1 python python-pip python-dev python3-dev python3-pip libpng16-dev libtiff5-dev libjpeg-dev tzdata sed curl unzip autoconf libtool rsync libxml2-dev git All Ubuntu systems . To avoid compatibility issues between Unreal Engine and the CARLA dependencies, use the same compiler version and C++ runtime library to compile everything. The CARLA team uses clang-8 and LLVM's libc++. Change the default clang version to compile Unreal Engine and the CARLA dependencies. sudo update-alternatives --install /usr/bin/clang++ clang++ /usr/lib/llvm-8/bin/clang++ 180 && sudo update-alternatives --install /usr/bin/clang clang /usr/lib/llvm-8/bin/clang 180 Starting with CARLA 0.9.12, users have the option to install the CARLA Python API using pip or pip3 . Version 20.3 or higher is required. To check if you have a suitable version, run the following command: # For Python 3 pip3 -V # For Python 2 pip -V If you need to upgrade: # For Python 3 pip3 install --upgrade pip # For Python 2 pip install --upgrade pip You must install the following Python dependencies: pip install --user setuptools && pip3 install --user -Iv setuptools==47.3.1 && pip install --user distro && pip3 install --user distro && pip install --user wheel && pip3 install --user wheel auditwheel","title":"Software requirements"},{"location":"build_linux/#unreal-engine","text":"Starting with version 0.9.12, CARLA uses a modified fork of Unreal Engine 4.26. This fork contains patches specific to CARLA. Be aware that to download this fork of Unreal Engine, you need to have a GitHub account linked to Unreal Engine's account . If you don't have this set up, please follow this guide before going any further. 1. Clone the content for CARLA's fork of Unreal Engine 4.26 to your local computer: git clone --depth 1 -b carla https://github.com/CarlaUnreal/UnrealEngine.git ~/UnrealEngine_4.26 2. Navigate into the directory where you cloned the repository: cd ~/UnrealEngine_4.26 3. Make the build. This may take an hour or two depending on your system. ./Setup.sh && ./GenerateProjectFiles.sh && make 4. Open the Editor to check that Unreal Engine has been installed properly. cd ~/UnrealEngine_4.26/Engine/Binaries/Linux && ./UE4Editor","title":"Unreal Engine"},{"location":"build_linux/#part-two-build-carla","text":"Note Downloading aria2 with sudo apt-get install aria2 will speed up the following commands.","title":"Part Two: Build CARLA"},{"location":"build_linux/#clone-the-carla-repository","text":"CARLA repository The button above will take you to the official repository of the project. Either download from there and extract it locally or clone it using the following command: git clone https://github.com/carla-simulator/carla Note The master branch contains the current release of CARLA with the latest fixes and features. Previous CARLA versions are tagged with the version name. Always remember to check the current branch in git with the command git branch .","title":"Clone the CARLA repository"},{"location":"build_linux/#get-assets","text":"You will need to download the latest assets to work with the current version of CARLA. We provide a script to automate this process. To use the script, run the following command in the CARLA root folder: ./Update.sh The assets will be downloaded and extracted to the appropriate location. Important To download the assets currently in development, visit Update CARLA and read Get development assets . To download the assets for a specific version of CARLA: From the root CARLA directory, navigate to \\Util\\ContentVersions.txt . This document contains the links to the assets for all CARLA releases. Extract the assets in Unreal\\CarlaUE4\\Content\\Carla . If the path doesn't exist, create it. Extract the file with a command similar to the following: tar -xvzf <assets_file_name>.tar.gz.tar -C C:\\path\\to\\carla\\Unreal\\CarlaUE4\\Content\\Carla","title":"Get assets"},{"location":"build_linux/#set-unreal-engine-environment-variable","text":"For CARLA to find the correct installation of Unreal Engine, we need to set the CARLA environment variable. To set the variable for this session only: export UE4_ROOT=~/UnrealEngine_4.26 To set the variable so it persists across sessions: 1. Open ~/.bashrc or ./profile . gedit ~/.bashrc # or gedit ~/.profile 2. Add the following line to the bottom of the file: export UE4_ROOT=~/UnrealEngine_4.26 3. Save the file and reset the terminal.","title":"Set Unreal Engine environment variable"},{"location":"build_linux/#build-carla","text":"This section outlines the commands to build CARLA. All commands should be run in the root CARLA folder. There are two parts to the build process for CARLA, compiling the client and compiling the server. Warning Make sure to run make PythonAPI to prepare the client and make launch for the server. Alternatively make LibCarla will prepare the CARLA library to be imported anywhere. 1. Compile the Python API client : The Python API client grants control over the simulation. Compilation of the Python API client is required the first time you build CARLA and again after you perform any updates. After the client is compiled, you will be able to run scripts to interact with the simulation. The following command compiles the Python API client: make PythonAPI Optionally, to compile the PythonAPI for a specific version of Python, run the below command in the root CARLA directory. # Delete versions as required make PythonAPI ARGS=\"--python-version=2.7, 3.6, 3.7, 3.8\" The CARLA client library will be built in two distinct, mutually exclusive forms. This gives users the freedom to choose which form they prefer to run the CARLA client code. The two forms include .egg files and .whl files. Choose one of the following options below to use the client library: A. .egg file The .egg file does not need to be installed. All of CARLA's example scripts automatically look for this file when importing CARLA. If you previously installed a CARLA .whl , the .whl will take precedence over an .egg file. B. .whl file The .whl file should be installed using pip or pip3 : # Python 3 pip3 install <path/to/wheel>.whl # Python 2 pip install <path/to/wheel>.whl This .whl file cannot be distributed as it is built specifically for your OS. Warning Issues can arise through the use of different methods to install the CARLA client library and having different versions of CARLA on your system. It is recommended to use virtual environments when installing the .whl and to uninstall any previously installed client libraries before installing new ones. 2. Compile the server : The following command compiles and launches Unreal Engine. Run this command each time you want to launch the server or use the Unreal Engine editor: make launch The project may ask to build other instances such as UE4Editor-Carla.dll the first time. Agree in order to open the project. During the first launch, the editor may show warnings regarding shaders and mesh distance fields. These take some time to be loaded and the map will not show properly until then. 3. Start the simulation : Press Play to start the server simulation. The camera can be moved with WASD keys and rotated by clicking the scene while moving the mouse around. Test the simulator using the example scripts inside PythonAPI\\examples . With the simulator running, open a new terminal for each script and run the following commands to spawn some life into the town and create a weather cycle: # Terminal A cd PythonAPI/examples python3 -m pip install -r requirements.txt python3 generate_traffic.py # Terminal B cd PythonAPI/examples python3 dynamic_weather.py Important If the simulation is running at a very low FPS rate, go to Edit -> Editor preferences -> Performance in the Unreal Engine editor and disable Use less CPU when in background .","title":"Build CARLA"},{"location":"build_linux/#other-make-commands","text":"There are more make commands that you may find useful. Find them in the table below: Command Description make help Prints all available commands. make launch Launches CARLA server in Editor window. make PythonAPI Builds the CARLA client. make LibCarla Prepares the CARLA library to be imported anywhere. make package Builds CARLA and creates a packaged version for distribution. make clean Deletes all the binaries and temporals generated by the build system. make rebuild make clean and make launch both in one command. Read the F.A.Q. page or post in the CARLA forum for any issues regarding this guide. Up next, learn how to update the CARLA build or take your first steps in the simulation, and learn some core concepts. Update CARLA First steps","title":"Other make commands"},{"location":"build_system/","text":"Build system Setup LibCarla CarlaUE4 and Carla plugin PythonAPI Versions 0.9.12+ Versions prior to 0.9.12 This document is a work in progress, only the Linux build system is taken into account here. The most challenging part of the setup is to compile all the dependencies and modules to be compatible with a) Unreal Engine in the server-side, and b) Python in the client-side. The goal is to be able to call Unreal Engine's functions from a separate Python process. In Linux, we compile CARLA and all the dependencies with clang-8.0 and C++14 standard. We however link against different runtime C++ libraries depending on where the code going to be used, since all the code that is going to be linked with Unreal Engine needs to be compiled using libc++ . Setup Command make setup Get and compile dependencies llvm-8 (libc++ and libc++abi) rpclib-2.2.1 (twice, with libstdc++ and libc++) boost-1.72.0 (headers and boost_python for libstdc++) googletest-1.8.1 (with libc++) LibCarla Compiled with CMake (minimum version required CMake 3.9). Command make LibCarla Two configurations: Server Client Unit tests Yes No Requirements rpclib, gtest, boost rpclib, boost std runtime LLVM's libc++ Default libstdc++ Output headers and test exes ibcarla_client.a Required by Carla plugin PythonAPI CarlaUE4 and Carla plugin Both compiled at the same step with Unreal Engine build tool. They require the UE4_ROOT environment variable set. Command make CarlaUE4Editor To launch Unreal Engine's Editor run make launch PythonAPI Versions 0.9.12+ Compiled using Python's setuptools (\"setup.py\"). Currently requires the following to be installed in the machine: Python, libpython-dev, and libboost-python-dev, pip>=20.3, wheel, and auditwheel. Command: make PythonAPI Creates two files that each contain the client library and correspond to the supported Python version on the system. One file is a .whl file and the other is an .egg file. This allows for the option of two different, mutually exclusive ways to use the client library. A. .whl file The .whl is installed using the command: pip install <wheel_file>.whl There is no need to import the library path directly in scripts as is required in previous versions or .egg files (see section Versions prior to 0.9.12 ); import carla is sufficient. B. .egg file See the section Versions prior to 0.9.12 for more information. Versions prior to 0.9.12 Compiled using Python's setuptools (\"setup.py\"). Currently requires the following to be installed in the machine: Python, libpython-dev, and libboost-python-dev. Command make PythonAPI It creates two \"egg\" packages PythonAPI/dist/carla-X.X.X-py2.7-linux-x86_64.egg PythonAPI/dist/carla-X.X.X-py3.7-linux-x86_64.egg This package can be directly imported into a Python script by adding it to the system path. #!/usr/bin/env python import sys sys.path.append( 'PythonAPI/dist/carla-X.X.X-py%d.%d-linux-x86_64.egg' % (sys.version_info.major, sys.version_info.minor)) import carla # ... Alternatively, it can be installed with easy_install easy_install2 --user --no-deps PythonAPI/dist/carla-X.X.X-py2.7-linux-x86_64.egg easy_install3 --user --no-deps PythonAPI/dist/carla-X.X.X-py3.7-linux-x86_64.egg","title":"Build system"},{"location":"build_system/#build-system","text":"Setup LibCarla CarlaUE4 and Carla plugin PythonAPI Versions 0.9.12+ Versions prior to 0.9.12 This document is a work in progress, only the Linux build system is taken into account here. The most challenging part of the setup is to compile all the dependencies and modules to be compatible with a) Unreal Engine in the server-side, and b) Python in the client-side. The goal is to be able to call Unreal Engine's functions from a separate Python process. In Linux, we compile CARLA and all the dependencies with clang-8.0 and C++14 standard. We however link against different runtime C++ libraries depending on where the code going to be used, since all the code that is going to be linked with Unreal Engine needs to be compiled using libc++ .","title":"Build system"},{"location":"build_system/#setup","text":"Command make setup Get and compile dependencies llvm-8 (libc++ and libc++abi) rpclib-2.2.1 (twice, with libstdc++ and libc++) boost-1.72.0 (headers and boost_python for libstdc++) googletest-1.8.1 (with libc++)","title":"Setup"},{"location":"build_system/#libcarla","text":"Compiled with CMake (minimum version required CMake 3.9). Command make LibCarla Two configurations: Server Client Unit tests Yes No Requirements rpclib, gtest, boost rpclib, boost std runtime LLVM's libc++ Default libstdc++ Output headers and test exes ibcarla_client.a Required by Carla plugin PythonAPI","title":"LibCarla"},{"location":"build_system/#carlaue4-and-carla-plugin","text":"Both compiled at the same step with Unreal Engine build tool. They require the UE4_ROOT environment variable set. Command make CarlaUE4Editor To launch Unreal Engine's Editor run make launch","title":"CarlaUE4 and Carla plugin"},{"location":"build_system/#pythonapi","text":"","title":"PythonAPI"},{"location":"build_system/#versions-0912","text":"Compiled using Python's setuptools (\"setup.py\"). Currently requires the following to be installed in the machine: Python, libpython-dev, and libboost-python-dev, pip>=20.3, wheel, and auditwheel. Command: make PythonAPI Creates two files that each contain the client library and correspond to the supported Python version on the system. One file is a .whl file and the other is an .egg file. This allows for the option of two different, mutually exclusive ways to use the client library. A. .whl file The .whl is installed using the command: pip install <wheel_file>.whl There is no need to import the library path directly in scripts as is required in previous versions or .egg files (see section Versions prior to 0.9.12 ); import carla is sufficient. B. .egg file See the section Versions prior to 0.9.12 for more information.","title":"Versions 0.9.12+"},{"location":"build_system/#versions-prior-to-0912","text":"Compiled using Python's setuptools (\"setup.py\"). Currently requires the following to be installed in the machine: Python, libpython-dev, and libboost-python-dev. Command make PythonAPI It creates two \"egg\" packages PythonAPI/dist/carla-X.X.X-py2.7-linux-x86_64.egg PythonAPI/dist/carla-X.X.X-py3.7-linux-x86_64.egg This package can be directly imported into a Python script by adding it to the system path. #!/usr/bin/env python import sys sys.path.append( 'PythonAPI/dist/carla-X.X.X-py%d.%d-linux-x86_64.egg' % (sys.version_info.major, sys.version_info.minor)) import carla # ... Alternatively, it can be installed with easy_install easy_install2 --user --no-deps PythonAPI/dist/carla-X.X.X-py2.7-linux-x86_64.egg easy_install3 --user --no-deps PythonAPI/dist/carla-X.X.X-py3.7-linux-x86_64.egg","title":"Versions prior to 0.9.12"},{"location":"build_update/","text":"Update CARLA Update commands summary Get the lastest binary release Update Linux and Windows build Clean the build Pull from origin Download the assets Launch the server Get development assets To post unexpected issues, doubts or suggestions, feel free to login in the CARLA forum. CARLA forum Update commands summary Show command lines to update CARLA # Update a CARLA packaged release. # 1. Delete the current one. # 2. Follow the Quick start installation to get the one desired. # Update Linux build. git checkout master make clean git pull origin master ./Update.sh # Update Windows build. git checkout master make clean git pull origin master # Erase the content in `Unreal\\CarlaUE4\\Content\\Carla`. # Go to `\\Util\\ContentVersions.txt`. # Download the latest content. # Extract the new content in `Unreal\\CarlaUE4\\Content\\Carla`. # Get development assets. # Delete the `/Carla` folder containing previous assets. # Go to the main carla folder. git clone https://bitbucket.org/carla-simulator/carla-content Unreal/CarlaUE4/Content/Carla Get latest binary release Binary releases are prepackaged and thus, tied to a specific version of CARLA. To get the latest, erase the previous and follow the quick start installation to get the one desired. Releases are listed in Development in the CARLA repository. There is also a highly experimental Nightly build containing the current state of CARLA up to date. Get releases Get the nightly build Update Linux and Windows build Make sure to be in the local master branch before the update. Then, merge or rebase the changes to other branches and solve possible conflicts. git checkout master Clean the build Go to the main CARLA folder and delete binaries and temporals generated by the previous build. make clean Pull from origin Get the current version from master in the CARLA repository. git pull origin master Download the assets Linux. ./Update.sh Windows. 1. Erase the previous content in Unreal\\CarlaUE4\\Content\\Carla . 2. Go to \\Util\\ContentVersions.txt . 3. Download the content for latest . 4. Extract the new content in Unreal\\CarlaUE4\\Content\\Carla . Note In order to work with that the CARLA team is devleoping, go to get development assets below. Launch the server Run the server in spectator view to make sure that everything worked properly. make launch Get development assets The CARLA team works with assets still in development. These models and maps have a public git repository where the CARLA team regularly pushes latest updates. Assets are still unfinished, using them is only recommended for developers. In order to handle this repository it is advisted to install git-lfs . The repository is modified regularly, and git-lfs works faster with large binary files. To clone the repository, go to the main CARLA directory and run the following command. git clone https://bitbucket.org/carla-simulator/carla-content Unreal/CarlaUE4/Content/Carla Warning Delete the /Carla folder containing the assets before cloning the repository. Otherwise, an error will show.","title":"Update CARLA"},{"location":"build_update/#update-carla","text":"Update commands summary Get the lastest binary release Update Linux and Windows build Clean the build Pull from origin Download the assets Launch the server Get development assets To post unexpected issues, doubts or suggestions, feel free to login in the CARLA forum. CARLA forum","title":"Update CARLA"},{"location":"build_update/#update-commands-summary","text":"Show command lines to update CARLA # Update a CARLA packaged release. # 1. Delete the current one. # 2. Follow the Quick start installation to get the one desired. # Update Linux build. git checkout master make clean git pull origin master ./Update.sh # Update Windows build. git checkout master make clean git pull origin master # Erase the content in `Unreal\\CarlaUE4\\Content\\Carla`. # Go to `\\Util\\ContentVersions.txt`. # Download the latest content. # Extract the new content in `Unreal\\CarlaUE4\\Content\\Carla`. # Get development assets. # Delete the `/Carla` folder containing previous assets. # Go to the main carla folder. git clone https://bitbucket.org/carla-simulator/carla-content Unreal/CarlaUE4/Content/Carla","title":"Update commands summary"},{"location":"build_update/#get-latest-binary-release","text":"Binary releases are prepackaged and thus, tied to a specific version of CARLA. To get the latest, erase the previous and follow the quick start installation to get the one desired. Releases are listed in Development in the CARLA repository. There is also a highly experimental Nightly build containing the current state of CARLA up to date. Get releases Get the nightly build","title":"Get latest binary release"},{"location":"build_update/#update-linux-and-windows-build","text":"Make sure to be in the local master branch before the update. Then, merge or rebase the changes to other branches and solve possible conflicts. git checkout master","title":"Update Linux and Windows build"},{"location":"build_update/#clean-the-build","text":"Go to the main CARLA folder and delete binaries and temporals generated by the previous build. make clean","title":"Clean the build"},{"location":"build_update/#pull-from-origin","text":"Get the current version from master in the CARLA repository. git pull origin master","title":"Pull from origin"},{"location":"build_update/#download-the-assets","text":"Linux. ./Update.sh Windows. 1. Erase the previous content in Unreal\\CarlaUE4\\Content\\Carla . 2. Go to \\Util\\ContentVersions.txt . 3. Download the content for latest . 4. Extract the new content in Unreal\\CarlaUE4\\Content\\Carla . Note In order to work with that the CARLA team is devleoping, go to get development assets below.","title":"Download the assets"},{"location":"build_update/#launch-the-server","text":"Run the server in spectator view to make sure that everything worked properly. make launch","title":"Launch the server"},{"location":"build_update/#get-development-assets","text":"The CARLA team works with assets still in development. These models and maps have a public git repository where the CARLA team regularly pushes latest updates. Assets are still unfinished, using them is only recommended for developers. In order to handle this repository it is advisted to install git-lfs . The repository is modified regularly, and git-lfs works faster with large binary files. To clone the repository, go to the main CARLA directory and run the following command. git clone https://bitbucket.org/carla-simulator/carla-content Unreal/CarlaUE4/Content/Carla Warning Delete the /Carla folder containing the assets before cloning the repository. Otherwise, an error will show.","title":"Get development assets"},{"location":"build_windows/","text":"Windows build This guide details how to build CARLA from source on Windows. There are two parts. Part one details system requirements and installations of required software, and part two details how to actually build and run CARLA. The build process is long (4 hours or more) and involves several kinds of software. It is highly recommended to read through the guide fully before starting. If you come across errors or difficulties then have a look at the F.A.Q. page which offers solutions for the most common complications. Alternatively, use the CARLA forum to post any queries you may have. Part One: Prerequisites System requirements Software requirements Minor installations Python dependencies Major installations Visual Studio 2019 Unreal Engine Part Two: Build CARLA Clone the CARLA repository Get assets Set Unreal Engine environment variable Build CARLA Other make commands Part One: Prerequisites In this section you will find details of system requirements, minor and major software installations and Python dependencies that are required before you can begin to build CARLA. System requirements x64 system. The simulator should run in any 64 bits Windows system. 165 GB disk space. CARLA itself will take around 32 GB and the related major software installations (including Unreal Engine) will take around 133 GB. An adequate GPU. CARLA aims for realistic simulations, so the server needs at least a 6 GB GPU although 8 GB is recommended. A dedicated GPU is highly recommended for machine learning. Two TCP ports and good internet connection. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications. ..warning:: If you are upgrading from CARLA 0.9.12 to 0.9.13 : you must first upgrade the CARLA fork of the UE4 engine to the latest version. See the Unreal Engine section for details on upgrading UE4 Software requirements Minor installations CMake generates standard build files from simple configuration files. Git is a version control system to manage CARLA repositories. Make generates the executables. It is necessary to use Make version 3.81 , otherwise the build may fail. If you have multiple versions of Make installed, check that you are using version 3.81 in your PATH when building CARLA. You can check your default version of Make by running make --version . 7Zip is a file compression software. This is required for automatic decompression of asset files and prevents errors during build time due to large files being extracted incorrectly or partially. Python3 x64 is the main scripting language in CARLA. Having a x32 version installed may cause conflict, so it is highly advisable to have it uninstalled. Important Be sure that the above programs are added to the environment path . Remember that the path added should correspond to the progam's bin directory. Python dependencies Starting with CARLA 0.9.12, users have the option to install the CARLA Python API using pip3 . Version 20.3 or higher is required. To check if you have a suitable version, run the following command: pip3 -V If you need to upgrade: pip3 install --upgrade pip You must install the following Python dependencies: pip3 install --user setuptools pip3 install --user wheel Major installations Visual Studio 2019 Get the 2019 version of Visual Studio from here . Choose Community for the free version. Use the Visual Studio Installer to install three additional elements: Windows 8.1 SDK. Select it in the Installation details section on the right or go to the Indivdual Components tab and look under the SDKs, libraries, and frameworks heading. x64 Visual C++ Toolset. In the Workloads section, choose Desktop development with C++ . This will enable a x64 command prompt that will be used for the build. Check that it has been installed correctly by pressing the Windows button and searching for x64 . Be careful not to open a x86_x64 prompt . .NET framework 4.6.2 . In the Workloads section, choose .NET desktop development and then in the Installation details panel on the right, select .NET Framework 4.6.2 development tools . This is required to build Unreal Engine. Important Other Visual Studio versions may cause conflict. Even if these have been uninstalled, some registers may persist. To completely clean Visual Studio from the computer, go to Program Files (x86)\\Microsoft Visual Studio\\Installer\\resources\\app\\layout and run .\\InstallCleanup.exe -full Unreal Engine Starting with version 0.9.12, CARLA uses a modified fork of Unreal Engine 4.26. This fork contains patches specific to CARLA. Be aware that to download this fork of Unreal Engine, you need to have a GitHub account linked to Unreal Engine's account . If you don't have this set up, please follow this guide before going any further. To build the modified version of Unreal Engine: 1. In a terminal, navigate to the location you want to save Unreal Engine and clone the carla branch: git clone --depth 1 -b carla https://github.com/CarlaUnreal/UnrealEngine.git . Note Keep the Unreal Engine folder as close as C:\\\\ as you can because if the path exceeds a certain length then Setup.bat will return errors in step 3. 2. Run the configuration scripts: Setup.bat GenerateProjectFiles.bat 3. Compile the modified engine: Open the UE4.sln file inside the source folder with Visual Studio 2019. In the build bar ensure that you have selected 'Development Editor', 'Win64' and 'UnrealBuildTool' options. Check this guide if you need any help. In the solution explorer, right-click UE4 and select Build . 4. Once the solution is compiled you can open the engine to check that everything was installed correctly by launching the executable Engine\\Binaries\\Win64\\UE4Editor.exe . Note If the installation was successful, this should be recognised by Unreal Engine's version selector. You can check this by right-clicking on any .uproject file and selecting Switch Unreal Engine version . You should see a pop-up showing Source Build at PATH where PATH is the installation path that you have chosen. If you can not see this selector or the Generate Visual Studio project files when you right-click on .uproject files, something went wrong with the Unreal Engine installation and you will likely need to reinstall it correctly. Important A lot has happened so far. It is highly advisable to restart the computer before continuing. Part Two: Build CARLA Clone the CARLA repository CARLA repository The button above will take you to the official repository of the project. Either download from there and extract it locally or clone it using the following command: git clone https://github.com/carla-simulator/carla Note The master branch contains the current release of CARLA with the latest fixes and features. Previous CARLA versions are tagged with the version name. Always remember to check the current branch in git with the command git branch . Get assets Download the latest assets to work with the current version of CARLA by running the following command in the CARLA root folder: Update.bat The assets will be downloaded and extracted to the appropriate location if have 7zip installed. If you do not have this software installed, you will need to manually extract the file contents to Unreal\\CarlaUE4\\Content\\Carla . To download the assets for a specific version of CARLA: From the root CARLA directory, navigate to \\Util\\ContentVersions.txt . This document contains the links to the assets for all CARLA releases. Extract the assets in Unreal\\CarlaUE4\\Content\\Carla . If the path doesn't exist, create it. Extract the file with a command similar to the following: tar -xvzf <assets_file_name>.tar.gz.tar -C C:\\path\\to\\carla\\Unreal\\CarlaUE4\\Content\\Carla Set Unreal Engine environment variable It is necessary to set an environment variable so that CARLA can find the Unreal Engine installation folder. This allows users to choose which specific version of Unreal Engine is to be used. If no environment variable is specified, then CARLA will search for Unreal Engine in the windows registry and use the first version it finds there. To set the environment variable: Open Windows Control Panel and go to Advanced System Settings or search for Advanced System Settings in the Windows search bar. On the Advanced panel open Environment Variables... . Click New... to create the variable. Name the variable UE4_ROOT and choose the path to the installation folder of the desired Unreal Engine installation. Build CARLA This section outlines the commands to build CARLA. All commands should be run in the root CARLA folder. Commands should be executed via the x64 Native Tools Command Prompt for VS 2019 . Open this by clicking the Windows key and searching for x64 . There are two parts to the build process for CARLA, compiling the client and compiling the server. 1. Compile the Python API client : The Python API client grants control over the simulation. Compilation of the Python API client is required the first time you build CARLA and again after you perform any updates. After the client is compiled, you will be able to run scripts to interact with the simulation. The following command compiles the Python API client: make PythonAPI The CARLA client library will be built in two distinct, mutually exclusive forms. This gives users the freedom to choose which form they prefer to run the CARLA client code. The two forms include .egg files and .whl files. Choose one of the following options below to use the client library: A. .egg file The .egg file does not need to be installed. All of CARLA's example scripts automatically look for this file when importing CARLA. If you previously installed a CARLA .whl , the .whl will take precedence over an .egg file. B. .whl file The .whl file should be installed using pip3 : pip3 install <path/to/wheel>.whl This .whl file cannot be distributed as it is built specifically for your OS. Warning Issues can arise through the use of different methods to install the CARLA client library and having different versions of CARLA on your system. It is recommended to use virtual environments when installing the .whl and to uninstall any previously installed client libraries before installing new ones. 2. Compile the server : The following command compiles and launches Unreal Engine. Run this command each time you want to launch the server or use the Unreal Engine editor: make launch The project may ask to build other instances such as UE4Editor-Carla.dll the first time. Agree in order to open the project. During the first launch, the editor may show warnings regarding shaders and mesh distance fields. These take some time to be loaded and the map will not show properly until then. 3. Start the simulation : Press Play to start the server simulation. The camera can be moved with WASD keys and rotated by clicking the scene while moving the mouse around. Test the simulator using the example scripts inside PythonAPI\\examples . With the simulator running, open a new terminal for each script and run the following commands to spawn some life into the town and create a weather cycle: # Terminal A cd PythonAPI\\examples pip3 install -r requirements.txt python3 generate_traffic.py # Terminal B cd PythonAPI\\examples python3 dynamic_weather.py Important If the simulation is running at a very low FPS rate, go to Edit -> Editor preferences -> Performance in the Unreal Engine editor and disable Use less CPU when in background . Other make commands There are more make commands that you may find useful. Find them in the table below: Command Description make help Prints all available commands. make launch Launches CARLA server in Editor window. make PythonAPI Builds the CARLA client. make LibCarla Prepares the CARLA library to be imported anywhere. make package Builds CARLA and creates a packaged version for distribution. make clean Deletes all the binaries and temporals generated by the build system. make rebuild make clean and make launch both in one command. Read the F.A.Q. page or post in the CARLA forum for any issues regarding this guide. Now that you have built CARLA, learn how to update the CARLA build or take your first steps in the simulation, and learn some core concepts. Update CARLA First steps","title":"Windows build"},{"location":"build_windows/#windows-build","text":"This guide details how to build CARLA from source on Windows. There are two parts. Part one details system requirements and installations of required software, and part two details how to actually build and run CARLA. The build process is long (4 hours or more) and involves several kinds of software. It is highly recommended to read through the guide fully before starting. If you come across errors or difficulties then have a look at the F.A.Q. page which offers solutions for the most common complications. Alternatively, use the CARLA forum to post any queries you may have. Part One: Prerequisites System requirements Software requirements Minor installations Python dependencies Major installations Visual Studio 2019 Unreal Engine Part Two: Build CARLA Clone the CARLA repository Get assets Set Unreal Engine environment variable Build CARLA Other make commands","title":"Windows build"},{"location":"build_windows/#part-one-prerequisites","text":"In this section you will find details of system requirements, minor and major software installations and Python dependencies that are required before you can begin to build CARLA.","title":"Part One: Prerequisites"},{"location":"build_windows/#system-requirements","text":"x64 system. The simulator should run in any 64 bits Windows system. 165 GB disk space. CARLA itself will take around 32 GB and the related major software installations (including Unreal Engine) will take around 133 GB. An adequate GPU. CARLA aims for realistic simulations, so the server needs at least a 6 GB GPU although 8 GB is recommended. A dedicated GPU is highly recommended for machine learning. Two TCP ports and good internet connection. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications. ..warning:: If you are upgrading from CARLA 0.9.12 to 0.9.13 : you must first upgrade the CARLA fork of the UE4 engine to the latest version. See the Unreal Engine section for details on upgrading UE4","title":"System requirements"},{"location":"build_windows/#software-requirements","text":"","title":"Software requirements"},{"location":"build_windows/#minor-installations","text":"CMake generates standard build files from simple configuration files. Git is a version control system to manage CARLA repositories. Make generates the executables. It is necessary to use Make version 3.81 , otherwise the build may fail. If you have multiple versions of Make installed, check that you are using version 3.81 in your PATH when building CARLA. You can check your default version of Make by running make --version . 7Zip is a file compression software. This is required for automatic decompression of asset files and prevents errors during build time due to large files being extracted incorrectly or partially. Python3 x64 is the main scripting language in CARLA. Having a x32 version installed may cause conflict, so it is highly advisable to have it uninstalled. Important Be sure that the above programs are added to the environment path . Remember that the path added should correspond to the progam's bin directory.","title":"Minor installations"},{"location":"build_windows/#python-dependencies","text":"Starting with CARLA 0.9.12, users have the option to install the CARLA Python API using pip3 . Version 20.3 or higher is required. To check if you have a suitable version, run the following command: pip3 -V If you need to upgrade: pip3 install --upgrade pip You must install the following Python dependencies: pip3 install --user setuptools pip3 install --user wheel","title":"Python dependencies"},{"location":"build_windows/#major-installations","text":"","title":"Major installations"},{"location":"build_windows/#visual-studio-2019","text":"Get the 2019 version of Visual Studio from here . Choose Community for the free version. Use the Visual Studio Installer to install three additional elements: Windows 8.1 SDK. Select it in the Installation details section on the right or go to the Indivdual Components tab and look under the SDKs, libraries, and frameworks heading. x64 Visual C++ Toolset. In the Workloads section, choose Desktop development with C++ . This will enable a x64 command prompt that will be used for the build. Check that it has been installed correctly by pressing the Windows button and searching for x64 . Be careful not to open a x86_x64 prompt . .NET framework 4.6.2 . In the Workloads section, choose .NET desktop development and then in the Installation details panel on the right, select .NET Framework 4.6.2 development tools . This is required to build Unreal Engine. Important Other Visual Studio versions may cause conflict. Even if these have been uninstalled, some registers may persist. To completely clean Visual Studio from the computer, go to Program Files (x86)\\Microsoft Visual Studio\\Installer\\resources\\app\\layout and run .\\InstallCleanup.exe -full","title":"Visual Studio 2019"},{"location":"build_windows/#unreal-engine","text":"Starting with version 0.9.12, CARLA uses a modified fork of Unreal Engine 4.26. This fork contains patches specific to CARLA. Be aware that to download this fork of Unreal Engine, you need to have a GitHub account linked to Unreal Engine's account . If you don't have this set up, please follow this guide before going any further. To build the modified version of Unreal Engine: 1. In a terminal, navigate to the location you want to save Unreal Engine and clone the carla branch: git clone --depth 1 -b carla https://github.com/CarlaUnreal/UnrealEngine.git . Note Keep the Unreal Engine folder as close as C:\\\\ as you can because if the path exceeds a certain length then Setup.bat will return errors in step 3. 2. Run the configuration scripts: Setup.bat GenerateProjectFiles.bat 3. Compile the modified engine: Open the UE4.sln file inside the source folder with Visual Studio 2019. In the build bar ensure that you have selected 'Development Editor', 'Win64' and 'UnrealBuildTool' options. Check this guide if you need any help. In the solution explorer, right-click UE4 and select Build . 4. Once the solution is compiled you can open the engine to check that everything was installed correctly by launching the executable Engine\\Binaries\\Win64\\UE4Editor.exe . Note If the installation was successful, this should be recognised by Unreal Engine's version selector. You can check this by right-clicking on any .uproject file and selecting Switch Unreal Engine version . You should see a pop-up showing Source Build at PATH where PATH is the installation path that you have chosen. If you can not see this selector or the Generate Visual Studio project files when you right-click on .uproject files, something went wrong with the Unreal Engine installation and you will likely need to reinstall it correctly. Important A lot has happened so far. It is highly advisable to restart the computer before continuing.","title":"Unreal Engine"},{"location":"build_windows/#part-two-build-carla","text":"","title":"Part Two: Build CARLA"},{"location":"build_windows/#clone-the-carla-repository","text":"CARLA repository The button above will take you to the official repository of the project. Either download from there and extract it locally or clone it using the following command: git clone https://github.com/carla-simulator/carla Note The master branch contains the current release of CARLA with the latest fixes and features. Previous CARLA versions are tagged with the version name. Always remember to check the current branch in git with the command git branch .","title":"Clone the CARLA repository"},{"location":"build_windows/#get-assets","text":"Download the latest assets to work with the current version of CARLA by running the following command in the CARLA root folder: Update.bat The assets will be downloaded and extracted to the appropriate location if have 7zip installed. If you do not have this software installed, you will need to manually extract the file contents to Unreal\\CarlaUE4\\Content\\Carla . To download the assets for a specific version of CARLA: From the root CARLA directory, navigate to \\Util\\ContentVersions.txt . This document contains the links to the assets for all CARLA releases. Extract the assets in Unreal\\CarlaUE4\\Content\\Carla . If the path doesn't exist, create it. Extract the file with a command similar to the following: tar -xvzf <assets_file_name>.tar.gz.tar -C C:\\path\\to\\carla\\Unreal\\CarlaUE4\\Content\\Carla","title":"Get assets"},{"location":"build_windows/#set-unreal-engine-environment-variable","text":"It is necessary to set an environment variable so that CARLA can find the Unreal Engine installation folder. This allows users to choose which specific version of Unreal Engine is to be used. If no environment variable is specified, then CARLA will search for Unreal Engine in the windows registry and use the first version it finds there. To set the environment variable: Open Windows Control Panel and go to Advanced System Settings or search for Advanced System Settings in the Windows search bar. On the Advanced panel open Environment Variables... . Click New... to create the variable. Name the variable UE4_ROOT and choose the path to the installation folder of the desired Unreal Engine installation.","title":"Set Unreal Engine environment variable"},{"location":"build_windows/#build-carla","text":"This section outlines the commands to build CARLA. All commands should be run in the root CARLA folder. Commands should be executed via the x64 Native Tools Command Prompt for VS 2019 . Open this by clicking the Windows key and searching for x64 . There are two parts to the build process for CARLA, compiling the client and compiling the server. 1. Compile the Python API client : The Python API client grants control over the simulation. Compilation of the Python API client is required the first time you build CARLA and again after you perform any updates. After the client is compiled, you will be able to run scripts to interact with the simulation. The following command compiles the Python API client: make PythonAPI The CARLA client library will be built in two distinct, mutually exclusive forms. This gives users the freedom to choose which form they prefer to run the CARLA client code. The two forms include .egg files and .whl files. Choose one of the following options below to use the client library: A. .egg file The .egg file does not need to be installed. All of CARLA's example scripts automatically look for this file when importing CARLA. If you previously installed a CARLA .whl , the .whl will take precedence over an .egg file. B. .whl file The .whl file should be installed using pip3 : pip3 install <path/to/wheel>.whl This .whl file cannot be distributed as it is built specifically for your OS. Warning Issues can arise through the use of different methods to install the CARLA client library and having different versions of CARLA on your system. It is recommended to use virtual environments when installing the .whl and to uninstall any previously installed client libraries before installing new ones. 2. Compile the server : The following command compiles and launches Unreal Engine. Run this command each time you want to launch the server or use the Unreal Engine editor: make launch The project may ask to build other instances such as UE4Editor-Carla.dll the first time. Agree in order to open the project. During the first launch, the editor may show warnings regarding shaders and mesh distance fields. These take some time to be loaded and the map will not show properly until then. 3. Start the simulation : Press Play to start the server simulation. The camera can be moved with WASD keys and rotated by clicking the scene while moving the mouse around. Test the simulator using the example scripts inside PythonAPI\\examples . With the simulator running, open a new terminal for each script and run the following commands to spawn some life into the town and create a weather cycle: # Terminal A cd PythonAPI\\examples pip3 install -r requirements.txt python3 generate_traffic.py # Terminal B cd PythonAPI\\examples python3 dynamic_weather.py Important If the simulation is running at a very low FPS rate, go to Edit -> Editor preferences -> Performance in the Unreal Engine editor and disable Use less CPU when in background .","title":"Build CARLA"},{"location":"build_windows/#other-make-commands","text":"There are more make commands that you may find useful. Find them in the table below: Command Description make help Prints all available commands. make launch Launches CARLA server in Editor window. make PythonAPI Builds the CARLA client. make LibCarla Prepares the CARLA library to be imported anywhere. make package Builds CARLA and creates a packaged version for distribution. make clean Deletes all the binaries and temporals generated by the build system. make rebuild make clean and make launch both in one command. Read the F.A.Q. page or post in the CARLA forum for any issues regarding this guide. Now that you have built CARLA, learn how to update the CARLA build or take your first steps in the simulation, and learn some core concepts. Update CARLA First steps","title":"Other make commands"},{"location":"cont_code_of_conduct/","text":"Contributor Covenant Code of Conduct Our pledge Our standards Our responsibilities Scope Enforcement Attribution Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at info-carla@osvf.org. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html","title":"\u884c\u4e3a\u51c6\u5219"},{"location":"cont_code_of_conduct/#contributor-covenant-code-of-conduct","text":"Our pledge Our standards Our responsibilities Scope Enforcement Attribution","title":"Contributor Covenant Code of Conduct"},{"location":"cont_code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"cont_code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"cont_code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"cont_code_of_conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"cont_code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at info-carla@osvf.org. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"cont_code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html","title":"Attribution"},{"location":"cont_coding_standard/","text":"Coding standard General Python C++ General Use spaces, not tabs. Avoid adding trailing whitespace as it creates noise in the diffs. Python Comments should not exceed 80 columns, code should not exceed 120 columns. All code must be compatible with Python 2.7 and 3.7. Pylint should not give any error or warning (few exceptions apply with external classes like numpy and pygame , see our .pylintrc ). Python code follows PEP8 style guide (use autopep8 whenever possible). C++ Comments should not exceed 80 columns, code may exceed this limit a bit in rare occasions if it results in clearer code. Compilation should not give any error or warning ( clang++-8 -Wall -Wextra -std=C++14 -Wno-missing-braces ). The use of throw is forbidden, use carla::throw_exception instead. Unreal C++ code (CarlaUE4 and Carla plugin) follow the Unreal Engine's Coding Standard with the exception of using spaces instead of tabs. LibCarla uses a variation of Google's style guide . Uses of try-catch blocks should be surrounded by #ifndef LIBCARLA_NO_EXCEPTIONS if the code is used in the server-side.","title":"\u7f16\u7801\u6807\u51c6"},{"location":"cont_coding_standard/#coding-standard","text":"General Python C++","title":"Coding standard"},{"location":"cont_coding_standard/#general","text":"Use spaces, not tabs. Avoid adding trailing whitespace as it creates noise in the diffs.","title":"General"},{"location":"cont_coding_standard/#python","text":"Comments should not exceed 80 columns, code should not exceed 120 columns. All code must be compatible with Python 2.7 and 3.7. Pylint should not give any error or warning (few exceptions apply with external classes like numpy and pygame , see our .pylintrc ). Python code follows PEP8 style guide (use autopep8 whenever possible).","title":"Python"},{"location":"cont_coding_standard/#c","text":"Comments should not exceed 80 columns, code may exceed this limit a bit in rare occasions if it results in clearer code. Compilation should not give any error or warning ( clang++-8 -Wall -Wextra -std=C++14 -Wno-missing-braces ). The use of throw is forbidden, use carla::throw_exception instead. Unreal C++ code (CarlaUE4 and Carla plugin) follow the Unreal Engine's Coding Standard with the exception of using spaces instead of tabs. LibCarla uses a variation of Google's style guide . Uses of try-catch blocks should be surrounded by #ifndef LIBCARLA_NO_EXCEPTIONS if the code is used in the server-side.","title":"C++"},{"location":"cont_contribution_guidelines/","text":"Contributing to CARLA The CARLA team is glad to accept contributions from anybody willing to collaborate. There are different ways to contribute to the project, depending on the capabilities of the contributor. The team will work as much as possible so that contributions are successfully integrated in CARLA. Take a look and don't hesitate! Report bugs Request features Code contributions Learn about Unreal Engine Before getting started Coding standard Submission Checklist Art contributions Docs contributions Report bugs Issues can be reported in the issue section on GitHub. Before reporting a new bug, make sure to do some checkups. 1. Check if the bug has been reported. Look it up in that same issue section on GitHub. 2. Read the docs. Make sure that the issue is a bug, not a misunderstanding on how is CARLA supposed to work. Read the pages related to the issue in the Documentation and take a look at the FAQ page. Request features Ideas for new features are also a great way to contribute. Any suggestion that could improve the users' experience can be submitted in the corresponding GitHub section here . Code contributions Before starting hands-on on coding, please check out the issue board to check what is the team already working on, to avoid overlapping. In case of doubt or to discuss how to proceed, please contact one of us (or send an email to carla.simulator@gmail.com ). In order to start working, fork the CARLA repository , and clone said fork in your computer. Remember to keep your fork in sync with the original repository. Learn about Unreal Engine A basic introduction to C++ programming with UE4 can be found at Unreal's C++ Programming Tutorials . There are other options online, some of them not free of charge. The Unreal C++ Course at Udemy it's pretty complete and there are usually offers that make it very affordable. Before getting started Check out the CARLA Design document to get an idea on the different modules that compose CARLA. Choose the most appropriate one to hold the new feature. Feel free to contact the team in the Discord server in case any doubt arises during the process. Coding standard Follow the current coding standard when submitting new code. Submission Contributions and new features are not merged directly to the master branch, but to an intermediate branch named dev . This Gitflow branching model makes it easier to maintain a stable master branch. This model requires a specific workflow for contributions. Always keep your dev branch updated with the lastest changes. Develop the contribution in child branch from dev named as username/name_of_the_contribution . Once the contribution is ready, submit a pull-request from your branch to dev . Try to be as descriptive as possible when filling the description. Note that there are some checks that the new code is required to pass before merging. The checks are automatically run by the continuous integration system. A green tick mark will appear if the checks are successful. If a red mark, please correct the code accordingly. Once the contribution is merged in dev , it can be tested with the rest of new features. By the time of the next release, the dev branch will be merged to master , and the contribution will be available and announced. Checklist [ ] Your branch is up-to-date with the dev branch and tested with latest changes. [ ] Extended the README/documentation, if necessary. [ ] Code compiles correctly. [ ] All tests passing with make check . Art contributions Art contributions include vehicles, walkers, maps or any other type of assets to be used in CARLA. These are stored in a BitBucket repository, which has some account space limitations. For said reason, the contributor will have to get in touch with the CARLA team, and ask them to create a branch on the content repository for the contributions. 1. Create a BitBucket account. Visit the Bitbucket page . 2. Contact the art team to get access to the content repository. Join the Discord server . Go to the Contributors channel and request for access to the content repostory. 3. A branch will be created for each contributor. The branch will be named as contributors/contributor_name . All the contributions made by said user should be made in that corresponding branch. 4. Build CARLA. In order to contribute, a CARLA build is necessary. Follow the instructions to build either in Linux or Windows . 5. Download the content repository. Follow the instructions to update the content in here . 6. Update the branch to be in sync with master. The branch should always be updated with the latest changes in master. 7. Upload the contribution. Do the corresponding changes and push the branch to origin. 8. Wait for the art team to check it up. Once the contribution is uploaded, the team will check that everything is prepared to be merged with master. Docs contributions If some documentation is missing, vague or imprecise, it can be reported as with any other bug (read the previous section on how to report bugs ). However, users can contribute by writing documentation. The documentation is written with a mix of Markdown and HTML tags, with a some extra CSS code for features such as tables or the town slider . Follow the steps below to start writing documentation. Important To submit docs contributions, follow the same workflow explained right above in code contributions . To sum up, contributions are made in a child branch from dev and merged to said branch. 1. Build CARLA from source. Follow the steps in the docs to build on Linux or Windows . 2. Install MkDocs . MkDocs is a static site generator used to build documentation. sudo pip install mkdocs 3. Visualize the docs. In the main CARLA folder, run the following command and click the link that appears in the terminal (http://127.0.0.1:8000) to open a local visualization of the documentation. mkdocs serve 4. Create a git branch. Make sure to be in the dev branch (updated to latest changes) when creating a new one. git checkout -b <contributor_name>/<branch_name> 5. Write the docs. Edit the files following the guidelines in the documentation standard page. 6. Submit the changes. Create a pull request in the GitHub repository, and add one of the suggested reviewers. Try to be as descriptive as possible when filling the pull-request description. 7. Wait for review. The team will check if everything is ready to be merged or any changes are needed. Warning The local repository must be updated with the latest updates in the dev branch.","title":"\u8d21\u732e\u6307\u5357"},{"location":"cont_contribution_guidelines/#contributing-to-carla","text":"The CARLA team is glad to accept contributions from anybody willing to collaborate. There are different ways to contribute to the project, depending on the capabilities of the contributor. The team will work as much as possible so that contributions are successfully integrated in CARLA. Take a look and don't hesitate! Report bugs Request features Code contributions Learn about Unreal Engine Before getting started Coding standard Submission Checklist Art contributions Docs contributions","title":"Contributing to CARLA"},{"location":"cont_contribution_guidelines/#report-bugs","text":"Issues can be reported in the issue section on GitHub. Before reporting a new bug, make sure to do some checkups. 1. Check if the bug has been reported. Look it up in that same issue section on GitHub. 2. Read the docs. Make sure that the issue is a bug, not a misunderstanding on how is CARLA supposed to work. Read the pages related to the issue in the Documentation and take a look at the FAQ page.","title":"Report bugs"},{"location":"cont_contribution_guidelines/#request-features","text":"Ideas for new features are also a great way to contribute. Any suggestion that could improve the users' experience can be submitted in the corresponding GitHub section here .","title":"Request features"},{"location":"cont_contribution_guidelines/#code-contributions","text":"Before starting hands-on on coding, please check out the issue board to check what is the team already working on, to avoid overlapping. In case of doubt or to discuss how to proceed, please contact one of us (or send an email to carla.simulator@gmail.com ). In order to start working, fork the CARLA repository , and clone said fork in your computer. Remember to keep your fork in sync with the original repository.","title":"Code contributions"},{"location":"cont_contribution_guidelines/#learn-about-unreal-engine","text":"A basic introduction to C++ programming with UE4 can be found at Unreal's C++ Programming Tutorials . There are other options online, some of them not free of charge. The Unreal C++ Course at Udemy it's pretty complete and there are usually offers that make it very affordable.","title":"Learn about Unreal Engine"},{"location":"cont_contribution_guidelines/#before-getting-started","text":"Check out the CARLA Design document to get an idea on the different modules that compose CARLA. Choose the most appropriate one to hold the new feature. Feel free to contact the team in the Discord server in case any doubt arises during the process.","title":"Before getting started"},{"location":"cont_contribution_guidelines/#coding-standard","text":"Follow the current coding standard when submitting new code.","title":"Coding standard"},{"location":"cont_contribution_guidelines/#submission","text":"Contributions and new features are not merged directly to the master branch, but to an intermediate branch named dev . This Gitflow branching model makes it easier to maintain a stable master branch. This model requires a specific workflow for contributions. Always keep your dev branch updated with the lastest changes. Develop the contribution in child branch from dev named as username/name_of_the_contribution . Once the contribution is ready, submit a pull-request from your branch to dev . Try to be as descriptive as possible when filling the description. Note that there are some checks that the new code is required to pass before merging. The checks are automatically run by the continuous integration system. A green tick mark will appear if the checks are successful. If a red mark, please correct the code accordingly. Once the contribution is merged in dev , it can be tested with the rest of new features. By the time of the next release, the dev branch will be merged to master , and the contribution will be available and announced.","title":"Submission"},{"location":"cont_contribution_guidelines/#checklist","text":"[ ] Your branch is up-to-date with the dev branch and tested with latest changes. [ ] Extended the README/documentation, if necessary. [ ] Code compiles correctly. [ ] All tests passing with make check .","title":"Checklist"},{"location":"cont_contribution_guidelines/#art-contributions","text":"Art contributions include vehicles, walkers, maps or any other type of assets to be used in CARLA. These are stored in a BitBucket repository, which has some account space limitations. For said reason, the contributor will have to get in touch with the CARLA team, and ask them to create a branch on the content repository for the contributions. 1. Create a BitBucket account. Visit the Bitbucket page . 2. Contact the art team to get access to the content repository. Join the Discord server . Go to the Contributors channel and request for access to the content repostory. 3. A branch will be created for each contributor. The branch will be named as contributors/contributor_name . All the contributions made by said user should be made in that corresponding branch. 4. Build CARLA. In order to contribute, a CARLA build is necessary. Follow the instructions to build either in Linux or Windows . 5. Download the content repository. Follow the instructions to update the content in here . 6. Update the branch to be in sync with master. The branch should always be updated with the latest changes in master. 7. Upload the contribution. Do the corresponding changes and push the branch to origin. 8. Wait for the art team to check it up. Once the contribution is uploaded, the team will check that everything is prepared to be merged with master.","title":"Art contributions"},{"location":"cont_contribution_guidelines/#docs-contributions","text":"If some documentation is missing, vague or imprecise, it can be reported as with any other bug (read the previous section on how to report bugs ). However, users can contribute by writing documentation. The documentation is written with a mix of Markdown and HTML tags, with a some extra CSS code for features such as tables or the town slider . Follow the steps below to start writing documentation. Important To submit docs contributions, follow the same workflow explained right above in code contributions . To sum up, contributions are made in a child branch from dev and merged to said branch. 1. Build CARLA from source. Follow the steps in the docs to build on Linux or Windows . 2. Install MkDocs . MkDocs is a static site generator used to build documentation. sudo pip install mkdocs 3. Visualize the docs. In the main CARLA folder, run the following command and click the link that appears in the terminal (http://127.0.0.1:8000) to open a local visualization of the documentation. mkdocs serve 4. Create a git branch. Make sure to be in the dev branch (updated to latest changes) when creating a new one. git checkout -b <contributor_name>/<branch_name> 5. Write the docs. Edit the files following the guidelines in the documentation standard page. 6. Submit the changes. Create a pull request in the GitHub repository, and add one of the suggested reviewers. Try to be as descriptive as possible when filling the pull-request description. 7. Wait for review. The team will check if everything is ready to be merged or any changes are needed. Warning The local repository must be updated with the latest updates in the dev branch.","title":"Docs contributions"},{"location":"cont_doc_standard/","text":"Documentation Standard This document will serve as a guide and example of some rules that need to be followed in order to contribute to the documentation. Docs structure Rules Exceptions Docs structure We use a mix of markdown and HTML tags to customize the documentation along with an extra.css file. To update Python API docs, instead of directly modifying the Markdown you need to edit the corresponding YAML files inside carla/PythonAPI/docs/ and run doc_gen.py or make PythonAPI.docs . This will re-generate the respective Markdown files inside carla/Docs/ , which can then be fed into mkdocs . Rules Leave always an empty line between sections and at the end of the document. Writting should not exceed 100 columns, except for HTML related content, markdown tables, code snipets and referenced links. If an inline link exceeds the limit, use referenced [name][reference_link] markdown notation [reference_link]: https:// rather than [name](https://) . Use <br> to make inline jumps rather than leaving two spaces at the end of a line. Use <h1>Title</h1> at the beggining of a new page in order to make a Title or <hx>Heading<hx> to make a heading that won't show on the navigation bar. Use ------ underlining a Heading or # hierarchy to make headings and show them in the navigation bar. Exceptions Documentation generated via Python scripts like PythonAPI reference Handy markdown cheatsheet .","title":"\u6587\u6863\u6807\u51c6"},{"location":"cont_doc_standard/#documentation-standard","text":"This document will serve as a guide and example of some rules that need to be followed in order to contribute to the documentation. Docs structure Rules Exceptions","title":"Documentation Standard"},{"location":"cont_doc_standard/#docs-structure","text":"We use a mix of markdown and HTML tags to customize the documentation along with an extra.css file. To update Python API docs, instead of directly modifying the Markdown you need to edit the corresponding YAML files inside carla/PythonAPI/docs/ and run doc_gen.py or make PythonAPI.docs . This will re-generate the respective Markdown files inside carla/Docs/ , which can then be fed into mkdocs .","title":"Docs structure"},{"location":"cont_doc_standard/#rules","text":"Leave always an empty line between sections and at the end of the document. Writting should not exceed 100 columns, except for HTML related content, markdown tables, code snipets and referenced links. If an inline link exceeds the limit, use referenced [name][reference_link] markdown notation [reference_link]: https:// rather than [name](https://) . Use <br> to make inline jumps rather than leaving two spaces at the end of a line. Use <h1>Title</h1> at the beggining of a new page in order to make a Title or <hx>Heading<hx> to make a heading that won't show on the navigation bar. Use ------ underlining a Heading or # hierarchy to make headings and show them in the navigation bar.","title":"Rules"},{"location":"cont_doc_standard/#exceptions","text":"Documentation generated via Python scripts like PythonAPI reference Handy markdown cheatsheet .","title":"Exceptions"},{"location":"core_actors/","text":"2nd. Actors and blueprints Actors not only include vehicles and walkers, but also sensors, traffic signs, traffic lights, and the spectator. It is crucial to have full understanding on how to operate on them. This section will cover spawning, destruction, types, and how to manage them. However, the possibilities are almost endless. Experiment, take a look at the tutorials in this documentation and share doubts and ideas in the CARLA forum . Blueprints Managing the blueprint library Actor life cycle Spawning Handling Destruction Types of actors Sensors Spectator Traffic signs and traffic lights Vehicles Walkers Blueprints These layouts allow the user to smoothly incorporate new actors into the simulation. They are already-made models with animations and a series of attributes. Some of these are modifiable and others are not. These attributes include, among others, vehicle color, amount of channels in a lidar sensor, a walker's speed, and much more. Available blueprints are listed in the blueprint library , along with their attributes. Vehicle and walker blueprints have a generation attribute that indicates if they are a new (gen 2) or old (gen 1) asset. Managing the blueprint library The carla.BlueprintLibrary class contains a list of carla.ActorBlueprint elements. It is the world object who can provide access to it. blueprint_library = world.get_blueprint_library() Blueprints have an ID to identify them and the actors spawned with it. The library can be read to find a certain ID, choose a blueprint at random, or filter results using a wildcard pattern . # Find a specific blueprint. collision_sensor_bp = blueprint_library.find('sensor.other.collision') # Choose a vehicle blueprint at random. vehicle_bp = random.choice(blueprint_library.filter('vehicle.*.*')) Besides that, each carla.ActorBlueprint has a series of carla.ActorAttribute that can be get and set . is_bike = [vehicle.get_attribute('number_of_wheels') == 2] if(is_bike) vehicle.set_attribute('color', '255,0,0') Note Some of the attributes cannot be modified. Check it out in the blueprint library . Attributes have an carla.ActorAttributeType variable. It states its type from a list of enums. Also, modifiable attributes come with a list of recommended values . for attr in blueprint: if attr.is_modifiable: blueprint.set_attribute(attr.id, random.choice(attr.recommended_values)) Note Users can create their own vehicles. Check the Tutorials (assets) to learn on that. Contributors can add their new content to CARLA . Actor life cycle Important This section mentions different methods regarding actors. The Python API provides for commands to apply batches of the most common ones, in just one frame. Spawning The world object is responsible of spawning actors and keeping track of these. Spawning only requires a blueprint, and a carla.Transform stating a location and rotation for the actor. The world has two different methods to spawn actors. spawn_actor() raises an exception if the spawning fails. try_spawn_actor() returns None if the spawning fails. transform = Transform(Location(x=230, y=195, z=40), Rotation(yaw=180)) actor = world.spawn_actor(blueprint, transform) Important CARLA uses the Unreal Engine coordinates system . Remember that carla.Rotation constructor is defined as (pitch, yaw, roll) , that differs from Unreal Engine Editor (roll, pitch, yaw) . The actor will not be spawned in case of collision at the specified location. No matter if this happens with a static object or another actor. It is possible to try avoiding these undesired spawning collisions. map.get_spawn_points() for vehicles . Returns a list of recommended spawning points. spawn_points = world.get_map().get_spawn_points() world.get_random_location() for walkers . Returns a random point on a sidewalk. This same method is used to set a goal location for walkers. spawn_point = carla.Transform() spawn_point.location = world.get_random_location_from_navigation() An actor can be attached to another one when spawned. Actors follow the parent they are attached to. This is specially useful for sensors. The attachment can be rigid (proper to retrieve precise data) or with an eased movement according to its parent. It is defined by the helper class carla.AttachmentType . The next example attaches a camera rigidly to a vehicle, so their relative position remains fixed. camera = world.spawn_actor(camera_bp, relative_transform, attach_to=my_vehicle, carla.AttachmentType.Rigid) Important When spawning attached actors, the transform provided must be relative to the parent actor. Once spawned, the world object adds the actors to a list. This can be easily searched or iterated on. actor_list = world.get_actors() # Find an actor by id. actor = actor_list.find(id) # Print the location of all the speed limit signs in the world. for speed_sign in actor_list.filter('traffic.speed_limit.*'): print(speed_sign.get_location()) Handling carla.Actor mostly consists of get() and set() methods to manage the actors around the map. print(actor.get_acceleration()) print(actor.get_velocity()) location = actor.get_location() location.z += 10.0 actor.set_location(location) The actor's physics can be disabled to freeze it in place. actor.set_simulate_physics(False) Besides that, actors also have tags provided by their blueprints. These are mostly useful for semantic segmentation sensors. Warning Most of the methods send requests to the simulator asynchronously. The simulator has a limited amount of time each update to parse them. Flooding the simulator with set() methods will accumulate a significant lag. Destruction Actors are not destroyed when a Python script finishes. They have to explicitly destroy themselves. destroyed_sucessfully = actor.destroy() # Returns True if successful Important Destroying an actor blocks the simulator until the process finishes. Types of actors Sensors Sensors are actors that produce a stream of data. They have their own section, 4th. Sensors and data . For now, let's just take a look at a common sensor spawning cycle. This example spawns a camera sensor, attaches it to a vehicle, and tells the camera to save the images generated to disk. camera_bp = blueprint_library.find('sensor.camera.rgb') camera = world.spawn_actor(camera_bp, relative_transform, attach_to=my_vehicle) camera.listen(lambda image: image.save_to_disk('output/%06d.png' % image.frame)) Sensors have blueprints too. Setting attributes is crucial. Most of the sensors will be attached to a vehicle to gather information on its surroundings. Sensors listen to data. When data is received, they call a function described with a Lambda expression (6.13 in the link provided) . Spectator Placed by Unreal Engine to provide an in-game point of view. It can be used to move the view of the simulator window. The following example would move the spectator actor, to point the view towards a desired vehicle. spectator = world.get_spectator() transform = vehicle.get_transform() spectator.set_transform(carla.Transform(transform.location + carla.Location(z=50), carla.Rotation(pitch=-90))) Traffic signs and traffic lights Only stops, yields and traffic lights are considered actors in CARLA so far. The rest of the OpenDRIVE signs are accessible from the API as carla.Landmark . Their information is accessible using these instances, but they do no exist in the simulation as actors. Landmarks are explained more in detail in the following step, 3rd. Maps and navigation . When the simulation starts, stop, yields and traffic light are automatically generated using the information in the OpenDRIVE file. None of these can be found in the blueprint library and thus, cannot be spawned. Note CARLA maps do not have traffic signs nor lights in the OpenDRIVE file. These are manually placed by developers. Traffic signs are not defined in the road map itself, as explained in the following page. Instead, they have a carla.BoundingBox to affect vehicles inside of it. #Get the traffic light affecting a vehicle if vehicle_actor.is_at_traffic_light(): traffic_light = vehicle_actor.get_traffic_light() Traffic lights are found in junctions. They have their unique ID, as any actor, but also a group ID for the junction. To identify the traffic lights in the same group, a pole ID is used. The traffic lights in the same group follow a cycle. The first one is set to green while the rest remain frozen in red. The active one spends a few seconds in green, yellow and red, so there is a period of time where all the lights are red. Then, the next traffic light starts its cycle, and the previous one is frozen with the rest. The state of a traffic light can be set using the API. So does the seconds spent on each state. Possible states are described with carla.TrafficLightState as a series of enum values. #Change a red traffic light to green if traffic_light.get_state() == carla.TrafficLightState.Red: traffic_light.set_state(carla.TrafficLightState.Green) traffic_light.set_set_green_time(4.0) Note Vehicles will only be aware of a traffic light if the light is red. Vehicles carla.Vehicle is a special type of actor. It incorporates special internal components that simulate the physics of wheeled vehicles. This is achieved by applying four types of different controls: carla.VehicleControl provides input for driving commands such as throttle, steering, brake, etc. vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=-1.0)) carla.VehiclePhysicsControl defines physical attributes of the vehicle and contains two more controllers: carla.GearPhysicsControl which controls the gears. carla.WheelPhysicsControl which provides specific control over each wheel. vehicle.apply_physics_control(carla.VehiclePhysicsControl(max_rpm = 5000.0, center_of_mass = carla.Vector3D(0.0, 0.0, 0.0), torque_curve=[[0,400],[5000,400]])) Vehicles have a carla.BoundingBox encapsulating them. This bounding box allows physics to be applied to the vehicle and enables collisions to be detected. box = vehicle.bounding_box print(box.location) # Location relative to the vehicle. print(box.extent) # XYZ half-box extents in meters. The physics of vehicle wheels can be improved by enabling the sweep wheel collision parameter . The default wheel physics uses single ray casting from the axis to the floor for each wheel but when sweep wheel collision is enabled, the full volume of the wheel is checked against collisions. It can be enabled as such: physics_control = vehicle.get_physics_control() physics_control.use_sweep_wheel_collision = True vehicle.apply_physics_control(physics_control) Vehicles include other functionalities unique to them: Autopilot mode will subscribe a vehicle to the Traffic Manager to simulate real urban conditions. This module is hard-coded, not based on machine learning. vehicle.set_autopilot(True) Vehicle lights have to be turned on and off by the user. Each vehicle has a set of lights listed in carla.VehicleLightState . Not all vehicles have lights integrated. At the time of writing, vehicles with integrated lights are as follows: Bikes: All bikes have a front and back position light. Motorcycles: Yamaha and Harley Davidson models. Cars: Audi TT, Chevrolet Impala, both Dodge police cars, Dodge Charger, Audi e-tron, Lincoln 2017 and 2020, Mustang, Tesla Model 3, Tesla Cybertruck, Volkswagen T2 and the Mercedes C-Class. The lights of a vehicle can be retrieved and updated anytime using the methods carla.Vehicle.get_light_state and carla.Vehicle.set_light_state . These use binary operations to customize the light setting. # Turn on position lights current_lights = carla.VehicleLightState.NONE current_lights |= carla.VehicleLightState.Position vehicle.set_light_state(current_lights) Walkers carla.Walker work in a similar way as vehicles do. Control over them is provided by controllers. carla.WalkerControl moves the pedestrian around with a certain direction and speed. It also allows them to jump. carla.WalkerBoneControl provides control over the 3D skeleton. This tutorial explains how to control it. Walkers can be AI controlled. They do not have an autopilot mode. The carla.WalkerAIController actor moves around the actor it is attached to. walker_controller_bp = world.get_blueprint_library().find('controller.ai.walker') world.SpawnActor(walker_controller_bp, carla.Transform(), parent_walker) Note The AI controller is bodiless and has no physics. It will not appear on scene. Also, location (0,0,0) relative to its parent will not cause a collision. Each AI controller needs initialization, a goal and, optionally, a speed . Stopping the controller works in the same manner. ai_controller.start() ai_controller.go_to_location(world.get_random_location_from_navigation()) ai_controller.set_max_speed(1 + random.random()) # Between 1 and 2 m/s (default is 1.4 m/s). ... ai_controller.stop() When a walker reaches the target location, they will automatically walk to another random point. If the target point is not reachable, walkers will go to the closest point from their current location. A snipet in carla.Client uses batches to spawn a lot of walkers and make them wander around. Important To destroy AI pedestrians , stop the AI controller and destroy both, the actor, and the controller. That is a wrap as regarding actors in CARLA. The next step takes a closer look into the map, roads and traffic in CARLA. Keep reading to learn more or visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 3rd. Maps and navigation","title":"\u7b2c\u4e8c\u3001 \u89d2\u8272\u548c\u84dd\u56fe"},{"location":"core_actors/#2nd-actors-and-blueprints","text":"Actors not only include vehicles and walkers, but also sensors, traffic signs, traffic lights, and the spectator. It is crucial to have full understanding on how to operate on them. This section will cover spawning, destruction, types, and how to manage them. However, the possibilities are almost endless. Experiment, take a look at the tutorials in this documentation and share doubts and ideas in the CARLA forum . Blueprints Managing the blueprint library Actor life cycle Spawning Handling Destruction Types of actors Sensors Spectator Traffic signs and traffic lights Vehicles Walkers","title":"2nd. Actors and blueprints"},{"location":"core_actors/#blueprints","text":"These layouts allow the user to smoothly incorporate new actors into the simulation. They are already-made models with animations and a series of attributes. Some of these are modifiable and others are not. These attributes include, among others, vehicle color, amount of channels in a lidar sensor, a walker's speed, and much more. Available blueprints are listed in the blueprint library , along with their attributes. Vehicle and walker blueprints have a generation attribute that indicates if they are a new (gen 2) or old (gen 1) asset.","title":"Blueprints"},{"location":"core_actors/#managing-the-blueprint-library","text":"The carla.BlueprintLibrary class contains a list of carla.ActorBlueprint elements. It is the world object who can provide access to it. blueprint_library = world.get_blueprint_library() Blueprints have an ID to identify them and the actors spawned with it. The library can be read to find a certain ID, choose a blueprint at random, or filter results using a wildcard pattern . # Find a specific blueprint. collision_sensor_bp = blueprint_library.find('sensor.other.collision') # Choose a vehicle blueprint at random. vehicle_bp = random.choice(blueprint_library.filter('vehicle.*.*')) Besides that, each carla.ActorBlueprint has a series of carla.ActorAttribute that can be get and set . is_bike = [vehicle.get_attribute('number_of_wheels') == 2] if(is_bike) vehicle.set_attribute('color', '255,0,0') Note Some of the attributes cannot be modified. Check it out in the blueprint library . Attributes have an carla.ActorAttributeType variable. It states its type from a list of enums. Also, modifiable attributes come with a list of recommended values . for attr in blueprint: if attr.is_modifiable: blueprint.set_attribute(attr.id, random.choice(attr.recommended_values)) Note Users can create their own vehicles. Check the Tutorials (assets) to learn on that. Contributors can add their new content to CARLA .","title":"Managing the blueprint library"},{"location":"core_actors/#actor-life-cycle","text":"Important This section mentions different methods regarding actors. The Python API provides for commands to apply batches of the most common ones, in just one frame.","title":"Actor life cycle"},{"location":"core_actors/#spawning","text":"The world object is responsible of spawning actors and keeping track of these. Spawning only requires a blueprint, and a carla.Transform stating a location and rotation for the actor. The world has two different methods to spawn actors. spawn_actor() raises an exception if the spawning fails. try_spawn_actor() returns None if the spawning fails. transform = Transform(Location(x=230, y=195, z=40), Rotation(yaw=180)) actor = world.spawn_actor(blueprint, transform) Important CARLA uses the Unreal Engine coordinates system . Remember that carla.Rotation constructor is defined as (pitch, yaw, roll) , that differs from Unreal Engine Editor (roll, pitch, yaw) . The actor will not be spawned in case of collision at the specified location. No matter if this happens with a static object or another actor. It is possible to try avoiding these undesired spawning collisions. map.get_spawn_points() for vehicles . Returns a list of recommended spawning points. spawn_points = world.get_map().get_spawn_points() world.get_random_location() for walkers . Returns a random point on a sidewalk. This same method is used to set a goal location for walkers. spawn_point = carla.Transform() spawn_point.location = world.get_random_location_from_navigation() An actor can be attached to another one when spawned. Actors follow the parent they are attached to. This is specially useful for sensors. The attachment can be rigid (proper to retrieve precise data) or with an eased movement according to its parent. It is defined by the helper class carla.AttachmentType . The next example attaches a camera rigidly to a vehicle, so their relative position remains fixed. camera = world.spawn_actor(camera_bp, relative_transform, attach_to=my_vehicle, carla.AttachmentType.Rigid) Important When spawning attached actors, the transform provided must be relative to the parent actor. Once spawned, the world object adds the actors to a list. This can be easily searched or iterated on. actor_list = world.get_actors() # Find an actor by id. actor = actor_list.find(id) # Print the location of all the speed limit signs in the world. for speed_sign in actor_list.filter('traffic.speed_limit.*'): print(speed_sign.get_location())","title":"Spawning"},{"location":"core_actors/#handling","text":"carla.Actor mostly consists of get() and set() methods to manage the actors around the map. print(actor.get_acceleration()) print(actor.get_velocity()) location = actor.get_location() location.z += 10.0 actor.set_location(location) The actor's physics can be disabled to freeze it in place. actor.set_simulate_physics(False) Besides that, actors also have tags provided by their blueprints. These are mostly useful for semantic segmentation sensors. Warning Most of the methods send requests to the simulator asynchronously. The simulator has a limited amount of time each update to parse them. Flooding the simulator with set() methods will accumulate a significant lag.","title":"Handling"},{"location":"core_actors/#destruction","text":"Actors are not destroyed when a Python script finishes. They have to explicitly destroy themselves. destroyed_sucessfully = actor.destroy() # Returns True if successful Important Destroying an actor blocks the simulator until the process finishes.","title":"Destruction"},{"location":"core_actors/#types-of-actors","text":"","title":"Types of actors"},{"location":"core_actors/#sensors","text":"Sensors are actors that produce a stream of data. They have their own section, 4th. Sensors and data . For now, let's just take a look at a common sensor spawning cycle. This example spawns a camera sensor, attaches it to a vehicle, and tells the camera to save the images generated to disk. camera_bp = blueprint_library.find('sensor.camera.rgb') camera = world.spawn_actor(camera_bp, relative_transform, attach_to=my_vehicle) camera.listen(lambda image: image.save_to_disk('output/%06d.png' % image.frame)) Sensors have blueprints too. Setting attributes is crucial. Most of the sensors will be attached to a vehicle to gather information on its surroundings. Sensors listen to data. When data is received, they call a function described with a Lambda expression (6.13 in the link provided) .","title":"Sensors"},{"location":"core_actors/#spectator","text":"Placed by Unreal Engine to provide an in-game point of view. It can be used to move the view of the simulator window. The following example would move the spectator actor, to point the view towards a desired vehicle. spectator = world.get_spectator() transform = vehicle.get_transform() spectator.set_transform(carla.Transform(transform.location + carla.Location(z=50), carla.Rotation(pitch=-90)))","title":"Spectator"},{"location":"core_actors/#traffic-signs-and-traffic-lights","text":"Only stops, yields and traffic lights are considered actors in CARLA so far. The rest of the OpenDRIVE signs are accessible from the API as carla.Landmark . Their information is accessible using these instances, but they do no exist in the simulation as actors. Landmarks are explained more in detail in the following step, 3rd. Maps and navigation . When the simulation starts, stop, yields and traffic light are automatically generated using the information in the OpenDRIVE file. None of these can be found in the blueprint library and thus, cannot be spawned. Note CARLA maps do not have traffic signs nor lights in the OpenDRIVE file. These are manually placed by developers. Traffic signs are not defined in the road map itself, as explained in the following page. Instead, they have a carla.BoundingBox to affect vehicles inside of it. #Get the traffic light affecting a vehicle if vehicle_actor.is_at_traffic_light(): traffic_light = vehicle_actor.get_traffic_light() Traffic lights are found in junctions. They have their unique ID, as any actor, but also a group ID for the junction. To identify the traffic lights in the same group, a pole ID is used. The traffic lights in the same group follow a cycle. The first one is set to green while the rest remain frozen in red. The active one spends a few seconds in green, yellow and red, so there is a period of time where all the lights are red. Then, the next traffic light starts its cycle, and the previous one is frozen with the rest. The state of a traffic light can be set using the API. So does the seconds spent on each state. Possible states are described with carla.TrafficLightState as a series of enum values. #Change a red traffic light to green if traffic_light.get_state() == carla.TrafficLightState.Red: traffic_light.set_state(carla.TrafficLightState.Green) traffic_light.set_set_green_time(4.0) Note Vehicles will only be aware of a traffic light if the light is red.","title":"Traffic signs and traffic lights"},{"location":"core_actors/#vehicles","text":"carla.Vehicle is a special type of actor. It incorporates special internal components that simulate the physics of wheeled vehicles. This is achieved by applying four types of different controls: carla.VehicleControl provides input for driving commands such as throttle, steering, brake, etc. vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=-1.0)) carla.VehiclePhysicsControl defines physical attributes of the vehicle and contains two more controllers: carla.GearPhysicsControl which controls the gears. carla.WheelPhysicsControl which provides specific control over each wheel. vehicle.apply_physics_control(carla.VehiclePhysicsControl(max_rpm = 5000.0, center_of_mass = carla.Vector3D(0.0, 0.0, 0.0), torque_curve=[[0,400],[5000,400]])) Vehicles have a carla.BoundingBox encapsulating them. This bounding box allows physics to be applied to the vehicle and enables collisions to be detected. box = vehicle.bounding_box print(box.location) # Location relative to the vehicle. print(box.extent) # XYZ half-box extents in meters. The physics of vehicle wheels can be improved by enabling the sweep wheel collision parameter . The default wheel physics uses single ray casting from the axis to the floor for each wheel but when sweep wheel collision is enabled, the full volume of the wheel is checked against collisions. It can be enabled as such: physics_control = vehicle.get_physics_control() physics_control.use_sweep_wheel_collision = True vehicle.apply_physics_control(physics_control) Vehicles include other functionalities unique to them: Autopilot mode will subscribe a vehicle to the Traffic Manager to simulate real urban conditions. This module is hard-coded, not based on machine learning. vehicle.set_autopilot(True) Vehicle lights have to be turned on and off by the user. Each vehicle has a set of lights listed in carla.VehicleLightState . Not all vehicles have lights integrated. At the time of writing, vehicles with integrated lights are as follows: Bikes: All bikes have a front and back position light. Motorcycles: Yamaha and Harley Davidson models. Cars: Audi TT, Chevrolet Impala, both Dodge police cars, Dodge Charger, Audi e-tron, Lincoln 2017 and 2020, Mustang, Tesla Model 3, Tesla Cybertruck, Volkswagen T2 and the Mercedes C-Class. The lights of a vehicle can be retrieved and updated anytime using the methods carla.Vehicle.get_light_state and carla.Vehicle.set_light_state . These use binary operations to customize the light setting. # Turn on position lights current_lights = carla.VehicleLightState.NONE current_lights |= carla.VehicleLightState.Position vehicle.set_light_state(current_lights)","title":"Vehicles"},{"location":"core_actors/#walkers","text":"carla.Walker work in a similar way as vehicles do. Control over them is provided by controllers. carla.WalkerControl moves the pedestrian around with a certain direction and speed. It also allows them to jump. carla.WalkerBoneControl provides control over the 3D skeleton. This tutorial explains how to control it. Walkers can be AI controlled. They do not have an autopilot mode. The carla.WalkerAIController actor moves around the actor it is attached to. walker_controller_bp = world.get_blueprint_library().find('controller.ai.walker') world.SpawnActor(walker_controller_bp, carla.Transform(), parent_walker) Note The AI controller is bodiless and has no physics. It will not appear on scene. Also, location (0,0,0) relative to its parent will not cause a collision. Each AI controller needs initialization, a goal and, optionally, a speed . Stopping the controller works in the same manner. ai_controller.start() ai_controller.go_to_location(world.get_random_location_from_navigation()) ai_controller.set_max_speed(1 + random.random()) # Between 1 and 2 m/s (default is 1.4 m/s). ... ai_controller.stop() When a walker reaches the target location, they will automatically walk to another random point. If the target point is not reachable, walkers will go to the closest point from their current location. A snipet in carla.Client uses batches to spawn a lot of walkers and make them wander around. Important To destroy AI pedestrians , stop the AI controller and destroy both, the actor, and the controller. That is a wrap as regarding actors in CARLA. The next step takes a closer look into the map, roads and traffic in CARLA. Keep reading to learn more or visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 3rd. Maps and navigation","title":"Walkers"},{"location":"core_concepts/","text":"Core concepts This page introduces the main features and modules in CARLA. Detailed explanations of the different subjects can be found in their corresponding page. In order to learn about the different classes and methods in the API, take a look at the Python API reference . First steps 1st- World and client 2nd- Actors and blueprints 3rd- Maps and navigation 4th- Sensors and data Advanced steps Important This documentation refers to CARLA 0.9.X . The API changed significantly from previous versions (0.8.X). There is another documentation regarding those versions that can be found here . First steps 1st- World and client The client is the module the user runs to ask for information or changes in the simulation. A client runs with an IP and a specific port. It communicates with the server via terminal. There can be many clients running at the same time. Advanced multiclient managing requires thorough understanding of CARLA and synchrony . The world is an object representing the simulation. It acts as an abstract layer containing the main methods to spawn actors, change the weather, get the current state of the world, etc. There is only one world per simulation. It will be destroyed and substituted for a new one when the map is changed. 2nd- Actors and blueprints An actor is anything that plays a role in the simulation. Vehicles. Walkers. Sensors. The spectator. Traffic signs and traffic lights. Blueprints are already-made actor layouts necessary to spawn an actor. Basically, models with animations and a set of attributes. Some of these attributes can be customized by the user, others don't. There is a Blueprint library containing all the blueprints available as well as information on them. 3rd- Maps and navigation The map is the object representing the simulated world, the town mostly. There are eight maps available. All of them use OpenDRIVE 1.4 standard to describe the roads. Roads, lanes and junctions are managed by the Python API to be accessed from the client. These are used along with the waypoint class to provide vehicles with a navigation path. Traffic signs and traffic lights are accessible as carla.Landmark objects that contain information about their OpenDRIVE definition. Additionally, the simulator automatically generates stops, yields and traffic light objects when running using the information on the OpenDRIVE file. These have bounding boxes placed on the road. Vehicles become aware of them once inside their bounding box. 4th- Sensors and data Sensors wait for some event to happen, and then gather data from the simulation. They call for a function defining how to manage the data. Depending on which, sensors retrieve different types of sensor data . A sensor is an actor attached to a parent vehicle. It follows the vehicle around, gathering information of the surroundings. The sensors available are defined by their blueprints in the Blueprint library . Cameras (RGB, depth and semantic segmentation). Collision detector. Gnss sensor. IMU sensor. Lidar raycast. Lane invasion detector. Obstacle detector. Radar. RSS. Advanced steps CARLA offers a wide range of features that go beyond the scope of this introduction to the simulator. Here are listed some of the most remarkable ones. However, it is highly encouraged to read the whole First steps section before starting with the advanced steps. OpenDRIVE standalone mode . Generates a road mesh using only an OpenDRIVE file. Allows to load any OpenDRIVE map into CARLA without the need of creating assets. PTV-Vissim co-simulation . Run a synchronous simulation between CARLA and PTV-Vissim traffic simulator. Recorder . Saves snapshots of the simulation state to reenact a simulation with exact precision. Rendering options . Graphics quality settings, off-screen rendering and a no-rendering mode. RSS . Integration of the C++ Library for Responsibility Sensitive Safety to modify a vehicle's trajectory using safety checks. Simulation time and synchrony . Everything regarding the simulation time and server-client communication. SUMO co-simulation . Run a synchronous simulation between CARLA and SUMO traffic simulator. Traffic manager . This module is in charge of every vehicle set to autopilot mode. It simulates traffic in the city for the simulation to look like a real urban environment. That is a wrap on the CARLA basics. The next step takes a closer look to the world and the clients connecting to it. Keep reading to learn more. Visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 1st. World and client","title":"\u6838\u5fc3\u6982\u5ff5"},{"location":"core_concepts/#core-concepts","text":"This page introduces the main features and modules in CARLA. Detailed explanations of the different subjects can be found in their corresponding page. In order to learn about the different classes and methods in the API, take a look at the Python API reference . First steps 1st- World and client 2nd- Actors and blueprints 3rd- Maps and navigation 4th- Sensors and data Advanced steps Important This documentation refers to CARLA 0.9.X . The API changed significantly from previous versions (0.8.X). There is another documentation regarding those versions that can be found here .","title":"Core concepts"},{"location":"core_concepts/#first-steps","text":"","title":"First steps"},{"location":"core_concepts/#1st-world-and-client","text":"The client is the module the user runs to ask for information or changes in the simulation. A client runs with an IP and a specific port. It communicates with the server via terminal. There can be many clients running at the same time. Advanced multiclient managing requires thorough understanding of CARLA and synchrony . The world is an object representing the simulation. It acts as an abstract layer containing the main methods to spawn actors, change the weather, get the current state of the world, etc. There is only one world per simulation. It will be destroyed and substituted for a new one when the map is changed.","title":"1st- World and client"},{"location":"core_concepts/#2nd-actors-and-blueprints","text":"An actor is anything that plays a role in the simulation. Vehicles. Walkers. Sensors. The spectator. Traffic signs and traffic lights. Blueprints are already-made actor layouts necessary to spawn an actor. Basically, models with animations and a set of attributes. Some of these attributes can be customized by the user, others don't. There is a Blueprint library containing all the blueprints available as well as information on them.","title":"2nd- Actors and blueprints"},{"location":"core_concepts/#3rd-maps-and-navigation","text":"The map is the object representing the simulated world, the town mostly. There are eight maps available. All of them use OpenDRIVE 1.4 standard to describe the roads. Roads, lanes and junctions are managed by the Python API to be accessed from the client. These are used along with the waypoint class to provide vehicles with a navigation path. Traffic signs and traffic lights are accessible as carla.Landmark objects that contain information about their OpenDRIVE definition. Additionally, the simulator automatically generates stops, yields and traffic light objects when running using the information on the OpenDRIVE file. These have bounding boxes placed on the road. Vehicles become aware of them once inside their bounding box.","title":"3rd- Maps and navigation"},{"location":"core_concepts/#4th-sensors-and-data","text":"Sensors wait for some event to happen, and then gather data from the simulation. They call for a function defining how to manage the data. Depending on which, sensors retrieve different types of sensor data . A sensor is an actor attached to a parent vehicle. It follows the vehicle around, gathering information of the surroundings. The sensors available are defined by their blueprints in the Blueprint library . Cameras (RGB, depth and semantic segmentation). Collision detector. Gnss sensor. IMU sensor. Lidar raycast. Lane invasion detector. Obstacle detector. Radar. RSS.","title":"4th- Sensors and data"},{"location":"core_concepts/#advanced-steps","text":"CARLA offers a wide range of features that go beyond the scope of this introduction to the simulator. Here are listed some of the most remarkable ones. However, it is highly encouraged to read the whole First steps section before starting with the advanced steps. OpenDRIVE standalone mode . Generates a road mesh using only an OpenDRIVE file. Allows to load any OpenDRIVE map into CARLA without the need of creating assets. PTV-Vissim co-simulation . Run a synchronous simulation between CARLA and PTV-Vissim traffic simulator. Recorder . Saves snapshots of the simulation state to reenact a simulation with exact precision. Rendering options . Graphics quality settings, off-screen rendering and a no-rendering mode. RSS . Integration of the C++ Library for Responsibility Sensitive Safety to modify a vehicle's trajectory using safety checks. Simulation time and synchrony . Everything regarding the simulation time and server-client communication. SUMO co-simulation . Run a synchronous simulation between CARLA and SUMO traffic simulator. Traffic manager . This module is in charge of every vehicle set to autopilot mode. It simulates traffic in the city for the simulation to look like a real urban environment. That is a wrap on the CARLA basics. The next step takes a closer look to the world and the clients connecting to it. Keep reading to learn more. Visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 1st. World and client","title":"Advanced steps"},{"location":"core_map/","text":"3rd. Maps and navigation After discussing about the world and its actors, it is time to put everything into place and understand the map and how do the actors navigate it. The map Changing the map Landmarks Lanes Junctions Waypoints Environment Objects Navigation in CARLA Navigating through waypoints Generating a map navigation CARLA maps Non-layered maps Layered maps The map A map includes both the 3D model of a town and its road definition. A map's road definition is based on an OpenDRIVE file, a standarized, annotated road definition format. The way the OpenDRIVE standard 1.4 defines roads, lanes, junctions, etc. determines the functionality of the Python API and the reasoning behind decisions made. The Python API acts as a high level querying system to navigate these roads. It is constantly evolving to provide a wider set of tools. Changing the map To change the map, the world has to change too . The simulation will be recreated from scratch. You can either restart with the same map in a new world or you can change both the map and the world: reload_world() creates a new instance of the world with the same map. load_world() changes the current map and creates a new world. world = client.load_world('Town01') Each map has a name attribute that matches the name of the currently loaded city, e.g. Town01 . To get a list of the available maps: print(client.get_available_maps()) Landmarks Traffic signs defined in the OpenDRIVE file are translated to CARLA as landmark objects that can be queried from the API. The following methods and classes can be used to manipulate and work with landmark objects: carla.Landmark objects represent OpenDRIVE signals. The attributes and methods of this class describe the landmark and its area of influence. carla.LandmarkOrientation states the orientation of the landmark with regard to the road's geometry definition. carla.LandmarkType contains common landmark types to facilitate translation to OpenDRIVE types. carla.Waypoint can get landmarks located a certain distance ahead of it. The landmark type to get can be specified. carla.Map retrieves sets of landmarks. It can return all landmarks in the map, or those which have a common ID, type or group. carla.World acts as intermediary between landmarks and the carla.TrafficSign and carla.TrafficLight that represent them in the simulation. my_waypoint.get_landmarks(200.0,True) Waypoints A carla.Waypoint is a 3D-directed point in the CARLA world corresponding to an OpenDRIVE lane. Everything related to waypoints happens on the client-side; communication with the server is only needed once to get the map object containing the waypoint information. Each waypoint contains a carla.Transform which states its location on the map and the orientation of the lane containing it. The variables road_id , section_id , lane_id and s correspond to the OpenDRIVE road. The id of the waypoint is constructed from a hash combination of these four values. Note Waypoints closer than 2cm within the same road share the same id . A waypoint holds information about the lane containing it. This information includes the lane's left and right lane markings , a boolean to determine if it's inside a junction, the lane type, width, and lane changing permissions. # Access lane information from a waypoint inside_junction = waypoint.is_junction() width = waypoint.lane_width right_lm_color = waypoint.right_lane_marking.color Lanes The lane types defined by OpenDRIVE standard 1.4 are translated to the API in carla.LaneType as a series of enum values. The lane markings surrounding a lane are accessed through carla.LaneMarking . Lane markings are defined by a series of variables: color: carla.LaneMarkingColor are enum values that define the marking's color. lane_change: carla.LaneChange states if the lane permits turning left, right, both or none. type: carla.LaneMarkingType are enum values that define the type of marking according to the OpenDRIVE standard. width: defines the marking's thickness. The below example shows to get information about the lane type, lane markings, and lane change permissions at a specific waypoint: # Get the lane type of the waypoint lane_type = waypoint.lane_type # Get the type of lane marking on the left. left_lanemarking_type = waypoint.left_lane_marking.type() # Get available lane changes for this waypoint. lane_change = waypoint.lane_change Junctions A carla.Junction represents an OpenDRIVE junction. This class encompasses a junction with a bounding box to identify lanes or vehicles within it. The carla.Junction class contains the get_waypoints method which returns a pair of waypoints for every lane within the junction. Each pair is located at the start and end points of the junction boundaries. waypoints_junc = my_junction.get_waypoints() Environment Objects Every object on a CARLA map has a set of associated variables which can be found here . Included in these variables is a unique ID that can be used to toggle that object's visibility on the map. You can use the Python API to fetch the IDs of each environment object based on their semantic tag : # Get the buildings in the world world = client.get_world() env_objs = world.get_environment_objects(carla.CityObjectLabel.Buildings) # Access individual building IDs and save in a set building_01 = env_objs[0] building_02 = env_objs[1] objects_to_toggle = {building_01.id, building_02.id} # Toggle buildings off world.enable_environment_objects(objects_to_toggle, False) # Toggle buildings on world.enable_environment_objects(objects_to_toggle, True) See an example of distinct objects being toggled: Navigation in CARLA Navigation in CARLA is managed via the Waypoint API, a combination of methods from carla.Waypoint and carla.Map . The client must initially communicate with the server to retrieve the map object containing the waypoint information. This is only required once, all subsequent queries are performed on the client side. Navigating through waypoints The Waypoint API exposes methods that allow waypoints to connect to each other and construct a path along a road for vehicles to navigate: next(d) creates a list of waypoints within an approximate distance, d , in the direction of the lane . The list contains one waypoint for each possible deviation. previous(d) creates a list of waypoints waypoint within an approximate distance, d , in the opposite direction of the lane . The list contains one waypoint for each possible deviation. next_until_lane_end(d) and previous_until_lane_start(d) return a list of waypoints a distance d apart. The lists go from the current waypoint to the end and beginning of its lane, respectively. get_right_lane() and get_left_lane() return the equivalent waypoint in an adjacent lane, if one exists. A lane change maneuver can be made by finding the next waypoint to the one on its right/left lane, and moving to it. # Find next waypoint 2 meters ahead. waypoint = waypoint.next(2.0) Generating map navigation The client needs to make a request to the server to get the .xodr map file and parse it to a carla.Map object. This only needs to be done once. To get the map object: map = world.get_map() The map object contains recommended spawn points for the creation of vehicles. You can get a list of these spawn points, each one containing a carla.Transform , using the method below. Bear in mind that the spawn points may be occupied already, resulting in failed creation of vehicles due to collisions. spawn_points = world.get_map().get_spawn_points() You can get started with waypoints by getting the closest waypoint to a specific location or to a particular road_id , lane_id and s value in the map's OpenDRIVE definition: # Nearest waypoint in the center of a Driving or Sidewalk lane. waypoint01 = map.get_waypoint(vehicle.get_location(),project_to_road=True, lane_type=(carla.LaneType.Driving | carla.LaneType.Sidewalk)) #Nearest waypoint but specifying OpenDRIVE parameters. waypoint02 = map.get_waypoint_xodr(road_id,lane_id,s) The below example shows how to generate a collection of waypoints to visualize the city lanes. This will create waypoints all over the map, for every road and lane. All of them will approximately 2 meters apart: waypoint_list = map.generate_waypoints(2.0) To generate a minimal graph of road topology , use the example below. This will return a list of pairs (tuples) of waypoints. The first element in each pair connects with the second element and both define the start and end points of each lane in the map. More information on this method is found in the PythonAPI . waypoint_tuple_list = map.get_topology() The example below converts a carla.Transform to geographical latitude and longitude coordinates, in the form of a carla.GeoLocation : my_geolocation = map.transform_to_geolocation(vehicle.transform) Use the following example to save road information in OpenDRIVE format to disk: info_map = map.to_opendrive() CARLA maps There are eight towns in the CARLA ecosystem and each of those towns have two kinds of map, non-layered and layered. Layers refer to the grouped objects within a map and consist of the following: NONE Buildings Decals Foliage Ground ParkedVehicles Particles Props StreetLights Walls All Non-layered maps Non-layered maps are shown in the table below (click the town name to see an overhead image of the layout). All of the layers are present at all times and cannot be toggled on or off in these maps. Up until CARLA 0.9.11, these were the only kinds of map available. Note Users can customize a map or even create a new map to be used in CARLA. Town Summary Town01 A basic town layout consisting of \"T junctions\". Town02 Similar to Town01 , but smaller. Town03 The most complex town, with a 5-lane junction, a roundabout, unevenness, a tunnel, and more. Town04 An infinite loop with a highway and a small town. Town05 Squared-grid town with cross junctions and a bridge. It has multiple lanes per direction. Useful to perform lane changes. Town06 Long highways with many highway entrances and exits. It also has a Michigan left . Town07 A rural environment with narrow roads, barns and hardly any traffic lights. Town10 A city environment with different environments such as an avenue or promenade, and more realistic textures. Layered maps The layout of layered maps is the same as non-layered maps but it is possible to toggle off and on the layers of the map. There is a minimum layout that cannot be toggled off and consists of roads, sidewalks, traffic lights and traffic signs. Layered maps can be identified by the suffix _Opt , for example, Town01_Opt . With these maps it is possible to load and unload layers via the Python API: # Load layered map for Town 01 with minimum layout plus buildings and parked vehicles world = client.load_world('Town01_Opt', carla.MapLayer.Buildings | carla.MapLayer.ParkedVehicles) # Toggle all buildings off world.unload_map_layer(carla.MapLayer.Buildings) # Toggle all buildings on world.load_map_layer(carla.MapLayer.Buildings) See an example of all layers being loaded and unloaded in sequence: That is a wrap as regarding maps and navigation in CARLA. The next step takes a closer look into sensors types, and the data they retrieve. Keep reading to learn more or visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 4th. Sensors and data","title":"\u7b2c\u4e09\u3001\u5730\u56fe\u548c\u5bfc\u822a "},{"location":"core_map/#3rd-maps-and-navigation","text":"After discussing about the world and its actors, it is time to put everything into place and understand the map and how do the actors navigate it. The map Changing the map Landmarks Lanes Junctions Waypoints Environment Objects Navigation in CARLA Navigating through waypoints Generating a map navigation CARLA maps Non-layered maps Layered maps","title":"3rd. Maps and navigation"},{"location":"core_map/#the-map","text":"A map includes both the 3D model of a town and its road definition. A map's road definition is based on an OpenDRIVE file, a standarized, annotated road definition format. The way the OpenDRIVE standard 1.4 defines roads, lanes, junctions, etc. determines the functionality of the Python API and the reasoning behind decisions made. The Python API acts as a high level querying system to navigate these roads. It is constantly evolving to provide a wider set of tools.","title":"The map"},{"location":"core_map/#changing-the-map","text":"To change the map, the world has to change too . The simulation will be recreated from scratch. You can either restart with the same map in a new world or you can change both the map and the world: reload_world() creates a new instance of the world with the same map. load_world() changes the current map and creates a new world. world = client.load_world('Town01') Each map has a name attribute that matches the name of the currently loaded city, e.g. Town01 . To get a list of the available maps: print(client.get_available_maps())","title":"Changing the map"},{"location":"core_map/#landmarks","text":"Traffic signs defined in the OpenDRIVE file are translated to CARLA as landmark objects that can be queried from the API. The following methods and classes can be used to manipulate and work with landmark objects: carla.Landmark objects represent OpenDRIVE signals. The attributes and methods of this class describe the landmark and its area of influence. carla.LandmarkOrientation states the orientation of the landmark with regard to the road's geometry definition. carla.LandmarkType contains common landmark types to facilitate translation to OpenDRIVE types. carla.Waypoint can get landmarks located a certain distance ahead of it. The landmark type to get can be specified. carla.Map retrieves sets of landmarks. It can return all landmarks in the map, or those which have a common ID, type or group. carla.World acts as intermediary between landmarks and the carla.TrafficSign and carla.TrafficLight that represent them in the simulation. my_waypoint.get_landmarks(200.0,True)","title":"Landmarks"},{"location":"core_map/#waypoints","text":"A carla.Waypoint is a 3D-directed point in the CARLA world corresponding to an OpenDRIVE lane. Everything related to waypoints happens on the client-side; communication with the server is only needed once to get the map object containing the waypoint information. Each waypoint contains a carla.Transform which states its location on the map and the orientation of the lane containing it. The variables road_id , section_id , lane_id and s correspond to the OpenDRIVE road. The id of the waypoint is constructed from a hash combination of these four values. Note Waypoints closer than 2cm within the same road share the same id . A waypoint holds information about the lane containing it. This information includes the lane's left and right lane markings , a boolean to determine if it's inside a junction, the lane type, width, and lane changing permissions. # Access lane information from a waypoint inside_junction = waypoint.is_junction() width = waypoint.lane_width right_lm_color = waypoint.right_lane_marking.color","title":"Waypoints"},{"location":"core_map/#lanes","text":"The lane types defined by OpenDRIVE standard 1.4 are translated to the API in carla.LaneType as a series of enum values. The lane markings surrounding a lane are accessed through carla.LaneMarking . Lane markings are defined by a series of variables: color: carla.LaneMarkingColor are enum values that define the marking's color. lane_change: carla.LaneChange states if the lane permits turning left, right, both or none. type: carla.LaneMarkingType are enum values that define the type of marking according to the OpenDRIVE standard. width: defines the marking's thickness. The below example shows to get information about the lane type, lane markings, and lane change permissions at a specific waypoint: # Get the lane type of the waypoint lane_type = waypoint.lane_type # Get the type of lane marking on the left. left_lanemarking_type = waypoint.left_lane_marking.type() # Get available lane changes for this waypoint. lane_change = waypoint.lane_change","title":"Lanes"},{"location":"core_map/#junctions","text":"A carla.Junction represents an OpenDRIVE junction. This class encompasses a junction with a bounding box to identify lanes or vehicles within it. The carla.Junction class contains the get_waypoints method which returns a pair of waypoints for every lane within the junction. Each pair is located at the start and end points of the junction boundaries. waypoints_junc = my_junction.get_waypoints()","title":"Junctions"},{"location":"core_map/#environment-objects","text":"Every object on a CARLA map has a set of associated variables which can be found here . Included in these variables is a unique ID that can be used to toggle that object's visibility on the map. You can use the Python API to fetch the IDs of each environment object based on their semantic tag : # Get the buildings in the world world = client.get_world() env_objs = world.get_environment_objects(carla.CityObjectLabel.Buildings) # Access individual building IDs and save in a set building_01 = env_objs[0] building_02 = env_objs[1] objects_to_toggle = {building_01.id, building_02.id} # Toggle buildings off world.enable_environment_objects(objects_to_toggle, False) # Toggle buildings on world.enable_environment_objects(objects_to_toggle, True) See an example of distinct objects being toggled:","title":"Environment Objects"},{"location":"core_map/#navigation-in-carla","text":"Navigation in CARLA is managed via the Waypoint API, a combination of methods from carla.Waypoint and carla.Map . The client must initially communicate with the server to retrieve the map object containing the waypoint information. This is only required once, all subsequent queries are performed on the client side.","title":"Navigation in CARLA"},{"location":"core_map/#navigating-through-waypoints","text":"The Waypoint API exposes methods that allow waypoints to connect to each other and construct a path along a road for vehicles to navigate: next(d) creates a list of waypoints within an approximate distance, d , in the direction of the lane . The list contains one waypoint for each possible deviation. previous(d) creates a list of waypoints waypoint within an approximate distance, d , in the opposite direction of the lane . The list contains one waypoint for each possible deviation. next_until_lane_end(d) and previous_until_lane_start(d) return a list of waypoints a distance d apart. The lists go from the current waypoint to the end and beginning of its lane, respectively. get_right_lane() and get_left_lane() return the equivalent waypoint in an adjacent lane, if one exists. A lane change maneuver can be made by finding the next waypoint to the one on its right/left lane, and moving to it. # Find next waypoint 2 meters ahead. waypoint = waypoint.next(2.0)","title":"Navigating through waypoints"},{"location":"core_map/#generating-map-navigation","text":"The client needs to make a request to the server to get the .xodr map file and parse it to a carla.Map object. This only needs to be done once. To get the map object: map = world.get_map() The map object contains recommended spawn points for the creation of vehicles. You can get a list of these spawn points, each one containing a carla.Transform , using the method below. Bear in mind that the spawn points may be occupied already, resulting in failed creation of vehicles due to collisions. spawn_points = world.get_map().get_spawn_points() You can get started with waypoints by getting the closest waypoint to a specific location or to a particular road_id , lane_id and s value in the map's OpenDRIVE definition: # Nearest waypoint in the center of a Driving or Sidewalk lane. waypoint01 = map.get_waypoint(vehicle.get_location(),project_to_road=True, lane_type=(carla.LaneType.Driving | carla.LaneType.Sidewalk)) #Nearest waypoint but specifying OpenDRIVE parameters. waypoint02 = map.get_waypoint_xodr(road_id,lane_id,s) The below example shows how to generate a collection of waypoints to visualize the city lanes. This will create waypoints all over the map, for every road and lane. All of them will approximately 2 meters apart: waypoint_list = map.generate_waypoints(2.0) To generate a minimal graph of road topology , use the example below. This will return a list of pairs (tuples) of waypoints. The first element in each pair connects with the second element and both define the start and end points of each lane in the map. More information on this method is found in the PythonAPI . waypoint_tuple_list = map.get_topology() The example below converts a carla.Transform to geographical latitude and longitude coordinates, in the form of a carla.GeoLocation : my_geolocation = map.transform_to_geolocation(vehicle.transform) Use the following example to save road information in OpenDRIVE format to disk: info_map = map.to_opendrive()","title":"Generating map navigation"},{"location":"core_map/#carla-maps","text":"There are eight towns in the CARLA ecosystem and each of those towns have two kinds of map, non-layered and layered. Layers refer to the grouped objects within a map and consist of the following: NONE Buildings Decals Foliage Ground ParkedVehicles Particles Props StreetLights Walls All","title":"CARLA maps"},{"location":"core_map/#non-layered-maps","text":"Non-layered maps are shown in the table below (click the town name to see an overhead image of the layout). All of the layers are present at all times and cannot be toggled on or off in these maps. Up until CARLA 0.9.11, these were the only kinds of map available. Note Users can customize a map or even create a new map to be used in CARLA. Town Summary Town01 A basic town layout consisting of \"T junctions\". Town02 Similar to Town01 , but smaller. Town03 The most complex town, with a 5-lane junction, a roundabout, unevenness, a tunnel, and more. Town04 An infinite loop with a highway and a small town. Town05 Squared-grid town with cross junctions and a bridge. It has multiple lanes per direction. Useful to perform lane changes. Town06 Long highways with many highway entrances and exits. It also has a Michigan left . Town07 A rural environment with narrow roads, barns and hardly any traffic lights. Town10 A city environment with different environments such as an avenue or promenade, and more realistic textures.","title":"Non-layered maps"},{"location":"core_map/#layered-maps","text":"The layout of layered maps is the same as non-layered maps but it is possible to toggle off and on the layers of the map. There is a minimum layout that cannot be toggled off and consists of roads, sidewalks, traffic lights and traffic signs. Layered maps can be identified by the suffix _Opt , for example, Town01_Opt . With these maps it is possible to load and unload layers via the Python API: # Load layered map for Town 01 with minimum layout plus buildings and parked vehicles world = client.load_world('Town01_Opt', carla.MapLayer.Buildings | carla.MapLayer.ParkedVehicles) # Toggle all buildings off world.unload_map_layer(carla.MapLayer.Buildings) # Toggle all buildings on world.load_map_layer(carla.MapLayer.Buildings) See an example of all layers being loaded and unloaded in sequence: That is a wrap as regarding maps and navigation in CARLA. The next step takes a closer look into sensors types, and the data they retrieve. Keep reading to learn more or visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 4th. Sensors and data","title":"Layered maps"},{"location":"core_sensors/","text":"4th. Sensors and data Sensors are actors that retrieve data from their surroundings. They are crucial to create learning environment for driving agents. This page summarizes everything necessary to start handling sensors. It introduces the types available and a step-by-step guide of their life cycle. The specifics for every sensor can be found in the sensors reference . Sensors step-by-step Setting Spawning Listening Data Types of sensors Cameras Detectors Other Sensors step-by-step The class carla.Sensor defines a special type of actor able to measure and stream data. What is this data? It varies a lot depending on the type of sensor. All the types of data are inherited from the general carla.SensorData . When do they retrieve the data? Either on every simulation step or when a certain event is registered. Depends on the type of sensor. How do they retrieve the data? Every sensor has a listen() method to receive and manage the data. Despite their differences, all the sensors are used in a similar way. Setting As with every other actor, find the blueprint and set specific attributes. This is essential when handling sensors. Their attributes will determine the results obtained. These are detailed in the sensors reference . The following example sets a dashboard HD camera. # Find the blueprint of the sensor. blueprint = world.get_blueprint_library().find('sensor.camera.rgb') # Modify the attributes of the blueprint to set image resolution and field of view. blueprint.set_attribute('image_size_x', '1920') blueprint.set_attribute('image_size_y', '1080') blueprint.set_attribute('fov', '110') # Set the time in seconds between sensor captures blueprint.set_attribute('sensor_tick', '1.0') Spawning attachment_to and attachment_type , are crucial. Sensors should be attached to a parent actor, usually a vehicle, to follow it around and gather the information. The attachment type will determine how its position is updated regarding said vehicle. Rigid attachment. Movement is strict regarding its parent location. This is the proper attachment to retrieve data from the simulation. SpringArm attachment. Movement is eased with little accelerations and decelerations. This attachment is only recommended to record videos from the simulation. The movement is smooth and \"hops\" are avoided when updating the cameras' positions. transform = carla.Transform(carla.Location(x=0.8, z=1.7)) sensor = world.spawn_actor(blueprint, transform, attach_to=my_vehicle) Important When spawning with attachment, location must be relative to the parent actor. Listening Every sensor has a listen() method. This is called every time the sensor retrieves data. The argument callback is a lambda function . It describes what should the sensor do when data is retrieved. This must have the data retrieved as an argument. # do_something() will be called each time a new image is generated by the camera. sensor.listen(lambda data: do_something(data)) ... # This collision sensor would print everytime a collision is detected. def callback(event): for actor_id in event: vehicle = world_ref().get_actor(actor_id) print('Vehicle too close: %s' % vehicle.type_id) sensor02.listen(callback) Data Most sensor data objects have a function to save the information to disk. This will allow it to be used in other environments. Sensor data differs a lot between sensor types. Take a look at the sensors reference to get a detailed explanation. However, all of them are always tagged with some basic information. Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Timestamp of the measurement in simulation seconds since the beginning of the episode. transform carla.Transform World reference of the sensor at the time of the measurement. Important is_listening is a sensor attribute that enables/disables data listening at will. sensor_tick is a blueprint attribute that sets the simulation time between data received. Types of sensors Cameras Take a shot of the world from their point of view. For cameras that return carla.Image , you can use the helper class carla.ColorConverter to modify the image to represent different information. Retrieve data every simulation step. Sensor Output Overview Depth carla.Image Renders the depth of the elements in the field of view in a gray-scale map. RGB carla.Image Provides clear vision of the surroundings. Looks like a normal photo of the scene. Optical Flow carla.Image Renders the motion of every pixel from the camera. Semantic segmentation carla.Image Renders elements in the field of view with a specific color according to their tags. DVS carla.DVSEventArray Measures changes of brightness intensity asynchronously as an event stream. Detectors Retrieve data when the object they are attached to registers a specific event. Retrieve data when triggered. Sensor Output Overview Collision carla.CollisionEvent Retrieves collisions between its parent and other actors. Lane invasion carla.LaneInvasionEvent Registers when its parent crosses a lane marking. Obstacle carla.ObstacleDetectionEvent Detects possible obstacles ahead of its parent. Other Different functionalities such as navigation, measurement of physical properties and 2D/3D point maps of the scene. Retrieve data every simulation step. Sensor Output Overview GNSS carla.GNSSMeasurement Retrieves the geolocation of the sensor. IMU carla.IMUMeasurement Comprises an accelerometer, a gyroscope, and a compass. LIDAR carla.LidarMeasurement A rotating LIDAR. Generates a 4D point cloud with coordinates and intensity per point to model the surroundings. Radar carla.RadarMeasurement 2D point map modelling elements in sight and their movement regarding the sensor. RSS carla.RssResponse Modifies the controller applied to a vehicle according to safety checks. This sensor works in a different manner than the rest, and there is specific RSS documentation for it. Semantic LIDAR carla.SemanticLidarMeasurement A rotating LIDAR. Generates a 3D point cloud with extra information regarding instance and semantic segmentation. That is a wrap on sensors and how do these retrieve simulation data. Thus concludes the introduction to CARLA. However there is yet a lot to learn. Continue learning. There are some advanced features in CARLA: rendering options, traffic manager, the recorder, and some more. This is a great moment to learn more about them. Synchrony and time-step Experiment freely. Take a look at the References section of this documentation. It contains detailed information on the classes in the Python API, sensors, code snippets and much more. Python API reference Give your two cents. Any doubts, suggestions and ideas are welcome in the forum. CARLA forum","title":"\u7b2c\u56db\u3001 \u4f20\u611f\u5668\u548c\u6570\u636e"},{"location":"core_sensors/#4th-sensors-and-data","text":"Sensors are actors that retrieve data from their surroundings. They are crucial to create learning environment for driving agents. This page summarizes everything necessary to start handling sensors. It introduces the types available and a step-by-step guide of their life cycle. The specifics for every sensor can be found in the sensors reference . Sensors step-by-step Setting Spawning Listening Data Types of sensors Cameras Detectors Other","title":"4th. Sensors and data"},{"location":"core_sensors/#sensors-step-by-step","text":"The class carla.Sensor defines a special type of actor able to measure and stream data. What is this data? It varies a lot depending on the type of sensor. All the types of data are inherited from the general carla.SensorData . When do they retrieve the data? Either on every simulation step or when a certain event is registered. Depends on the type of sensor. How do they retrieve the data? Every sensor has a listen() method to receive and manage the data. Despite their differences, all the sensors are used in a similar way.","title":"Sensors step-by-step"},{"location":"core_sensors/#setting","text":"As with every other actor, find the blueprint and set specific attributes. This is essential when handling sensors. Their attributes will determine the results obtained. These are detailed in the sensors reference . The following example sets a dashboard HD camera. # Find the blueprint of the sensor. blueprint = world.get_blueprint_library().find('sensor.camera.rgb') # Modify the attributes of the blueprint to set image resolution and field of view. blueprint.set_attribute('image_size_x', '1920') blueprint.set_attribute('image_size_y', '1080') blueprint.set_attribute('fov', '110') # Set the time in seconds between sensor captures blueprint.set_attribute('sensor_tick', '1.0')","title":"Setting"},{"location":"core_sensors/#spawning","text":"attachment_to and attachment_type , are crucial. Sensors should be attached to a parent actor, usually a vehicle, to follow it around and gather the information. The attachment type will determine how its position is updated regarding said vehicle. Rigid attachment. Movement is strict regarding its parent location. This is the proper attachment to retrieve data from the simulation. SpringArm attachment. Movement is eased with little accelerations and decelerations. This attachment is only recommended to record videos from the simulation. The movement is smooth and \"hops\" are avoided when updating the cameras' positions. transform = carla.Transform(carla.Location(x=0.8, z=1.7)) sensor = world.spawn_actor(blueprint, transform, attach_to=my_vehicle) Important When spawning with attachment, location must be relative to the parent actor.","title":"Spawning"},{"location":"core_sensors/#listening","text":"Every sensor has a listen() method. This is called every time the sensor retrieves data. The argument callback is a lambda function . It describes what should the sensor do when data is retrieved. This must have the data retrieved as an argument. # do_something() will be called each time a new image is generated by the camera. sensor.listen(lambda data: do_something(data)) ... # This collision sensor would print everytime a collision is detected. def callback(event): for actor_id in event: vehicle = world_ref().get_actor(actor_id) print('Vehicle too close: %s' % vehicle.type_id) sensor02.listen(callback)","title":"Listening"},{"location":"core_sensors/#data","text":"Most sensor data objects have a function to save the information to disk. This will allow it to be used in other environments. Sensor data differs a lot between sensor types. Take a look at the sensors reference to get a detailed explanation. However, all of them are always tagged with some basic information. Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Timestamp of the measurement in simulation seconds since the beginning of the episode. transform carla.Transform World reference of the sensor at the time of the measurement. Important is_listening is a sensor attribute that enables/disables data listening at will. sensor_tick is a blueprint attribute that sets the simulation time between data received.","title":"Data"},{"location":"core_sensors/#types-of-sensors","text":"","title":"Types of sensors"},{"location":"core_sensors/#cameras","text":"Take a shot of the world from their point of view. For cameras that return carla.Image , you can use the helper class carla.ColorConverter to modify the image to represent different information. Retrieve data every simulation step. Sensor Output Overview Depth carla.Image Renders the depth of the elements in the field of view in a gray-scale map. RGB carla.Image Provides clear vision of the surroundings. Looks like a normal photo of the scene. Optical Flow carla.Image Renders the motion of every pixel from the camera. Semantic segmentation carla.Image Renders elements in the field of view with a specific color according to their tags. DVS carla.DVSEventArray Measures changes of brightness intensity asynchronously as an event stream.","title":"Cameras"},{"location":"core_sensors/#detectors","text":"Retrieve data when the object they are attached to registers a specific event. Retrieve data when triggered. Sensor Output Overview Collision carla.CollisionEvent Retrieves collisions between its parent and other actors. Lane invasion carla.LaneInvasionEvent Registers when its parent crosses a lane marking. Obstacle carla.ObstacleDetectionEvent Detects possible obstacles ahead of its parent.","title":"Detectors"},{"location":"core_sensors/#other","text":"Different functionalities such as navigation, measurement of physical properties and 2D/3D point maps of the scene. Retrieve data every simulation step. Sensor Output Overview GNSS carla.GNSSMeasurement Retrieves the geolocation of the sensor. IMU carla.IMUMeasurement Comprises an accelerometer, a gyroscope, and a compass. LIDAR carla.LidarMeasurement A rotating LIDAR. Generates a 4D point cloud with coordinates and intensity per point to model the surroundings. Radar carla.RadarMeasurement 2D point map modelling elements in sight and their movement regarding the sensor. RSS carla.RssResponse Modifies the controller applied to a vehicle according to safety checks. This sensor works in a different manner than the rest, and there is specific RSS documentation for it. Semantic LIDAR carla.SemanticLidarMeasurement A rotating LIDAR. Generates a 3D point cloud with extra information regarding instance and semantic segmentation. That is a wrap on sensors and how do these retrieve simulation data. Thus concludes the introduction to CARLA. However there is yet a lot to learn. Continue learning. There are some advanced features in CARLA: rendering options, traffic manager, the recorder, and some more. This is a great moment to learn more about them. Synchrony and time-step Experiment freely. Take a look at the References section of this documentation. It contains detailed information on the classes in the Python API, sensors, code snippets and much more. Python API reference Give your two cents. Any doubts, suggestions and ideas are welcome in the forum. CARLA forum","title":"Other"},{"location":"core_world/","text":"1st. World and client The client and the world are two of the fundamentals of CARLA, a necessary abstraction to operate the simulation and its actors. This tutorial goes from defining the basics and creation of these elements, to describing their possibilities. If any doubt or issue arises during the reading, the CARLA forum is there to solve them. The client Client creation World connection Other client utilities The world Actors Weather Lights Debugging World snapshots World settings The client Clients are one of the main elements in the CARLA architecture. They connect to the server, retrieve information, and command changes. That is done via scripts. The client identifies itself, and connects to the world to then operate with the simulation. Besides that, clients are able to access advanced CARLA modules, features, and apply command batches. Only command batches will be covered in this section. These are useful for basic things such as spawning lots of actors. The rest of features are more complex, and they will be addressed in their respective pages in Advanced steps . Take a look at carla.Client in the Python API reference to learn on specific methods and variables of the class. Client creation Two things are needed. The IP address identifying it, and two TCP ports to communicate with the server. An optional third parameter sets the amount of working threads. By default this is set to all ( 0 ). The carla.Client in the Python API reference contains a snipet that shows how to parse these as arguments when running the script. client = carla.Client('localhost', 2000) By default, CARLA uses local host IP, and port 2000 to connect but these can be changed at will. The second port will always be n+1 , 2001 in this case. Once the client is created, set its time-out . This limits all networking operations so that these don't block the client forever. An error will be returned if connection fails. client.set_timeout(10.0) # seconds It is possible to have many clients connected, as it is common to have more than one script running at a time. Working in a multiclient scheme with advanced CARLA features, such as the traffic manager, is bound to make communication more complex. Note Client and server have different libcarla modules. If the versions differ, issues may arise. This can be checked using the get_client_version() and get_server_version() methods. World connection A client can connect and retrieve the current world fairly easily. world = client.get_world() The client can also get a list of available maps to change the current one. This will destroy the current world and create a new one. print(client.get_available_maps()) ... world = client.load_world('Town01') # client.reload_world() creates a new instance of the world with the same map. Every world object has an id or episode. Everytime the client calls for load_world() or reload_world() the previous one is destroyed. A new one is created from scratch with a new episode. Unreal Engine is not rebooted in the process. Using commands Commands are adaptations of some of the most-common CARLA methods, that can be applied in batches. For instance, the command.SetAutopilot is equivalent to Vehicle.set_autopilot() , enables the autopilot for a vehicle. However, using the methods Client.apply_batch or Client.apply_batch_sync() , a list of commands can be applied in one single simulation step. This becomes extremely useful for methods that are usually applied to even hundreds of elements. The following example uses a batch to destroy a list of vehicles all at once. client.apply_batch([carla.command.DestroyActor(x) for x in vehicles_list]) All the commands available are listed in the latest section of the Python API reference. Other client utilities The main purpose of the client object is to get or change the world, and apply commands. However, it also provides access to some additional features. Traffic manager. This module is in charge of every vehicle set to autopilot to recreate urban traffic. Recorder . Allows to reenact a previous simulation. Uses snapshots summarizing the simulation state per frame. The world The major ruler of the simulation. Its instance should be retrieved by the client. It does not contain the model of the world itself, that is part of the Map class. Instead, most of the information, and general settings can be accessed from this class. Actors in the simulation and the spectator. Blueprint library. Map. Simulation settings. Snapshots. Weather and light manager. Some of its most important methods are getters , precisely to retrieve information or instances of these elements. Take a look at carla.World to learn more about it. Actors The world has different methods related with actors that allow for different functionalities. Spawn actors (but not destroy them). Get every actor on scene, or find one in particular. Access the blueprint library. Access the spectator actor, the simulation's point of view. Retrieve a random location that is fitting to spawn an actor. Spawning will be explained in 2nd. Actors and blueprints . It requires some understanding on the blueprint library, attributes, etc. Weather The weather is not a class on its own, but a set of parameters accessible from the world. The parametrization includes sun orientation, cloudiness, wind, fog, and much more. The helper class carla.WeatherParameters is used to define a custom weather. weather = carla.WeatherParameters( cloudiness=80.0, precipitation=30.0, sun_altitude_angle=70.0) world.set_weather(weather) print(world.get_weather()) There are some weather presets that can be directly applied to the world. These are listed in carla.WeatherParameters and accessible as an enum. world.set_weather(carla.WeatherParameters.WetCloudySunset) The weather can also be customized using two scripts provided by CARLA. environment.py (in PythonAPI/util ) \u2014 Provides access to weather and light parameters so that these can be changed in real time. Optional arguments in environment.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) --sun SUN Sun position presets [sunset | day | night] --weather WEATHER Weather condition presets [clear | overcast | rain] --altitude A, -alt A Sun altitude [-90.0, 90.0] --azimuth A, -azm A Sun azimuth [0.0, 360.0] --clouds C, -c C Clouds amount [0.0, 100.0] --rain R, -r R Rain amount [0.0, 100.0] --puddles Pd, -pd Pd Puddles amount [0.0, 100.0] --wind W, -w W Wind intensity [0.0, 100.0] --fog F, -f F Fog intensity [0.0, 100.0] --fogdist Fd, -fd Fd Fog Distance [0.0, inf) --wetness Wet, -wet Wet Wetness intensity [0.0, 100.0] dynamic_weather.py (in PythonAPI/examples ) \u2014 Enables a particular weather cycle prepared by developers for each CARLA map. Optional arguments in dynamic_weather.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) -s FACTOR, --speed FACTOR rate at which the weather changes (default: 1.0) Note Changes in the weather do not affect physics. They are only visuals that can be captured by the camera sensors. Night mode starts when sun_altitude_angle < 0 , which is considered sunset. This is when lights become especially relevant. Lights Street lights automatically turn on when the simulation enters night mode. The lights are placed by the developers of the map, and accessible as carla.Light objects. Properties such as color and intensity can be changed at will. The variable light_state of type carla.LightState allows setting all of these in one call. Street lights are categorized using their attribute light_group , of type carla.LightGroup . This allows to classify lights as street lights, building lights... An instance of carla.LightManager can be retrieved to handle groups of lights in one call. # Get the light manager and lights lmanager = world.get_lightmanager() mylights = lmanager.get_all_lights() # Custom a specific light light01 = mylights[0] light01.turn_on() light01.set_intensity(100.0) state01 = carla.LightState(200.0,red,carla.LightGroup.Building,True) light01.set_light_state(state01) # Custom a group of lights my_lights = lmanager.get_light_group(carla.LightGroup.Building) lmanager.turn_on(my_lights) lmanager.set_color(my_lights,carla.Color(255,0,0)) lmanager.set_intensities(my_lights,list_of_intensities) Vehicle lights have to be turned on/off by the user. Each vehicle has a set of lights listed in carla.VehicleLightState . So far, not all vehicles have lights integrated. Here is a list of those that are available by the time of writing. Bikes. All of them have a front and back position light. Motorcycles. Yamaha and Harley Davidson models. Cars. Audi TT, Chevrolet, Dodge (the police car), Etron, Lincoln, Mustang, Tesla 3S, Wolkswagen T2 and the new guests coming to CARLA. The lights of a vehicle can be retrieved and updated anytime using the methods carla.Vehicle.get_light_state and carla.Vehicle.set_light_state . These use binary operations to customize the light setting. # Turn on position lights current_lights = carla.VehicleLightState.NONE current_lights |= carla.VehicleLightState.Position vehicle.set_light_state(current_lights) Note Lights can also be set in real time using the environment.py described in the weather section. Debugging World objects have a carla.DebugHelper object as a public attribute. It allows for different shapes to be drawn during the simulation. These are used to trace the events happening. The following example would draw a red box at an actor's location and rotation. debug = world.debug debug.draw_box(carla.BoundingBox(actor_snapshot.get_transform().location,carla.Vector3D(0.5,0.5,2)),actor_snapshot.get_transform().rotation, 0.05, carla.Color(255,0,0,0),0) This example is extended in a snipet in carla.DebugHelper that shows how to draw boxes for every actor in a world snapshot. World snapshots Contains the state of every actor in the simulation at a single frame. A sort of still image of the world with a time reference. The information comes from the same simulation step, even in asynchronous mode. # Retrieve a snapshot of the world at current frame. world_snapshot = world.get_snapshot() A carla.WorldSnapshot contains a carla.Timestamp and a list of carla.ActorSnapshot . Actor snapshots can be searched using the id of an actor. A snapshot lists the id of the actors appearing in it. timestamp = world_snapshot.timestamp # Get the time reference for actor_snapshot in world_snapshot: # Get the actor and the snapshot information actual_actor = world.get_actor(actor_snapshot.id) actor_snapshot.get_transform() actor_snapshot.get_velocity() actor_snapshot.get_angular_velocity() actor_snapshot.get_acceleration() actor_snapshot = world_snapshot.find(actual_actor.id) # Get an actor's snapshot World settings The world has access to some advanced configurations for the simulation. These determine rendering conditions, simulation time-steps, and synchrony between clients and server. They are accessible from the helper class carla.WorldSettings . For the time being, default CARLA runs with the best graphics quality, a variable time-step, and asynchronously. To dive further in this matters take a look at the Advanced steps section. The pages on synchrony and time-step , and rendering options could be a great starting point. That is a wrap on the world and client objects. The next step takes a closer look into actors and blueprints to give life to the simulation. Keep reading to learn more. Visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 2nd. Actors and blueprints","title":"\u7b2c\u4e00\u3001 \u4e16\u754c\u548c\u5ba2\u6237\u7aef"},{"location":"core_world/#1st-world-and-client","text":"The client and the world are two of the fundamentals of CARLA, a necessary abstraction to operate the simulation and its actors. This tutorial goes from defining the basics and creation of these elements, to describing their possibilities. If any doubt or issue arises during the reading, the CARLA forum is there to solve them. The client Client creation World connection Other client utilities The world Actors Weather Lights Debugging World snapshots World settings","title":"1st. World and client"},{"location":"core_world/#the-client","text":"Clients are one of the main elements in the CARLA architecture. They connect to the server, retrieve information, and command changes. That is done via scripts. The client identifies itself, and connects to the world to then operate with the simulation. Besides that, clients are able to access advanced CARLA modules, features, and apply command batches. Only command batches will be covered in this section. These are useful for basic things such as spawning lots of actors. The rest of features are more complex, and they will be addressed in their respective pages in Advanced steps . Take a look at carla.Client in the Python API reference to learn on specific methods and variables of the class.","title":"The client"},{"location":"core_world/#client-creation","text":"Two things are needed. The IP address identifying it, and two TCP ports to communicate with the server. An optional third parameter sets the amount of working threads. By default this is set to all ( 0 ). The carla.Client in the Python API reference contains a snipet that shows how to parse these as arguments when running the script. client = carla.Client('localhost', 2000) By default, CARLA uses local host IP, and port 2000 to connect but these can be changed at will. The second port will always be n+1 , 2001 in this case. Once the client is created, set its time-out . This limits all networking operations so that these don't block the client forever. An error will be returned if connection fails. client.set_timeout(10.0) # seconds It is possible to have many clients connected, as it is common to have more than one script running at a time. Working in a multiclient scheme with advanced CARLA features, such as the traffic manager, is bound to make communication more complex. Note Client and server have different libcarla modules. If the versions differ, issues may arise. This can be checked using the get_client_version() and get_server_version() methods.","title":"Client creation"},{"location":"core_world/#world-connection","text":"A client can connect and retrieve the current world fairly easily. world = client.get_world() The client can also get a list of available maps to change the current one. This will destroy the current world and create a new one. print(client.get_available_maps()) ... world = client.load_world('Town01') # client.reload_world() creates a new instance of the world with the same map. Every world object has an id or episode. Everytime the client calls for load_world() or reload_world() the previous one is destroyed. A new one is created from scratch with a new episode. Unreal Engine is not rebooted in the process.","title":"World connection"},{"location":"core_world/#using-commands","text":"Commands are adaptations of some of the most-common CARLA methods, that can be applied in batches. For instance, the command.SetAutopilot is equivalent to Vehicle.set_autopilot() , enables the autopilot for a vehicle. However, using the methods Client.apply_batch or Client.apply_batch_sync() , a list of commands can be applied in one single simulation step. This becomes extremely useful for methods that are usually applied to even hundreds of elements. The following example uses a batch to destroy a list of vehicles all at once. client.apply_batch([carla.command.DestroyActor(x) for x in vehicles_list]) All the commands available are listed in the latest section of the Python API reference.","title":"Using commands"},{"location":"core_world/#other-client-utilities","text":"The main purpose of the client object is to get or change the world, and apply commands. However, it also provides access to some additional features. Traffic manager. This module is in charge of every vehicle set to autopilot to recreate urban traffic. Recorder . Allows to reenact a previous simulation. Uses snapshots summarizing the simulation state per frame.","title":"Other client utilities"},{"location":"core_world/#the-world","text":"The major ruler of the simulation. Its instance should be retrieved by the client. It does not contain the model of the world itself, that is part of the Map class. Instead, most of the information, and general settings can be accessed from this class. Actors in the simulation and the spectator. Blueprint library. Map. Simulation settings. Snapshots. Weather and light manager. Some of its most important methods are getters , precisely to retrieve information or instances of these elements. Take a look at carla.World to learn more about it.","title":"The world"},{"location":"core_world/#actors","text":"The world has different methods related with actors that allow for different functionalities. Spawn actors (but not destroy them). Get every actor on scene, or find one in particular. Access the blueprint library. Access the spectator actor, the simulation's point of view. Retrieve a random location that is fitting to spawn an actor. Spawning will be explained in 2nd. Actors and blueprints . It requires some understanding on the blueprint library, attributes, etc.","title":"Actors"},{"location":"core_world/#weather","text":"The weather is not a class on its own, but a set of parameters accessible from the world. The parametrization includes sun orientation, cloudiness, wind, fog, and much more. The helper class carla.WeatherParameters is used to define a custom weather. weather = carla.WeatherParameters( cloudiness=80.0, precipitation=30.0, sun_altitude_angle=70.0) world.set_weather(weather) print(world.get_weather()) There are some weather presets that can be directly applied to the world. These are listed in carla.WeatherParameters and accessible as an enum. world.set_weather(carla.WeatherParameters.WetCloudySunset) The weather can also be customized using two scripts provided by CARLA. environment.py (in PythonAPI/util ) \u2014 Provides access to weather and light parameters so that these can be changed in real time. Optional arguments in environment.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) --sun SUN Sun position presets [sunset | day | night] --weather WEATHER Weather condition presets [clear | overcast | rain] --altitude A, -alt A Sun altitude [-90.0, 90.0] --azimuth A, -azm A Sun azimuth [0.0, 360.0] --clouds C, -c C Clouds amount [0.0, 100.0] --rain R, -r R Rain amount [0.0, 100.0] --puddles Pd, -pd Pd Puddles amount [0.0, 100.0] --wind W, -w W Wind intensity [0.0, 100.0] --fog F, -f F Fog intensity [0.0, 100.0] --fogdist Fd, -fd Fd Fog Distance [0.0, inf) --wetness Wet, -wet Wet Wetness intensity [0.0, 100.0] dynamic_weather.py (in PythonAPI/examples ) \u2014 Enables a particular weather cycle prepared by developers for each CARLA map. Optional arguments in dynamic_weather.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) -s FACTOR, --speed FACTOR rate at which the weather changes (default: 1.0) Note Changes in the weather do not affect physics. They are only visuals that can be captured by the camera sensors. Night mode starts when sun_altitude_angle < 0 , which is considered sunset. This is when lights become especially relevant.","title":"Weather"},{"location":"core_world/#lights","text":"Street lights automatically turn on when the simulation enters night mode. The lights are placed by the developers of the map, and accessible as carla.Light objects. Properties such as color and intensity can be changed at will. The variable light_state of type carla.LightState allows setting all of these in one call. Street lights are categorized using their attribute light_group , of type carla.LightGroup . This allows to classify lights as street lights, building lights... An instance of carla.LightManager can be retrieved to handle groups of lights in one call. # Get the light manager and lights lmanager = world.get_lightmanager() mylights = lmanager.get_all_lights() # Custom a specific light light01 = mylights[0] light01.turn_on() light01.set_intensity(100.0) state01 = carla.LightState(200.0,red,carla.LightGroup.Building,True) light01.set_light_state(state01) # Custom a group of lights my_lights = lmanager.get_light_group(carla.LightGroup.Building) lmanager.turn_on(my_lights) lmanager.set_color(my_lights,carla.Color(255,0,0)) lmanager.set_intensities(my_lights,list_of_intensities) Vehicle lights have to be turned on/off by the user. Each vehicle has a set of lights listed in carla.VehicleLightState . So far, not all vehicles have lights integrated. Here is a list of those that are available by the time of writing. Bikes. All of them have a front and back position light. Motorcycles. Yamaha and Harley Davidson models. Cars. Audi TT, Chevrolet, Dodge (the police car), Etron, Lincoln, Mustang, Tesla 3S, Wolkswagen T2 and the new guests coming to CARLA. The lights of a vehicle can be retrieved and updated anytime using the methods carla.Vehicle.get_light_state and carla.Vehicle.set_light_state . These use binary operations to customize the light setting. # Turn on position lights current_lights = carla.VehicleLightState.NONE current_lights |= carla.VehicleLightState.Position vehicle.set_light_state(current_lights) Note Lights can also be set in real time using the environment.py described in the weather section.","title":"Lights"},{"location":"core_world/#debugging","text":"World objects have a carla.DebugHelper object as a public attribute. It allows for different shapes to be drawn during the simulation. These are used to trace the events happening. The following example would draw a red box at an actor's location and rotation. debug = world.debug debug.draw_box(carla.BoundingBox(actor_snapshot.get_transform().location,carla.Vector3D(0.5,0.5,2)),actor_snapshot.get_transform().rotation, 0.05, carla.Color(255,0,0,0),0) This example is extended in a snipet in carla.DebugHelper that shows how to draw boxes for every actor in a world snapshot.","title":"Debugging"},{"location":"core_world/#world-snapshots","text":"Contains the state of every actor in the simulation at a single frame. A sort of still image of the world with a time reference. The information comes from the same simulation step, even in asynchronous mode. # Retrieve a snapshot of the world at current frame. world_snapshot = world.get_snapshot() A carla.WorldSnapshot contains a carla.Timestamp and a list of carla.ActorSnapshot . Actor snapshots can be searched using the id of an actor. A snapshot lists the id of the actors appearing in it. timestamp = world_snapshot.timestamp # Get the time reference for actor_snapshot in world_snapshot: # Get the actor and the snapshot information actual_actor = world.get_actor(actor_snapshot.id) actor_snapshot.get_transform() actor_snapshot.get_velocity() actor_snapshot.get_angular_velocity() actor_snapshot.get_acceleration() actor_snapshot = world_snapshot.find(actual_actor.id) # Get an actor's snapshot","title":"World snapshots"},{"location":"core_world/#world-settings","text":"The world has access to some advanced configurations for the simulation. These determine rendering conditions, simulation time-steps, and synchrony between clients and server. They are accessible from the helper class carla.WorldSettings . For the time being, default CARLA runs with the best graphics quality, a variable time-step, and asynchronously. To dive further in this matters take a look at the Advanced steps section. The pages on synchrony and time-step , and rendering options could be a great starting point. That is a wrap on the world and client objects. The next step takes a closer look into actors and blueprints to give life to the simulation. Keep reading to learn more. Visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum 2nd. Actors and blueprints","title":"World settings"},{"location":"download/","text":"Download Latest Release CARLA 0.9.13 - Documentation Nightly build This is an automated build with the latest changes pushed to our dev branch. It contains the very latest fixes and features that will be part of the next release, but also some experimental changes. Use at your own risk! CARLA Nightly Build (Linux) CARLA Nightly Build (Windows) Versions 0.9.x Here are the previous versions of CARLA with links to the specific documentation for each version: CARLA 0.9.12 - Documentation CARLA 0.9.11 - Documentation CARLA 0.9.10 - Documentation CARLA 0.9.9 - Documentation CARLA 0.9.8 - Documentation CARLA 0.9.7 - Documentation CARLA 0.9.6 - Documentation CARLA 0.9.5 - Documentation CARLA 0.9.4 - Documentation CARLA 0.9.3 - Documentation CARLA 0.9.2 - Documentation CARLA 0.9.1 - Documentation CARLA 0.9.0 - Documentation Versions 0.8.x CARLA 0.8.4 - Documentation CARLA 0.8.3 CARLA 0.8.2 - Documentation Docker All versions are available to pull from DockerHub: docker pull carlasim/carla:X.X.X Use tag \"latest\" for the most recent release: docker pull carlasim/carla:latest","title":"Download"},{"location":"download/#download","text":"","title":"Download"},{"location":"download/#latest-release","text":"CARLA 0.9.13 - Documentation","title":"Latest Release"},{"location":"download/#nightly-build","text":"This is an automated build with the latest changes pushed to our dev branch. It contains the very latest fixes and features that will be part of the next release, but also some experimental changes. Use at your own risk! CARLA Nightly Build (Linux) CARLA Nightly Build (Windows)","title":"Nightly build"},{"location":"download/#versions-09x","text":"Here are the previous versions of CARLA with links to the specific documentation for each version: CARLA 0.9.12 - Documentation CARLA 0.9.11 - Documentation CARLA 0.9.10 - Documentation CARLA 0.9.9 - Documentation CARLA 0.9.8 - Documentation CARLA 0.9.7 - Documentation CARLA 0.9.6 - Documentation CARLA 0.9.5 - Documentation CARLA 0.9.4 - Documentation CARLA 0.9.3 - Documentation CARLA 0.9.2 - Documentation CARLA 0.9.1 - Documentation CARLA 0.9.0 - Documentation","title":"Versions 0.9.x"},{"location":"download/#versions-08x","text":"CARLA 0.8.4 - Documentation CARLA 0.8.3 CARLA 0.8.2 - Documentation","title":"Versions 0.8.x"},{"location":"download/#docker","text":"All versions are available to pull from DockerHub: docker pull carlasim/carla:X.X.X Use tag \"latest\" for the most recent release: docker pull carlasim/carla:latest","title":"Docker"},{"location":"ecosys_ansys/","text":"Ansys Real Time Radar Model: Training a Vehicle Longitudinal Controller Using Reinforcement Learning In a webinair series in April 2021, Ansys presented the details of their integration of the Ansys Real Time Radar (RTR) with the CARLA simulator. Here you can download and view the presentation slides and videos that accompanied the webinair. The presentation details how the RTR was integrated with CARLA to train a vehicle longitudinal controller using reinforcement learning and includes the model, action space and reward policy used. The videos show the results of the training in the CARLA simulator. View the presentation here and the videos here .","title":"Ansys \u5b9e\u65f6\u96f7\u8fbe\u6a21\u578b"},{"location":"ecosys_ansys/#ansys-real-time-radar-model-training-a-vehicle-longitudinal-controller-using-reinforcement-learning","text":"In a webinair series in April 2021, Ansys presented the details of their integration of the Ansys Real Time Radar (RTR) with the CARLA simulator. Here you can download and view the presentation slides and videos that accompanied the webinair. The presentation details how the RTR was integrated with CARLA to train a vehicle longitudinal controller using reinforcement learning and includes the model, action space and reward policy used. The videos show the results of the training in the CARLA simulator. View the presentation here and the videos here .","title":"Ansys Real Time Radar Model: Training a Vehicle Longitudinal Controller Using Reinforcement Learning"},{"location":"large_map_import/","text":"Import/Package a Large Map Large maps generated in RoadRunner can be imported into the source build of CARLA and packaged for distribution and usage in a CARLA standalone package. The process is very simlar to that of standard maps with the addition of specific nomenclature for tiles and batch importing. Files and folders Create the JSON description (Optional) Making the import Package a large map Files and folders All files to be imported should be placed in the Import folder of the root CARLA directory. These files should include: The mesh of the map in multiple .fbx files representing different tiles of the map. The OpenDRIVE definition in a single .xodr file. Warning You cannot import large maps and standard maps at the same time. The naming convention of map tiles is very important. Each map tile should be named according to the following convention: <mapName>_Tile_<x-coordinate>_<y-coordinate>.fbx Be aware that a more positive y coordinate refers to a tile lower on the y-axis. For example, Map01_Tile_0_1 would sit just below Map01_Tile_0_0 . A resulting Import folder with a package containing a large map made of four tiles should have a structure similar to the one below: Import \u2502 \u2514\u2500\u2500 Package01 \u251c\u2500\u2500 Package01.json \u251c\u2500\u2500 Map01_Tile_0_0.fbx \u251c\u2500\u2500 Map01_Tile_0_1.fbx \u251c\u2500\u2500 Map01_Tile_1_0.fbx \u251c\u2500\u2500 Map01_Tile_1_1.fbx \u2514\u2500\u2500 Map01.xodr Note The package.json file is not strictly necessary. If there is no package.json file created, the automated import process will create one. Find out more about to structure your own package.json in the next section. Create the JSON description (Optional) The .json description is created automatically during the import process, but there is also the option to create one manually. An existing .json description will override any values passed as arguments in the import process. The .json file should be created in the root folder of the package. The file name will be the package distribution name. The content of the file describes a JSON array of maps and props with basic information for each one. Maps need the following parameters: name: Name of the map. This must be the same as the .fbx and .xodr files. xodr: Path to the .xodr file. use_carla_materials: If True , the map will use CARLA materials. Otherwise, it will use RoadRunner materials. tile_size: The size of the tiles. Default value is 2000 (2kmx2km). tiles: A list of the .fbx tile files that make up the entire map. Props are not part of this tutorial. Please see this tutorial for how to add new props. The resulting .json file should resemble the following: { \"maps\": [ { \"name\": \"Map01\", \"xodr\": \"./Map01.xodr\", \"use_carla_materials\": true, \"tile_size\": 2000, \"tiles\": [ \"./Map01_Tile_0_0.fbx\", \"./Map01_Tile_0_1.fbx\", \"./Map01_Tile_1_0.fbx\", \"./Map01_Tile_1_1.fbx\" ] } ], \"props\": [] } Making the import When all files have been placed in the Import folder, run the following command in the root CARLA folder: make import Depending on your system, Unreal Engine may consume too much memory to be able to import all files at once. You can choose to import the files in batches of MB by running the command: make import ARGS=\"--batch-size=200\" Two more flags exist for the make import command: --package=<package_name> specifies the name of the package. By default, this is set to map_package . Two packages cannot have the same name, so using the default value will lead to errors on a subsequent ingestion. It is highly recommended to change the name of the package . Use this flag by running the command: make import ARGS=\"--package=<package_name>\" --no-carla-materials specifies that you do not want to use the default CARLA materials (road textures etc). You will use the RoadRunner materials instead. This flag is only required if you are not providing your own .json file . Any value in the .json file will override this flag. Use this flag by running the command: make import ARGS=\"--no-carla-materials\" All files will be imported and prepared to be used in the Unreal Editor. The map package will be created in Unreal/CarlaUE4/Content . A base map tile, <mapName> , will be created as a streaming level for all the tiles. The base tile will contain the sky, weather, and large map actors and will be ready for use in a simulation. Note It is currently not recommended to use the customization tools provided for standard maps in the Unreal Editor, e.g., road painter, procedural buildings, etc. Package a large map To package your large map so it can be used in the CARLA standalone package, run the following command: make package ARGS=\"--packages=<mapPackage>\" This will create a standalone package compressed in a .tar.gz file. The files will be saved in the Dist folder on Linux, and /Build/UE4Carla/ on Windows. They can then be distributed and packaged to use in standalone CARLA packages. If you have any questions about the large map import and packaging process, then you can ask in the forum . CARLA forum","title":"\u5bfc\u5165/\u6253\u5305\u5927\u5730\u56fe"},{"location":"large_map_import/#importpackage-a-large-map","text":"Large maps generated in RoadRunner can be imported into the source build of CARLA and packaged for distribution and usage in a CARLA standalone package. The process is very simlar to that of standard maps with the addition of specific nomenclature for tiles and batch importing. Files and folders Create the JSON description (Optional) Making the import Package a large map","title":"Import/Package a Large Map"},{"location":"large_map_import/#files-and-folders","text":"All files to be imported should be placed in the Import folder of the root CARLA directory. These files should include: The mesh of the map in multiple .fbx files representing different tiles of the map. The OpenDRIVE definition in a single .xodr file. Warning You cannot import large maps and standard maps at the same time. The naming convention of map tiles is very important. Each map tile should be named according to the following convention: <mapName>_Tile_<x-coordinate>_<y-coordinate>.fbx Be aware that a more positive y coordinate refers to a tile lower on the y-axis. For example, Map01_Tile_0_1 would sit just below Map01_Tile_0_0 . A resulting Import folder with a package containing a large map made of four tiles should have a structure similar to the one below: Import \u2502 \u2514\u2500\u2500 Package01 \u251c\u2500\u2500 Package01.json \u251c\u2500\u2500 Map01_Tile_0_0.fbx \u251c\u2500\u2500 Map01_Tile_0_1.fbx \u251c\u2500\u2500 Map01_Tile_1_0.fbx \u251c\u2500\u2500 Map01_Tile_1_1.fbx \u2514\u2500\u2500 Map01.xodr Note The package.json file is not strictly necessary. If there is no package.json file created, the automated import process will create one. Find out more about to structure your own package.json in the next section.","title":"Files and folders"},{"location":"large_map_import/#create-the-json-description-optional","text":"The .json description is created automatically during the import process, but there is also the option to create one manually. An existing .json description will override any values passed as arguments in the import process. The .json file should be created in the root folder of the package. The file name will be the package distribution name. The content of the file describes a JSON array of maps and props with basic information for each one. Maps need the following parameters: name: Name of the map. This must be the same as the .fbx and .xodr files. xodr: Path to the .xodr file. use_carla_materials: If True , the map will use CARLA materials. Otherwise, it will use RoadRunner materials. tile_size: The size of the tiles. Default value is 2000 (2kmx2km). tiles: A list of the .fbx tile files that make up the entire map. Props are not part of this tutorial. Please see this tutorial for how to add new props. The resulting .json file should resemble the following: { \"maps\": [ { \"name\": \"Map01\", \"xodr\": \"./Map01.xodr\", \"use_carla_materials\": true, \"tile_size\": 2000, \"tiles\": [ \"./Map01_Tile_0_0.fbx\", \"./Map01_Tile_0_1.fbx\", \"./Map01_Tile_1_0.fbx\", \"./Map01_Tile_1_1.fbx\" ] } ], \"props\": [] }","title":"Create the JSON description (Optional)"},{"location":"large_map_import/#making-the-import","text":"When all files have been placed in the Import folder, run the following command in the root CARLA folder: make import Depending on your system, Unreal Engine may consume too much memory to be able to import all files at once. You can choose to import the files in batches of MB by running the command: make import ARGS=\"--batch-size=200\" Two more flags exist for the make import command: --package=<package_name> specifies the name of the package. By default, this is set to map_package . Two packages cannot have the same name, so using the default value will lead to errors on a subsequent ingestion. It is highly recommended to change the name of the package . Use this flag by running the command: make import ARGS=\"--package=<package_name>\" --no-carla-materials specifies that you do not want to use the default CARLA materials (road textures etc). You will use the RoadRunner materials instead. This flag is only required if you are not providing your own .json file . Any value in the .json file will override this flag. Use this flag by running the command: make import ARGS=\"--no-carla-materials\" All files will be imported and prepared to be used in the Unreal Editor. The map package will be created in Unreal/CarlaUE4/Content . A base map tile, <mapName> , will be created as a streaming level for all the tiles. The base tile will contain the sky, weather, and large map actors and will be ready for use in a simulation. Note It is currently not recommended to use the customization tools provided for standard maps in the Unreal Editor, e.g., road painter, procedural buildings, etc.","title":"Making the import"},{"location":"large_map_import/#package-a-large-map","text":"To package your large map so it can be used in the CARLA standalone package, run the following command: make package ARGS=\"--packages=<mapPackage>\" This will create a standalone package compressed in a .tar.gz file. The files will be saved in the Dist folder on Linux, and /Build/UE4Carla/ on Windows. They can then be distributed and packaged to use in standalone CARLA packages. If you have any questions about the large map import and packaging process, then you can ask in the forum . CARLA forum","title":"Package a large map"},{"location":"large_map_overview/","text":"Large maps overview Large maps overview Tile streaming Dormant actors Large maps overview The large map feature in CARLA allows users to perform simulations at a vast scale. In CARLA, large maps are divided into square tiles no larger than 2kmx2km. Tiles are streamed in and out of the server based on their proximity (streaming distance) to the ego vehicle. Other actors on the map are also managed according to their streaming distance from the ego vehicle. Tile streaming The ego vehicle is integral to the loading and unloading of map tiles. Tiles are streamed in and out of the server based on the value of the streaming distance from the ego vehicle. For example, tiles located outside the streaming distance will not be rendered in the simulation, and tiles within the streaming distance will be rendered. The rendered tiles will change as the hero vehicle moves. To set a vehicle as ego, use the set_attribute method as shown below: blueprint.set_attribute('role_name', 'hero' ) world.spawn_actor(blueprint, spawn_point) Use the code snippet below to set the streaming distance so tiles will be loaded within a 2km radius of the ego vehicle: settings = world.get_settings() settings.tile_stream_distance = 2000 world.apply_settings(settings) You can also set the streaming distance using config.py : cd PythonAPI/util python3 config.py --tile-stream-distance 2000 Note Large maps currently supports only one ego vehicle at a time. Dormant actors The large map feature introduces the concept of dormant actors to CARLA. Dormant actors exist within the context of large maps only. Dormant actors are non-ego-vehicle actors in the simulation that are located outside of the actor active distance of the ego vehicle, e.g., vehicles far from the ego vehicle. The actor active distance can be equal to or less than the streaming distance. If an actor finds itself outside of the actor active distance of the ego vehicle, it will become dormant. The actor will still exist, but it will not be rendered. Physics will not be calculated (unless running in hybrid mode via the traffic manager), although location and transformation can still be set. Once the dormant actor comes within actor active distance of the ego vehicle again, it will wake up, and its rendering and physics will resume as normal. Actors controlled by the Traffic Manager have distinct behaviors that can be configured when operating within a large map. Read more in the Traffic Manager documentation to find out about how this works. An actor will become dormant or wake up on a world.tick() . To set the actor active distance to a 2 km radius around the ego vehicle: settings = world.get_settings() settings.actor_active_distance = 2000 world.apply_settings(settings) You can also set the actor active distance using config.py : cd PythonAPI/util python3 config.py --actor-active-distance 2000 To check if an actor is dormant, you can use the Python API: actor.is_dormant If you have any questions about large maps, then you can ask in the forum . CARLA forum","title":"\u5927\u578b\u5730\u56fe\u6982\u8ff0"},{"location":"large_map_overview/#large-maps-overview","text":"Large maps overview Tile streaming Dormant actors","title":"Large maps overview"},{"location":"large_map_overview/#large-maps-overview_1","text":"The large map feature in CARLA allows users to perform simulations at a vast scale. In CARLA, large maps are divided into square tiles no larger than 2kmx2km. Tiles are streamed in and out of the server based on their proximity (streaming distance) to the ego vehicle. Other actors on the map are also managed according to their streaming distance from the ego vehicle.","title":"Large maps overview"},{"location":"large_map_overview/#tile-streaming","text":"The ego vehicle is integral to the loading and unloading of map tiles. Tiles are streamed in and out of the server based on the value of the streaming distance from the ego vehicle. For example, tiles located outside the streaming distance will not be rendered in the simulation, and tiles within the streaming distance will be rendered. The rendered tiles will change as the hero vehicle moves. To set a vehicle as ego, use the set_attribute method as shown below: blueprint.set_attribute('role_name', 'hero' ) world.spawn_actor(blueprint, spawn_point) Use the code snippet below to set the streaming distance so tiles will be loaded within a 2km radius of the ego vehicle: settings = world.get_settings() settings.tile_stream_distance = 2000 world.apply_settings(settings) You can also set the streaming distance using config.py : cd PythonAPI/util python3 config.py --tile-stream-distance 2000 Note Large maps currently supports only one ego vehicle at a time.","title":"Tile streaming"},{"location":"large_map_overview/#dormant-actors","text":"The large map feature introduces the concept of dormant actors to CARLA. Dormant actors exist within the context of large maps only. Dormant actors are non-ego-vehicle actors in the simulation that are located outside of the actor active distance of the ego vehicle, e.g., vehicles far from the ego vehicle. The actor active distance can be equal to or less than the streaming distance. If an actor finds itself outside of the actor active distance of the ego vehicle, it will become dormant. The actor will still exist, but it will not be rendered. Physics will not be calculated (unless running in hybrid mode via the traffic manager), although location and transformation can still be set. Once the dormant actor comes within actor active distance of the ego vehicle again, it will wake up, and its rendering and physics will resume as normal. Actors controlled by the Traffic Manager have distinct behaviors that can be configured when operating within a large map. Read more in the Traffic Manager documentation to find out about how this works. An actor will become dormant or wake up on a world.tick() . To set the actor active distance to a 2 km radius around the ego vehicle: settings = world.get_settings() settings.actor_active_distance = 2000 world.apply_settings(settings) You can also set the actor active distance using config.py : cd PythonAPI/util python3 config.py --actor-active-distance 2000 To check if an actor is dormant, you can use the Python API: actor.is_dormant If you have any questions about large maps, then you can ask in the forum . CARLA forum","title":"Dormant actors"},{"location":"large_map_roadrunner/","text":"Create a Large Map in RoadRunner RoadRunner is the recommended software to create large maps to be imported into CARLA. This guide outlines what RoadRunner is, things to consider when building the large map and how to export custom large maps ready for importing into CARLA. Introduction to RoadRunner Before you start Build a large map in RoadRunner Export a large map in RoadRunner Next steps Introduction to RoadRunner RoadRunner is an interactive editor that lets you design 3D scenes for simulating and testing automated driving systems. It can be used to create road layouts and accompanying OpenDRIVE and geometry information. Find out more about RoadRunner here . RoadRunner is part of the MATLAB Campus-Wide Licenses, so many universities can provide unlimited academic access. Check if your university has access. Reach out to automated-driving@mathworks.com for any questions or troubles regarding accessibility. There is also a trial version available. A license for RoadRunner is also available to everyone participating in the CARLA Leaderboard. Click here for more information. Before you start You will need to install RoadRunner. You can follow the installation guide at the Mathworks website. Build a large map in RoadRunner The specifics of how to build a large map in RoadRunner go beyond the scope of this guide, however, there are video tutorials available in the RoadRunner documentation . If you are building a large map with elevation, the recommended largest size of the map is 20km by 20km. Maps larger than this may cause RoadRunner to crash on export. Export a large map in RoadRunner Below is a basic guideline to export your custom large map from RoadRunner. Once you have made your map in RoadRunner you will be able to export it. Be aware that the road layout cannot be modified after it has been exported. Before exporting, ensure that: The map is centered at (0,0) to ensure the map can be visualized correctly in Unreal Engine. The map definition is correct. The map validation is correct, paying close attention to connections and geometries. Once the map is ready, click on the OpenDRIVE Preview Tool button to visualize the OpenDRIVE road network and give everything one last check. Note OpenDrive Preview Tool makes it easier to test the integrity of the map. If there are any errors with junctions, click on Maneuver Tool , and Rebuild Maneuver Roads . Make sure the full map is selected for export by clicking on the World settings tool and dragging the edges of the blue boundary box to encompass the full area you would like to export. when it's ready, click on Apply World Changes . When you are ready to export: 1. Export the .fbx : In the main toolbar, select File -> Export -> Firebox (.fbx) 2. In the window that pops up: Check the following options: Split by Segmentation : Divides the mesh by semantic segmentation and imroves pedestrian navigation. Power of Two Texture Dimensions : Improves performance. Embed Textures : Ensures textures are embedded in the mesh. Export to Tiles : Choose the size of the tiles. The maximum size that can be used by CARLA is 2000 x 2000. Export Individual Tiles : Generates the individual tiles needed for streaming large maps in CARLA. 3. Export the .xodr : In the main toolbar, select File -> Export -> OpendDRIVE (.xodr) Warning Make sure that the .xodr and the .fbx files have the same name. Next steps You are now ready to import your map into CARLA. See the Import a Large Map guide for more details. If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u5728RoadRunner\u4e2d\u521b\u5efa\u5927\u5730\u56fe"},{"location":"large_map_roadrunner/#create-a-large-map-in-roadrunner","text":"RoadRunner is the recommended software to create large maps to be imported into CARLA. This guide outlines what RoadRunner is, things to consider when building the large map and how to export custom large maps ready for importing into CARLA. Introduction to RoadRunner Before you start Build a large map in RoadRunner Export a large map in RoadRunner Next steps","title":"Create a Large Map in RoadRunner"},{"location":"large_map_roadrunner/#introduction-to-roadrunner","text":"RoadRunner is an interactive editor that lets you design 3D scenes for simulating and testing automated driving systems. It can be used to create road layouts and accompanying OpenDRIVE and geometry information. Find out more about RoadRunner here . RoadRunner is part of the MATLAB Campus-Wide Licenses, so many universities can provide unlimited academic access. Check if your university has access. Reach out to automated-driving@mathworks.com for any questions or troubles regarding accessibility. There is also a trial version available. A license for RoadRunner is also available to everyone participating in the CARLA Leaderboard. Click here for more information.","title":"Introduction to RoadRunner"},{"location":"large_map_roadrunner/#before-you-start","text":"You will need to install RoadRunner. You can follow the installation guide at the Mathworks website.","title":"Before you start"},{"location":"large_map_roadrunner/#build-a-large-map-in-roadrunner","text":"The specifics of how to build a large map in RoadRunner go beyond the scope of this guide, however, there are video tutorials available in the RoadRunner documentation . If you are building a large map with elevation, the recommended largest size of the map is 20km by 20km. Maps larger than this may cause RoadRunner to crash on export.","title":"Build a large map in RoadRunner"},{"location":"large_map_roadrunner/#export-a-large-map-in-roadrunner","text":"Below is a basic guideline to export your custom large map from RoadRunner. Once you have made your map in RoadRunner you will be able to export it. Be aware that the road layout cannot be modified after it has been exported. Before exporting, ensure that: The map is centered at (0,0) to ensure the map can be visualized correctly in Unreal Engine. The map definition is correct. The map validation is correct, paying close attention to connections and geometries. Once the map is ready, click on the OpenDRIVE Preview Tool button to visualize the OpenDRIVE road network and give everything one last check. Note OpenDrive Preview Tool makes it easier to test the integrity of the map. If there are any errors with junctions, click on Maneuver Tool , and Rebuild Maneuver Roads . Make sure the full map is selected for export by clicking on the World settings tool and dragging the edges of the blue boundary box to encompass the full area you would like to export. when it's ready, click on Apply World Changes . When you are ready to export: 1. Export the .fbx : In the main toolbar, select File -> Export -> Firebox (.fbx) 2. In the window that pops up: Check the following options: Split by Segmentation : Divides the mesh by semantic segmentation and imroves pedestrian navigation. Power of Two Texture Dimensions : Improves performance. Embed Textures : Ensures textures are embedded in the mesh. Export to Tiles : Choose the size of the tiles. The maximum size that can be used by CARLA is 2000 x 2000. Export Individual Tiles : Generates the individual tiles needed for streaming large maps in CARLA. 3. Export the .xodr : In the main toolbar, select File -> Export -> OpendDRIVE (.xodr) Warning Make sure that the .xodr and the .fbx files have the same name.","title":"Export a large map in RoadRunner"},{"location":"large_map_roadrunner/#next-steps","text":"You are now ready to import your map into CARLA. See the Import a Large Map guide for more details. If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Next steps"},{"location":"plugins_carlaviz/","text":"carlaviz The carlaviz plugin is used to visualize the simulation in a web browser. A windows with some basic representation of the scene is created. Actors are updated on-the-fly, sensor data can be retrieved, and additional text, lines and polylines can be drawn in the scene. General information Support Get carlaviz Prerequisites Download the plugin Utilities General information Contributor \u2014 Minjun Xu, also known as wx9698 . License \u2014 MIT . Support Linux \u2014 CARLA 0.9.6, 0.9.7, 0.9.8, 0.9.9, 0.9.10. Windows \u2014 CARLA 0.9.9, 0.9.10. Build from source \u2014 Latest updates. Get carlaviz Prerequisites Docker \u2014 Visit the docs and install Docker . Operative system \u2014 Any OS able to run CARLA should work. Websocket-client \u2014 pip3 install websocket_client . Install pip if it is not already in the system. Download the plugin Open a terminal and pull the Docker image of carlaviz, based on the CARLA version to be run. # Pull only the image that matches the CARLA package being used docker pull mjxu96/carlaviz:0.9.6 docker pull mjxu96/carlaviz:0.9.7 docker pull mjxu96/carlaviz:0.9.8 docker pull mjxu96/carlaviz:0.9.9 docker pull mjxu96/carlaviz:0.9.10 # Pull this image if working on a CARLA build from source docker pull mjxu96/carlaviz:latest Important Currently in Windows there is only support for 0.9.9 and 0.9.10. CARLA up to 0.9.9 (included) is set to be single-stream. For later versions, multi-streaming for sensors is implemented. In single-stream , a sensor can only be heard by one client. When a sensor is already being heard by another client, for example when running manual_control.py , carlaviz is forced to duplicate the sensor in order to retrieve the data, and performance may suffer. In multi-stream , a sensor can be heard by multiple clients. carlaviz has no need to duplicate these and performance does not suffer. Note Alternatively on Linux, users can build carlaviz following the instructions here , but using a Docker image will make things much easier. Run carlaviz 1. Run CARLA. a) In a CARLA package \u2014 Go to the CARLA folder and start the simulation with CarlaUE4.exe (Windows) or ./CarlaUE4.sh (Linux). b) In a build from source \u2014 Go to the CARLA folder, run the UE editor with make launch and press Play . 2. Run carlaviz. In another terminal run the following command according to the Docker image that has been downloaded. Change <name_of_Docker_image> for the name of the image previously downloaded, e.g. mjxu96/carlaviz:latest or mjxu96/carlaviz:0.9.10 . # On Linux system docker run -it --network=\"host\" -e CARLAVIZ_HOST_IP=localhost -e CARLA_SERVER_IP=localhost -e CARLA_SERVER_PORT=2000 <name_of_Docker_image> # On Windows/MacOS system docker run -it -e CARLAVIZ_HOST_IP=localhost -e CARLA_SERVER_IP=host.docker.internal -e CARLA_SERVER_PORT=2000 -p 8080-8081:8080-8081 -p 8089:8089 <name_of_Docker_image> If the everything has been properly set, carlaviz will show a successful message similar to the following. Warning Remember to edit the previous command to match the Docker image being used. 3. Open the localhost Open your web browser and go to http://127.0.0.1:8080/ . carlaviz runs by default in port 8080 . The output should be similar to the following. Utilities Once the plugin is operative, it can be used to visualize the simulation, the actors that live in it, and the data the sensors retrieve. The plugin shows a visualization window on the right, were the scene is updated in real-tme, and a sidebar on the left with a list of items to be shown. Some of these items will appear in the visualization window, others (mainly sensor and game data) appear just above the items list. Here is a list of options available for visualization. Additional elements may show, such as View Mode \u2014 Change the point of view in the visualization window. Top Down \u2014 Aerial point of view. Perspective \u2014 Free point of view. Driver \u2014 First person point of view. /vehicle \u2014 Show properties of the ego vehicle. Includes a speedometer and accelerometer in the visualization window, and the data retrieved by IMU, GNSS and collision detector sensors. /velocity \u2014 Velocity of the ego vehicle. /acceleration \u2014 Acceleration of the ego vehicle. /drawing \u2014 Show additional elements in the visualization window drawn with CarlaPainter . /texts \u2014 Text elements. /points \u2014 Point elements. /polylines \u2014 Polyline elements. /objects \u2014 Show actors in the visualization window. /walkers \u2014 Update walkers. /vehicles \u2014 Update vehicles. /game \u2014 Show game data. /time \u2014 Current simulation time and frame. /lidar \u2014 LIDAR sensor data. /points \u2014 Cloud of points detected by a LIDAR sensor. /radar \u2014 LIDAR sensor data. /points \u2014 Cloud of points detected by a RADAR sensor. /traffic \u2014 Landmark data. /traffic_light \u2014 Show the map's traffic lights in the visualization window. /stop_sign \u2014 Show the map's stop signs in the visualization window. Try to spawn some actors. These will be automatically updated in the visualization window. cd PythonAPI/examples # Spawns actors in a synchronous mode simulation python3 generate_traffic.py -n 10 -w 5 Spawn an ego vehicle with manual control and move around, to see how the plugin updates sensor data. cd PythonAPI/examples python3 manual_control.py The contributor ( wx9698 ), created an additional class, CarlaPainter , that allows the user to draw elements to be shown in the visualization window. These include text, points and polylines. Follow this example to spawn an ego vehicle with a LIDAR, and draw the LIDAR data, the trajectory and velocity of the vehicle. That is all there is to know about the carlaviz plugin. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"carlaviz \u2014 web \u53ef\u89c6\u5316\u5668"},{"location":"plugins_carlaviz/#carlaviz","text":"The carlaviz plugin is used to visualize the simulation in a web browser. A windows with some basic representation of the scene is created. Actors are updated on-the-fly, sensor data can be retrieved, and additional text, lines and polylines can be drawn in the scene. General information Support Get carlaviz Prerequisites Download the plugin Utilities","title":"carlaviz"},{"location":"plugins_carlaviz/#general-information","text":"Contributor \u2014 Minjun Xu, also known as wx9698 . License \u2014 MIT .","title":"General information"},{"location":"plugins_carlaviz/#support","text":"Linux \u2014 CARLA 0.9.6, 0.9.7, 0.9.8, 0.9.9, 0.9.10. Windows \u2014 CARLA 0.9.9, 0.9.10. Build from source \u2014 Latest updates.","title":"Support"},{"location":"plugins_carlaviz/#get-carlaviz","text":"","title":"Get carlaviz"},{"location":"plugins_carlaviz/#prerequisites","text":"Docker \u2014 Visit the docs and install Docker . Operative system \u2014 Any OS able to run CARLA should work. Websocket-client \u2014 pip3 install websocket_client . Install pip if it is not already in the system.","title":"Prerequisites"},{"location":"plugins_carlaviz/#download-the-plugin","text":"Open a terminal and pull the Docker image of carlaviz, based on the CARLA version to be run. # Pull only the image that matches the CARLA package being used docker pull mjxu96/carlaviz:0.9.6 docker pull mjxu96/carlaviz:0.9.7 docker pull mjxu96/carlaviz:0.9.8 docker pull mjxu96/carlaviz:0.9.9 docker pull mjxu96/carlaviz:0.9.10 # Pull this image if working on a CARLA build from source docker pull mjxu96/carlaviz:latest Important Currently in Windows there is only support for 0.9.9 and 0.9.10. CARLA up to 0.9.9 (included) is set to be single-stream. For later versions, multi-streaming for sensors is implemented. In single-stream , a sensor can only be heard by one client. When a sensor is already being heard by another client, for example when running manual_control.py , carlaviz is forced to duplicate the sensor in order to retrieve the data, and performance may suffer. In multi-stream , a sensor can be heard by multiple clients. carlaviz has no need to duplicate these and performance does not suffer. Note Alternatively on Linux, users can build carlaviz following the instructions here , but using a Docker image will make things much easier.","title":"Download the plugin"},{"location":"plugins_carlaviz/#run-carlaviz","text":"1. Run CARLA. a) In a CARLA package \u2014 Go to the CARLA folder and start the simulation with CarlaUE4.exe (Windows) or ./CarlaUE4.sh (Linux). b) In a build from source \u2014 Go to the CARLA folder, run the UE editor with make launch and press Play . 2. Run carlaviz. In another terminal run the following command according to the Docker image that has been downloaded. Change <name_of_Docker_image> for the name of the image previously downloaded, e.g. mjxu96/carlaviz:latest or mjxu96/carlaviz:0.9.10 . # On Linux system docker run -it --network=\"host\" -e CARLAVIZ_HOST_IP=localhost -e CARLA_SERVER_IP=localhost -e CARLA_SERVER_PORT=2000 <name_of_Docker_image> # On Windows/MacOS system docker run -it -e CARLAVIZ_HOST_IP=localhost -e CARLA_SERVER_IP=host.docker.internal -e CARLA_SERVER_PORT=2000 -p 8080-8081:8080-8081 -p 8089:8089 <name_of_Docker_image> If the everything has been properly set, carlaviz will show a successful message similar to the following. Warning Remember to edit the previous command to match the Docker image being used. 3. Open the localhost Open your web browser and go to http://127.0.0.1:8080/ . carlaviz runs by default in port 8080 . The output should be similar to the following.","title":"Run carlaviz"},{"location":"plugins_carlaviz/#utilities","text":"Once the plugin is operative, it can be used to visualize the simulation, the actors that live in it, and the data the sensors retrieve. The plugin shows a visualization window on the right, were the scene is updated in real-tme, and a sidebar on the left with a list of items to be shown. Some of these items will appear in the visualization window, others (mainly sensor and game data) appear just above the items list. Here is a list of options available for visualization. Additional elements may show, such as View Mode \u2014 Change the point of view in the visualization window. Top Down \u2014 Aerial point of view. Perspective \u2014 Free point of view. Driver \u2014 First person point of view. /vehicle \u2014 Show properties of the ego vehicle. Includes a speedometer and accelerometer in the visualization window, and the data retrieved by IMU, GNSS and collision detector sensors. /velocity \u2014 Velocity of the ego vehicle. /acceleration \u2014 Acceleration of the ego vehicle. /drawing \u2014 Show additional elements in the visualization window drawn with CarlaPainter . /texts \u2014 Text elements. /points \u2014 Point elements. /polylines \u2014 Polyline elements. /objects \u2014 Show actors in the visualization window. /walkers \u2014 Update walkers. /vehicles \u2014 Update vehicles. /game \u2014 Show game data. /time \u2014 Current simulation time and frame. /lidar \u2014 LIDAR sensor data. /points \u2014 Cloud of points detected by a LIDAR sensor. /radar \u2014 LIDAR sensor data. /points \u2014 Cloud of points detected by a RADAR sensor. /traffic \u2014 Landmark data. /traffic_light \u2014 Show the map's traffic lights in the visualization window. /stop_sign \u2014 Show the map's stop signs in the visualization window. Try to spawn some actors. These will be automatically updated in the visualization window. cd PythonAPI/examples # Spawns actors in a synchronous mode simulation python3 generate_traffic.py -n 10 -w 5 Spawn an ego vehicle with manual control and move around, to see how the plugin updates sensor data. cd PythonAPI/examples python3 manual_control.py The contributor ( wx9698 ), created an additional class, CarlaPainter , that allows the user to draw elements to be shown in the visualization window. These include text, points and polylines. Follow this example to spawn an ego vehicle with a LIDAR, and draw the LIDAR data, the trajectory and velocity of the vehicle. That is all there is to know about the carlaviz plugin. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"Utilities"},{"location":"python_api/","text":"Python API reference This reference contains all the details the Python API. To consult a previous reference for a specific CARLA release, change the documentation version using the panel in the bottom right corner. This will change the whole documentation to a previous state. Remember that the latest version is the dev branch and may show features not available in any packaged versions of CARLA. carla.Actor CARLA defines actors as anything that plays a role in the simulation or can be moved around. That includes: pedestrians, vehicles, sensors and traffic signs (considering traffic lights as part of these). Actors are spawned in the simulation by carla.World and they need for a carla.ActorBlueprint to be created. These blueprints belong into a library provided by CARLA, find more about them here . Instance Variables attributes ( dict ) A dictionary containing the attributes of the blueprint this actor was based on. id ( int ) Identifier for this actor. Unique during a given episode. is_alive ( bool ) Returns whether this object was destroyed using this actor handle. parent ( carla.Actor ) Actors may be attached to a parent actor that they will follow around. This is said actor. semantic_tags ( list(int) ) A list of semantic tags provided by the blueprint listing components for this actor. E.g. a traffic light could be tagged with Pole and TrafficLight . These tags are used by the semantic segmentation sensor. Find more about this and other sensors here . type_id ( str ) The identifier of the blueprint this actor was based on, e.g. vehicle.ford.mustang . Methods add_angular_impulse ( self , angular_impulse ) Applies an angular impulse at the center of mass of the actor. This method should be used for instantaneous torques, usually applied once. Use add_torque() to apply rotation forces over a period of time. Parameters: angular_impulse ( carla.Vector3D - degrees*s ) - Angular impulse vector in global coordinates. add_force ( self , force ) Applies a force at the center of mass of the actor. This method should be used for forces that are applied over a certain period of time. Use add_impulse() to apply an impulse that only lasts an instant. Parameters: force ( carla.Vector3D - N ) - Force vector in global coordinates. add_impulse ( self , impulse ) Applies an impulse at the center of mass of the actor. This method should be used for instantaneous forces, usually applied once. Use add_force() to apply forces over a period of time. Parameters: impulse ( carla.Vector3D - N*s ) - Impulse vector in global coordinates. add_torque ( self , torque ) Applies a torque at the center of mass of the actor. This method should be used for torques that are applied over a certain period of time. Use add_angular_impulse() to apply a torque that only lasts an instant. Parameters: torque ( carla.Vector3D - degrees ) - Torque vector in global coordinates. close_door ( self , door_idx ) Close the door door_idx if the vehicle has it. Use carla.VehicleDoor.All to close all available doors. Parameters: door_idx ( carla.VehicleDoor ) - door index. Note: Only carla.Vehicle actors can use this method. destroy ( self ) Tells the simulator to destroy this actor and returns True if it was successful. It has no effect if it was already destroyed. Return: bool Warning: This method blocks the script until the destruction is completed by the simulator. disable_constant_velocity ( self ) Disables any constant velocity previously set for a carla.Vehicle actor. enable_chrono_physics ( self , max_substeps , max_substep_delta_time , vehicle_json , powertrain_json , tire_json , base_json_path ) Enables Chrono physics on a spawned vehicle. Parameters: max_substeps ( int ) - Max number of Chrono substeps. max_substep_delta_time ( int ) - Max size of substep. vehicle_json ( str ) - Path to vehicle json file relative to base_json_path . powertrain_json ( str ) - Path to powertrain json file relative to base_json_path . tire_json ( str ) - Path to tire json file relative to base_json_path . base_json_path ( str ) - Path to chrono/data/vehicle folder. E.g., /home/user/carla/Build/chrono-install/share/chrono/data/vehicle/ (the final / character is required). Note: Ensure that you have started the CARLA server with the ARGS=\"--chrono\" flag. You will not be able to use Chrono physics without this flag set. Warning: Collisions are not supported. When a collision is detected, physics will revert to the default CARLA physics. enable_constant_velocity ( self , velocity ) Sets a vehicle's velocity vector to a constant value over time. The resulting velocity will be approximately the velocity being set, as with set_target_velocity() . Parameters: velocity ( carla.Vector3D - m/s ) - Velocity vector in local space. Note: Only carla.Vehicle actors can use this method. Warning: Enabling a constant velocity for a vehicle managed by the Traffic Manager may cause conflicts. This method overrides any changes in velocity by the TM. open_door ( self , door_idx ) Open the door door_idx if the vehicle has it. Use carla.VehicleDoor.All to open all available doors. Parameters: door_idx ( carla.VehicleDoor ) - door index. Note: Only carla.Vehicle actors can use this method. show_debug_telemetry ( self , enabled =True ) Enables or disables the telemetry on this vehicle. This shows information about the vehicles current state and forces applied to it in the spectator window. Only information for one vehicle can be shown so if you enable a second one, the previous will be automatically disabled. Parameters: enabled ( bool ) Getters get_acceleration ( self ) Returns the actor's 3D acceleration vector the client recieved during last tick. The method does not call the simulator. Return: carla.Vector3D - m/s 2 get_angular_velocity ( self ) Returns the actor's angular velocity vector the client recieved during last tick. The method does not call the simulator. Return: carla.Vector3D - deg/s get_location ( self ) Returns the actor's location the client recieved during last tick. The method does not call the simulator. Return: carla.Location - meters Setter: carla.Actor.set_location get_transform ( self ) Returns the actor's transform (location and rotation) the client recieved during last tick. The method does not call the simulator. Return: carla.Transform Setter: carla.Actor.set_transform get_velocity ( self ) Returns the actor's velocity vector the client recieved during last tick. The method does not call the simulator. Return: carla.Vector3D - m/s get_world ( self ) Returns the world this actor belongs to. Return: carla.World Setters set_enable_gravity ( self , enabled ) Enables or disables gravity for the actor. Default is True. Parameters: enabled ( bool ) set_location ( self , location ) Teleports the actor to a given location. Parameters: location ( carla.Location - meters ) Getter: carla.Actor.get_location set_simulate_physics ( self , enabled =True ) Enables or disables the simulation of physics on this actor. Parameters: enabled ( bool ) set_target_angular_velocity ( self , angular_velocity ) Sets the actor's angular velocity vector. This is applied before the physics step so the resulting angular velocity will be affected by external forces such as friction. Parameters: angular_velocity ( carla.Vector3D - deg/s ) set_target_velocity ( self , velocity ) Sets the actor's velocity vector. This is applied before the physics step so the resulting angular velocity will be affected by external forces such as friction. Parameters: velocity ( carla.Vector3D ) set_transform ( self , transform ) Teleports the actor to a given transform (location and rotation). Parameters: transform ( carla.Transform ) Getter: carla.Actor.get_transform Dunder methods __str__ ( self ) carla.ActorAttribute CARLA provides a library of blueprints for actors that can be accessed as carla.BlueprintLibrary . Each of these blueprints has a series of attributes defined internally. Some of these are modifiable, others are not. A list of recommended values is provided for those that can be set. Instance Variables id ( str ) The attribute's name and identifier in the library. is_modifiable ( bool ) It is True if the attribute's value can be modified. recommended_values ( list(str) ) A list of values suggested by those who designed the blueprint. type ( carla.ActorAttributeType ) The attribute's parameter type. Methods as_bool ( self ) Reads the attribute as boolean value. as_color ( self ) Reads the attribute as carla.Color . as_float ( self ) Reads the attribute as float. as_int ( self ) Reads the attribute as int. as_str ( self ) Reads the attribute as string. Dunder methods __bool__ ( self ) __eq__ ( self , other =bool / int / float / str / carla.Color / carla.ActorAttribute ) Returns true if this actor's attribute and other are the same. Return: bool __float__ ( self ) __int__ ( self ) __ne__ ( self , other =bool / int / float / str / carla.Color / carla.ActorAttribute ) Returns true if this actor's attribute and other are different. Return: bool __nonzero__ ( self ) Returns true if this actor's attribute is not zero or null. Return: bool __str__ ( self ) carla.ActorAttributeType CARLA provides a library of blueprints for actors in carla.BlueprintLibrary with different attributes each. This class defines the types those at carla.ActorAttribute can be as a series of enum. All this information is managed internally and listed here for a better comprehension of how CARLA works. Instance Variables Bool Int Float String RGBColor carla.ActorBlueprint CARLA provides a blueprint library for actors that can be consulted through carla.BlueprintLibrary . Each of these consists of an identifier for the blueprint and a series of attributes that may be modifiable or not. This class is the intermediate step between the library and the actor creation. Actors need an actor blueprint to be spawned. These store the information for said blueprint in an object with its attributes and some tags to categorize them. The user can then customize some attributes and eventually spawn the actors through carla.World . Instance Variables id ( str ) The identifier of said blueprint inside the library. E.g. walker.pedestrian.0001 . tags ( list(str) ) A list of tags each blueprint has that helps describing them. E.g. ['0001', 'pedestrian', 'walker'] . Methods has_attribute ( self , id ) Returns True if the blueprint contains the attribute id . Parameters: id ( str ) - e.g. gender would return True for pedestrians' blueprints. Return: bool has_tag ( self , tag ) Returns True if the blueprint has the specified tag listed. Parameters: tag ( str ) - e.g. 'walker'. Return: bool match_tags ( self , wildcard_pattern ) Returns True if any of the tags listed for this blueprint matches wildcard_pattern . Matching follows fnmatch standard. Parameters: wildcard_pattern ( str ) Return: bool Getters get_attribute ( self , id ) Returns the actor's attribute with id as identifier if existing. Parameters: id ( str ) Return: carla.ActorAttribute Setter: carla.ActorBlueprint.set_attribute Setters set_attribute ( self , id , value ) snippet \u2192 If the id attribute is modifiable, changes its value to value . Parameters: id ( str ) - The identifier for the attribute that is intended to be changed. value ( str ) - The new value for said attribute. Getter: carla.ActorBlueprint.get_attribute Dunder methods __iter__ ( self ) Iterate over the carla.ActorAttribute that this blueprint has. __len__ ( self ) Returns the amount of attributes for this blueprint. __str__ ( self ) carla.ActorList A class that contains every actor present on the scene and provides access to them. The list is automatically created and updated by the server and it can be returned using carla.World . Methods filter ( self , wildcard_pattern ) Filters a list of Actors matching wildcard_pattern against their variable type_id (which identifies the blueprint used to spawn them). Matching follows fnmatch standard. Parameters: wildcard_pattern ( str ) Return: list find ( self , actor_id ) Finds an actor using its identifier and returns it or None if it is not present. Parameters: actor_id ( int ) Return: carla.Actor Dunder methods __getitem__ ( self , pos =int ) Returns the actor corresponding to pos position in the list. Return: carla.Actor __iter__ ( self ) Iterate over the carla.Actor contained in the list. __len__ ( self ) Returns the amount of actors listed. Return: int __str__ ( self ) Parses to the ID for every actor listed. Return: str carla.ActorSnapshot A class that comprises all the information for an actor at a certain moment in time. These objects are contained in a carla.WorldSnapshot and sent to the client once every tick. Instance Variables id ( int ) An identifier for the snapshot itself. Methods Getters get_acceleration ( self ) Returns the acceleration vector registered for an actor in that tick. Return: carla.Vector3D - m/s 2 get_angular_velocity ( self ) Returns the angular velocity vector registered for an actor in that tick. Return: carla.Vector3D - rad/s get_transform ( self ) Returns the actor's transform (location and rotation) for an actor in that tick. Return: carla.Transform get_velocity ( self ) Returns the velocity vector registered for an actor in that tick. Return: carla.Vector3D - m/s carla.AttachmentType Class that defines attachment options between an actor and its parent. When spawning actors, these can be attached to another actor so their position changes accordingly. This is specially useful for sensors. The snipet in carla.World.spawn_actor shows some sensors being attached to a car when spawned. Note that the attachment type is declared as an enum within the class. Instance Variables Rigid With this fixed attatchment the object follow its parent position strictly. This is the recommended attachment to retrieve precise data from the simulation. SpringArm An attachment that expands or retracts the position of the actor, depending on its parent. This attachment is only recommended to record videos from the simulation where a smooth movement is needed. SpringArms are an Unreal Engine component so check the UE docs to learn more about them. Warning: The SpringArm attachment presents weird behaviors when an actor is spawned with a relative translation in the Z-axis (e.g. child_location = Location(0,0,2) ). carla.BlueprintLibrary A class that contains the blueprints provided for actor spawning. Its main application is to return carla.ActorBlueprint objects needed to spawn actors. Each blueprint has an identifier and attributes that may or may not be modifiable. The library is automatically created by the server and can be accessed through carla.World . Here is a reference containing every available blueprint and its specifics. Methods filter ( self , wildcard_pattern ) Filters a list of blueprints matching the wildcard_pattern against the id and tags of every blueprint contained in this library and returns the result as a new one. Matching follows fnmatch standard. Parameters: wildcard_pattern ( str ) Return: carla.BlueprintLibrary find ( self , id ) Returns the blueprint corresponding to that identifier. Parameters: id ( str ) Return: carla.ActorBlueprint Dunder methods __getitem__ ( self , pos =int ) Returns the blueprint stored in pos position inside the data structure containing them. Return: carla.ActorBlueprint __iter__ ( self ) Iterate over the carla.ActorBlueprint stored in the library. __len__ ( self ) Returns the amount of blueprints comprising the library. Return: int __str__ ( self ) Parses the identifiers for every blueprint to string. Return: string carla.BoundingBox Bounding boxes contain the geometry of an actor or an element in the scene. They can be used by carla.DebugHelper or a carla.Client to draw their shapes for debugging. Check out the snipet in carla.DebugHelper.draw_box where a snapshot of the world is used to draw bounding boxes for traffic lights. Instance Variables extent ( carla.Vector3D - meters ) Vector from the center of the box to one vertex. The value in each axis equals half the size of the box for that axis. extent.x * 2 would return the size of the box in the X-axis. location ( carla.Location - meters ) The center of the bounding box. rotation ( carla.Rotation ) The orientation of the bounding box. Methods __init__ ( self , location , extent ) Parameters: location ( carla.Location ) - Center of the box, relative to its parent. extent ( carla.Vector3D - meters ) - Vector containing half the size of the box for every axis. contains ( self , world_point , transform ) Returns True if a point passed in world space is inside this bounding box. Parameters: world_point ( carla.Location - meters ) - The point in world space to be checked. transform ( carla.Transform ) - Contains location and rotation needed to convert this object's local space to world space. Return: bool Getters get_local_vertices ( self ) Returns a list containing the locations of this object's vertices in local space. Return: list( carla.Location ) get_world_vertices ( self , transform ) Returns a list containing the locations of this object's vertices in world space. Parameters: transform ( carla.Transform ) - Contains location and rotation needed to convert this object's local space to world space. Return: list( carla.Location ) Dunder methods __eq__ ( self , other = carla.BoundingBox ) Returns true if both location and extent are equal for this and other . Return: bool __ne__ ( self , other = carla.BoundingBox ) Returns true if either location or extent are different for this and other . Return: bool __str__ ( self ) Parses the location and extent of the bounding box to string. Return: str carla.CityObjectLabel Enum declaration that contains the different tags available to filter the bounding boxes returned by carla.World.get_level_bbs (). These values correspond to the semantic tag that the elements in the scene have. Instance Variables None Buildings Fences Other Pedestrians Poles RoadLines Roads Sidewalks TrafficSigns Vegetation Vehicles Walls Sky Ground Bridge RailTrack GuardRail TrafficLight Static Dynamic Water Terrain Any carla.Client The Client connects CARLA to the server which runs the simulation. Both server and client contain a CARLA library (libcarla) with some differences that allow communication between them. Many clients can be created and each of these will connect to the RPC server inside the simulation to send commands. The simulation runs server-side. Once the connection is established, the client will only receive data retrieved from the simulation. Walkers are the exception. The client is in charge of managing pedestrians so, if you are running a simulation with multiple clients, some issues may arise. For example, if you spawn walkers through different clients, collisions may happen, as each client is only aware of the ones it is in charge of. The client also has a recording feature that saves all the information of a simulation while running it. This allows the server to replay it at will to obtain information and experiment with it. Here is some information about how to use this recorder. Methods __init__ ( self , host =127.0.0.1 , port =2000 , worker_threads =0 ) snippet \u2192 Client constructor. Parameters: host ( str ) - IP address where a CARLA Simulator instance is running. Default is localhost (127.0.0.1). port ( int ) - TCP port where the CARLA Simulator instance is running. Default are 2000 and the subsequent 2001. worker_threads ( int ) - Number of working threads used for background updates. If 0, use all available concurrency. apply_batch ( self , commands ) Executes a list of commands on a single simulation step and retrieves no information. If you need information about the response of each command, use the apply_batch_sync() method. Here is an example on how to delete the actors that appear in carla.ActorList all at once. Parameters: commands ( list ) - A list of commands to execute in batch. Each command is different and has its own parameters. They appear listed at the bottom of this page. apply_batch_sync ( self , commands , due_tick_cue =False ) snippet \u2192 Executes a list of commands on a single simulation step, blocks until the commands are linked, and returns a list of command.Response that can be used to determine whether a single command succeeded or not. Here is an example of it being used to spawn actors. Parameters: commands ( list ) - A list of commands to execute in batch. The commands available are listed right above, in the method apply_batch() . due_tick_cue ( bool ) - A boolean parameter to specify whether or not to perform a carla.World.tick after applying the batch in synchronous mode . It is False by default. Return: list(command.Response) generate_opendrive_world ( self , opendrive , parameters =(2.0, 50.0, 1.0, 0.6, true, true) , reset_settings =True ) Loads a new world with a basic 3D topology generated from the content of an OpenDRIVE file. This content is passed as a string parameter. It is similar to client.load_world(map_name) but allows for custom OpenDRIVE maps in server side. Cars can drive around the map, but there are no graphics besides the road and sidewalks. Parameters: opendrive ( str ) - Content of an OpenDRIVE file as string , not the path to the .xodr . parameters ( carla.OpendriveGenerationParameters ) - Additional settings for the mesh generation. If none are provided, default values will be used. reset_settings ( bool ) - Option to reset the episode setting to default values, set to false to keep the current settings. This is useful to keep sync mode when changing map and to keep deterministic scenarios. load_world ( self , map_name , reset_settings =True , map_layers = carla.MapLayer.All ) Creates a new world with default settings using map_name map. All actors in the current world will be destroyed. Parameters: map_name ( str ) - Name of the map to be used in this world. Accepts both full paths and map names, e.g. '/Game/Carla/Maps/Town01' or 'Town01'. Remember that these paths are dynamic. reset_settings ( bool ) - Option to reset the episode setting to default values, set to false to keep the current settings. This is useful to keep sync mode when changing map and to keep deterministic scenarios. map_layers ( carla.MapLayer ) - Layers of the map that will be loaded. By default all layers are loaded. This parameter works like a flag mask. Warning: map_layers are only available for \"Opt\" maps reload_world ( self , reset_settings =True ) Reload the current world, note that a new world is created with default settings using the same map. All actors present in the world will be destroyed, but traffic manager instances will stay alive. Parameters: reset_settings ( bool ) - Option to reset the episode setting to default values, set to false to keep the current settings. This is useful to keep sync mode when changing map and to keep deterministic scenarios. Raises: RuntimeError when corresponding. replay_file ( self , name , start , duration , follow_id , replay_sensors ) Load a new world with default settings using map_name map. All actors present in the current world will be destroyed, but traffic manager instances will stay alive. Parameters: name ( str ) - Name of the file containing the information of the simulation. start ( float - seconds ) - Time where to start playing the simulation. Negative is read as beginning from the end, being -10 just 10 seconds before the recording finished. duration ( float - seconds ) - Time that will be reenacted using the information name file. If the end is reached, the simulation will continue. follow_id ( int ) - ID of the actor to follow. If this is 0 then camera is disabled. replay_sensors ( bool ) - Flag to enable or disable the spawn of sensors during playback. request_file ( self , name ) Requests one of the required files returned by carla.Client.get_required_files . Parameters: name ( str ) - Name of the file you are requesting. show_recorder_actors_blocked ( self , filename , min_time , min_distance ) The terminal will show the information registered for actors considered blocked. An actor is considered blocked when it does not move a minimum distance in a period of time, being these min_distance and min_time . Parameters: filename ( str ) - Name of the recorded file to load. min_time ( float - seconds ) - Minimum time the actor has to move a minimum distance before being considered blocked. Default is 60 seconds. min_distance ( float - centimeters ) - Minimum distance the actor has to move to not be considered blocked. Default is 100 centimeters. Return: string show_recorder_collisions ( self , filename , category1 , category2 ) The terminal will show the collisions registered by the recorder. These can be filtered by specifying the type of actor involved. The categories will be specified in category1 and category2 as follows: 'h' = Hero, the one vehicle that can be controlled manually or managed by the user. 'v' = Vehicle 'w' = Walker 't' = Traffic light 'o' = Other 'a' = Any If you want to see only collisions between a vehicles and a walkers, use for category1 as 'v' and category2 as 'w' or vice versa. If you want to see all the collisions (filter off) you can use 'a' for both parameters. Parameters: filename ( str ) - Name or absolute path of the file recorded, depending on your previous choice. category1 ( single char ) - Character variable specifying a first type of actor involved in the collision. category2 ( single char ) - Character variable specifying the second type of actor involved in the collision. Return: string show_recorder_file_info ( self , filename , show_all ) The information saved by the recorder will be parsed and shown in your terminal as text (frames, times, events, state, positions...). The information shown can be specified by using the show_all parameter. Here is some more information about how to read the recorder file. Parameters: filename ( str ) - Name or absolute path of the file recorded, depending on your previous choice. show_all ( bool ) - If True , returns all the information stored for every frame (traffic light states, positions of all actors, orientation and animation data...). If False , returns a summary of key events and frames. Return: string start_recorder ( self , filename , additional_data =False ) Enables the recording feature, which will start saving every information possible needed by the server to replay the simulation. Parameters: filename ( str ) - Name of the file to write the recorded data. A simple name will save the recording in 'CarlaUE4/Saved/recording.log'. Otherwise, if some folder appears in the name, it will be considered an absolute path. additional_data ( bool ) - Enables or disable recording non-essential data for reproducing the simulation (bounding box location, physics control parameters, etc). stop_recorder ( self ) Stops the recording in progress. If you specified a path in filename , the recording will be there. If not, look inside CarlaUE4/Saved/ . stop_replayer ( self , keep_actors ) Stop current replayer. Parameters: keep_actors ( bool ) - True if you want autoremove all actors from the replayer, or False to keep them. Getters get_available_maps ( self ) Returns a list of strings containing the paths of the maps available on server. These paths are dynamic, they will be created during the simulation and so you will not find them when looking up in your files. One of the possible returns for this method would be: ['/Game/Carla/Maps/Town01', '/Game/Carla/Maps/Town02', '/Game/Carla/Maps/Town03', '/Game/Carla/Maps/Town04', '/Game/Carla/Maps/Town05', '/Game/Carla/Maps/Town06', '/Game/Carla/Maps/Town07']. Return: list(str) get_client_version ( self ) Returns the client libcarla version by consulting it in the \"Version.h\" file. Both client and server can use different libcarla versions but some issues may arise regarding unexpected incompatibilities. Return: str get_required_files ( self , folder , download =True ) Asks the server which files are required by the client to use the current map. Option to download files automatically if they are not already in the cache. Parameters: folder ( str ) - Folder where files required by the client will be downloaded to. download ( bool ) - If True, downloads files that are not already in cache. get_server_version ( self ) Returns the server libcarla version by consulting it in the \"Version.h\" file. Both client and server should use the same libcarla version. Return: str get_trafficmanager ( self , client_connection =8000 ) Returns an instance of the traffic manager related to the specified port. If it does not exist, this will be created. Parameters: client_connection ( int ) - Port that will be used by the traffic manager. Default is 8000 . Return: carla.TrafficManager get_world ( self ) Returns the world object currently active in the simulation. This world will be later used for example to load maps. Return: carla.World Setters set_files_base_folder ( self , path ) Parameters: path ( str ) - Specifies the base folder where the local cache for required files will be placed. set_replayer_ignore_hero ( self , ignore_hero ) Parameters: ignore_hero ( bool ) - Enables or disables playback of the hero vehicle during a playback of a recorded simulation. set_replayer_time_factor ( self , time_factor =1.0 ) When used, the time speed of the reenacted simulation is modified at will. It can be used several times while a playback is in curse. Parameters: time_factor ( float ) - 1.0 means normal time speed. Greater than 1.0 means fast motion (2.0 would be double speed) and lesser means slow motion (0.5 would be half speed). set_timeout ( self , seconds ) Sets the maxixum time a network call is allowed before blocking it and raising a timeout exceeded error. Parameters: seconds ( float - seconds ) - New timeout value. Default is 5 seconds. carla.CollisionEvent Inherited from carla.SensorData Class that defines a collision data for sensor.other.collision . The sensor creates one of this for every collision detected which may be many for one simulation step. Learn more about this here . Instance Variables actor ( carla.Actor ) The actor the sensor is attached to, the one that measured the collision. other_actor ( carla.Actor ) The second actor involved in the collision. normal_impulse ( carla.Vector3D - N*s ) Normal impulse resulting of the collision. carla.Color Class that defines a 32-bit RGBA color. Instance Variables r ( int ) Red color (0-255). g ( int ) Green color (0-255). b ( int ) Blue color (0-255). a ( int ) Alpha channel (0-255). Methods __init__ ( self , r =0 , g =0 , b =0 , a =255 ) Initializes a color, black by default. Parameters: r ( int ) g ( int ) b ( int ) a ( int ) Dunder methods __eq__ ( self , other = carla.Color ) __ne__ ( self , other = carla.Color ) __str__ ( self ) carla.ColorConverter Class that defines conversion patterns that can be applied to a carla.Image in order to show information provided by carla.Sensor . Depth conversions cause a loss of accuracy, as sensors detect depth as float that is then converted to a grayscale value between 0 and 255. Take a look at the snipet in carla.Sensor.listen to see an example of how to create and save image data for sensor.camera.semantic_segmentation . Instance Variables CityScapesPalette Converts the image to a segmentated map using tags provided by the blueprint library. Used by the semantic segmentation camera . Depth Converts the image to a linear depth map. Used by the depth camera . LogarithmicDepth Converts the image to a depth map using a logarithmic scale, leading to better precision for small distances at the expense of losing it when further away. Raw No changes applied to the image. Used by the RGB camera . carla.DVSEvent Class that defines a DVS event. An event is a quadruple, so a tuple of 4 elements, with x , y pixel coordinate location, timestamp t and polarity pol of the event. Learn more about them here . Instance Variables x ( int ) X pixel coordinate. y ( int ) Y pixel coordinate. t ( int ) Timestamp of the moment the event happened. pol ( bool ) Polarity of the event. True for positive and False for negative. Methods Dunder methods __str__ ( self ) carla.DVSEventArray Class that defines a stream of events in carla.DVSEvent . Such stream is an array of arbitrary size depending on the number of events. This class also stores the field of view, the height and width of the image and the timestamp from convenience. Learn more about them here . Instance Variables fov ( float - degrees ) Horizontal field of view of the image. height ( int ) Image height in pixels. width ( int ) Image width in pixels. raw_data ( bytes ) Methods to_array ( self ) Converts the stream of events to an array of int values in the following order [x, y, t, pol] . to_array_pol ( self ) Returns an array with the polarity of all the events in the stream. to_array_t ( self ) Returns an array with the timestamp of all the events in the stream. to_array_x ( self ) Returns an array with X pixel coordinate of all the events in the stream. to_array_y ( self ) Returns an array with Y pixel coordinate of all the events in the stream. to_image ( self ) Converts the image following this pattern: blue indicates positive events, red indicates negative events. Dunder methods __getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.DVSEvent retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , color = carla.Color ) __str__ ( self ) carla.DebugHelper Helper class part of carla.World that defines methods for creating debug shapes. By default, shapes last one second. They can be permanent, but take into account the resources needed to do so. Take a look at the snipets available for this class to learn how to debug easily in CARLA. Methods draw_arrow ( self , begin , end , thickness =0.1 , arrow_size =0.1 , color =(255,0,0) , life_time =-1.0 ) Draws an arrow from begin to end pointing in that direction. Parameters: begin ( carla.Location - meters ) - Point in the coordinate system where the arrow starts. end ( carla.Location - meters ) - Point in the coordinate system where the arrow ends and points towards to. thickness ( float - meters ) - Density of the line. arrow_size ( float - meters ) - Size of the tip of the arrow. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_box ( self , box , rotation , thickness =0.1 , color =(255,0,0) , life_time =-1.0 ) snippet \u2192 Draws a box, ussually to act for object colliders. Parameters: box ( carla.BoundingBox ) - Object containing a location and the length of a box for every axis. rotation ( carla.Rotation - degrees (pitch,yaw,roll) ) - Orientation of the box according to Unreal Engine's axis system. thickness ( float - meters ) - Density of the lines that define the box. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_line ( self , begin , end , thickness =0.1 , color =(255,0,0) , life_time =-1.0 ) Draws a line in between begin and end . Parameters: begin ( carla.Location - meters ) - Point in the coordinate system where the line starts. end ( carla.Location - meters ) - Spot in the coordinate system where the line ends. thickness ( float - meters ) - Density of the line. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_point ( self , location , size =0.1 , color =(255,0,0) , life_time =-1.0 ) Draws a point location . Parameters: location ( carla.Location - meters ) - Spot in the coordinate system to center the object. size ( float - meters ) - Density of the point. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_string ( self , location , text , draw_shadow =False , color =(255,0,0) , life_time =-1.0 ) snippet \u2192 Draws a string in a given location of the simulation which can only be seen server-side. Parameters: location ( carla.Location - meters ) - Spot in the simulation where the text will be centered. text ( str ) - Text intended to be shown in the world. draw_shadow ( bool ) - Casts a shadow for the string that could help in visualization. It is disabled by default. color ( carla.Color ) - RGB code to color the string. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. carla.EnvironmentObject Class that represents a geometry in the level, this geometry could be part of an actor formed with other EnvironmentObjects (ie: buildings). Instance Variables transform ( carla.Transform ) Contains the location and orientation of the EnvironmentObject in world space. bounding_box ( carla.BoundingBox ) Object containing a location, rotation and the length of a box for every axis in world space. id ( int ) Unique ID to identify the object in the level. name ( string ) Name of the EnvironmentObject. type ( carla.CityObjectLabel ) Semantic tag. Methods Dunder methods __str__ ( self ) Parses the EnvironmentObject to a string and shows them in command line. Return: str carla.FloatColor Class that defines a float RGBA color. Instance Variables r ( float ) Red color. g ( float ) Green color. b ( float ) Blue color. a ( float ) Alpha channel. Methods __init__ ( self , r =0 , g =0 , b =0 , a =1.0 ) Initializes a color, black by default. Parameters: r ( float ) g ( float ) b ( float ) a ( float ) Dunder methods __eq__ ( self , other = carla.FloatColor ) __ne__ ( self , other = carla.FloatColor ) carla.GearPhysicsControl Class that provides access to vehicle transmission details by defining a gear and when to run on it. This will be later used by carla.VehiclePhysicsControl to help simulate physics. Instance Variables ratio ( float ) The transmission ratio of the gear. down_ratio ( float ) Quotient between current RPM and MaxRPM where the autonomous gear box should shift down. up_ratio ( float ) Quotient between current RPM and MaxRPM where the autonomous gear box should shift up. Methods __init__ ( self , ratio =1.0 , down_ratio =0.5 , up_ratio =0.65 ) Parameters: ratio ( float ) down_ratio ( float ) up_ratio ( float ) Dunder methods __eq__ ( self , other = carla.GearPhysicsControl ) __ne__ ( self , other = carla.GearPhysicsControl ) __str__ ( self ) carla.GeoLocation Class that contains geographical coordinates simulated data. The carla.Map can convert simulation locations by using the tag in the OpenDRIVE file. Instance Variables latitude ( float - degrees ) North/South value of a point on the map. longitude ( float - degrees ) West/East value of a point on the map. altitude ( float - meters ) Height regarding ground level. Methods __init__ ( self , latitude =0.0 , longitude =0.0 , altitude =0.0 ) Parameters: latitude ( float - degrees ) longitude ( float - degrees ) altitude ( float - meters ) Dunder methods __eq__ ( self , other = carla.GeoLocation ) __ne__ ( self , other = carla.GeoLocation ) __str__ ( self ) carla.GnssMeasurement Inherited from carla.SensorData Class that defines the Gnss data registered by a sensor.other.gnss . It essentially reports its position with the position of the sensor and an OpenDRIVE geo-reference. Instance Variables altitude ( float - meters ) Height regarding ground level. latitude ( float - degrees ) North/South value of a point on the map. longitude ( float - degrees ) West/East value of a point on the map. Methods Dunder methods __str__ ( self ) carla.IMUMeasurement Inherited from carla.SensorData Class that defines the data registered by a sensor.other.imu , regarding the sensor's transformation according to the current carla.World . It essentially acts as accelerometer, gyroscope and compass. Instance Variables accelerometer ( carla.Vector3D - m/s 2 ) Linear acceleration. compass ( float - radians ) Orientation with regard to the North ([0.0, -1.0, 0.0] in Unreal Engine). gyroscope ( carla.Vector3D - rad/s ) Angular velocity. Methods Dunder methods __str__ ( self ) carla.Image Inherited from carla.SensorData Class that defines an image of 32-bit BGRA colors that will be used as initial data retrieved by camera sensors. There are different camera sensors (currently three, RGB, depth and semantic segmentation) and each of these makes different use for the images. Learn more about them here . Instance Variables fov ( float - degrees ) Horizontal field of view of the image. height ( int ) Image height in pixels. width ( int ) Image width in pixels. raw_data ( bytes ) Methods convert ( self , color_converter ) Converts the image following the color_converter pattern. Parameters: color_converter ( carla.ColorConverter ) save_to_disk ( self , path , color_converter =Raw ) Saves the image to disk using a converter pattern stated as color_converter . The default conversion pattern is Raw that will make no changes to the image. Parameters: path ( str ) - Path that will contain the image. color_converter ( carla.ColorConverter ) - Default Raw will make no changes. Dunder methods __getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.Color that form the image. __len__ ( self ) __setitem__ ( self , pos =int , color = carla.Color ) __str__ ( self ) carla.Junction Class that embodies the intersections on the road described in the OpenDRIVE file according to OpenDRIVE 1.4 standards. Instance Variables id ( int ) Identificator found in the OpenDRIVE file. bounding_box ( carla.BoundingBox ) Bounding box encapsulating the junction lanes. Methods Getters get_waypoints ( self , lane_type ) Returns a list of pairs of waypoints. Every tuple on the list contains first an initial and then a final waypoint within the intersection boundaries that describe the beginning and the end of said lane along the junction. Lanes follow their OpenDRIVE definitions so there may be many different tuples with the same starting waypoint due to possible deviations, as this are considered different lanes. Parameters: lane_type ( carla.LaneType ) - Type of lanes to get the waypoints. Return: list(tuple( carla.Waypoint )) carla.LabelledPoint Class that represent a position in space with a semantic label. Instance Variables location Position in 3D space. label Semantic tag of the point. carla.Landmark Class that defines any type of traffic landmark or sign affecting a road. These class mediates between the OpenDRIVE 1.4 standard definition of the landmarks and their representation in the simulation. This class retrieves all the information defining a landmark in OpenDRIVE and facilitates information about which lanes does it affect and when. Landmarks will be accessed by carla.Waypoint objects trying to retrieve the regulation of their lane. Therefore some attributes depend on the waypoint that is consulting the landmark and so, creating the object. Instance Variables road_id ( int ) The OpenDRIVE ID of the road where this landmark is defined. Due to OpenDRIVE road definitions, this road may be different from the road the landmark is currently affecting. It is mostly the case in junctions where the road diverges in different routes. Example: a traffic light is defined in one of the divergent roads in a junction, but it affects all the possible routes . distance ( float - meters ) Distance between the landmark and the waypoint creating the object (querying get_landmarks or get_landmarks_of_type ). s ( float - meters ) Distance where the landmark is positioned along the geometry of the road road_id . t ( float - meters ) Lateral distance where the landmark is positioned from the edge of the road road_id . id ( str ) Unique ID of the landmark in the OpenDRIVE file. name ( str ) Name of the landmark in the in the OpenDRIVE file. is_dynamic ( bool ) Indicates if the landmark has state changes over time such as traffic lights. orientation ( carla.LandmarkOrientation - degrees ) Indicates which lanes the landmark is facing towards to. z_offset ( float - meters ) Height where the landmark is placed. country ( str ) Country code where the landmark is defined (default to OpenDRIVE is Germany 2017). type ( str ) Type identificator of the landmark according to the country code. sub_type ( str ) Subtype identificator of the landmark according to the country code. value ( float ) Value printed in the signal (e.g. speed limit, maximum weight, etc). unit ( str ) Units of measurement for the attribute value . height ( float - meters ) Total height of the signal. width ( float - meters ) Total width of the signal. text ( str ) Additional text in the signal. h_offset ( float - meters ) Orientation offset of the signal relative to the the definition of road_id at s in OpenDRIVE. pitch ( float - meters ) Pitch rotation of the signal (Y-axis in UE coordinates system ). roll ( float ) Roll rotation of the signal (X-axis in UE coordinates system ). waypoint ( carla.Waypoint ) A waypoint placed in the lane of the one that made the query and at the s of the landmark. It is the first waypoint for which the landmark will be effective. transform ( carla.Transform ) The location and orientation of the landmark in the simulation. Methods Getters get_lane_validities ( self ) Returns which lanes the landmark is affecting to. As there may be specific lanes where the landmark is not effective, the return is a list of pairs containing ranges of the lane_id affected: Example: In a road with 5 lanes, being 3 not affected: [(from_lane1,to_lane2),(from_lane4,to_lane5)] . Return: list(tuple(int)) carla.LandmarkOrientation Helper class to define the orientation of a landmark in the road. The definition is not directly translated from OpenDRIVE but converted for the sake of understanding. Instance Variables Positive The landmark faces towards vehicles going on the same direction as the road's geometry definition (lanes 0 and negative in OpenDRIVE). Negative The landmark faces towards vehicles going on the opposite direction to the road's geometry definition (positive lanes in OpenDRIVE). Both Affects vehicles going in both directions of the road. carla.LandmarkType Helper class containing a set of commonly used landmark types as defined by the default country code in the OpenDRIVE standard (Germany 2017). carla.Landmark does not reference this class . The landmark type is a string that varies greatly depending on the country code being used. This class only makes it easier to manage some of the most commonly used in the default set by describing them as an enum. Instance Variables Danger Type 101. LanesMerging Type 121. CautionPedestrian Type 133. CautionBicycle Type 138. LevelCrossing Type 150. StopSign Type 206. YieldSign Type 205. MandatoryTurnDirection Type 209. MandatoryLeftRightDirection Type 211. TwoChoiceTurnDirection Type 214. Roundabout Type 215. PassRightLeft Type 222. AccessForbidden Type 250. AccessForbiddenMotorvehicles Type 251. AccessForbiddenTrucks Type 253. AccessForbiddenBicycle Type 254. AccessForbiddenWeight Type 263. AccessForbiddenWidth Type 264. AccessForbiddenHeight Type 265. AccessForbiddenWrongDirection Type 267. ForbiddenUTurn Type 272. MaximumSpeed Type 274. ForbiddenOvertakingMotorvehicles Type 276. ForbiddenOvertakingTrucks Type 277. AbsoluteNoStop Type 283. RestrictedStop Type 286. HasWayNextIntersection Type 301. PriorityWay Type 306. PriorityWayEnd Type 307. CityBegin Type 310. CityEnd Type 311. Highway Type 330. DeadEnd Type 357. RecomendedSpeed Type 380. RecomendedSpeedEnd Type 381. carla.LaneChange Class that defines the permission to turn either left, right, both or none (meaning only going straight is allowed). This information is stored for every carla.Waypoint according to the OpenDRIVE file. The snipet in carla.Map.get_waypoint shows how a waypoint can be used to learn which turns are permitted. Instance Variables NONE Traffic rules do not allow turning right or left, only going straight. Right Traffic rules allow turning right. Left Traffic rules allow turning left. Both Traffic rules allow turning either right or left. carla.LaneInvasionEvent Inherited from carla.SensorData Class that defines lanes invasion for sensor.other.lane_invasion . It works only client-side and is dependant on OpenDRIVE to provide reliable information. The sensor creates one of this every time there is a lane invasion, which may be more than once per simulation step. Learn more about this here . Instance Variables actor ( carla.Actor ) Gets the actor the sensor is attached to, the one that invaded another lane. crossed_lane_markings ( list( carla.LaneMarking ) ) List of lane markings that have been crossed and detected by the sensor. Methods Dunder methods __str__ ( self ) carla.LaneMarking Class that gathers all the information regarding a lane marking according to OpenDRIVE 1.4 standard standard. Instance Variables color ( carla.LaneMarkingColor ) Actual color of the marking. lane_change ( carla.LaneChange ) Permissions for said lane marking to be crossed. type ( carla.LaneMarkingType ) Lane marking type. width ( float ) Horizontal lane marking thickness. carla.LaneMarkingColor Class that defines the lane marking colors according to OpenDRIVE 1.4. Instance Variables Standard White by default. Blue Green Red White Yellow Other carla.LaneMarkingType Class that defines the lane marking types accepted by OpenDRIVE 1.4. The snipet in carla.Map.get_waypoint shows how a waypoint can be used to retrieve the information about adjacent lane markings. Note on double types: Lane markings are defined under the OpenDRIVE standard that determines whereas a line will be considered \"BrokenSolid\" or \"SolidBroken\". For each road there is a center lane marking, defined from left to right regarding the lane's directions. The rest of the lane markings are defined in order from the center lane to the closest outside of the road. Instance Variables NONE Other Broken Solid SolidSolid SolidBroken BrokenSolid BrokenBroken BottsDots Grass Curb carla.LaneType Class that defines the possible lane types accepted by OpenDRIVE 1.4. This standards define the road information. The snipet in carla.Map.get_waypoint makes use of a waypoint to get the current and adjacent lane types. Instance Variables NONE Driving Stop Shoulder Biking Sidewalk Border Restricted Parking Bidirectional Median Special1 Special2 Special3 RoadWorks Tram Rail Entry Exit OffRamp OnRamp Any Every type except for NONE. carla.LidarDetection Data contained inside a carla.LidarMeasurement . Each of these represents one of the points in the cloud with its location and its asociated intensity. Instance Variables point ( carla.Location - meters ) Point in xyz coordinates. intensity ( float ) Computed intensity for this point as a scalar value between [0.0 , 1.0]. Methods Dunder methods __str__ ( self ) carla.LidarMeasurement Inherited from carla.SensorData Class that defines the LIDAR data retrieved by a sensor.lidar.ray_cast . This essentially simulates a rotating LIDAR using ray-casting. Learn more about this here . Instance Variables channels ( int ) Number of lasers shot. horizontal_angle ( float - radians ) Horizontal angle the LIDAR is rotated at the time of the measurement. raw_data ( bytes ) Received list of 4D points. Each point consists of [x,y,z] coordiantes plus the intensity computed for that point. Methods save_to_disk ( self , path ) Saves the point cloud to disk as a .ply file describing data from 3D scanners. The files generated are ready to be used within MeshLab , an open source system for processing said files. Just take into account that axis may differ from Unreal Engine and so, need to be reallocated. Parameters: path ( str ) Getters get_point_count ( self , channel ) Retrieves the number of points sorted by channel that are generated by this measure. Sorting by channel allows to identify the original channel for every point. Parameters: channel ( int ) Dunder methods __getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.LidarDetection retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , detection = carla.LidarDetection ) __str__ ( self ) carla.Light This class exposes the lights that exist in the scene, except for vehicle lights. The properties of a light can be queried and changed at will. Lights are automatically turned on when the simulator enters night mode (sun altitude is below zero). Instance Variables color ( carla.Color ) Color of the light. id ( int ) Identifier of the light. intensity ( float - lumens ) Intensity of the light. is_on ( bool ) Switch of the light. It is True when the light is on. When the night mode starts, this is set to True . location ( carla.Location - meters ) Position of the light. light_group ( carla.LightGroup ) Group the light belongs to. light_state ( carla.LightState ) State of the light. Summarizes its attributes, group, and if it is on/off. Methods turn_off ( self ) Switches off the light. turn_on ( self ) Switches on the light. Setters set_color ( self , color ) Changes the color of the light to color . Parameters: color ( carla.Color ) set_intensity ( self , intensity ) Changes the intensity of the light to intensity . Parameters: intensity ( float - lumens ) set_light_group ( self , light_group ) Changes the light to the group light_group . Parameters: light_group ( carla.LightGroup ) set_light_state ( self , light_state ) Changes the state of the light to light_state . This may change attributes, group and turn the light on/off all at once. Parameters: light_state ( carla.LightState ) carla.LightGroup This class categorizes the lights on scene into different groups. These groups available are provided as a enum values that can be used as flags. Note. So far, though there is a vehicle group, vehicle lights are not available as carla.Light objects. These have to be managed using carla.Vehicle and carla.VehicleLightState . Instance Variables None All lights. Vehicle Street Building Other carla.LightManager This class handles the lights in the scene. Its main use is to get and set the state of groups or lists of lights in one call. An instance of this class can be retrieved by the carla.World.get_lightmanager (). Note. So far, though there is a vehicle group, vehicle lights are not available as carla.Light objects. These have to be managed using carla.Vehicle and carla.VehicleLightState . Methods is_active ( self , lights ) Returns a list with booleans stating if the elements in lights are switched on/off. Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list(bool) turn_off ( self , lights ) Switches off all the lights in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be switched off. turn_on ( self , lights ) Switches on all the lights in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be switched on. Getters get_all_lights ( self , light_group = carla.LightGroup.None ) Returns a list containing the lights in a certain group. By default, the group is None . Parameters: light_group ( carla.LightGroup ) - Group to filter the lights returned. Default is None . Return: list( carla.Light ) get_color ( self , lights ) Returns a list with the colors of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list( carla.Color ) Setter: carla.LightManager.set_color get_intensity ( self , lights ) Returns a list with the intensity of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list(float) - lumens Setter: carla.LightManager.set_intensity get_light_group ( self , lights ) Returns a list with the group of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list( carla.LightGroup ) Setter: carla.LightManager.set_light_group get_light_state ( self , lights ) Returns a list with the state of all the attributes of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list( carla.LightState ) Setter: carla.LightManager.set_light_state get_turned_off_lights ( self , light_group ) Returns a list containing lights switched off in the scene, filtered by group. Parameters: light_group ( carla.LightGroup ) - List of lights to be queried. Return: list( carla.Light ) get_turned_on_lights ( self , light_group ) Returns a list containing lights switched on in the scene, filtered by group. Parameters: light_group ( carla.LightGroup ) - List of lights to be queried. Return: list( carla.Light ) Setters set_active ( self , lights , active ) Switches on/off the elements in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be switched on/off. active ( list(bool) ) - List of booleans to be applied. set_color ( self , lights , color ) Changes the color of the elements in lights to color . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. color ( carla.Color ) - Color to be applied. Getter: carla.LightManager.get_color set_colors ( self , lights , colors ) Changes the color of each element in lights to the corresponding in colors . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. colors ( list( carla.Color ) ) - List of colors to be applied. set_intensities ( self , lights , intensities ) Changes the intensity of each element in lights to the corresponding in intensities . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. intensities ( list(float) - lumens ) - List of intensities to be applied. set_intensity ( self , lights , intensity ) Changes the intensity of every element in lights to intensity . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. intensity ( float - lumens ) - Intensity to be applied. Getter: carla.LightManager.get_intensity set_light_group ( self , lights , light_group ) Changes the group of every element in lights to light_group . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_group ( carla.LightGroup ) - Group to be applied. Getter: carla.LightManager.get_light_group set_light_groups ( self , lights , light_groups ) Changes the group of each element in lights to the corresponding in light_groups . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_groups ( list( carla.LightGroup ) ) - List of groups to be applied. set_light_state ( self , lights , light_state ) Changes the state of the attributes of every element in lights to light_state . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_state ( carla.LightState ) - State of the attributes to be applied. Getter: carla.LightManager.get_light_state set_light_states ( self , lights , light_states ) Changes the state of the attributes of each element in lights to the corresponding in light_states . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_states ( list( carla.LightState ) ) - List of state of the attributes to be applied. carla.LightState This class represents all the light variables except the identifier and the location, which are should to be static. Using this class allows to manage all the parametrization of the light in one call. Instance Variables intensity ( float - lumens ) Intensity of a light. color ( carla.Color ) Color of a light. group ( carla.LightGroup ) Group a light belongs to. active ( bool ) Switch of a light. It is True when the light is on. Methods __init__ ( self , intensity =0.0 , color = carla.Color () , group = carla.LightGroup.None , active =False ) Parameters: intensity ( float - lumens ) - Intensity of the light. Default is 0.0 . color ( carla.Color ) - Color of the light. Default is black. group ( carla.LightGroup ) - Group the light belongs to. Default is the generic group None . active ( bool ) - Swith of the light. Default is False , light is off. carla.Location Inherited from carla.Vector3D Represents a spot in the world. Instance Variables x ( float - meters ) Distance from origin to spot on X axis. y ( float - meters ) Distance from origin to spot on Y axis. z ( float - meters ) Distance from origin to spot on Z axis. Methods __init__ ( self , x =0.0 , y =0.0 , z =0.0 ) Parameters: x ( float ) y ( float ) z ( float ) distance ( self , location ) Returns Euclidean distance from this location to another one. Parameters: location ( carla.Location ) - The other point to compute the distance with. Return: float - meters Dunder methods __abs__ ( self ) Returns a Location with the absolute value of the components x, y and z. Return: carla.Location __eq__ ( self , other = carla.Location ) Returns True if both locations are the same point in space. Return: bool __ne__ ( self , other = carla.Location ) Returns True if both locations are different points in space. Return: bool __str__ ( self ) Parses the axis' values to string. Return: str carla.Map Class containing the road information and waypoint managing. Data is retrieved from an OpenDRIVE file that describes the road. A query system is defined which works hand in hand with carla.Waypoint to translate geometrical information from the .xodr to natural world points. CARLA is currently working with OpenDRIVE 1.4 standard . Instance Variables name ( str ) The name of the map. It corresponds to the .umap from Unreal Engine that is loaded from a CARLA server, which then references to the .xodr road description. Methods __init__ ( self , name , xodr_content ) Constructor for this class. Though a map is automatically generated when initializing the world, using this method in no-rendering mode facilitates working with an .xodr without any CARLA server running. Parameters: name ( str ) - Name of the current map. xodr_content ( str ) - .xodr content in string format. Return: list( carla.Transform ) generate_waypoints ( self , distance ) Returns a list of waypoints with a certain distance between them for every lane and centered inside of it. Waypoints are not listed in any particular order. Remember that waypoints closer than 2cm within the same road, section and lane will have the same identificator. Parameters: distance ( float - meters ) - Approximate distance between waypoints. Return: list( carla.Waypoint ) save_to_disk ( self , path ) Saves the .xodr OpenDRIVE file of the current map to disk. Parameters: path - Path where the file will be saved. to_opendrive ( self ) Returns the .xodr OpenDRIVe file of the current map as string. Return: str transform_to_geolocation ( self , location ) Converts a given location , a point in the simulation, to a carla.GeoLocation , which represents world coordinates. The geographical location of the map is defined inside OpenDRIVE within the tag . Parameters: location ( carla.Location ) Return: carla.GeoLocation Getters get_all_landmarks ( self ) Returns all the landmarks in the map. Landmarks retrieved using this method have a null waypoint. Return: list( carla.Landmark ) get_all_landmarks_from_id ( self , opendrive_id ) Returns the landmarks with a certain OpenDRIVE ID. Landmarks retrieved using this method have a null waypoint. Parameters: opendrive_id ( string ) - The OpenDRIVE ID of the landmarks. Return: list( carla.Landmark ) get_all_landmarks_of_type ( self , type ) Returns the landmarks of a specific type. Landmarks retrieved using this method have a null waypoint. Parameters: type ( string ) - The type of the landmarks. Return: list( carla.Landmark ) get_crosswalks ( self ) Returns a list of locations with all crosswalk zones in the form of closed polygons. The first point is repeated, symbolizing where the polygon begins and ends. Return: list( carla.Location ) get_landmark_group ( self , landmark ) Returns the landmarks in the same group as the specified landmark (including itself). Returns an empty list if the landmark does not belong to any group. Parameters: landmark ( carla.Landmark ) - A landmark that belongs to the group. Return: list( carla.Landmark ) get_spawn_points ( self ) Returns a list of recommendations made by the creators of the map to be used as spawning points for the vehicles. The list includes carla.Transform objects with certain location and orientation. Said locations are slightly on-air in order to avoid Z-collisions, so vehicles fall for a bit before starting their way. Return: list( carla.Transform ) get_topology ( self ) Returns a list of tuples describing a minimal graph of the topology of the OpenDRIVE file. The tuples contain pairs of waypoints located either at the point a road begins or ends. The first one is the origin and the second one represents another road end that can be reached. This graph can be loaded into NetworkX to work with. Output could look like this: [(w0, w1), (w0, w2), (w1, w3), (w2, w3), (w0, w4)] . Return: list(tuple( carla.Waypoint , carla.Waypoint )) get_waypoint ( self , location , project_to_road =True , lane_type = carla.LaneType.Driving ) snippet \u2192 Returns a waypoint that can be located in an exact location or translated to the center of the nearest lane. Said lane type can be defined using flags such as LaneType.Driving & LaneType.Shoulder . The method will return None if the waypoint is not found, which may happen only when trying to retrieve a waypoint for an exact location. That eases checking if a point is inside a certain road, as otherwise, it will return the corresponding waypoint. Parameters: location ( carla.Location - meters ) - Location used as reference for the carla.Waypoint . project_to_road ( bool ) - If True , the waypoint will be at the center of the closest lane. This is the default setting. If False , the waypoint will be exactly in location . None means said location does not belong to a road. lane_type ( carla.LaneType ) - Limits the search for nearest lane to one or various lane types that can be flagged. Return: carla.Waypoint get_waypoint_xodr ( self , road_id , lane_id , s ) Returns a waypoint if all the parameters passed are correct. Otherwise, returns None . Parameters: road_id ( int ) - ID of the road to get the waypoint. lane_id ( int ) - ID of the lane to get the waypoint. s ( float - meters ) - Specify the length from the road start. Return: carla.Waypoint Dunder methods __str__ ( self ) carla.MapLayer Class that represents each manageable layer of the map. Can be used as flags. WARNING: Only \"Opt\" maps are able to work with map layers. . Instance Variables NONE No layers selected. Buildings Decals Foliage Ground ParkedVehicles Particles Props StreetLights Walls All All layers selected. carla.MaterialParameter Class that represents material parameters. Not all objects in the scene contain all parameters. Instance Variables Normal The Normal map of the object. Present in all objects. Diffuse The Diffuse texture of the object. Present in all objects. AO_Roughness_Metallic_Emissive A texture where each color channel represent a property of the material (R: Ambien oclusion, G: Roughness, B: Metallic, A: Emissive/Height map in some objects). Emissive Emissive texture. Present in a few objects. carla.ObstacleDetectionEvent Inherited from carla.SensorData Class that defines the obstacle data for sensor.other.obstacle . Learn more about this here . Instance Variables actor ( carla.Actor ) The actor the sensor is attached to. other_actor ( carla.Actor ) The actor or object considered to be an obstacle. distance ( float - meters ) Distance between actor and other . Methods Dunder methods __str__ ( self ) carla.OpendriveGenerationParameters This class defines the parameters used when generating a world using an OpenDRIVE file. Instance Variables vertex_distance ( float ) Distance between vertices of the mesh generated. Default is 2.0 . max_road_length ( float ) Max road length for a single mesh portion. The mesh of the map is divided into portions, in order to avoid propagating issues. Default is 50.0 . wall_height ( float ) Height of walls created on the boundaries of the road. These prevent vehicles from falling off the road. Default is 1.0 . additional_width ( float ) Additional with applied junction lanes. Complex situations tend to occur at junctions, and a little increase can prevent vehicles from falling off the road. Default is 0.6 . smooth_junctions ( bool ) If True , the mesh at junctions will be smoothed to prevent issues where roads blocked other roads. Default is True . enable_mesh_visibility ( bool ) If True , the road mesh will be rendered. Setting this to False should reduce the rendering overhead. Default is True . enable_pedestrian_navigation ( bool ) If True , Pedestrian navigation will be enabled using Recast tool. For very large maps it is recomended to disable this option. Default is True . carla.OpticalFlowImage Inherited from carla.SensorData Class that defines an optical flow image of 2-Dimension float (32-bit) vectors representing the optical flow detected in the field of view. The components of the vector represents the displacement of an object in the image plane. Each component outputs values in the normalized range [-2,2] which scales to [-2 size, 2 size] with size being the total resolution in the corresponding component. Instance Variables fov ( float - degrees ) Horizontal field of view of the image. height ( int ) Image height in pixels. width ( int ) Image width in pixels. raw_data ( bytes ) Methods Getters get_color_coded_flow ( self ) Visualization helper. Converts the optical flow image to an RGB image. Return: carla.Image Dunder methods __getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.OpticalFlowPixel that form the image. __len__ ( self ) __setitem__ ( self , pos =int , color = carla.Color ) __str__ ( self ) carla.OpticalFlowPixel Class that defines a 2 dimensional vector representing an optical flow pixel. Instance Variables x ( float ) Optical flow in the x component. y ( float ) Optical flow in the y component. Methods __init__ ( self , x =0 , y =0 ) Initializes the Optical Flow Pixel. Zero by default. Parameters: x ( float ) y ( float ) Dunder methods __eq__ ( self , other = carla.OpticalFlowPixel ) __ne__ ( self , other = carla.OpticalFlowPixel ) __str__ ( self ) carla.Osm2Odr Class that converts an OpenStreetMap map to OpenDRIVE format, so that it can be loaded in CARLA. Find out more about this feature in the docs . Methods convert ( osm_file , settings ) Takes the content of an .osm file (OpenStreetMap format) and returns the content of the .xodr (OpenDRIVE format) describing said map. Some parameterization is passed to do the conversion. Parameters: osm_file ( str ) - The content of the input OpenStreetMap file parsed as string. settings ( carla.OSM2ODRSettings ) - Parameterization for the conversion. Return: str carla.Osm2OdrSettings Helper class that contains the parameterization that will be used by carla.Osm2Odr to convert an OpenStreetMap map to OpenDRIVE format. Find out more about this feature in the docs . Instance Variables use_offsets ( bool ) Enables the use of offset for the conversion. The offset will move the origin position of the map. Default value is False . offset_x ( float - meters ) Offset in the X axis. Default value is 0.0 . offset_y ( float - meters ) Offset in the Y axis. Default value is 0.0 . default_lane_width ( float - meters ) Width of the lanes described in the resulting XODR map. Default value is 4.0 . elevation_layer_height ( float - meters ) Defines the height separating two different OpenStreetMap layers . Default value is 0.0 . center_map ( bool ) When this option is enabled, the geometry of the map will be displaced so that the origin of coordinates matches the center of the bounding box of the entire road map. proj_string ( str ) Defines the proj4 string that will be used to compute the projection from geocoordinates to cartesian coordinates. This string will be written in the resulting OpenDRIVE unless the options use_offsets or center_map are enabled as these options override some of the definitions in the string. generate_traffic_lights ( bool ) Indicates wether to generate traffic light data in the OpenDRIVE. Road types defined by set_traffic_light_excluded_way_types(way_types) will not generate traffic lights. all_junctions_with_traffic_lights ( bool ) When disabled, the converter will generate traffic light data from the OpenStreetMaps data only. When enabled, all junctions will generate traffic lights. Methods Setters set_osm_way_types ( self , way_types ) Defines the OpenStreetMaps road types that will be imported to OpenDRIVE. By default the road types imported are motorway, motorway_link, trunk, trunk_link, primary, primary_link, secondary, secondary_link, tertiary, tertiary_link, unclassified, residential . For a full list of road types check here . Parameters: way_types ( list(str) ) - The list of road types. set_traffic_light_excluded_way_types ( self , way_types ) Defines the OpenStreetMaps road types that will not generate traffic lights even if generate_traffic_lights is enabled. By default the road types excluded are motorway_link, primary_link, secondary_link, tertiary_link . Parameters: way_types ( list(str) ) - The list of road types. carla.RadarDetection Data contained inside a carla.RadarMeasurement . Each of these represents one of the points in the cloud that a sensor.other.radar registers and contains the distance, angle and velocity in relation to the radar. Instance Variables altitude ( float - radians ) Altitude angle of the detection. azimuth ( float - radians ) Azimuth angle of the detection. depth ( float - meters ) Distance from the sensor to the detection position. velocity ( float - m/s ) The velocity of the detected object towards the sensor. Methods Dunder methods __str__ ( self ) carla.RadarMeasurement Inherited from carla.SensorData Class that defines and gathers the measures registered by a sensor.other.radar , representing a wall of points in front of the sensor with a distance, angle and velocity in relation to it. The data consists of a carla.RadarDetection array. Learn more about this here . Instance Variables raw_data ( bytes ) The complete information of the carla.RadarDetection the radar has registered. Methods Getters get_detection_count ( self ) Retrieves the number of entries generated, same as __str__() . Dunder methods __getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.RadarDetection retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , detection = carla.RadarDetection ) __str__ ( self ) carla.Rotation Class that represents a 3D rotation and therefore, an orientation in space. CARLA uses the Unreal Engine coordinates system. This is a Z-up left-handed system. The constructor method follows a specific order of declaration: (pitch, yaw, roll) , which corresponds to (Y-rotation,Z-rotation,X-rotation) . Unreal Engine's coordinates system . Instance Variables pitch ( float - degrees ) Y-axis rotation angle. yaw ( float - degrees ) Z-axis rotation angle. roll ( float - degrees ) X-axis rotation angle. Methods __init__ ( self , pitch =0.0 , yaw =0.0 , roll =0.0 ) Parameters: pitch ( float - degrees ) - Y-axis rotation angle. yaw ( float - degrees ) - Z-axis rotation angle. roll ( float - degrees ) - X-axis rotation angle. Warning: The declaration order is different in CARLA (pitch,yaw,roll) , and in the Unreal Engine Editor (roll,pitch,yaw) . When working in a build from source, don't mix up the axes' rotations. Getters get_forward_vector ( self ) Computes the vector pointing forward according to the rotation of the object. Return: carla.Vector3D get_right_vector ( self ) Computes the vector pointing to the right according to the rotation of the object. Return: carla.Vector3D get_up_vector ( self ) Computes the vector pointing upwards according to the rotation of the object. Return: carla.Vector3D Dunder methods __eq__ ( self , other = carla.Rotation ) Returns True if both rotations represent the same orientation for every axis. Return: bool __ne__ ( self , other = carla.Rotation ) Returns True if both rotations represent the same orientation for every axis. Return: bool __str__ ( self ) Parses the axis' orientations to string. carla.RssActorConstellationData Data structure that is provided within the callback registered by RssSensor.register_actor_constellation_callback(). Instance Variables ego_match_object ( ad.map.match.Object ) The ego map matched information. ego_route ( ad.map.route.FullRoute ) The ego route. ego_dynamics_on_route ( carla.RssEgoDynamicsOnRoute ) Current ego vehicle dynamics regarding the route. other_match_object ( ad.map.match.Object ) The other object's map matched information. This is only valid if 'other_actor' is not 'None'. other_actor ( carla.Actor ) The other actor. This is 'None' in case of query of default parameters or articial objects of kind ad.rss.world.ObjectType.ArtificialObject with no dedicated ' carla.Actor ' (as e.g. for the road boundaries at the moment). Methods Dunder methods __str__ ( self ) carla.RssActorConstellationResult Data structure that should be returned by the callback registered by RssSensor.register_actor_constellation_callback(). Instance Variables rss_calculation_mode ( ad.rss.map.RssMode ) The calculation mode to be applied with the actor. restrict_speed_limit_mode ( ad.rss.map.RestrictSpeedLimitMode ) The mode for restricting speed limit. ego_vehicle_dynamics ( ad.rss.world.RssDynamics ) The RSS dynamics to be applied for the ego vehicle. actor_object_type ( ad.rss.world.ObjectType ) The RSS object type to be used for the actor. actor_dynamics ( ad.rss.world.RssDynamics ) The RSS dynamics to be applied for the actor. Methods Dunder methods __str__ ( self ) carla.RssEgoDynamicsOnRoute Part of the data contained inside a carla.RssResponse describing the state of the vehicle. The parameters include its current dynamics, and how it is heading regarding the target route. Instance Variables ego_speed ( ad.physics.Speed ) The ego vehicle's speed. min_stopping_distance ( ad.physics.Distance ) The current minimum stopping distance. ego_center ( ad.map.point.ENUPoint ) The considered enu position of the ego vehicle. ego_heading ( ad.map.point.ENUHeading ) The considered heading of the ego vehicle. ego_center_within_route ( bool ) States if the ego vehicle's center is within the route. crossing_border ( bool ) States if the vehicle is already crossing one of the lane borders. route_heading ( ad.map.point.ENUHeading ) The considered heading of the route. route_nominal_center ( ad.map.point.ENUPoint ) The considered nominal center of the current route. heading_diff ( ad.map.point.ENUHeading ) The considered heading diff towards the route. route_speed_lat ( ad.physics.Speed ) The ego vehicle's speed component lat regarding the route. route_speed_lon ( ad.physics.Speed ) The ego vehicle's speed component lon regarding the route. route_accel_lat ( ad.physics.Acceleration ) The ego vehicle's acceleration component lat regarding the route. route_accel_lon ( ad.physics.Acceleration ) The ego vehicle's acceleration component lon regarding the route. avg_route_accel_lat ( ad.physics.Acceleration ) The ego vehicle's acceleration component lat regarding the route smoothened by an average filter. avg_route_accel_lon ( ad.physics.Acceleration ) The ego acceleration component lon regarding the route smoothened by an average filter. Methods Dunder methods __str__ ( self ) carla.RssLogLevel Enum declaration used in carla.RssSensor to set the log level. Instance Variables trace debug info warn err critical off carla.RssResponse Inherited from carla.SensorData Class that contains the output of a carla.RssSensor . This is the result of the RSS calculations performed for the parent vehicle of the sensor. A carla.RssRestrictor will use the data to modify the carla.VehicleControl of the vehicle. Instance Variables response_valid ( bool ) States if the response is valid. It is False if calculations failed or an exception occured. proper_response ( ad.rss.state.ProperResponse ) The proper response that the RSS calculated for the vehicle. rss_state_snapshot ( ad.rss.state.RssStateSnapshot ) Detailed RSS states at the current moment in time. ego_dynamics_on_route ( carla.RssEgoDynamicsOnRoute ) Current ego vehicle dynamics regarding the route. world_model ( ad.rss.world.WorldModel ) World model used for calculations. situation_snapshot ( ad.rss.situation.SituationSnapshot ) Detailed RSS situations extracted from the world model. Methods Dunder methods __str__ ( self ) carla.RssRestrictor These objects apply restrictions to a carla.VehicleControl . It is part of the CARLA implementation of the C++ Library for Responsibility Sensitive Safety . This class works hand in hand with a rss sensor , which provides the data of the restrictions to be applied. Methods restrict_vehicle_control ( self , vehicle_control , proper_response , ego_dynamics_on_route , vehicle_physics ) Applies the safety restrictions given by a carla.RssSensor to a carla.VehicleControl . Parameters: vehicle_control ( carla.VehicleControl ) - The input vehicle control to be restricted. proper_response ( ad.rss.state.ProperResponse ) - Part of the response generated by the sensor. Contains restrictions to be applied to the acceleration of the vehicle. ego_dynamics_on_route ( carla.RssEgoDynamicsOnRoute ) - Part of the response generated by the sensor. Contains dynamics and heading of the vehicle regarding its route. vehicle_physics ( carla.VehiclePhysicsControl ) - The current physics of the vehicle. Used to apply the restrictions properly. Return: carla.VehicleControl Setters set_log_level ( self , log_level ) Sets the log level. Parameters: log_level ( carla.RssLogLevel ) - New log level. carla.RssRoadBoundariesMode Enum declaration used in carla.RssSensor to enable or disable the stay on road feature. In summary, this feature considers the road boundaries as virtual objects. The minimum safety distance check is applied to these virtual walls, in order to make sure the vehicle does not drive off the road. Instance Variables On Enables the stay on road feature. Off Disables the stay on road feature. carla.RssSensor Inherited from carla.Sensor This sensor works a bit differently than the rest. Take look at the specific documentation , and the rss sensor reference to gain full understanding of it. The RSS sensor uses world information, and a RSS library to make safety checks on a vehicle. The output retrieved by the sensor is a carla.RssResponse . This will be used by a carla.RssRestrictor to modify a carla.VehicleControl before applying it to a vehicle. Instance Variables ego_vehicle_dynamics ( ad.rss.world.RssDynamics ) States the RSS parameters that the sensor will consider for the ego vehicle if no actor constellation callback is registered. other_vehicle_dynamics ( ad.rss.world.RssDynamics ) States the RSS parameters that the sensor will consider for the rest of vehicles if no actor constellation callback is registered. pedestrian_dynamics ( ad.rss.world.RssDynamics ) States the RSS parameters that the sensor will consider for pedestrians if no actor constellation callback is registered. road_boundaries_mode ( carla.RssRoadBoundariesMode ) Switches the stay on road feature. By default is Off . routing_targets ( vector< carla.Transform > ) The current list of targets considered to route the vehicle. If no routing targets are defined, a route is generated at random. Methods append_routing_target ( self , routing_target ) Appends a new target position to the current route of the vehicle. Parameters: routing_target ( carla.Transform ) - New target point for the route. Choose these after the intersections to force the route to take the desired turn. drop_route ( self ) Discards the current route. If there are targets remaining in routing_targets , creates a new route using those. Otherwise, a new route is created at random. register_actor_constellation_callback ( self , callback ) Register a callback to customize a carla.RssActorConstellationResult . By this callback the settings of RSS parameters are done per actor constellation and the settings (ego_vehicle_dynamics, other_vehicle_dynamics and pedestrian_dynamics) have no effect. Parameters: callback - The function to be called whenever a RSS situation is about to be calculated. reset_routing_targets ( self ) Erases the targets that have been appended to the route. Setters set_log_level ( self , log_level ) Sets the log level. Parameters: log_level ( carla.RssLogLevel ) - New log level. set_map_log_level ( self , log_level ) Sets the map log level. Parameters: log_level ( carla.RssLogLevel ) - New map log level. Dunder methods __str__ ( self ) carla.SemanticLidarDetection Data contained inside a carla.SemanticLidarMeasurement . Each of these represents one of the points in the cloud with its location, the cosine of the incident angle, index of the object hit, and its semantic tag. Instance Variables point ( carla.Location - meters ) [x,y,z] coordinates of the point. cos_inc_angle ( float ) Cosine of the incident angle between the ray, and the normal of the hit object. object_idx ( uint ) ID of the actor hit by the ray. object_tag ( uint ) Semantic tag of the component hit by the ray. Methods Dunder methods __str__ ( self ) carla.SemanticLidarMeasurement Inherited from carla.SensorData Class that defines the semantic LIDAR data retrieved by a sensor.lidar.ray_cast_semantic . This essentially simulates a rotating LIDAR using ray-casting. Learn more about this here . Instance Variables channels ( int ) Number of lasers shot. horizontal_angle ( float - radians ) Horizontal angle the LIDAR is rotated at the time of the measurement. raw_data ( bytes ) Received list of raw detection points. Each point consists of [x,y,z] coordinates plus the cosine of the incident angle, the index of the hit actor, and its semantic tag. Methods save_to_disk ( self , path ) Saves the point cloud to disk as a .ply file describing data from 3D scanners. The files generated are ready to be used within MeshLab , an open-source system for processing said files. Just take into account that axis may differ from Unreal Engine and so, need to be reallocated. Parameters: path ( str ) Getters get_point_count ( self , channel ) Retrieves the number of points sorted by channel that are generated by this measure. Sorting by channel allows to identify the original channel for every point. Parameters: channel ( int ) Dunder methods __getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.SemanticLidarDetection retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , detection = carla.SemanticLidarDetection ) __str__ ( self ) carla.Sensor Inherited from carla.Actor Sensors compound a specific family of actors quite diverse and unique. They are normally spawned as attachment/sons of a vehicle (take a look at carla.World to learn about actor spawning). Sensors are thoroughly designed to retrieve different types of data that they are listening to. The data they receive is shaped as different subclasses inherited from carla.SensorData (depending on the sensor). Most sensors can be divided in two groups: those receiving data on every tick (cameras, point clouds and some specific sensors) and those who only receive under certain circumstances (trigger detectors). CARLA provides a specific set of sensors and their blueprint can be found in carla.BlueprintLibrary . All the information on their preferences and settlement can be found here , but the list of those available in CARLA so far goes as follow. Receive data on every tick. - Depth camera . - Gnss sensor . - IMU sensor . - Lidar raycast . - SemanticLidar raycast . - Radar . - RGB camera . - RSS sensor . - Semantic Segmentation camera . Only receive data when triggered. - Collision detector . - Lane invasion detector . - Obstacle detector . Instance Variables is_listening ( boolean ) When True the sensor will be waiting for data. Methods listen ( self , callback ) snippet \u2192 The function the sensor will be calling to every time a new measurement is received. This function needs for an argument containing an object type carla.SensorData to work with. Parameters: callback ( function ) - The called function with one argument containing the sensor data. stop ( self ) Commands the sensor to stop listening for data. Dunder methods __str__ ( self ) carla.SensorData Base class for all the objects containing data generated by a carla.Sensor . This objects should be the argument of the function said sensor is listening to, in order to work with them. Each of these sensors needs for a specific type of sensor data. Hereunder is a list of the sensors and their corresponding data. - Cameras (RGB, depth and semantic segmentation): carla.Image . - Collision detector: carla.CollisionEvent . - GNSS sensor: carla.GnssMeasurement . - IMU sensor: carla.IMUMeasurement . - Lane invasion detector: carla.LaneInvasionEvent . - LIDAR sensor: carla.LidarMeasurement . - Obstacle detector: carla.ObstacleDetectionEvent . - Radar sensor: carla.RadarMeasurement . - RSS sensor: carla.RssResponse . - Semantic LIDAR sensor: carla.SemanticLidarMeasurement . Instance Variables frame ( int ) Frame count when the data was generated. timestamp ( float - seconds ) Simulation-time when the data was generated. transform ( carla.Transform ) Sensor's transform when the data was generated. carla.TextureColor Class representing a texture object to be uploaded to the server. Pixel format is RGBA, uint8 per channel. Instance Variables width ( int ) X-coordinate size of the texture. height ( int ) Y-coordinate size of the texture. Methods __init__ ( self , width , height ) Initializes a the texture with a ( width , height ) size. Parameters: width ( int ) height ( int ) get ( self , x , y ) Get the (x,y) pixel data. Parameters: x ( int ) y ( int ) Return: carla.Color set ( self , x , y , value ) Sets the (x,y) pixel data with value . Parameters: x ( int ) y ( int ) value ( carla.Color ) Setters set_dimensions ( self , width , height ) Resizes the texture to te specified dimensions. Parameters: width ( int ) height ( int ) carla.TextureFloatColor Class representing a texture object to be uploaded to the server. Pixel format is RGBA, float per channel. Instance Variables width ( int ) X-coordinate size of the texture. height ( int ) Y-coordinate size of the texture. Methods __init__ ( self , width , height ) Initializes a the texture with a ( width , height ) size. Parameters: width ( int ) height ( int ) get ( self , x , y ) Get the (x,y) pixel data. Parameters: x ( int ) y ( int ) Return: carla.FloatColor set ( self , x , y , value ) Sets the (x,y) pixel data with value . Parameters: x ( int ) y ( int ) value ( carla.FloatColor ) Setters set_dimensions ( self , width , height ) Resizes the texture to te specified dimensions. Parameters: width ( int ) height ( int ) carla.Timestamp Class that contains time information for simulated data. This information is automatically retrieved as part of the carla.WorldSnapshot the client gets on every frame, but might also be used in many other situations such as a carla.Sensor retrieveing data. Instance Variables frame ( int ) The number of frames elapsed since the simulator was launched. elapsed_seconds ( float - seconds ) Simulated seconds elapsed since the beginning of the current episode. delta_seconds ( float - seconds ) Simulated seconds elapsed since the previous frame. platform_timestamp ( float - seconds ) Time register of the frame at which this measurement was taken given by the OS in seconds. Methods __init__ ( self , frame , elapsed_seconds , delta_seconds , platform_timestamp ) Parameters: frame ( int ) elapsed_seconds ( float - seconds ) delta_seconds ( float - seconds ) platform_timestamp ( float - seconds ) Dunder methods __eq__ ( self , other = carla.Timestamp ) __ne__ ( self , other = carla.Timestamp ) __str__ ( self ) carla.TrafficLight Inherited from carla.TrafficSign A traffic light actor, considered a specific type of traffic sign. As traffic lights will mostly appear at junctions, they belong to a group which contains the different traffic lights in it. Inside the group, traffic lights are differenciated by their pole index. Within a group the state of traffic lights is changed in a cyclic pattern: one index is chosen and it spends a few seconds in green, yellow and eventually red. The rest of the traffic lights remain frozen in red this whole time, meaning that there is a gap in the last seconds of the cycle where all the traffic lights are red. However, the state of a traffic light can be changed manually. Instance Variables state ( carla.TrafficLightState ) Current state of the traffic light. Methods freeze ( self , freeze ) Stops all the traffic lights in the scene at their current state. Parameters: freeze ( bool ) is_frozen ( self ) The client returns True if a traffic light is frozen according to last tick. The method does not call the simulator. Return: bool reset_group ( self ) Resets the state of the traffic lights of the group to the initial state at the start of the simulation. Note: This method calls the simulator. Getters get_affected_lane_waypoints ( self ) Returns a list of waypoints indicating the positions and lanes where the traffic light is having an effect. Return: list( carla.Waypoint ) get_elapsed_time ( self ) The client returns the time in seconds since current light state started according to last tick. The method does not call the simulator. Return: float - seconds get_green_time ( self ) The client returns the time set for the traffic light to be green, according to last tick. The method does not call the simulator. Return: float - seconds Setter: carla.TrafficLight.set_green_time get_group_traffic_lights ( self ) Returns all traffic lights in the group this one belongs to. Return: list( carla.TrafficLight ) Note: This method calls the simulator. get_light_boxes ( self ) Returns a list of the bounding boxes encapsulating each light box of the traffic light. Return: list( carla.BoundingBox ) get_opendrive_id ( self ) Returns the OpenDRIVE id of this traffic light. Return: str get_pole_index ( self ) Returns the index of the pole that identifies it as part of the traffic light group of a junction. Return: int get_red_time ( self ) The client returns the time set for the traffic light to be red, according to last tick. The method does not call the simulator. Return: float - seconds Setter: carla.TrafficLight.set_red_time get_state ( self ) The client returns the state of the traffic light according to last tick. The method does not call the simulator. Return: carla.TrafficLightState Setter: carla.TrafficLight.set_state get_stop_waypoints ( self ) Returns a list of waypoints indicating the stop position for the traffic light. These waypoints are computed from the trigger boxes of the traffic light that indicate where a vehicle should stop. Return: list( carla.Waypoint ) get_yellow_time ( self ) The client returns the time set for the traffic light to be yellow, according to last tick. The method does not call the simulator. Return: float - seconds Setter: carla.TrafficLight.set_yellow_time Setters set_green_time ( self , green_time ) Parameters: green_time ( float - seconds ) - Sets a given time for the green light to be active. Getter: carla.TrafficLight.get_green_time set_red_time ( self , red_time ) Sets a given time for the red state to be active. Parameters: red_time ( float - seconds ) Getter: carla.TrafficLight.get_red_time set_state ( self , state ) snippet \u2192 Sets a given state to a traffic light actor. Parameters: state ( carla.TrafficLightState ) Getter: carla.TrafficLight.get_state set_yellow_time ( self , yellow_time ) Sets a given time for the yellow light to be active. Parameters: yellow_time ( float - seconds ) Getter: carla.TrafficLight.get_yellow_time Dunder methods __str__ ( self ) carla.TrafficLightState All possible states for traffic lights. These can either change at a specific time step or be changed manually. The snipet in carla.TrafficLight.set_state changes the state of a traffic light on the fly. Instance Variables Red Yellow Green Off Unknown carla.TrafficManager The traffic manager is a module built on top of the CARLA API in C++. It handles any group of vehicles set to autopilot mode to populate the simulation with realistic urban traffic conditions and give the chance to user to customize some behaviours. The architecture of the traffic manager is divided in five different goal-oriented stages and a PID controller where the information flows until eventually, a carla.VehicleControl is applied to every vehicle registered in a traffic manager. In order to learn more, visit the documentation regarding this module. Methods auto_lane_change ( self , actor , enable ) Turns on or off lane changing behaviour for a vehicle. Parameters: actor ( carla.Actor ) - The vehicle whose settings are changed. enable ( bool ) - True is default and enables lane changes. False will disable them. auto_update_lights ( self , actor , do_update ) Sets if the Traffic Manager is responsible of updating the vehicle lights, or not. Default is False . The traffic manager will not change the vehicle light status of a vehicle, unless its auto_update_status is st to True . Parameters: actor ( carla.Actor ) - Vehicle whose lights status is being changed. do_update ( bool ) - If True the traffic manager will manage the vehicle lights for the specified vehicle. collision_detection ( self , reference_actor , other_actor , detect_collision ) Tunes on/off collisions between a vehicle and another specific actor. In order to ignore all other vehicles, traffic lights or walkers, use the specific ignore methods described in this same section. Parameters: reference_actor ( carla.Actor ) - Vehicle that is going to ignore collisions. other_actor ( carla.Actor ) - The actor that reference_actor is going to ignore collisions with. detect_collision ( bool ) - True is default and enables collisions. False will disable them. distance_to_leading_vehicle ( self , actor , distance ) Sets the minimum distance in meters that a vehicle has to keep with the others. The distance is in meters and will affect the minimum moving distance. It is computed from front to back of the vehicle objects. Parameters: actor ( carla.Actor ) - Vehicle whose minimum distance is being changed. distance ( float - meters ) - Meters between both vehicles. force_lane_change ( self , actor , direction ) Forces a vehicle to change either to the lane on its left or right, if existing, as indicated in direction . This method applies the lane change no matter what, disregarding possible collisions. Parameters: actor ( carla.Actor ) - Vehicle being forced to change lanes. direction ( bool ) - Destination lane. True is the one on the right and False is the left one. global_percentage_speed_difference ( self , percentage ) Sets the difference the vehicle's intended speed and its current speed limit. Speed limits can be exceeded by setting the perc to a negative value. Default is 30. Exceeding a speed limit can be done using negative percentages. Parameters: percentage ( float ) - Percentage difference between intended speed and the current limit. ignore_lights_percentage ( self , actor , perc ) During the traffic light stage, which runs every frame, this method sets the percent chance that traffic lights will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The actor that is going to ignore traffic lights. perc ( float ) - Between 0 and 100. Amount of times traffic lights will be ignored. ignore_signs_percentage ( self , actor , perc ) During the traffic light stage, which runs every frame, this method sets the percent chance that stop signs will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The actor that is going to ignore stop signs. perc ( float ) - Between 0 and 100. Amount of times stop signs will be ignored. ignore_vehicles_percentage ( self , actor , perc ) During the collision detection stage, which runs every frame, this method sets a percent chance that collisions with another vehicle will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The vehicle that is going to ignore other vehicles. perc ( float ) - Between 0 and 100. Amount of times collisions will be ignored. ignore_walkers_percentage ( self , actor , perc ) During the collision detection stage, which runs every frame, this method sets a percent chance that collisions with walkers will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The vehicle that is going to ignore walkers on scene. perc ( float ) - Between 0 and 100. Amount of times collisions will be ignored. vehicle_percentage_speed_difference ( self , actor , percentage ) Sets the difference the vehicle's intended speed and its current speed limit. Speed limits can be exceeded by setting the perc to a negative value. Default is 30. Exceeding a speed limit can be done using negative percentages. Parameters: actor ( carla.Actor ) - Vehicle whose speed behaviour is being changed. percentage ( float ) - Percentage difference between intended speed and the current limit. Getters get_port ( self ) Returns the port where the Traffic Manager is connected. If the object is a TM-Client, it will return the port of its TM-Server. Read the documentation to learn the difference. Return: uint16 Setters set_boundaries_respawn_dormant_vehicles ( self , lower_bound =25.0 , upper_bound =actor_active_distance ) Sets the upper and lower boundaries for dormant actors to be respawned near the hero vehicle. Parameters: lower_bound ( float ) - The minimum distance in meters from the hero vehicle that a dormant actor will be respawned. upper_bound ( float ) - The maximum distance in meters from the hero vehicle that a dormant actor will be respawned. Warning: The upper_bound cannot be higher than the actor_active_distance . The lower_bound cannot be less than 25. set_global_distance_to_leading_vehicle ( self , distance ) Sets the minimum distance in meters that vehicles have to keep with the rest. The distance is in meters and will affect the minimum moving distance. It is computed from center to center of the vehicle objects. Parameters: distance ( float - meters ) - Meters between vehicles. set_hybrid_physics_mode ( self , enabled =False ) Enables or disables the hybrid physics mode. In this mode, vehicle's farther than a certain radius from the ego vehicle will have their physics disabled. Computation cost will be reduced by not calculating vehicle dynamics. Vehicles will be teleported. Parameters: enabled ( bool ) - If True , enables the hybrid physics. set_hybrid_physics_radius ( self , r =50.0 ) With hybrid physics on, changes the radius of the area of influence where physics are enabled. Parameters: r ( float - meters ) - New radius where physics are enabled. set_osm_mode ( self , mode_switch =True ) Enables or disables the OSM mode. This mode allows the user to run TM in a map created with the OSM feature . These maps allow having dead-end streets. Normally, if vehicles cannot find the next waypoint, TM crashes. If OSM mode is enabled, it will show a warning, and destroy vehicles when necessary. Parameters: mode_switch ( bool ) \u2013 If True , the OSM mode is enabled. keep_right_rule_percentage ( self , actor , perc ) During the localization stage, this method sets a percent chance that vehicle will follow the keep right rule, and stay in the right lane. Parameters: actor ( carla.Actor ) - Vehicle whose behaviour is being changed. perc ( float ) - Between 0 and 100. Amount of times the vehicle will follow the keep right rule. set_random_device_seed ( self , value ) Sets a specific random seed for the Traffic Manager, thereby setting it to be deterministic. Parameters: value ( int ) - Seed value for the random number generation of the Traffic Manager. set_respawn_dormant_vehicles ( self , mode_switch =False ) If True , vehicles in large maps will respawn near the hero vehicle when they become dormant. Otherwise, they will stay dormant until they are within actor_active_distance of the hero vehicle again. Parameters: mode_switch ( bool ) set_synchronous_mode ( self , mode_switch =True ) Sets the Traffic Manager to synchronous mode . In a multiclient situation , only the TM-Server can tick. Similarly, in a multiTM situation , only one TM-Server must tick. Use this method in the client that does the world tick, and right after setting the world to synchronous mode, to set which TM will be the master while in sync. Parameters: mode_switch ( bool ) - If True , the TM synchronous mode is enabled. Warning: If the server is set to synchronous mode, the TM must be set to synchronous mode too in the same client that does the tick. carla.TrafficSign Inherited from carla.Actor Traffic signs appearing in the simulation except for traffic lights. These have their own class inherited from this in carla.TrafficLight . Right now, speed signs, stops and yields are mainly the ones implemented, but many others are borne in mind. Instance Variables trigger_volume A carla.BoundingBox situated near a traffic sign where the carla.Actor who is inside can know about it. carla.Transform Class that defines a transformation, a combination of location and rotation, without scaling. Instance Variables location ( carla.Location ) Describes a point in the coordinate system. rotation ( carla.Rotation - degrees (pitch, yaw, roll) ) Describes a rotation for an object according to Unreal Engine's axis system. Methods __init__ ( self , location , rotation ) Parameters: location ( carla.Location ) rotation ( carla.Rotation - degrees (pitch, yaw, roll) ) transform ( self , in_point ) Translates a 3D point from local to global coordinates using the current transformation as frame of reference. Parameters: in_point ( carla.Location ) - Location in the space to which the transformation will be applied. Getters get_forward_vector ( self ) Computes a forward vector using the rotation of the object. Return: carla.Vector3D get_inverse_matrix ( self ) Computes the 4-matrix representation of the inverse transformation. Return: list(list(float)) get_matrix ( self ) Computes the 4-matrix representation of the transformation. Return: list(list(float)) get_right_vector ( self ) Computes a right vector using the rotatio of the object. Return: carla.Vector3D get_up_vector ( self ) Computes an up vector using the rotation of the object. Return: carla.Vector3D Dunder methods __eq__ ( self , other = carla.Transform ) Returns True if both location and rotation are equal for this and other . Return: bool __ne__ ( self , other = carla.Transform ) Returns True if any location and rotation are not equal for this and other . Return: bool __str__ ( self ) Parses both location and rotation to string. Return: str carla.Vector2D Helper class to perform 2D operations. Instance Variables x ( float ) X-axis value. y ( float ) Y-axis value. Methods __init__ ( self , x =0.0 , y =0.0 ) Parameters: x ( float ) y ( float ) length ( self ) Computes the length of the vector. Return: float make_unit_vector ( self ) Returns a vector with the same direction and unitary length. Return: carla.Vector3D squared_length ( self ) Computes the squared length of the vector. Return: float Dunder methods __add__ ( self , other = carla.Vector2D ) __eq__ ( self , other = carla.Vector2D ) Returns True if values for every axis are equal. Return: bool __mul__ ( self , other = carla.Vector2D ) __ne__ ( self , bool = carla.Vector2D ) Returns True if the value for any axis is different. Return: bool __str__ ( self ) Returns the axis values for the vector parsed as string. Return: str __sub__ ( self , other = carla.Vector2D ) __truediv__ ( self , other = carla.Vector2D ) carla.Vector3D Helper class to perform 3D operations. Instance Variables x ( float ) X-axis value. y ( float ) Y-axis value. z ( float ) Z-axis value. Methods __init__ ( self , x =0.0 , y =0.0 , z =0.0 ) Parameters: x ( float ) y ( float ) z ( float ) cross ( self , vector ) Computes the cross product between two vectors. Parameters: vector ( carla.Vector3D ) Return: carla.Vector3D distance ( self , vector ) Computes the distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float distance_2d ( self , vector ) Computes the 2-dimensional distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float distance_squared ( self , vector ) Computes the squared distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float distance_squared_2d ( self , vector ) Computes the 2-dimensional squared distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float dot ( self , vector ) Computes the dot product between two vectors. Parameters: vector ( carla.Vector3D ) Return: float dot_2d ( self , vector ) Computes the 2-dimensional dot product between two vectors. Parameters: vector ( carla.Vector3D ) Return: float length ( self ) Computes the length of the vector. Return: float make_unit_vector ( self ) Returns a vector with the same direction and unitary length. Return: carla.Vector3D squared_length ( self ) Computes the squared length of the vector. Return: float Dunder methods __abs__ ( self ) Returns a Vector3D with the absolute value of the components x, y and z. Return: carla.Vector3D __add__ ( self , other = carla.Vector3D ) __eq__ ( self , other = carla.Vector3D ) Returns True if values for every axis are equal. Return: bool __mul__ ( self , other = carla.Vector3D ) __ne__ ( self , other = carla.Vector3D ) Returns True if the value for any axis is different. Return: bool __str__ ( self ) Returns the axis values for the vector parsed as string. Return: str __sub__ ( self , other = carla.Vector3D ) __truediv__ ( self , other = carla.Vector3D ) carla.Vehicle Inherited from carla.Actor One of the most important group of actors in CARLA. These include any type of vehicle from cars to trucks, motorbikes, vans, bycicles and also official vehicles such as police cars. A wide set of these actors is provided in carla.BlueprintLibrary to facilitate differente requirements. Vehicles can be either manually controlled or set to an autopilot mode that will be conducted client-side by the traffic manager . Instance Variables bounding_box ( carla.BoundingBox ) Bounding box containing the geometry of the vehicle. Its location and rotation are relative to the vehicle it is attached to. Methods apply_control ( self , control ) Applies a control object on the next tick, containing driving parameters such as throttle, steering or gear shifting. Parameters: control ( carla.VehicleControl ) apply_physics_control ( self , physics_control ) Applies a physics control object in the next tick containing the parameters that define the vehicle as a corporeal body. E.g.: moment of inertia, mass, drag coefficient and many more. Parameters: physics_control ( carla.VehiclePhysicsControl ) enable_carsim ( self , simfile_path ) Enables the CarSim physics solver for this particular vehicle. In order for this function to work, there needs to be a valid license manager running on the server side. The control inputs are redirected to CarSim which will provide the position and orientation of the vehicle for every frame. Parameters: simfile_path ( str ) - Path to the .simfile file with the parameters of the simulation. is_at_traffic_light ( self ) Vehicles will be affected by a traffic light when the light is red and the vehicle is inside its bounding box. The client returns whether a traffic light is affecting this vehicle according to last tick (it does not call the simulator). Return: bool use_carsim_road ( self , enabled ) Enables or disables the usage of CarSim vs terrain file specified in the .simfile . By default this option is disabled and CarSim uses unreal engine methods to process the geometry of the scene. Parameters: enabled ( bool ) Getters get_control ( self ) The client returns the control applied in the last tick. The method does not call the simulator. Return: carla.VehicleControl get_light_state ( self ) Returns a flag representing the vehicle light state, this represents which lights are active or not. Return: carla.VehicleLightState Setter: carla.Vehicle.set_light_state get_physics_control ( self ) The simulator returns the last physics control applied to this vehicle. Return: carla.VehiclePhysicsControl Warning: This method does call the simulator to retrieve the value. get_speed_limit ( self ) The client returns the speed limit affecting this vehicle according to last tick (it does not call the simulator). The speed limit is updated when passing by a speed limit signal, so a vehicle might have none right after spawning. Return: float - m/s get_traffic_light ( self ) Retrieves the traffic light actor affecting this vehicle (if any) according to last tick. The method does not call the simulator. Return: carla.TrafficLight get_traffic_light_state ( self ) The client returns the state of the traffic light affecting this vehicle according to last tick. The method does not call the simulator. If no traffic light is currently affecting the vehicle, returns green . Return: carla.TrafficLightState get_wheel_steer_angle ( self , wheel_location ) Returns the physics angle in degrees of a vehicle's wheel. Parameters: wheel_location ( carla.VehicleWheelLocation ) Return: float Note: Returns the angle based on the physics of the wheel, not the visual angle. Setters set_autopilot ( self , enabled =True , port =8000 ) Registers or deletes the vehicle from a Traffic Manager's list. When True , the Traffic Manager passed as parameter will move the vehicle around. The autopilot takes place client-side. Parameters: enabled ( bool ) port ( uint16 ) - The port of the TM-Server where the vehicle is to be registered or unlisted. If None is passed, it will consider a TM at default port 8000 . set_light_state ( self , light_state ) Sets the light state of a vehicle using a flag that represents the lights that are on and off. Parameters: light_state ( carla.VehicleLightState ) Getter: carla.Vehicle.get_light_state set_wheel_steer_direction ( self , wheel_location , angle_in_deg ) snippet \u2192 Sets the angle of a vehicle's wheel visually. Parameters: wheel_location ( carla.VehicleWheelLocation ) angle_in_deg ( float ) Warning: Does not affect the physics of the vehicle. Dunder methods __str__ ( self ) carla.VehicleControl Manages the basic movement of a vehicle using typical driving controls. Instance Variables throttle ( float ) A scalar value to control the vehicle throttle [0.0, 1.0]. Default is 0.0. steer ( float ) A scalar value to control the vehicle steering [-1.0, 1.0]. Default is 0.0. brake ( float ) A scalar value to control the vehicle brake [0.0, 1.0]. Default is 0.0. hand_brake ( bool ) Determines whether hand brake will be used. Default is False . reverse ( bool ) Determines whether the vehicle will move backwards. Default is False . manual_gear_shift ( bool ) Determines whether the vehicle will be controlled by changing gears manually. Default is False . gear ( int ) States which gear is the vehicle running on. Methods __init__ ( self , throttle =0.0 , steer =0.0 , brake =0.0 , hand_brake =False , reverse =False , manual_gear_shift =False , gear =0 ) Parameters: throttle ( float ) - Scalar value between [0.0,1.0]. steer ( float ) - Scalar value between [0.0,1.0]. brake ( float ) - Scalar value between [0.0,1.0]. hand_brake ( bool ) reverse ( bool ) manual_gear_shift ( bool ) gear ( int ) Dunder methods __eq__ ( self , other = carla.VehicleControl ) __ne__ ( self , other = carla.VehicleControl ) __str__ ( self ) carla.VehicleDoor Possible index representing the possible doors that can be open. Notice that not all possible doors are able to open in some vehicles. Instance Variables FL Front left door. FR Front right door. RL Back left door. RR Back right door. All Represents all doors. carla.VehicleLightState Class that recaps the state of the lights of a vehicle, these can be used as a flags. E.g: VehicleLightState.HighBeam & VehicleLightState.Brake will return True when both are active. Lights are off by default in any situation and should be managed by the user via script. The blinkers blink automatically. Warning: Right now, not all vehicles have been prepared to work with this functionality, this will be added to all of them in later updates . Instance Variables NONE All lights off. Position LowBeam HighBeam Brake RightBlinker LeftBlinker Reverse Fog Interior Special1 This is reserved for certain vehicles that can have special lights, like a siren. Special2 This is reserved for certain vehicles that can have special lights, like a siren. All All lights on. carla.VehiclePhysicsControl Summarizes the parameters that will be used to simulate a carla.Vehicle as a physical object. The specific settings for the wheels though are stipulated using carla.WheelPhysicsControl . Instance Variables torque_curve ( list( carla.Vector2D ) ) Curve that indicates the torque measured in Nm for a specific RPM of the vehicle's engine. max_rpm ( float ) The maximum RPM of the vehicle's engine. moi ( float - kg*m 2 ) The moment of inertia of the vehicle's engine. damping_rate_full_throttle ( float ) Damping ratio when the throttle is maximum. damping_rate_zero_throttle_clutch_engaged ( float ) Damping ratio when the throttle is zero with clutch engaged. damping_rate_zero_throttle_clutch_disengaged ( float ) Damping ratio when the throttle is zero with clutch disengaged. use_gear_autobox ( bool ) If True , the vehicle will have an automatic transmission. gear_switch_time ( float - seconds ) Switching time between gears. clutch_strength ( float - kg*m 2 /s ) Clutch strength of the vehicle. final_ratio ( float ) Fixed ratio from transmission to wheels. forward_gears ( list( carla.GearPhysicsControl ) ) List of objects defining the vehicle's gears. mass ( float - kilograms ) Mass of the vehicle. drag_coefficient ( float ) Drag coefficient of the vehicle's chassis. center_of_mass ( carla.Vector3D - meters ) Center of mass of the vehicle. steering_curve ( list( carla.Vector2D ) ) Curve that indicates the maximum steering for a specific forward speed. use_sweep_wheel_collision ( bool ) Enable the use of sweep for wheel collision. By default, it is disabled and it uses a simple raycast from the axis to the floor for each wheel. This option provides a better collision model in which the full volume of the wheel is checked against collisions. wheels ( list( carla.WheelPhysicsControl ) ) List of wheel physics objects. This list should have 4 elements, where index 0 corresponds to the front left wheel, index 1 corresponds to the front right wheel, index 2 corresponds to the back left wheel and index 3 corresponds to the back right wheel. For 2 wheeled vehicles, set the same values for both front and back wheels. Methods __init__ ( self , torque_curve =[[0.0, 500.0], [5000.0, 500.0]] , max_rpm =5000.0 , moi =1.0 , damping_rate_full_throttle =0.15 , damping_rate_zero_throttle_clutch_engaged =2.0 , damping_rate_zero_throttle_clutch_disengaged =0.35 , use_gear_autobox =True , gear_switch_time =0.5 , clutch_strength =10.0 , final_ratio =4.0 , forward_gears =list() , drag_coefficient =0.3 , center_of_mass =[0.0, 0.0, 0.0] , steering_curve =[[0.0, 1.0], [10.0, 0.5]] , wheels =list() , use_sweep_wheel_collision =False , mass =1000.0 ) VehiclePhysicsControl constructor. Parameters: torque_curve ( list( carla.Vector2D ) ) max_rpm ( float ) moi ( float - kg*m 2 ) damping_rate_full_throttle ( float ) damping_rate_zero_throttle_clutch_engaged ( float ) damping_rate_zero_throttle_clutch_disengaged ( float ) use_gear_autobox ( bool ) gear_switch_time ( float - seconds ) clutch_strength ( float - kg*m 2 /s ) final_ratio ( float ) forward_gears ( list( carla.GearPhysicsControl ) ) drag_coefficient ( float ) center_of_mass ( carla.Vector3D ) steering_curve ( carla.Vector2D ) wheels ( list( carla.WheelPhysicsControl ) ) use_sweep_wheel_collision ( bool ) mass ( float - kilograms ) Dunder methods __eq__ ( self , other = carla.VehiclePhysicsControl ) __ne__ ( self , other = carla.VehiclePhysicsControl ) __str__ ( self ) carla.VehicleWheelLocation enum representing the position of each wheel on a vehicle. Used to identify the target wheel when setting an angle in carla.Vehicle.set_wheel_steer_direction or carla.Vehicle.get_wheel_steer_angle . Instance Variables FL_Wheel Front left wheel of a 4 wheeled vehicle. FR_Wheel Front right wheel of a 4 wheeled vehicle. BL_Wheel Back left wheel of a 4 wheeled vehicle. BR_Wheel Back right wheel of a 4 wheeled vehicle. Front_Wheel Front wheel of a 2 wheeled vehicle. Back_Wheel Back wheel of a 2 wheeled vehicle. carla.Walker Inherited from carla.Actor This class inherits from the carla.Actor and defines pedestrians in the simulation. Walkers are a special type of actor that can be controlled either by an AI ( carla.WalkerAIController ) or manually via script, using a series of carla.WalkerControl to move these and their skeletons. Instance Variables bounding_box ( carla.BoundingBox ) Bounding box containing the geometry of the walker. Its location and rotation are relative to the walker it is attached to. Methods apply_control ( self , control ) On the next tick, the control will move the walker in a certain direction with a certain speed. Jumps can be commanded too. Parameters: control ( carla.WalkerControl ) blend_pose ( self , blend_value ) Set the blending value of the custom pose with the animation. The values can be: 0: will show only the animation 1: will show only the custom pose (set by the user with set_bones()) any other: will interpolate all the bone positions between animation and the custom pose. Parameters: blend_value ( float - value from 0 to 1 with the blend percentage ) hide_pose ( self ) Hide the custom pose and show the animation (same as calling blend_pose(0)). show_pose ( self ) Show the custom pose and hide the animation (same as calling blend_pose(1)). Getters get_bones ( self ) Return the structure with all the bone transformations from the actor. For each bone, we get the name and its transform in three different spaces: name: bone name world: transform in world coordinates component: transform based on the pivot of the actor relative: transform based on the bone parent. Return: carla.WalkerBoneControlOut Setter: carla.Walker.set_bones get_control ( self ) The client returns the control applied to this walker during last tick. The method does not call the simulator. Return: carla.WalkerControl get_pose_from_animation ( self ) Make a copy of the current animation frame as the custom pose. Initially the custom pose is the neutral pedestrian pose. Setters set_bones ( self , bones ) Set the bones of the actor. For each bone we want to set we use a relative transform. Only the bones in this list will be set. For each bone you need to setup this info: name: bone name relative: transform based on the bone parent. Parameters: bones ( carla.WalkerBoneControlIn - list of pairs (bone_name, transform) for the bones that we want to set ) Getter: carla.Walker.get_bones Dunder methods __str__ ( self ) carla.WalkerAIController Inherited from carla.Actor Class that conducts AI control for a walker. The controllers are defined as actors, but they are quite different from the rest. They need to be attached to a parent actor during their creation, which is the walker they will be controlling (take a look at carla.World if you are yet to learn on how to spawn actors). They also need for a special blueprint (already defined in carla.BlueprintLibrary as \"controller.ai.walker\"). This is an empty blueprint, as the AI controller will be invisible in the simulation but will follow its parent around to dictate every step of the way. Methods go_to_location ( self , destination ) Sets the destination that the pedestrian will reach. Parameters: destination ( carla.Location - meters ) start ( self ) Enables AI control for its parent walker. stop ( self ) snippet \u2192 Disables AI control for its parent walker. Setters set_max_speed ( self , speed =1.4 ) Sets a speed for the walker in meters per second. Parameters: speed ( float - m/s ) - An easy walking speed is set by default. Dunder methods __str__ ( self ) carla.WalkerBoneControlIn This class grants bone specific manipulation for walker. The skeletons of walkers have been unified for clarity and the transform applied to each bone are always relative to its parent. Take a look here to learn more on how to create a walker and define its movement. Instance Variables bone_transforms ( list([name,transform]) ) List with the data for each bone we want to set: name: bone name relative: transform based on the bone parent. Methods __init__ ( self , list(name,transform) ) Initializes an object containing moves to be applied on tick. These are listed with the name of the bone and the transform that will be applied to it. Parameters: list(name,transform) ( tuple ) Dunder methods __str__ ( self ) carla.WalkerBoneControlOut This class is used to return all bone positions of a pedestrian. For each bone we get its name and its transform in three different spaces (world, actor and relative). Instance Variables bone_transforms ( list([name,world, actor, relative]) ) List of one entry per bone with this information: name: bone name world: transform in world coordinates component: transform based on the pivot of the actor relative: transform based on the bone parent. Methods Dunder methods __str__ ( self ) carla.WalkerControl This class defines specific directions that can be commanded to a carla.Walker to control it via script. AI control can be settled for walkers, but the control used to do so is carla.WalkerAIController . Instance Variables direction ( carla.Vector3D ) Vector using global coordinates that will correspond to the direction of the walker. speed ( float - m/s ) A scalar value to control the walker's speed. jump ( bool ) If True , the walker will perform a jump. Methods __init__ ( self , direction =[1.0, 0.0, 0.0] , speed =0.0 , jump =False ) Parameters: direction ( carla.Vector3D ) speed ( float - m/s ) jump ( bool ) Dunder methods __eq__ ( self , other = carla.WalkerControl ) Compares every variable with other and returns True if these are all the same. __ne__ ( self , other = carla.WalkerControl ) Compares every variable with other and returns True if any of these differ. __str__ ( self ) carla.Waypoint Waypoints in CARLA are described as 3D directed points. They have a carla.Transform which locates the waypoint in a road and orientates it according to the lane. They also store the road information belonging to said point regarding its lane and lane markings. All the information regarding waypoints and the waypoint API is retrieved as provided by the OpenDRIVE file. Once the client asks for the map object to the server, no longer communication will be needed. Instance Variables id ( int ) The identificator is generated using a hash combination of the road , section , lane and s values that correspond to said point in the OpenDRIVE geometry. The s precision is set to 2 centimeters, so 2 waypoints closer than 2 centimeters in the same road, section and lane, will have the same identificator. transform ( carla.Transform ) Position and orientation of the waypoint according to the current lane information. This data is computed the first time it is accessed. It is not created right away in order to ease computing costs when lots of waypoints are created but their specific transform is not needed. road_id ( int ) OpenDRIVE road's id. section_id ( int ) OpenDRIVE section's id, based on the order that they are originally defined. lane_id ( int ) OpenDRIVE lane's id, this value can be positive or negative which represents the direction of the current lane with respect to the road. For more information refer to OpenDRIVE documentation . s ( float ) OpenDRIVE s value of the current position. is_junction ( bool ) True if the current Waypoint is on a junction as defined by OpenDRIVE. lane_width ( float ) Horizontal size of the road at current s . lane_change ( carla.LaneChange ) Lane change definition of the current Waypoint's location, based on the traffic rules defined in the OpenDRIVE file. It states if a lane change can be done and in which direction. lane_type ( carla.LaneType ) The lane type of the current Waypoint, based on OpenDRIVE 1.4 standard. right_lane_marking ( carla.LaneMarking ) The right lane marking information based on the direction of the Waypoint. left_lane_marking ( carla.LaneMarking ) The left lane marking information based on the direction of the Waypoint. Methods next ( self , distance ) Returns a list of waypoints at a certain approximate distance from the current one. It takes into account the road and its possible deviations without performing any lane change and returns one waypoint per option. The list may be empty if the lane is not connected to any other at the specified distance. Parameters: distance ( float - meters ) - The approximate distance where to get the next waypoints. Return: list( carla.Waypoint ) next_until_lane_end ( self , distance ) Returns a list of waypoints from this to the end of the lane separated by a certain distance . Parameters: distance ( float - meters ) - The approximate distance between waypoints. Return: list( carla.Waypoint ) previous ( self , distance ) This method does not return the waypoint previously visited by an actor, but a list of waypoints at an approximate distance but in the opposite direction of the lane. Similarly to next() , it takes into account the road and its possible deviations without performing any lane change and returns one waypoint per option. The list may be empty if the lane is not connected to any other at the specified distance. Parameters: distance ( float - meters ) - The approximate distance where to get the previous waypoints. Return: list( carla.Waypoint ) previous_until_lane_start ( self , distance ) Returns a list of waypoints from this to the start of the lane separated by a certain distance . Parameters: distance ( float - meters ) - The approximate distance between waypoints. Return: list( carla.Waypoint ) Getters get_junction ( self ) If the waypoint belongs to a junction this method returns the asociated junction object. Otherwise returns null. Return: carla.Junction get_landmarks ( self , distance , stop_at_junction =False ) Returns a list of landmarks in the road from the current waypoint until the specified distance. Parameters: distance ( float - meters ) - The maximum distance to search for landmarks from the current waypoint. stop_at_junction ( bool ) - Enables or disables the landmark search through junctions. Return: list( carla.Landmark ) get_landmarks_of_type ( self , distance , type , stop_at_junction =False ) Returns a list of landmarks in the road of a specified type from the current waypoint until the specified distance. Parameters: distance ( float - meters ) - The maximum distance to search for landmarks from the current waypoint. type ( str ) - The type of landmarks to search. stop_at_junction ( bool ) - Enables or disables the landmark search through junctions. Return: list( carla.Landmark ) get_left_lane ( self ) Generates a Waypoint at the center of the left lane based on the direction of the current Waypoint, taking into account if the lane change is allowed in this location. Will return None if the lane does not exist. Return: carla.Waypoint get_right_lane ( self ) Generates a waypoint at the center of the right lane based on the direction of the current waypoint, taking into account if the lane change is allowed in this location. Will return None if the lane does not exist. Return: carla.Waypoint Dunder methods __str__ ( self ) carla.WeatherParameters This class defines objects containing lighting and weather specifications that can later be applied in carla.World . So far, these conditions only intervene with sensor.camera.rgb . They neither affect the actor's physics nor other sensors. Each of these parameters acts indepently from the rest. Increasing the rainfall will not automatically create puddles nor change the road's humidity. That makes for a better customization but means that realistic conditions need to be scripted. However an example of dynamic weather conditions working realistically can be found here . Instance Variables cloudiness ( float ) Values range from 0 to 100, being 0 a clear sky and 100 one completely covered with clouds. precipitation ( float ) Rain intensity values range from 0 to 100, being 0 none at all and 100 a heavy rain. precipitation_deposits ( float ) Determines the creation of puddles. Values range from 0 to 100, being 0 none at all and 100 a road completely capped with water. Puddles are created with static noise, meaning that they will always appear at the same locations. wind_intensity ( float ) Controls the strenght of the wind with values from 0, no wind at all, to 100, a strong wind. The wind does affect rain direction and leaves from trees, so this value is restricted to avoid animation issues. sun_azimuth_angle ( float - degrees ) The azimuth angle of the sun. Values range from 0 to 360. Zero is an origin point in a sphere determined by Unreal Engine. sun_altitude_angle ( float - degrees ) Altitude angle of the sun. Values range from -90 to 90 corresponding to midnight and midday each. fog_density ( float ) Fog concentration or thickness. It only affects the RGB camera sensor. Values range from 0 to 100. fog_distance ( float - meters ) Fog start distance. Values range from 0 to infinite. wetness ( float ) Wetness intensity. It only affects the RGB camera sensor. Values range from 0 to 100. fog_falloff ( float ) Density of the fog (as in specific mass) from 0 to infinity. The bigger the value, the more dense and heavy it will be, and the fog will reach smaller heights. Corresponds to Fog Height Falloff in the UE docs. If the value is 0, the fog will be lighter than air, and will cover the whole scene. A value of 1 is approximately as dense as the air, and reaches normal-sized buildings. For values greater than 5, the air will be so dense that it will be compressed on ground level. scattering_intensity ( float ) Controls how much the light will contribute to volumetric fog. When set to 0, there is no contribution. mie_scattering_scale ( float ) Controls interaction of light with large particles like pollen or air pollution resulting in a hazy sky with halos around the light sources. When set to 0, there is no contribution. rayleigh_scattering_scale ( float ) Controls interaction of light with small particles like air molecules. Dependent on light wavelength, resulting in a blue sky in the day or red sky in the evening. Methods __init__ ( self , cloudiness =0.0 , precipitation =0.0 , precipitation_deposits =0.0 , wind_intensity =0.0 , sun_azimuth_angle =0.0 , sun_altitude_angle =0.0 , fog_density =0.0 , fog_distance =0.0 , wetness =0.0 , fog_falloff =0.0 , scattering_intensity =0.0 , mie_scattering_scale =0.0 , rayleigh_scattering_scale =0.0331 ) Method to initialize an object defining weather conditions. This class has some presets for different noon and sunset conditions listed in a note below. Parameters: cloudiness ( float ) - 0 is a clear sky, 100 complete overcast. precipitation ( float ) - 0 is no rain at all, 100 a heavy rain. precipitation_deposits ( float ) - 0 means no puddles on the road, 100 means roads completely capped by rain. wind_intensity ( float ) - 0 is calm, 100 a strong wind. sun_azimuth_angle ( float - degrees ) - 0 is an arbitrary North, 180 its corresponding South. sun_altitude_angle ( float - degrees ) - 90 is midday, -90 is midnight. fog_density ( float ) - Concentration or thickness of the fog, from 0 to 100. fog_distance ( float - meters ) - Distance where the fog starts in meters. wetness ( float ) - Humidity percentages of the road, from 0 to 100. fog_falloff ( float ) - Density (specific mass) of the fog, from 0 to infinity. scattering_intensity ( float ) - Controls how much the light will contribute to volumetric fog. When set to 0, there is no contribution. mie_scattering_scale ( float ) - Controls interaction of light with large particles like pollen or air pollution resulting in a hazy sky with halos around the light sources. When set to 0, there is no contribution. rayleigh_scattering_scale ( float ) - Controls interaction of light with small particles like air molecules. Dependent on light wavelength, resulting in a blue sky in the day or red sky in the evening. Note: ClearNoon, CloudyNoon, WetNoon, WetCloudyNoon, SoftRainNoon, MidRainyNoon, HardRainNoon, ClearSunset, CloudySunset, WetSunset, WetCloudySunset, SoftRainSunset, MidRainSunset, HardRainSunset. Dunder methods __eq__ ( self , other ) Returns True if both objects' variables are the same. Return: bool __ne__ ( self , other ) Returns True if both objects' variables are different. Return: bool __str__ ( self ) carla.WheelPhysicsControl Class that defines specific physical parameters for wheel objects that will be part of a carla.VehiclePhysicsControl to simulate vehicle it as a material object. Instance Variables tire_friction ( float ) A scalar value that indicates the friction of the wheel. damping_rate ( float ) Damping rate of the wheel. max_steer_angle ( float - degrees ) Maximum angle that the wheel can steer. radius ( float - centimeters ) Radius of the wheel. max_brake_torque ( float - N*m ) Maximum brake torque. max_handbrake_torque ( float - N*m ) Maximum handbrake torque. position ( carla.Vector3D ) World position of the wheel. This is a read-only parameter. long_stiff_value ( float - kg per radian ) Tire longitudinal stiffness per unit gravitational acceleration. Each vehicle has a custom value. lat_stiff_max_load ( float ) Maximum normalized tire load at which the tire can deliver no more lateral stiffness no matter how much extra load is applied to the tire. Each vehicle has a custom value. lat_stiff_value ( float ) Maximum stiffness per unit of lateral slip. Each vehicle has a custom value. Methods __init__ ( self , tire_friction =2.0 , damping_rate =0.25 , max_steer_angle =70.0 , radius =30.0 , max_brake_torque =1500.0 , max_handbrake_torque =3000.0 , position =(0.0,0.0,0.0) ) Parameters: tire_friction ( float ) damping_rate ( float ) max_steer_angle ( float - degrees ) radius ( float - centimerers ) max_brake_torque ( float - N*m ) max_handbrake_torque ( float - N*m ) position ( carla.Vector3D - meters ) Dunder methods __eq__ ( self , other = carla.WheelPhysicsControl ) __ne__ ( self , other = carla.WheelPhysicsControl ) __str__ ( self ) carla.World World objects are created by the client to have a place for the simulation to happen. The world contains the map we can see, meaning the asset, not the navigation map. Navigation maps are part of the carla.Map class. It also manages the weather and actors present in it. There can only be one world per simulation, but it can be changed anytime. Instance Variables id ( int ) The ID of the episode associated with this world. Episodes are different sessions of a simulation. These change everytime a world is disabled or reloaded. Keeping track is useful to avoid possible issues. debug ( carla.DebugHelper ) Responsible for creating different shapes for debugging. Take a look at its class to learn more about it. Methods apply_color_texture_to_object ( self , object_name , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to object_name . Parameters: object_name ( str ) material_parameter ( carla.MaterialParameter ) texture ( TextureColor ) apply_color_texture_to_objects ( self , objects_name_list , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to all objects in objects_name_list . Parameters: objects_name_list ( list(str) ) material_parameter ( carla.MaterialParameter ) texture ( TextureColor ) apply_float_color_texture_to_object ( self , object_name , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to object_name . Parameters: object_name ( str ) material_parameter ( carla.MaterialParameter ) texture ( TextureFloatColor ) apply_float_color_texture_to_objects ( self , objects_name_list , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to all objects in objects_name_list . Parameters: objects_name_list ( list(str) ) material_parameter ( carla.MaterialParameter ) texture ( TextureFloatColor ) apply_settings ( self , world_settings ) This method applies settings contained in an object to the simulation running and returns the ID of the frame they were implemented. Parameters: world_settings ( carla.WorldSettings ) Return: int Warning: If synchronous mode is enabled, and there is a Traffic Manager running, this must be set to sync mode too. Read this to learn how to do it. apply_textures_to_object ( self , object_name , diffuse_texture , emissive_texture , normal_texture , ao_roughness_metallic_emissive_texture ) Applies all texture fields in carla.MaterialParameter to the object object_name . Empty textures here will not be applied. Parameters: object_name ( str ) diffuse_texture ( TextureColor ) emissive_texture ( TextureFloatColor ) normal_texture ( TextureFloatColor ) ao_roughness_metallic_emissive_texture ( TextureFloatColor ) apply_textures_to_objects ( self , objects_name_list , diffuse_texture , emissive_texture , normal_texture , ao_roughness_metallic_emissive_texture ) Applies all texture fields in carla.MaterialParameter to all objects in objects_name_list . Empty textures here will not be applied. Parameters: objects_name_list ( list(str) ) diffuse_texture ( TextureColor ) emissive_texture ( TextureFloatColor ) normal_texture ( TextureFloatColor ) ao_roughness_metallic_emissive_texture ( TextureFloatColor ) cast_ray ( self , initial_location , final_location ) Casts a ray from the specified initial_location to final_location. The function then detects all geometries intersecting the ray and returns a list of carla.LabelledPoint in order. Parameters: initial_location ( carla.Location ) - The initial position of the ray. final_location ( carla.Location ) - The final position of the ray. Return: list( carla.LabelledPoint ) enable_environment_objects ( self , env_objects_ids , enable ) snippet \u2192 Enable or disable a set of EnvironmentObject identified by their id. These objects will appear or disappear from the level. Parameters: env_objects_ids ( set(int) ) - Set of EnvironmentObject ids to change. enable ( bool ) - State to be applied to all the EnvironmentObject of the set. freeze_all_traffic_lights ( self , frozen ) Freezes or unfreezes all traffic lights in the scene. Frozen traffic lights can be modified by the user but the time will not update them until unfrozen. Parameters: frozen ( bool ) ground_projection ( self , location , search_distance ) Projects the specified point downwards in the scene. The functions casts a ray from location in the direction (0,0,-1) (downwards) and returns a carla.Labelled object with the first geometry this ray intersects (usually the ground). If no geometry is found in the search_distance range the function returns None . Parameters: location ( carla.Location ) - The point to be projected. search_distance ( float ) - The maximum distance to perform the projection. Return: carla.LabelledPoint load_map_layer ( self , map_layers ) snippet \u2192 Loads the selected layers to the level. If the layer is already loaded the call has no effect. Parameters: map_layers ( carla.MapLayer ) - Mask of level layers to be loaded. Warning: This only affects \"Opt\" maps. The minimum layout includes roads, sidewalks, traffic lights and traffic signs. on_tick ( self , callback ) This method is used in asynchronous mode . It starts callbacks from the client for the function defined as callback , and returns the ID of the callback. The function will be called everytime the server ticks. It requires a carla.WorldSnapshot as argument, which can be retrieved from wait_for_tick() . Use remove_on_tick() to stop the callbacks. Parameters: callback ( carla.WorldSnapshot ) - Function with a snapshot as compulsory parameter that will be called when the client receives a tick. Return: int project_point ( self , location , direction , search_distance ) Projects the specified point to the desired direction in the scene. The functions casts a ray from location in a direction and returns a carla.Labelled object with the first geometry this ray intersects. If no geometry is found in the search_distance range the function returns None . Parameters: location ( carla.Location ) - The point to be projected. direction ( carla.Vector3D ) - The direction of projection. search_distance ( float ) - The maximum distance to perform the projection. Return: carla.LabelledPoint remove_on_tick ( self , callback_id ) Stops the callback for callback_id started with on_tick() . Parameters: callback_id ( callback ) - The callback to be removed. The ID is returned when creating the callback. reset_all_traffic_lights ( self ) Resets the cycle of all traffic lights in the map to the initial state. spawn_actor ( self , blueprint , transform , attach_to =None , attachment =Rigid ) snippet \u2192 The method will create, return and spawn an actor into the world. The actor will need an available blueprint to be created and a transform (location and rotation). It can also be attached to a parent with a certain attachment type. Parameters: blueprint ( carla.ActorBlueprint ) - The reference from which the actor will be created. transform ( carla.Transform ) - Contains the location and orientation the actor will be spawned with. attach_to ( carla.Actor ) - The parent object that the spawned actor will follow around. attachment ( carla.AttachmentType ) - Determines how fixed and rigorous should be the changes in position according to its parent object. Return: carla.Actor tick ( self , seconds =10.0 ) This method is used in synchronous mode , when the server waits for a client tick before computing the next frame. This method will send the tick, and give way to the server. It returns the ID of the new frame computed by the server. Parameters: seconds ( float - seconds ) - Maximum time the server should wait for a tick. It is set to 10.0 by default. Return: int Note: If no tick is received in synchronous mode, the simulation will freeze. Also, if many ticks are received from different clients, there may be synchronization issues. Please read the docs about synchronous mode to learn more. try_spawn_actor ( self , blueprint , transform , attach_to =None , attachment =Rigid ) Same as spawn_actor() but returns None on failure instead of throwing an exception. Parameters: blueprint ( carla.ActorBlueprint ) - The reference from which the actor will be created. transform ( carla.Transform ) - Contains the location and orientation the actor will be spawned with. attach_to ( carla.Actor ) - The parent object that the spawned actor will follow around. attachment ( carla.AttachmentType ) - Determines how fixed and rigorous should be the changes in position according to its parent object. Return: carla.Actor unload_map_layer ( self , map_layers ) snippet \u2192 Unloads the selected layers to the level. If the layer is already unloaded the call has no effect. Parameters: map_layers ( carla.MapLayer ) - Mask of level layers to be unloaded. Warning: This only affects \"Opt\" maps. The minimum layout includes roads, sidewalks, traffic lights and traffic signs. wait_for_tick ( self , seconds =10.0 ) This method is used in asynchronous mode . It makes the client wait for a server tick. When the next frame is computed, the server will tick and return a snapshot describing the new state of the world. Parameters: seconds ( float - seconds ) - Maximum time the server should wait for a tick. It is set to 10.0 by default. Return: carla.WorldSnapshot Getters get_actor ( self , actor_id ) Looks up for an actor by ID and returns None if not found. Parameters: actor_id ( int ) Return: carla.Actor get_actors ( self , actor_ids =None ) Retrieves a list of carla.Actor elements, either using a list of IDs provided or just listing everyone on stage. If an ID does not correspond with any actor, it will be excluded from the list returned, meaning that both the list of IDs and the list of actors may have different lengths. Parameters: actor_ids ( list ) - The IDs of the actors being searched. By default it is set to None and returns every actor on scene. Return: carla.ActorList get_blueprint_library ( self ) Returns a list of actor blueprints available to ease the spawn of these into the world. Return: carla.BlueprintLibrary get_environment_objects ( self , object_type =Any ) Returns a list of EnvironmentObject with the requested semantic tag. The method returns all the EnvironmentObjects in the level by default, but the query can be filtered by semantic tags with the argument object_type . Parameters: object_type ( carla.CityObjectLabel ) - Semantic tag of the EnvironmentObjects that are returned. Return: array( carla.EnvironmentObject ) get_level_bbs ( self , actor_type =Any ) Returns an array of bounding boxes with location and rotation in world space. The method returns all the bounding boxes in the level by default, but the query can be filtered by semantic tags with the argument actor_type . Parameters: actor_type ( carla.CityObjectLabel ) - Semantic tag of the elements contained in the bounding boxes that are returned. Return: array( carla.BoundingBox ) get_lightmanager ( self ) Returns an instance of carla.LightManager that can be used to handle the lights in the scene. Return: carla.LightManager get_map ( self ) Asks the server for the XODR containing the map file, and returns this parsed as a carla.Map . Return: carla.Map Warning: This method does call the simulation. It is expensive, and should only be called once. get_names_of_all_objects ( self ) Returns a list of the names of all objects in the scene that can be painted with the apply texture functions. Return: list(str) get_random_location_from_navigation ( self ) This can only be used with walkers. It retrieves a random location to be used as a destination using the go_to_location() method in carla.WalkerAIController . This location will be part of a sidewalk. Roads, crosswalks and grass zones are excluded. The method does not take into consideration locations of existing actors so if a collision happens when trying to spawn an actor, it will return an error. Take a look at generate_traffic.py for an example. Return: carla.Location get_settings ( self ) Returns an object containing some data about the simulation such as synchrony between client and server or rendering mode. Return: carla.WorldSettings get_snapshot ( self ) Returns a snapshot of the world at a certain moment comprising all the information about the actors. Return: carla.WorldSnapshot get_spectator ( self ) snippet \u2192 Returns the spectator actor. The spectator is a special type of actor created by Unreal Engine, usually with ID=0, that acts as a camera and controls the view in the simulator window. Return: carla.Actor get_traffic_light ( self , landmark ) Provided a landmark, returns the traffic light object it describes. Parameters: landmark ( carla.Landmark ) - The landmark object describing a traffic light. Return: carla.TrafficLight get_traffic_light_from_opendrive_id ( self , traffic_light_id ) Returns the traffic light actor corresponding to the indicated OpenDRIVE id. Parameters: traffic_light_id ( str ) - The OpenDRIVE id. Return: carla.TrafficLight get_traffic_lights_from_waypoint ( self , waypoint , distance ) This function performs a search along the road in front of the specified waypoint and returns a list of traffic light actors found in the specified search distance. Parameters: waypoint ( carla.Waypoint ) - The input waypoint. distance ( float ) - Search distance. Return: list( carla.TrafficLight ) get_traffic_lights_in_junction ( self , junction_id ) Returns the list of traffic light actors affecting the junction indicated in junction_id . Parameters: junction_id ( int ) - The id of the junction. Return: list( carla.TrafficLight ) get_traffic_sign ( self , landmark ) Provided a landmark, returns the traffic sign object it describes. Parameters: landmark ( carla.Landmark ) - The landmark object describing a traffic sign. Return: carla.TrafficSign get_vehicles_light_states ( self ) Returns a dict where the keys are carla.Actor IDs and the values are carla.VehicleLightState of that vehicle. Return: dict get_weather ( self ) Retrieves an object containing weather parameters currently active in the simulation, mainly cloudiness, precipitation, wind and sun position. Return: carla.WeatherParameters Setter: carla.World.set_weather Setters set_pedestrians_cross_factor ( self , percentage ) Parameters: percentage ( float ) - Sets the percentage of pedestrians that can walk on the road or cross at any point on the road. Value should be between 0.0 and 1.0 . For example, a value of 0.1 would allow 10% of pedestrians to walk on the road. Default is 0.0 . Note: Should be set before pedestrians are spawned. set_pedestrians_seed ( self , seed ) Parameters: seed ( int ) - Sets the seed to use for any random number generated in relation to pedestrians. Note: Should be set before pedestrians are spawned. If you want to repeat the same exact bodies (blueprint) for each pedestrian, then use the same seed in the Python code (where the blueprint is choosen randomly) and here, otherwise the pedestrians will repeat the same paths but the bodies will be different. set_weather ( self , weather ) Changes the weather parameteres ruling the simulation to another ones defined in an object. Parameters: weather ( carla.WeatherParameters ) - New conditions to be applied. Getter: carla.World.get_weather Dunder methods __str__ ( self ) The content of the world is parsed and printed as a brief report of its current state. Return: string carla.WorldSettings The simulation has some advanced configuration options that are contained in this class and can be managed using carla.World and its methods. These allow the user to choose between client-server synchrony/asynchrony, activation of \"no rendering mode\" and either if the simulation should run with a fixed or variable time-step. Check this out if you want to learn about it. Instance Variables synchronous_mode ( bool ) States the synchrony between client and server. When set to true, the server will wait for a client tick in order to move forward. It is false by default. no_rendering_mode ( bool ) When enabled, the simulation will run no rendering at all. This is mainly used to avoid overhead during heavy traffic simulations. It is false by default. fixed_delta_seconds ( float ) Ensures that the time elapsed between two steps of the simulation is fixed. Set this to 0.0 to work with a variable time-step, as happens by default. substepping ( bool ) Enable the physics substepping. This option allows computing some physics substeps between two render frames. If synchronous mode is set, the number of substeps and its time interval are fixed and computed are so they fulfilled the requirements of carla.WorldSettings.max_substep and carla.WorldSettings.max_substep_delta_time . These last two parameters need to be compatible with carla.WorldSettings.fixed_delta_seconds . Enabled by default. max_substep_delta_time ( float ) Maximum delta time of the substeps. If the carla.WorldSettingsmax_substep is high enough, the substep delta time would be always below or equal to this value. By default, the value is set to 0.01. max_substeps ( int ) The maximum number of physics substepping that are allowed. By default, the value is set to 10. max_culling_distance ( float ) Configure the max draw distance for each mesh of the level. deterministic_ragdolls ( bool ) Defines wether to use deterministic physics for pedestrian death animations or physical ragdoll simulation. When enabled, pedestrians have less realistic death animation but ensures determinism. When disabled, pedestrians are simulated as ragdolls with more realistic simulation and collision but no determinsm can be ensured. tile_stream_distance ( float ) Used for large maps only. Configures the maximum distance from the hero vehicle to stream tiled maps. Regions of the map within this range will be visible (and capable of simulating physics). Regions outside this region will not be loaded. actor_active_distance ( float ) Used for large maps only. Configures the distance from the hero vehicle to convert actors to dormant. Actors within this range will be active, and actors outside will become dormant. Methods __init__ ( self , synchronous_mode =False , no_rendering_mode =False , fixed_delta_seconds =0.0 ) Creates an object containing desired settings that could later be applied through carla.World and its method apply_settings() . Parameters: synchronous_mode ( bool ) - Set this to true to enable client-server synchrony. no_rendering_mode ( bool ) - Set this to true to completely disable rendering in the simulation. fixed_delta_seconds ( float - seconds ) - Set a fixed time-step in between frames. 0.0 means variable time-step and it is the default mode. Dunder methods __eq__ ( self , other = carla.WorldSettings ) Returns True if both objects' variables are the same. Return: bool __ne__ ( self , other = carla.WorldSettings ) Returns True if both objects' variables are different. Return: bool __str__ ( self ) Parses the established settings to a string and shows them in command line. Return: str carla.WorldSnapshot This snapshot comprises all the information for every actor on scene at a certain moment of time. It creates and gives acces to a data structure containing a series of carla.ActorSnapshot . The client recieves a new snapshot on every tick that cannot be stored. Instance Variables id ( int ) A value unique for every snapshot to differenciate them. frame ( int ) Simulation frame in which the snapshot was taken. timestamp ( carla.Timestamp - seconds ) Precise moment in time when snapshot was taken. This class works in seconds as given by the operative system. Methods find ( self , actor_id ) Given a certain actor ID, returns its corresponding snapshot or None if it is not found. Parameters: actor_id ( int ) Return: carla.ActorSnapshot has_actor ( self , actor_id ) Given a certain actor ID, checks if there is a snapshot corresponding it and so, if the actor was present at that moment. Parameters: actor_id ( int ) Return: bool Dunder methods __eq__ ( self , other = carla.WorldSnapshot ) Returns True if both timestamp are the same. Return: bool __iter__ ( self ) Iterate over the carla.ActorSnapshot stored in the snapshot. __len__ ( self ) Returns the amount of carla.ActorSnapshot present in this snapshot. Return: int __ne__ ( self , other = carla.WorldSnapshot ) Returns True if both timestamp are different. Return: bool command.ApplyAngularImpulse Command adaptation of add_angular_impulse() in carla.Actor . Applies an angular impulse to an actor. Instance Variables actor_id ( int ) Actor affected by the command. impulse ( carla.Vector3D - degrees*s ) Angular impulse applied to the actor. Methods __init__ ( self , actor , impulse ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. impulse ( carla.Vector3D - degrees*s ) command.ApplyForce Command adaptation of add_force() in carla.Actor . Applies a force to an actor. Instance Variables actor_id ( int ) Actor affected by the command. force ( carla.Vector3D - N ) Force applied to the actor over time. Methods __init__ ( self , actor , force ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. force ( carla.Vector3D - N ) command.ApplyImpulse Command adaptation of add_impulse() in carla.Actor . Applies an impulse to an actor. Instance Variables actor_id ( int ) Actor affected by the command. impulse ( carla.Vector3D - N*s ) Impulse applied to the actor. Methods __init__ ( self , actor , impulse ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. impulse ( carla.Vector3D - N*s ) command.ApplyTargetAngularVelocity Command adaptation of set_target_angular_velocity() in carla.Actor . Sets the actor's angular velocity vector. Instance Variables actor_id ( int ) Actor affected by the command. angular_velocity ( carla.Vector3D - deg/s ) The 3D angular velocity that will be applied to the actor. Methods __init__ ( self , actor , angular_velocity ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. angular_velocity ( carla.Vector3D - deg/s ) - Angular velocity vector applied to the actor. command.ApplyTargetVelocity Command adaptation of set_target_velocity() in carla.Actor . Instance Variables actor_id ( int ) Actor affected by the command. velocity ( carla.Vector3D - m/s ) The 3D velocity applied to the actor. Methods __init__ ( self , actor , velocity ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. velocity ( carla.Vector3D - m/s ) - Velocity vector applied to the actor. command.ApplyTorque Command adaptation of add_torque() in carla.Actor . Applies a torque to an actor. Instance Variables actor_id ( int ) Actor affected by the command. torque ( carla.Vector3D - degrees ) Torque applied to the actor over time. Methods __init__ ( self , actor , torque ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. torque ( carla.Vector3D - degrees ) command.ApplyTransform Command adaptation of set_transform() in carla.Actor . Sets a new transform to an actor. Instance Variables actor_id ( int ) Actor affected by the command. transform ( carla.Transform ) Transformation to be applied. Methods __init__ ( self , actor , transform ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. transform ( carla.Transform ) command.ApplyVehicleControl Command adaptation of apply_control() in carla.Vehicle . Applies a certain control to a vehicle. Instance Variables actor_id ( int ) Vehicle actor affected by the command. control ( carla.VehicleControl ) Vehicle control to be applied. Methods __init__ ( self , actor , control ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. control ( carla.VehicleControl ) command.ApplyVehiclePhysicsControl Command adaptation of apply_physics_control() in carla.Vehicle . Applies a new physics control to a vehicle, modifying its physical parameters. Instance Variables actor_id ( int ) Vehicle actor affected by the command. control ( carla.VehiclePhysicsControl ) Physics control to be applied. Methods __init__ ( self , actor , control ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. control ( carla.VehiclePhysicsControl ) command.ApplyWalkerControl Command adaptation of apply_control() in carla.Walker . Applies a control to a walker. Instance Variables actor_id ( int ) Walker actor affected by the command. control ( carla.WalkerControl ) Walker control to be applied. Methods __init__ ( self , actor , control ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. control ( carla.WalkerControl ) command.ApplyWalkerState Apply a state to the walker actor. Specially useful to initialize an actor them with a specific location, orientation and speed. Instance Variables actor_id ( int ) Walker actor affected by the command. transform ( carla.Transform ) Transform to be applied. speed ( float - m/s ) Speed to be applied. Methods __init__ ( self , actor , transform , speed ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. transform ( carla.Transform ) speed ( float - m/s ) command.DestroyActor Command adaptation of destroy() in carla.Actor that tells the simulator to destroy this actor. It has no effect if the actor was already destroyed. When executed with apply_batch_sync() in carla.Client there will be a command.Response that will return a boolean stating whether the actor was successfully destroyed. Instance Variables actor_id ( int ) Actor affected by the command. Methods __init__ ( self , actor ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. command.Response States the result of executing a command as either the ID of the actor to whom the command was applied to (when succeeded) or an error string (when failed). actor ID, depending on whether or not the command succeeded. The method apply_batch_sync() in carla.Client returns a list of these to summarize the execution of a batch. Instance Variables actor_id ( int ) Actor to whom the command was applied to. States that the command was successful. error ( str ) A string stating the command has failed. Methods has_error ( self ) Returns True if the command execution fails, and False if it was successful. Return: bool command.SetAutopilot Command adaptation of set_autopilot() in carla.Vehicle . Turns on/off the vehicle's autopilot mode. Instance Variables actor_id ( int ) Actor that is affected by the command. enabled ( bool ) If autopilot should be activated or not. port ( uint16 ) Port of the Traffic Manager where the vehicle is to be registered or unlisted. Methods __init__ ( self , actor , enabled , port =8000 ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. enabled ( bool ) port ( uint16 ) - The Traffic Manager port where the vehicle is to be registered or unlisted. If None is passed, it will consider a TM at default port 8000 . command.SetEnableGravity Command adaptation of set_enable_gravity() in carla.Actor . Enables or disables gravity on an actor. Instance Variables actor_id ( carla.Actor or int ) Actor that is affected by the command. enabled ( bool ) Methods __init__ ( self , actor , enabled ) Parameters: actor ( carla.Actor or int ) - Actor or Actor ID to which the command will be applied to. enabled ( bool ) command.SetSimulatePhysics Command adaptation of set_simulate_physics() in carla.Actor . Determines whether an actor will be affected by physics or not. Instance Variables actor_id ( int ) Actor affected by the command. enabled ( bool ) If physics should be activated or not. Methods __init__ ( self , actor , enabled ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. enabled ( bool ) command.SetVehicleLightState Command adaptation of set_light_state() in carla.Vehicle . Sets the light state of a vehicle. Instance Variables actor_id ( int ) Actor that is affected by the command. light_state ( carla.VehicleLightState ) Defines the light state of a vehicle. Methods __init__ ( self , actor , light_state ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. light_state ( carla.VehicleLightState ) - Recaps the state of the lights of a vehicle, these can be used as a flags. command.ShowDebugTelemetry Command adaptation of show_debug_telemetry() in carla.Actor . Displays vehicle control telemetry data. Instance Variables actor_id ( carla.Actor or int ) Actor that is affected by the command. enabled ( bool ) Methods __init__ ( self , actor , enabled ) Parameters: actor ( carla.Actor or int ) - Actor or Actor ID to which the command will be applied to. enabled ( bool ) command.SpawnActor Command adaptation of spawn_actor() in carla.World . Spawns an actor into the world based on the blueprint provided and the transform. If a parent is provided, the actor is attached to it. Instance Variables transform ( carla.Transform ) Transform to be applied. parent_id ( int ) Identificator of the parent actor. Methods __init__ ( self ) __init__ ( self , blueprint , transform ) Parameters: blueprint ( carla.ActorBlueprint ) transform ( carla.Transform ) __init__ ( self , blueprint , transform , parent ) Parameters: blueprint ( carla.ActorBlueprint ) transform ( carla.Transform ) parent ( carla.Actor or int ) then ( self , command ) Links another command to be executed right after. It allows to ease very common flows such as spawning a set of vehicles by command and then using this method to set them to autopilot automatically. Parameters: command ( any carla Command ) - a Carla command. function CopyToClipboard(containerid) { if (document.selection) { var range = document.body.createTextRange(); range.moveToElementText(document.getElementById(containerid)); range.select().createTextRange(); document.execCommand(\"copy\"); } else if (window.getSelection) { var range = document.createRange(); range.selectNode(document.getElementById(containerid)); window.getSelection().addRange(range); document.execCommand(\"copy\"); } } function CloseSnipet() { document.getElementById(\"snipets-container\").innerHTML = null; } Snippet for carla.World.load_map_layer # This recipe toggles on several layers in our \"_Opt\" maps # Load town one with only minimum layout (roads, sidewalks, traffic lights and traffic signs) world = client.load_world('Town01_Opt', carla.MapLayer.None) # Toggle all buildings on world.load_map_layer(carla.MapLayer.Buildings) # Toggle all foliage on world.load_map_layer(carla.MapLayer.Foliage) # Toggle all parked vehicles on world.load_map_layer(carla.MapLayer.ParkedVehicles) Copy snippet Close snippet Snippet for carla.ActorBlueprint.set_attribute # This recipe changes attributes of different type of blueprint actors. # ... walker_bp = world.get_blueprint_library().filter('walker.pedestrian.0002') walker_bp.set_attribute('is_invincible', True) # ... # Changes attribute randomly by the recommended value vehicle_bp = wolrd.get_blueprint_library().filter('vehicle.bmw.*') color = random.choice(vehicle_bp.get_attribute('color').recommended_values) vehicle_bp.set_attribute('color', color) # ... camera_bp = world.get_blueprint_library().filter('sensor.camera.rgb') camera_bp.set_attribute('image_size_x', 600) camera_bp.set_attribute('image_size_y', 600) # ... Copy snippet Close snippet Snippet for carla.Client.apply_batch_sync # 0. Choose a blueprint fo the walkers world = client.get_world() blueprintsWalkers = world.get_blueprint_library().filter(\"walker.pedestrian.*\") walker_bp = random.choice(blueprintsWalkers) # 1. Take all the random locations to spawn spawn_points = [] for i in range(50): spawn_point = carla.Transform() spawn_point.location = world.get_random_location_from_navigation() if (spawn_point.location != None): spawn_points.append(spawn_point) # 2. Build the batch of commands to spawn the pedestrians batch = [] for spawn_point in spawn_points: walker_bp = random.choice(blueprintsWalkers) batch.append(carla.command.SpawnActor(walker_bp, spawn_point)) # 2.1 apply the batch results = client.apply_batch_sync(batch, True) for i in range(len(results)): if results[i].error: logging.error(results[i].error) else: walkers_list.append({\"id\": results[i].actor_id}) # 3. Spawn walker AI controllers for each walker batch = [] walker_controller_bp = world.get_blueprint_library().find('controller.ai.walker') for i in range(len(walkers_list)): batch.append(carla.command.SpawnActor(walker_controller_bp, carla.Transform(), walkers_list[i][\"id\"])) # 3.1 apply the batch results = client.apply_batch_sync(batch, True) for i in range(len(results)): if results[i].error: logging.error(results[i].error) else: walkers_list[i][\"con\"] = results[i].actor_id # 4. Put altogether the walker and controller ids for i in range(len(walkers_list)): all_id.append(walkers_list[i][\"con\"]) all_id.append(walkers_list[i][\"id\"]) all_actors = world.get_actors(all_id) # wait for a tick to ensure client receives the last transform of the walkers we have just created world.wait_for_tick() # 5. initialize each controller and set target to walk to (list is [controller, actor, controller, actor ...]) for i in range(0, len(all_actors), 2): # start walker all_actors[i].start() # set walk to random point all_actors[i].go_to_location(world.get_random_location_from_navigation()) # random max speed all_actors[i].set_max_speed(1 + random.random()) # max speed between 1 and 2 (default is 1.4 m/s) Copy snippet Close snippet Snippet for carla.WalkerAIController.stop #To destroy the pedestrians, stop them from the navigation, and then destroy the objects (actor and controller). # stop pedestrians (list is [controller, actor, controller, actor ...]) for i in range(0, len(all_id), 2): all_actors[i].stop() # destroy pedestrian (actor and controller) client.apply_batch([carla.command.DestroyActor(x) for x in all_id]) Copy snippet Close snippet Snippet for carla.DebugHelper.draw_string # This recipe is a modification of lane_explorer.py example. # It draws the path of an actor through the world, printing information at each waypoint. # ... current_w = map.get_waypoint(vehicle.get_location()) while True: next_w = map.get_waypoint(vehicle.get_location(), lane_type=carla.LaneType.Driving | carla.LaneType.Shoulder | carla.LaneType.Sidewalk ) # Check if the vehicle is moving if next_w.id != current_w.id: vector = vehicle.get_velocity() # Check if the vehicle is on a sidewalk if current_w.lane_type == carla.LaneType.Sidewalk: draw_waypoint_union(debug, current_w, next_w, cyan if current_w.is_junction else red, 60) else: draw_waypoint_union(debug, current_w, next_w, cyan if current_w.is_junction else green, 60) debug.draw_string(current_w.transform.location, str('%15.0f km/h' % (3.6 * math.sqrt(vector.x**2 + vector.y**2 + vector.z**2))), False, orange, 60) draw_transform(debug, current_w.transform, white, 60) # Update the current waypoint and sleep for some time current_w = next_w time.sleep(args.tick_time) # ... Copy snippet Close snippet Snippet for carla.Map.get_waypoint # This recipe shows the current traffic rules affecting the vehicle. # Shows the current lane type and if a lane change can be done in the actual lane or the surrounding ones. # ... waypoint = world.get_map().get_waypoint(vehicle.get_location(),project_to_road=True, lane_type=(carla.LaneType.Driving | carla.LaneType.Shoulder | carla.LaneType.Sidewalk)) print(\"Current lane type: \" + str(waypoint.lane_type)) # Check current lane change allowed print(\"Current Lane change: \" + str(waypoint.lane_change)) # Left and Right lane markings print(\"L lane marking type: \" + str(waypoint.left_lane_marking.type)) print(\"L lane marking change: \" + str(waypoint.left_lane_marking.lane_change)) print(\"R lane marking type: \" + str(waypoint.right_lane_marking.type)) print(\"R lane marking change: \" + str(waypoint.right_lane_marking.lane_change)) # ... Copy snippet Close snippet Snippet for carla.TrafficLight.set_state # This recipe changes from red to green the traffic light that affects the vehicle. # This is done by detecting if the vehicle actor is at a traffic light. # ... world = client.get_world() spectator = world.get_spectator() vehicle_bp = random.choice(world.get_blueprint_library().filter('vehicle.bmw.*')) transform = random.choice(world.get_map().get_spawn_points()) vehicle = world.try_spawn_actor(vehicle_bp, transform) # Wait for world to get the vehicle actor world.tick() world_snapshot = world.wait_for_tick() actor_snapshot = world_snapshot.find(vehicle.id) # Set spectator at given transform (vehicle transform) spectator.set_transform(actor_snapshot.get_transform()) # ...# ... if vehicle_actor.is_at_traffic_light(): traffic_light = vehicle_actor.get_traffic_light() if traffic_light.get_state() == carla.TrafficLightState.Red: # world.hud.notification(\"Traffic light changed! Good to go!\") traffic_light.set_state(carla.TrafficLightState.Green) # ... Copy snippet Close snippet Snippet for carla.World.unload_map_layer # This recipe toggles off several layers in our \"_Opt\" maps # Load town one with minimum layout (roads, sidewalks, traffic lights and traffic signs) # as well as buildings and parked vehicles world = client.load_world('Town01_Opt', carla.MapLayer.Buildings | carla.MapLayer.ParkedVehicles) # Toggle all buildings off world.unload_map_layer(carla.MapLayer.Buildings) # Toggle all parked vehicles off world.unload_map_layer(carla.MapLayer.ParkedVehicles) Copy snippet Close snippet Snippet for carla.DebugHelper.draw_box # This recipe shows how to draw traffic light actor bounding boxes from a world snapshot. # .... debug = world.debug world_snapshot = world.get_snapshot() for actor_snapshot in world_snapshot: actual_actor = world.get_actor(actor_snapshot.id) if actual_actor.type_id == 'traffic.traffic_light': debug.draw_box(carla.BoundingBox(actor_snapshot.get_transform().location,carla.Vector3D(0.5,0.5,2)),actor_snapshot.get_transform().rotation, 0.05, carla.Color(255,0,0,0),0) # ... Copy snippet Close snippet Snippet for carla.Client.__init__ # This recipe shows in every script provided in PythonAPI/Examples # and it is used to parse the client creation arguments when running the script. argparser = argparse.ArgumentParser( description=__doc__) argparser.add_argument( '--host', metavar='H', default='127.0.0.1', help='IP of the host server (default: 127.0.0.1)') argparser.add_argument( '-p', '--port', metavar='P', default=2000, type=int, help='TCP port to listen to (default: 2000)') argparser.add_argument( '-s', '--speed', metavar='FACTOR', default=1.0, type=float, help='rate at which the weather changes (default: 1.0)') args = argparser.parse_args() speed_factor = args.speed update_freq = 0.1 / speed_factor client = carla.Client(args.host, args.port) Copy snippet Close snippet Snippet for carla.Vehicle.set_wheel_steer_direction # Sets the appearance of the vehicles front wheels to 40\u00b0. Vehicle physics will not be affected. vehicle.set_wheel_steer_direction(carla.VehicleWheelLocation.FR_Wheel, 40.0) vehicle.set_wheel_steer_direction(carla.VehicleWheelLocation.FL_Wheel, 40.0) Copy snippet Close snippet Snippet for carla.Sensor.listen # This recipe applies a color conversion to the image taken by a camera sensor, # so it is converted to a semantic segmentation image. # ... camera_bp = world.get_blueprint_library().filter('sensor.camera.semantic_segmentation') # ... cc = carla.ColorConverter.CityScapesPalette camera.listen(lambda image: image.save_to_disk('output/%06d.png' % image.frame, cc)) # ... Copy snippet Close snippet Snippet for carla.World.enable_environment_objects # This recipe turn visibility off and on for two specifc buildings on the map # Get the buildings in the world world = client.get_world() env_objs = world.get_environment_objects(carla.CityObjectLabel.Buildings) # Access individual building IDs and save in a set building_01 = env_objs[0] building_02 = env_objs[1] objects_to_toggle = {building_01.id, building_02.id} # Toggle buildings off world.enable_environment_objects(objects_to_toggle, False) # Toggle buildings on world.enable_environment_objects(objects_to_toggle, True) Copy snippet Close snippet Snippet for carla.World.spawn_actor # This recipe attaches different camera / sensors to a vehicle with different attachments. # ... camera = world.spawn_actor(rgb_camera_bp, transform, attach_to=vehicle, attachment_type=Attachment.Rigid) # Default attachment: Attachment.Rigid gnss_sensor = world.spawn_actor(sensor_gnss_bp, transform, attach_to=vehicle) collision_sensor = world.spawn_actor(sensor_collision_bp, transform, attach_to=vehicle) lane_invasion_sensor = world.spawn_actor(sensor_lane_invasion_bp, transform, attach_to=vehicle) # ... Copy snippet Close snippet Snippet for carla.World.get_spectator # This recipe spawns an actor and the spectator camera at the actor's location. # ... world = client.get_world() spectator = world.get_spectator() vehicle_bp = random.choice(world.get_blueprint_library().filter('vehicle.bmw.*')) transform = random.choice(world.get_map().get_spawn_points()) vehicle = world.try_spawn_actor(vehicle_bp, transform) # Wait for world to get the vehicle actor world.tick() world_snapshot = world.wait_for_tick() actor_snapshot = world_snapshot.find(vehicle.id) # Set spectator at given transform (vehicle transform) spectator.set_transform(actor_snapshot.get_transform()) # ... Copy snippet Close snippet function ButtonAction(container_name){ if(window_big){ snipet_name = container_name.replace('-snipet_button','-snipet'); document.getElementById(\"snipets-container\").innerHTML = document.getElementById(snipet_name).innerHTML; } else{ document.getElementById(\"snipets-container\").innerHTML = null;code_name = container_name.replace('-snipet_button','-code'); var range = document.createRange(); range.selectNode(document.getElementById(code_name)); alert(range); } } function WindowResize(){ if(window.innerWidth > 1200){ window_big = true; } else{ window_big = false; } } var window_big; if(window.innerWidth > 1200){ window_big = true; } else{ window_big = false; } buttons = document.getElementsByClassName('SnipetButton') for (let i = 0; i < buttons.length; i++) { buttons[i].addEventListener(\"click\",function(){ButtonAction(buttons[i].id);},true); } window.onresize = WindowResize;","title":"Python API \u53c2\u8003"},{"location":"python_api/#python-api-reference","text":"This reference contains all the details the Python API. To consult a previous reference for a specific CARLA release, change the documentation version using the panel in the bottom right corner. This will change the whole documentation to a previous state. Remember that the latest version is the dev branch and may show features not available in any packaged versions of CARLA.","title":"Python API reference"},{"location":"python_api/#carlaactor","text":"CARLA defines actors as anything that plays a role in the simulation or can be moved around. That includes: pedestrians, vehicles, sensors and traffic signs (considering traffic lights as part of these). Actors are spawned in the simulation by carla.World and they need for a carla.ActorBlueprint to be created. These blueprints belong into a library provided by CARLA, find more about them here .","title":"carla.Actor"},{"location":"python_api/#instance-variables","text":"attributes ( dict ) A dictionary containing the attributes of the blueprint this actor was based on. id ( int ) Identifier for this actor. Unique during a given episode. is_alive ( bool ) Returns whether this object was destroyed using this actor handle. parent ( carla.Actor ) Actors may be attached to a parent actor that they will follow around. This is said actor. semantic_tags ( list(int) ) A list of semantic tags provided by the blueprint listing components for this actor. E.g. a traffic light could be tagged with Pole and TrafficLight . These tags are used by the semantic segmentation sensor. Find more about this and other sensors here . type_id ( str ) The identifier of the blueprint this actor was based on, e.g. vehicle.ford.mustang .","title":"Instance Variables"},{"location":"python_api/#methods","text":"add_angular_impulse ( self , angular_impulse ) Applies an angular impulse at the center of mass of the actor. This method should be used for instantaneous torques, usually applied once. Use add_torque() to apply rotation forces over a period of time. Parameters: angular_impulse ( carla.Vector3D - degrees*s ) - Angular impulse vector in global coordinates. add_force ( self , force ) Applies a force at the center of mass of the actor. This method should be used for forces that are applied over a certain period of time. Use add_impulse() to apply an impulse that only lasts an instant. Parameters: force ( carla.Vector3D - N ) - Force vector in global coordinates. add_impulse ( self , impulse ) Applies an impulse at the center of mass of the actor. This method should be used for instantaneous forces, usually applied once. Use add_force() to apply forces over a period of time. Parameters: impulse ( carla.Vector3D - N*s ) - Impulse vector in global coordinates. add_torque ( self , torque ) Applies a torque at the center of mass of the actor. This method should be used for torques that are applied over a certain period of time. Use add_angular_impulse() to apply a torque that only lasts an instant. Parameters: torque ( carla.Vector3D - degrees ) - Torque vector in global coordinates. close_door ( self , door_idx ) Close the door door_idx if the vehicle has it. Use carla.VehicleDoor.All to close all available doors. Parameters: door_idx ( carla.VehicleDoor ) - door index. Note: Only carla.Vehicle actors can use this method. destroy ( self ) Tells the simulator to destroy this actor and returns True if it was successful. It has no effect if it was already destroyed. Return: bool Warning: This method blocks the script until the destruction is completed by the simulator. disable_constant_velocity ( self ) Disables any constant velocity previously set for a carla.Vehicle actor. enable_chrono_physics ( self , max_substeps , max_substep_delta_time , vehicle_json , powertrain_json , tire_json , base_json_path ) Enables Chrono physics on a spawned vehicle. Parameters: max_substeps ( int ) - Max number of Chrono substeps. max_substep_delta_time ( int ) - Max size of substep. vehicle_json ( str ) - Path to vehicle json file relative to base_json_path . powertrain_json ( str ) - Path to powertrain json file relative to base_json_path . tire_json ( str ) - Path to tire json file relative to base_json_path . base_json_path ( str ) - Path to chrono/data/vehicle folder. E.g., /home/user/carla/Build/chrono-install/share/chrono/data/vehicle/ (the final / character is required). Note: Ensure that you have started the CARLA server with the ARGS=\"--chrono\" flag. You will not be able to use Chrono physics without this flag set. Warning: Collisions are not supported. When a collision is detected, physics will revert to the default CARLA physics. enable_constant_velocity ( self , velocity ) Sets a vehicle's velocity vector to a constant value over time. The resulting velocity will be approximately the velocity being set, as with set_target_velocity() . Parameters: velocity ( carla.Vector3D - m/s ) - Velocity vector in local space. Note: Only carla.Vehicle actors can use this method. Warning: Enabling a constant velocity for a vehicle managed by the Traffic Manager may cause conflicts. This method overrides any changes in velocity by the TM. open_door ( self , door_idx ) Open the door door_idx if the vehicle has it. Use carla.VehicleDoor.All to open all available doors. Parameters: door_idx ( carla.VehicleDoor ) - door index. Note: Only carla.Vehicle actors can use this method. show_debug_telemetry ( self , enabled =True ) Enables or disables the telemetry on this vehicle. This shows information about the vehicles current state and forces applied to it in the spectator window. Only information for one vehicle can be shown so if you enable a second one, the previous will be automatically disabled. Parameters: enabled ( bool )","title":"Methods"},{"location":"python_api/#getters","text":"get_acceleration ( self ) Returns the actor's 3D acceleration vector the client recieved during last tick. The method does not call the simulator. Return: carla.Vector3D - m/s 2 get_angular_velocity ( self ) Returns the actor's angular velocity vector the client recieved during last tick. The method does not call the simulator. Return: carla.Vector3D - deg/s get_location ( self ) Returns the actor's location the client recieved during last tick. The method does not call the simulator. Return: carla.Location - meters Setter: carla.Actor.set_location get_transform ( self ) Returns the actor's transform (location and rotation) the client recieved during last tick. The method does not call the simulator. Return: carla.Transform Setter: carla.Actor.set_transform get_velocity ( self ) Returns the actor's velocity vector the client recieved during last tick. The method does not call the simulator. Return: carla.Vector3D - m/s get_world ( self ) Returns the world this actor belongs to. Return: carla.World","title":"Getters"},{"location":"python_api/#setters","text":"set_enable_gravity ( self , enabled ) Enables or disables gravity for the actor. Default is True. Parameters: enabled ( bool ) set_location ( self , location ) Teleports the actor to a given location. Parameters: location ( carla.Location - meters ) Getter: carla.Actor.get_location set_simulate_physics ( self , enabled =True ) Enables or disables the simulation of physics on this actor. Parameters: enabled ( bool ) set_target_angular_velocity ( self , angular_velocity ) Sets the actor's angular velocity vector. This is applied before the physics step so the resulting angular velocity will be affected by external forces such as friction. Parameters: angular_velocity ( carla.Vector3D - deg/s ) set_target_velocity ( self , velocity ) Sets the actor's velocity vector. This is applied before the physics step so the resulting angular velocity will be affected by external forces such as friction. Parameters: velocity ( carla.Vector3D ) set_transform ( self , transform ) Teleports the actor to a given transform (location and rotation). Parameters: transform ( carla.Transform ) Getter: carla.Actor.get_transform","title":"Setters"},{"location":"python_api/#dunder-methods","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaactorattribute","text":"CARLA provides a library of blueprints for actors that can be accessed as carla.BlueprintLibrary . Each of these blueprints has a series of attributes defined internally. Some of these are modifiable, others are not. A list of recommended values is provided for those that can be set.","title":"carla.ActorAttribute"},{"location":"python_api/#instance-variables_1","text":"id ( str ) The attribute's name and identifier in the library. is_modifiable ( bool ) It is True if the attribute's value can be modified. recommended_values ( list(str) ) A list of values suggested by those who designed the blueprint. type ( carla.ActorAttributeType ) The attribute's parameter type.","title":"Instance Variables"},{"location":"python_api/#methods_1","text":"as_bool ( self ) Reads the attribute as boolean value. as_color ( self ) Reads the attribute as carla.Color . as_float ( self ) Reads the attribute as float. as_int ( self ) Reads the attribute as int. as_str ( self ) Reads the attribute as string.","title":"Methods"},{"location":"python_api/#dunder-methods_1","text":"__bool__ ( self ) __eq__ ( self , other =bool / int / float / str / carla.Color / carla.ActorAttribute ) Returns true if this actor's attribute and other are the same. Return: bool __float__ ( self ) __int__ ( self ) __ne__ ( self , other =bool / int / float / str / carla.Color / carla.ActorAttribute ) Returns true if this actor's attribute and other are different. Return: bool __nonzero__ ( self ) Returns true if this actor's attribute is not zero or null. Return: bool __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaactorattributetype","text":"CARLA provides a library of blueprints for actors in carla.BlueprintLibrary with different attributes each. This class defines the types those at carla.ActorAttribute can be as a series of enum. All this information is managed internally and listed here for a better comprehension of how CARLA works.","title":"carla.ActorAttributeType"},{"location":"python_api/#instance-variables_2","text":"Bool Int Float String RGBColor","title":"Instance Variables"},{"location":"python_api/#carlaactorblueprint","text":"CARLA provides a blueprint library for actors that can be consulted through carla.BlueprintLibrary . Each of these consists of an identifier for the blueprint and a series of attributes that may be modifiable or not. This class is the intermediate step between the library and the actor creation. Actors need an actor blueprint to be spawned. These store the information for said blueprint in an object with its attributes and some tags to categorize them. The user can then customize some attributes and eventually spawn the actors through carla.World .","title":"carla.ActorBlueprint"},{"location":"python_api/#instance-variables_3","text":"id ( str ) The identifier of said blueprint inside the library. E.g. walker.pedestrian.0001 . tags ( list(str) ) A list of tags each blueprint has that helps describing them. E.g. ['0001', 'pedestrian', 'walker'] .","title":"Instance Variables"},{"location":"python_api/#methods_2","text":"has_attribute ( self , id ) Returns True if the blueprint contains the attribute id . Parameters: id ( str ) - e.g. gender would return True for pedestrians' blueprints. Return: bool has_tag ( self , tag ) Returns True if the blueprint has the specified tag listed. Parameters: tag ( str ) - e.g. 'walker'. Return: bool match_tags ( self , wildcard_pattern ) Returns True if any of the tags listed for this blueprint matches wildcard_pattern . Matching follows fnmatch standard. Parameters: wildcard_pattern ( str ) Return: bool","title":"Methods"},{"location":"python_api/#getters_1","text":"get_attribute ( self , id ) Returns the actor's attribute with id as identifier if existing. Parameters: id ( str ) Return: carla.ActorAttribute Setter: carla.ActorBlueprint.set_attribute","title":"Getters"},{"location":"python_api/#setters_1","text":"set_attribute ( self , id , value ) snippet \u2192 If the id attribute is modifiable, changes its value to value . Parameters: id ( str ) - The identifier for the attribute that is intended to be changed. value ( str ) - The new value for said attribute. Getter: carla.ActorBlueprint.get_attribute","title":"Setters"},{"location":"python_api/#dunder-methods_2","text":"__iter__ ( self ) Iterate over the carla.ActorAttribute that this blueprint has. __len__ ( self ) Returns the amount of attributes for this blueprint. __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaactorlist","text":"A class that contains every actor present on the scene and provides access to them. The list is automatically created and updated by the server and it can be returned using carla.World .","title":"carla.ActorList"},{"location":"python_api/#methods_3","text":"filter ( self , wildcard_pattern ) Filters a list of Actors matching wildcard_pattern against their variable type_id (which identifies the blueprint used to spawn them). Matching follows fnmatch standard. Parameters: wildcard_pattern ( str ) Return: list find ( self , actor_id ) Finds an actor using its identifier and returns it or None if it is not present. Parameters: actor_id ( int ) Return: carla.Actor","title":"Methods"},{"location":"python_api/#dunder-methods_3","text":"__getitem__ ( self , pos =int ) Returns the actor corresponding to pos position in the list. Return: carla.Actor __iter__ ( self ) Iterate over the carla.Actor contained in the list. __len__ ( self ) Returns the amount of actors listed. Return: int __str__ ( self ) Parses to the ID for every actor listed. Return: str","title":"Dunder methods"},{"location":"python_api/#carlaactorsnapshot","text":"A class that comprises all the information for an actor at a certain moment in time. These objects are contained in a carla.WorldSnapshot and sent to the client once every tick.","title":"carla.ActorSnapshot"},{"location":"python_api/#instance-variables_4","text":"id ( int ) An identifier for the snapshot itself.","title":"Instance Variables"},{"location":"python_api/#methods_4","text":"","title":"Methods"},{"location":"python_api/#getters_2","text":"get_acceleration ( self ) Returns the acceleration vector registered for an actor in that tick. Return: carla.Vector3D - m/s 2 get_angular_velocity ( self ) Returns the angular velocity vector registered for an actor in that tick. Return: carla.Vector3D - rad/s get_transform ( self ) Returns the actor's transform (location and rotation) for an actor in that tick. Return: carla.Transform get_velocity ( self ) Returns the velocity vector registered for an actor in that tick. Return: carla.Vector3D - m/s","title":"Getters"},{"location":"python_api/#carlaattachmenttype","text":"Class that defines attachment options between an actor and its parent. When spawning actors, these can be attached to another actor so their position changes accordingly. This is specially useful for sensors. The snipet in carla.World.spawn_actor shows some sensors being attached to a car when spawned. Note that the attachment type is declared as an enum within the class.","title":"carla.AttachmentType"},{"location":"python_api/#instance-variables_5","text":"Rigid With this fixed attatchment the object follow its parent position strictly. This is the recommended attachment to retrieve precise data from the simulation. SpringArm An attachment that expands or retracts the position of the actor, depending on its parent. This attachment is only recommended to record videos from the simulation where a smooth movement is needed. SpringArms are an Unreal Engine component so check the UE docs to learn more about them. Warning: The SpringArm attachment presents weird behaviors when an actor is spawned with a relative translation in the Z-axis (e.g. child_location = Location(0,0,2) ).","title":"Instance Variables"},{"location":"python_api/#carlablueprintlibrary","text":"A class that contains the blueprints provided for actor spawning. Its main application is to return carla.ActorBlueprint objects needed to spawn actors. Each blueprint has an identifier and attributes that may or may not be modifiable. The library is automatically created by the server and can be accessed through carla.World . Here is a reference containing every available blueprint and its specifics.","title":"carla.BlueprintLibrary"},{"location":"python_api/#methods_5","text":"filter ( self , wildcard_pattern ) Filters a list of blueprints matching the wildcard_pattern against the id and tags of every blueprint contained in this library and returns the result as a new one. Matching follows fnmatch standard. Parameters: wildcard_pattern ( str ) Return: carla.BlueprintLibrary find ( self , id ) Returns the blueprint corresponding to that identifier. Parameters: id ( str ) Return: carla.ActorBlueprint","title":"Methods"},{"location":"python_api/#dunder-methods_4","text":"__getitem__ ( self , pos =int ) Returns the blueprint stored in pos position inside the data structure containing them. Return: carla.ActorBlueprint __iter__ ( self ) Iterate over the carla.ActorBlueprint stored in the library. __len__ ( self ) Returns the amount of blueprints comprising the library. Return: int __str__ ( self ) Parses the identifiers for every blueprint to string. Return: string","title":"Dunder methods"},{"location":"python_api/#carlaboundingbox","text":"Bounding boxes contain the geometry of an actor or an element in the scene. They can be used by carla.DebugHelper or a carla.Client to draw their shapes for debugging. Check out the snipet in carla.DebugHelper.draw_box where a snapshot of the world is used to draw bounding boxes for traffic lights.","title":"carla.BoundingBox"},{"location":"python_api/#instance-variables_6","text":"extent ( carla.Vector3D - meters ) Vector from the center of the box to one vertex. The value in each axis equals half the size of the box for that axis. extent.x * 2 would return the size of the box in the X-axis. location ( carla.Location - meters ) The center of the bounding box. rotation ( carla.Rotation ) The orientation of the bounding box.","title":"Instance Variables"},{"location":"python_api/#methods_6","text":"__init__ ( self , location , extent ) Parameters: location ( carla.Location ) - Center of the box, relative to its parent. extent ( carla.Vector3D - meters ) - Vector containing half the size of the box for every axis. contains ( self , world_point , transform ) Returns True if a point passed in world space is inside this bounding box. Parameters: world_point ( carla.Location - meters ) - The point in world space to be checked. transform ( carla.Transform ) - Contains location and rotation needed to convert this object's local space to world space. Return: bool","title":"Methods"},{"location":"python_api/#getters_3","text":"get_local_vertices ( self ) Returns a list containing the locations of this object's vertices in local space. Return: list( carla.Location ) get_world_vertices ( self , transform ) Returns a list containing the locations of this object's vertices in world space. Parameters: transform ( carla.Transform ) - Contains location and rotation needed to convert this object's local space to world space. Return: list( carla.Location )","title":"Getters"},{"location":"python_api/#dunder-methods_5","text":"__eq__ ( self , other = carla.BoundingBox ) Returns true if both location and extent are equal for this and other . Return: bool __ne__ ( self , other = carla.BoundingBox ) Returns true if either location or extent are different for this and other . Return: bool __str__ ( self ) Parses the location and extent of the bounding box to string. Return: str","title":"Dunder methods"},{"location":"python_api/#carlacityobjectlabel","text":"Enum declaration that contains the different tags available to filter the bounding boxes returned by carla.World.get_level_bbs (). These values correspond to the semantic tag that the elements in the scene have.","title":"carla.CityObjectLabel"},{"location":"python_api/#instance-variables_7","text":"None Buildings Fences Other Pedestrians Poles RoadLines Roads Sidewalks TrafficSigns Vegetation Vehicles Walls Sky Ground Bridge RailTrack GuardRail TrafficLight Static Dynamic Water Terrain Any","title":"Instance Variables"},{"location":"python_api/#carlaclient","text":"The Client connects CARLA to the server which runs the simulation. Both server and client contain a CARLA library (libcarla) with some differences that allow communication between them. Many clients can be created and each of these will connect to the RPC server inside the simulation to send commands. The simulation runs server-side. Once the connection is established, the client will only receive data retrieved from the simulation. Walkers are the exception. The client is in charge of managing pedestrians so, if you are running a simulation with multiple clients, some issues may arise. For example, if you spawn walkers through different clients, collisions may happen, as each client is only aware of the ones it is in charge of. The client also has a recording feature that saves all the information of a simulation while running it. This allows the server to replay it at will to obtain information and experiment with it. Here is some information about how to use this recorder.","title":"carla.Client"},{"location":"python_api/#methods_7","text":"__init__ ( self , host =127.0.0.1 , port =2000 , worker_threads =0 ) snippet \u2192 Client constructor. Parameters: host ( str ) - IP address where a CARLA Simulator instance is running. Default is localhost (127.0.0.1). port ( int ) - TCP port where the CARLA Simulator instance is running. Default are 2000 and the subsequent 2001. worker_threads ( int ) - Number of working threads used for background updates. If 0, use all available concurrency. apply_batch ( self , commands ) Executes a list of commands on a single simulation step and retrieves no information. If you need information about the response of each command, use the apply_batch_sync() method. Here is an example on how to delete the actors that appear in carla.ActorList all at once. Parameters: commands ( list ) - A list of commands to execute in batch. Each command is different and has its own parameters. They appear listed at the bottom of this page. apply_batch_sync ( self , commands , due_tick_cue =False ) snippet \u2192 Executes a list of commands on a single simulation step, blocks until the commands are linked, and returns a list of command.Response that can be used to determine whether a single command succeeded or not. Here is an example of it being used to spawn actors. Parameters: commands ( list ) - A list of commands to execute in batch. The commands available are listed right above, in the method apply_batch() . due_tick_cue ( bool ) - A boolean parameter to specify whether or not to perform a carla.World.tick after applying the batch in synchronous mode . It is False by default. Return: list(command.Response) generate_opendrive_world ( self , opendrive , parameters =(2.0, 50.0, 1.0, 0.6, true, true) , reset_settings =True ) Loads a new world with a basic 3D topology generated from the content of an OpenDRIVE file. This content is passed as a string parameter. It is similar to client.load_world(map_name) but allows for custom OpenDRIVE maps in server side. Cars can drive around the map, but there are no graphics besides the road and sidewalks. Parameters: opendrive ( str ) - Content of an OpenDRIVE file as string , not the path to the .xodr . parameters ( carla.OpendriveGenerationParameters ) - Additional settings for the mesh generation. If none are provided, default values will be used. reset_settings ( bool ) - Option to reset the episode setting to default values, set to false to keep the current settings. This is useful to keep sync mode when changing map and to keep deterministic scenarios. load_world ( self , map_name , reset_settings =True , map_layers = carla.MapLayer.All ) Creates a new world with default settings using map_name map. All actors in the current world will be destroyed. Parameters: map_name ( str ) - Name of the map to be used in this world. Accepts both full paths and map names, e.g. '/Game/Carla/Maps/Town01' or 'Town01'. Remember that these paths are dynamic. reset_settings ( bool ) - Option to reset the episode setting to default values, set to false to keep the current settings. This is useful to keep sync mode when changing map and to keep deterministic scenarios. map_layers ( carla.MapLayer ) - Layers of the map that will be loaded. By default all layers are loaded. This parameter works like a flag mask. Warning: map_layers are only available for \"Opt\" maps reload_world ( self , reset_settings =True ) Reload the current world, note that a new world is created with default settings using the same map. All actors present in the world will be destroyed, but traffic manager instances will stay alive. Parameters: reset_settings ( bool ) - Option to reset the episode setting to default values, set to false to keep the current settings. This is useful to keep sync mode when changing map and to keep deterministic scenarios. Raises: RuntimeError when corresponding. replay_file ( self , name , start , duration , follow_id , replay_sensors ) Load a new world with default settings using map_name map. All actors present in the current world will be destroyed, but traffic manager instances will stay alive. Parameters: name ( str ) - Name of the file containing the information of the simulation. start ( float - seconds ) - Time where to start playing the simulation. Negative is read as beginning from the end, being -10 just 10 seconds before the recording finished. duration ( float - seconds ) - Time that will be reenacted using the information name file. If the end is reached, the simulation will continue. follow_id ( int ) - ID of the actor to follow. If this is 0 then camera is disabled. replay_sensors ( bool ) - Flag to enable or disable the spawn of sensors during playback. request_file ( self , name ) Requests one of the required files returned by carla.Client.get_required_files . Parameters: name ( str ) - Name of the file you are requesting. show_recorder_actors_blocked ( self , filename , min_time , min_distance ) The terminal will show the information registered for actors considered blocked. An actor is considered blocked when it does not move a minimum distance in a period of time, being these min_distance and min_time . Parameters: filename ( str ) - Name of the recorded file to load. min_time ( float - seconds ) - Minimum time the actor has to move a minimum distance before being considered blocked. Default is 60 seconds. min_distance ( float - centimeters ) - Minimum distance the actor has to move to not be considered blocked. Default is 100 centimeters. Return: string show_recorder_collisions ( self , filename , category1 , category2 ) The terminal will show the collisions registered by the recorder. These can be filtered by specifying the type of actor involved. The categories will be specified in category1 and category2 as follows: 'h' = Hero, the one vehicle that can be controlled manually or managed by the user. 'v' = Vehicle 'w' = Walker 't' = Traffic light 'o' = Other 'a' = Any If you want to see only collisions between a vehicles and a walkers, use for category1 as 'v' and category2 as 'w' or vice versa. If you want to see all the collisions (filter off) you can use 'a' for both parameters. Parameters: filename ( str ) - Name or absolute path of the file recorded, depending on your previous choice. category1 ( single char ) - Character variable specifying a first type of actor involved in the collision. category2 ( single char ) - Character variable specifying the second type of actor involved in the collision. Return: string show_recorder_file_info ( self , filename , show_all ) The information saved by the recorder will be parsed and shown in your terminal as text (frames, times, events, state, positions...). The information shown can be specified by using the show_all parameter. Here is some more information about how to read the recorder file. Parameters: filename ( str ) - Name or absolute path of the file recorded, depending on your previous choice. show_all ( bool ) - If True , returns all the information stored for every frame (traffic light states, positions of all actors, orientation and animation data...). If False , returns a summary of key events and frames. Return: string start_recorder ( self , filename , additional_data =False ) Enables the recording feature, which will start saving every information possible needed by the server to replay the simulation. Parameters: filename ( str ) - Name of the file to write the recorded data. A simple name will save the recording in 'CarlaUE4/Saved/recording.log'. Otherwise, if some folder appears in the name, it will be considered an absolute path. additional_data ( bool ) - Enables or disable recording non-essential data for reproducing the simulation (bounding box location, physics control parameters, etc). stop_recorder ( self ) Stops the recording in progress. If you specified a path in filename , the recording will be there. If not, look inside CarlaUE4/Saved/ . stop_replayer ( self , keep_actors ) Stop current replayer. Parameters: keep_actors ( bool ) - True if you want autoremove all actors from the replayer, or False to keep them.","title":"Methods"},{"location":"python_api/#getters_4","text":"get_available_maps ( self ) Returns a list of strings containing the paths of the maps available on server. These paths are dynamic, they will be created during the simulation and so you will not find them when looking up in your files. One of the possible returns for this method would be: ['/Game/Carla/Maps/Town01', '/Game/Carla/Maps/Town02', '/Game/Carla/Maps/Town03', '/Game/Carla/Maps/Town04', '/Game/Carla/Maps/Town05', '/Game/Carla/Maps/Town06', '/Game/Carla/Maps/Town07']. Return: list(str) get_client_version ( self ) Returns the client libcarla version by consulting it in the \"Version.h\" file. Both client and server can use different libcarla versions but some issues may arise regarding unexpected incompatibilities. Return: str get_required_files ( self , folder , download =True ) Asks the server which files are required by the client to use the current map. Option to download files automatically if they are not already in the cache. Parameters: folder ( str ) - Folder where files required by the client will be downloaded to. download ( bool ) - If True, downloads files that are not already in cache. get_server_version ( self ) Returns the server libcarla version by consulting it in the \"Version.h\" file. Both client and server should use the same libcarla version. Return: str get_trafficmanager ( self , client_connection =8000 ) Returns an instance of the traffic manager related to the specified port. If it does not exist, this will be created. Parameters: client_connection ( int ) - Port that will be used by the traffic manager. Default is 8000 . Return: carla.TrafficManager get_world ( self ) Returns the world object currently active in the simulation. This world will be later used for example to load maps. Return: carla.World","title":"Getters"},{"location":"python_api/#setters_2","text":"set_files_base_folder ( self , path ) Parameters: path ( str ) - Specifies the base folder where the local cache for required files will be placed. set_replayer_ignore_hero ( self , ignore_hero ) Parameters: ignore_hero ( bool ) - Enables or disables playback of the hero vehicle during a playback of a recorded simulation. set_replayer_time_factor ( self , time_factor =1.0 ) When used, the time speed of the reenacted simulation is modified at will. It can be used several times while a playback is in curse. Parameters: time_factor ( float ) - 1.0 means normal time speed. Greater than 1.0 means fast motion (2.0 would be double speed) and lesser means slow motion (0.5 would be half speed). set_timeout ( self , seconds ) Sets the maxixum time a network call is allowed before blocking it and raising a timeout exceeded error. Parameters: seconds ( float - seconds ) - New timeout value. Default is 5 seconds.","title":"Setters"},{"location":"python_api/#carlacollisionevent","text":"Inherited from carla.SensorData Class that defines a collision data for sensor.other.collision . The sensor creates one of this for every collision detected which may be many for one simulation step. Learn more about this here .","title":"carla.CollisionEvent"},{"location":"python_api/#instance-variables_8","text":"actor ( carla.Actor ) The actor the sensor is attached to, the one that measured the collision. other_actor ( carla.Actor ) The second actor involved in the collision. normal_impulse ( carla.Vector3D - N*s ) Normal impulse resulting of the collision.","title":"Instance Variables"},{"location":"python_api/#carlacolor","text":"Class that defines a 32-bit RGBA color.","title":"carla.Color"},{"location":"python_api/#instance-variables_9","text":"r ( int ) Red color (0-255). g ( int ) Green color (0-255). b ( int ) Blue color (0-255). a ( int ) Alpha channel (0-255).","title":"Instance Variables"},{"location":"python_api/#methods_8","text":"__init__ ( self , r =0 , g =0 , b =0 , a =255 ) Initializes a color, black by default. Parameters: r ( int ) g ( int ) b ( int ) a ( int )","title":"Methods"},{"location":"python_api/#dunder-methods_6","text":"__eq__ ( self , other = carla.Color ) __ne__ ( self , other = carla.Color ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlacolorconverter","text":"Class that defines conversion patterns that can be applied to a carla.Image in order to show information provided by carla.Sensor . Depth conversions cause a loss of accuracy, as sensors detect depth as float that is then converted to a grayscale value between 0 and 255. Take a look at the snipet in carla.Sensor.listen to see an example of how to create and save image data for sensor.camera.semantic_segmentation .","title":"carla.ColorConverter"},{"location":"python_api/#instance-variables_10","text":"CityScapesPalette Converts the image to a segmentated map using tags provided by the blueprint library. Used by the semantic segmentation camera . Depth Converts the image to a linear depth map. Used by the depth camera . LogarithmicDepth Converts the image to a depth map using a logarithmic scale, leading to better precision for small distances at the expense of losing it when further away. Raw No changes applied to the image. Used by the RGB camera .","title":"Instance Variables"},{"location":"python_api/#carladvsevent","text":"Class that defines a DVS event. An event is a quadruple, so a tuple of 4 elements, with x , y pixel coordinate location, timestamp t and polarity pol of the event. Learn more about them here .","title":"carla.DVSEvent"},{"location":"python_api/#instance-variables_11","text":"x ( int ) X pixel coordinate. y ( int ) Y pixel coordinate. t ( int ) Timestamp of the moment the event happened. pol ( bool ) Polarity of the event. True for positive and False for negative.","title":"Instance Variables"},{"location":"python_api/#methods_9","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_7","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carladvseventarray","text":"Class that defines a stream of events in carla.DVSEvent . Such stream is an array of arbitrary size depending on the number of events. This class also stores the field of view, the height and width of the image and the timestamp from convenience. Learn more about them here .","title":"carla.DVSEventArray"},{"location":"python_api/#instance-variables_12","text":"fov ( float - degrees ) Horizontal field of view of the image. height ( int ) Image height in pixels. width ( int ) Image width in pixels. raw_data ( bytes )","title":"Instance Variables"},{"location":"python_api/#methods_10","text":"to_array ( self ) Converts the stream of events to an array of int values in the following order [x, y, t, pol] . to_array_pol ( self ) Returns an array with the polarity of all the events in the stream. to_array_t ( self ) Returns an array with the timestamp of all the events in the stream. to_array_x ( self ) Returns an array with X pixel coordinate of all the events in the stream. to_array_y ( self ) Returns an array with Y pixel coordinate of all the events in the stream. to_image ( self ) Converts the image following this pattern: blue indicates positive events, red indicates negative events.","title":"Methods"},{"location":"python_api/#dunder-methods_8","text":"__getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.DVSEvent retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , color = carla.Color ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carladebughelper","text":"Helper class part of carla.World that defines methods for creating debug shapes. By default, shapes last one second. They can be permanent, but take into account the resources needed to do so. Take a look at the snipets available for this class to learn how to debug easily in CARLA.","title":"carla.DebugHelper"},{"location":"python_api/#methods_11","text":"draw_arrow ( self , begin , end , thickness =0.1 , arrow_size =0.1 , color =(255,0,0) , life_time =-1.0 ) Draws an arrow from begin to end pointing in that direction. Parameters: begin ( carla.Location - meters ) - Point in the coordinate system where the arrow starts. end ( carla.Location - meters ) - Point in the coordinate system where the arrow ends and points towards to. thickness ( float - meters ) - Density of the line. arrow_size ( float - meters ) - Size of the tip of the arrow. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_box ( self , box , rotation , thickness =0.1 , color =(255,0,0) , life_time =-1.0 ) snippet \u2192 Draws a box, ussually to act for object colliders. Parameters: box ( carla.BoundingBox ) - Object containing a location and the length of a box for every axis. rotation ( carla.Rotation - degrees (pitch,yaw,roll) ) - Orientation of the box according to Unreal Engine's axis system. thickness ( float - meters ) - Density of the lines that define the box. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_line ( self , begin , end , thickness =0.1 , color =(255,0,0) , life_time =-1.0 ) Draws a line in between begin and end . Parameters: begin ( carla.Location - meters ) - Point in the coordinate system where the line starts. end ( carla.Location - meters ) - Spot in the coordinate system where the line ends. thickness ( float - meters ) - Density of the line. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_point ( self , location , size =0.1 , color =(255,0,0) , life_time =-1.0 ) Draws a point location . Parameters: location ( carla.Location - meters ) - Spot in the coordinate system to center the object. size ( float - meters ) - Density of the point. color ( carla.Color ) - RGB code to color the object. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes. draw_string ( self , location , text , draw_shadow =False , color =(255,0,0) , life_time =-1.0 ) snippet \u2192 Draws a string in a given location of the simulation which can only be seen server-side. Parameters: location ( carla.Location - meters ) - Spot in the simulation where the text will be centered. text ( str ) - Text intended to be shown in the world. draw_shadow ( bool ) - Casts a shadow for the string that could help in visualization. It is disabled by default. color ( carla.Color ) - RGB code to color the string. Red by default. life_time ( float - seconds ) - Shape's lifespan. By default it only lasts one frame. Set this to 0 for permanent shapes.","title":"Methods"},{"location":"python_api/#carlaenvironmentobject","text":"Class that represents a geometry in the level, this geometry could be part of an actor formed with other EnvironmentObjects (ie: buildings).","title":"carla.EnvironmentObject"},{"location":"python_api/#instance-variables_13","text":"transform ( carla.Transform ) Contains the location and orientation of the EnvironmentObject in world space. bounding_box ( carla.BoundingBox ) Object containing a location, rotation and the length of a box for every axis in world space. id ( int ) Unique ID to identify the object in the level. name ( string ) Name of the EnvironmentObject. type ( carla.CityObjectLabel ) Semantic tag.","title":"Instance Variables"},{"location":"python_api/#methods_12","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_9","text":"__str__ ( self ) Parses the EnvironmentObject to a string and shows them in command line. Return: str","title":"Dunder methods"},{"location":"python_api/#carlafloatcolor","text":"Class that defines a float RGBA color.","title":"carla.FloatColor"},{"location":"python_api/#instance-variables_14","text":"r ( float ) Red color. g ( float ) Green color. b ( float ) Blue color. a ( float ) Alpha channel.","title":"Instance Variables"},{"location":"python_api/#methods_13","text":"__init__ ( self , r =0 , g =0 , b =0 , a =1.0 ) Initializes a color, black by default. Parameters: r ( float ) g ( float ) b ( float ) a ( float )","title":"Methods"},{"location":"python_api/#dunder-methods_10","text":"__eq__ ( self , other = carla.FloatColor ) __ne__ ( self , other = carla.FloatColor )","title":"Dunder methods"},{"location":"python_api/#carlagearphysicscontrol","text":"Class that provides access to vehicle transmission details by defining a gear and when to run on it. This will be later used by carla.VehiclePhysicsControl to help simulate physics.","title":"carla.GearPhysicsControl"},{"location":"python_api/#instance-variables_15","text":"ratio ( float ) The transmission ratio of the gear. down_ratio ( float ) Quotient between current RPM and MaxRPM where the autonomous gear box should shift down. up_ratio ( float ) Quotient between current RPM and MaxRPM where the autonomous gear box should shift up.","title":"Instance Variables"},{"location":"python_api/#methods_14","text":"__init__ ( self , ratio =1.0 , down_ratio =0.5 , up_ratio =0.65 ) Parameters: ratio ( float ) down_ratio ( float ) up_ratio ( float )","title":"Methods"},{"location":"python_api/#dunder-methods_11","text":"__eq__ ( self , other = carla.GearPhysicsControl ) __ne__ ( self , other = carla.GearPhysicsControl ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlageolocation","text":"Class that contains geographical coordinates simulated data. The carla.Map can convert simulation locations by using the tag in the OpenDRIVE file.","title":"carla.GeoLocation"},{"location":"python_api/#instance-variables_16","text":"latitude ( float - degrees ) North/South value of a point on the map. longitude ( float - degrees ) West/East value of a point on the map. altitude ( float - meters ) Height regarding ground level.","title":"Instance Variables"},{"location":"python_api/#methods_15","text":"__init__ ( self , latitude =0.0 , longitude =0.0 , altitude =0.0 ) Parameters: latitude ( float - degrees ) longitude ( float - degrees ) altitude ( float - meters )","title":"Methods"},{"location":"python_api/#dunder-methods_12","text":"__eq__ ( self , other = carla.GeoLocation ) __ne__ ( self , other = carla.GeoLocation ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlagnssmeasurement","text":"Inherited from carla.SensorData Class that defines the Gnss data registered by a sensor.other.gnss . It essentially reports its position with the position of the sensor and an OpenDRIVE geo-reference.","title":"carla.GnssMeasurement"},{"location":"python_api/#instance-variables_17","text":"altitude ( float - meters ) Height regarding ground level. latitude ( float - degrees ) North/South value of a point on the map. longitude ( float - degrees ) West/East value of a point on the map.","title":"Instance Variables"},{"location":"python_api/#methods_16","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_13","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaimumeasurement","text":"Inherited from carla.SensorData Class that defines the data registered by a sensor.other.imu , regarding the sensor's transformation according to the current carla.World . It essentially acts as accelerometer, gyroscope and compass.","title":"carla.IMUMeasurement"},{"location":"python_api/#instance-variables_18","text":"accelerometer ( carla.Vector3D - m/s 2 ) Linear acceleration. compass ( float - radians ) Orientation with regard to the North ([0.0, -1.0, 0.0] in Unreal Engine). gyroscope ( carla.Vector3D - rad/s ) Angular velocity.","title":"Instance Variables"},{"location":"python_api/#methods_17","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_14","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaimage","text":"Inherited from carla.SensorData Class that defines an image of 32-bit BGRA colors that will be used as initial data retrieved by camera sensors. There are different camera sensors (currently three, RGB, depth and semantic segmentation) and each of these makes different use for the images. Learn more about them here .","title":"carla.Image"},{"location":"python_api/#instance-variables_19","text":"fov ( float - degrees ) Horizontal field of view of the image. height ( int ) Image height in pixels. width ( int ) Image width in pixels. raw_data ( bytes )","title":"Instance Variables"},{"location":"python_api/#methods_18","text":"convert ( self , color_converter ) Converts the image following the color_converter pattern. Parameters: color_converter ( carla.ColorConverter ) save_to_disk ( self , path , color_converter =Raw ) Saves the image to disk using a converter pattern stated as color_converter . The default conversion pattern is Raw that will make no changes to the image. Parameters: path ( str ) - Path that will contain the image. color_converter ( carla.ColorConverter ) - Default Raw will make no changes.","title":"Methods"},{"location":"python_api/#dunder-methods_15","text":"__getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.Color that form the image. __len__ ( self ) __setitem__ ( self , pos =int , color = carla.Color ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlajunction","text":"Class that embodies the intersections on the road described in the OpenDRIVE file according to OpenDRIVE 1.4 standards.","title":"carla.Junction"},{"location":"python_api/#instance-variables_20","text":"id ( int ) Identificator found in the OpenDRIVE file. bounding_box ( carla.BoundingBox ) Bounding box encapsulating the junction lanes.","title":"Instance Variables"},{"location":"python_api/#methods_19","text":"","title":"Methods"},{"location":"python_api/#getters_5","text":"get_waypoints ( self , lane_type ) Returns a list of pairs of waypoints. Every tuple on the list contains first an initial and then a final waypoint within the intersection boundaries that describe the beginning and the end of said lane along the junction. Lanes follow their OpenDRIVE definitions so there may be many different tuples with the same starting waypoint due to possible deviations, as this are considered different lanes. Parameters: lane_type ( carla.LaneType ) - Type of lanes to get the waypoints. Return: list(tuple( carla.Waypoint ))","title":"Getters"},{"location":"python_api/#carlalabelledpoint","text":"Class that represent a position in space with a semantic label.","title":"carla.LabelledPoint"},{"location":"python_api/#instance-variables_21","text":"location Position in 3D space. label Semantic tag of the point.","title":"Instance Variables"},{"location":"python_api/#carlalandmark","text":"Class that defines any type of traffic landmark or sign affecting a road. These class mediates between the OpenDRIVE 1.4 standard definition of the landmarks and their representation in the simulation. This class retrieves all the information defining a landmark in OpenDRIVE and facilitates information about which lanes does it affect and when. Landmarks will be accessed by carla.Waypoint objects trying to retrieve the regulation of their lane. Therefore some attributes depend on the waypoint that is consulting the landmark and so, creating the object.","title":"carla.Landmark"},{"location":"python_api/#instance-variables_22","text":"road_id ( int ) The OpenDRIVE ID of the road where this landmark is defined. Due to OpenDRIVE road definitions, this road may be different from the road the landmark is currently affecting. It is mostly the case in junctions where the road diverges in different routes. Example: a traffic light is defined in one of the divergent roads in a junction, but it affects all the possible routes . distance ( float - meters ) Distance between the landmark and the waypoint creating the object (querying get_landmarks or get_landmarks_of_type ). s ( float - meters ) Distance where the landmark is positioned along the geometry of the road road_id . t ( float - meters ) Lateral distance where the landmark is positioned from the edge of the road road_id . id ( str ) Unique ID of the landmark in the OpenDRIVE file. name ( str ) Name of the landmark in the in the OpenDRIVE file. is_dynamic ( bool ) Indicates if the landmark has state changes over time such as traffic lights. orientation ( carla.LandmarkOrientation - degrees ) Indicates which lanes the landmark is facing towards to. z_offset ( float - meters ) Height where the landmark is placed. country ( str ) Country code where the landmark is defined (default to OpenDRIVE is Germany 2017). type ( str ) Type identificator of the landmark according to the country code. sub_type ( str ) Subtype identificator of the landmark according to the country code. value ( float ) Value printed in the signal (e.g. speed limit, maximum weight, etc). unit ( str ) Units of measurement for the attribute value . height ( float - meters ) Total height of the signal. width ( float - meters ) Total width of the signal. text ( str ) Additional text in the signal. h_offset ( float - meters ) Orientation offset of the signal relative to the the definition of road_id at s in OpenDRIVE. pitch ( float - meters ) Pitch rotation of the signal (Y-axis in UE coordinates system ). roll ( float ) Roll rotation of the signal (X-axis in UE coordinates system ). waypoint ( carla.Waypoint ) A waypoint placed in the lane of the one that made the query and at the s of the landmark. It is the first waypoint for which the landmark will be effective. transform ( carla.Transform ) The location and orientation of the landmark in the simulation.","title":"Instance Variables"},{"location":"python_api/#methods_20","text":"","title":"Methods"},{"location":"python_api/#getters_6","text":"get_lane_validities ( self ) Returns which lanes the landmark is affecting to. As there may be specific lanes where the landmark is not effective, the return is a list of pairs containing ranges of the lane_id affected: Example: In a road with 5 lanes, being 3 not affected: [(from_lane1,to_lane2),(from_lane4,to_lane5)] . Return: list(tuple(int))","title":"Getters"},{"location":"python_api/#carlalandmarkorientation","text":"Helper class to define the orientation of a landmark in the road. The definition is not directly translated from OpenDRIVE but converted for the sake of understanding.","title":"carla.LandmarkOrientation"},{"location":"python_api/#instance-variables_23","text":"Positive The landmark faces towards vehicles going on the same direction as the road's geometry definition (lanes 0 and negative in OpenDRIVE). Negative The landmark faces towards vehicles going on the opposite direction to the road's geometry definition (positive lanes in OpenDRIVE). Both Affects vehicles going in both directions of the road.","title":"Instance Variables"},{"location":"python_api/#carlalandmarktype","text":"Helper class containing a set of commonly used landmark types as defined by the default country code in the OpenDRIVE standard (Germany 2017). carla.Landmark does not reference this class . The landmark type is a string that varies greatly depending on the country code being used. This class only makes it easier to manage some of the most commonly used in the default set by describing them as an enum.","title":"carla.LandmarkType"},{"location":"python_api/#instance-variables_24","text":"Danger Type 101. LanesMerging Type 121. CautionPedestrian Type 133. CautionBicycle Type 138. LevelCrossing Type 150. StopSign Type 206. YieldSign Type 205. MandatoryTurnDirection Type 209. MandatoryLeftRightDirection Type 211. TwoChoiceTurnDirection Type 214. Roundabout Type 215. PassRightLeft Type 222. AccessForbidden Type 250. AccessForbiddenMotorvehicles Type 251. AccessForbiddenTrucks Type 253. AccessForbiddenBicycle Type 254. AccessForbiddenWeight Type 263. AccessForbiddenWidth Type 264. AccessForbiddenHeight Type 265. AccessForbiddenWrongDirection Type 267. ForbiddenUTurn Type 272. MaximumSpeed Type 274. ForbiddenOvertakingMotorvehicles Type 276. ForbiddenOvertakingTrucks Type 277. AbsoluteNoStop Type 283. RestrictedStop Type 286. HasWayNextIntersection Type 301. PriorityWay Type 306. PriorityWayEnd Type 307. CityBegin Type 310. CityEnd Type 311. Highway Type 330. DeadEnd Type 357. RecomendedSpeed Type 380. RecomendedSpeedEnd Type 381.","title":"Instance Variables"},{"location":"python_api/#carlalanechange","text":"Class that defines the permission to turn either left, right, both or none (meaning only going straight is allowed). This information is stored for every carla.Waypoint according to the OpenDRIVE file. The snipet in carla.Map.get_waypoint shows how a waypoint can be used to learn which turns are permitted.","title":"carla.LaneChange"},{"location":"python_api/#instance-variables_25","text":"NONE Traffic rules do not allow turning right or left, only going straight. Right Traffic rules allow turning right. Left Traffic rules allow turning left. Both Traffic rules allow turning either right or left.","title":"Instance Variables"},{"location":"python_api/#carlalaneinvasionevent","text":"Inherited from carla.SensorData Class that defines lanes invasion for sensor.other.lane_invasion . It works only client-side and is dependant on OpenDRIVE to provide reliable information. The sensor creates one of this every time there is a lane invasion, which may be more than once per simulation step. Learn more about this here .","title":"carla.LaneInvasionEvent"},{"location":"python_api/#instance-variables_26","text":"actor ( carla.Actor ) Gets the actor the sensor is attached to, the one that invaded another lane. crossed_lane_markings ( list( carla.LaneMarking ) ) List of lane markings that have been crossed and detected by the sensor.","title":"Instance Variables"},{"location":"python_api/#methods_21","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_16","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlalanemarking","text":"Class that gathers all the information regarding a lane marking according to OpenDRIVE 1.4 standard standard.","title":"carla.LaneMarking"},{"location":"python_api/#instance-variables_27","text":"color ( carla.LaneMarkingColor ) Actual color of the marking. lane_change ( carla.LaneChange ) Permissions for said lane marking to be crossed. type ( carla.LaneMarkingType ) Lane marking type. width ( float ) Horizontal lane marking thickness.","title":"Instance Variables"},{"location":"python_api/#carlalanemarkingcolor","text":"Class that defines the lane marking colors according to OpenDRIVE 1.4.","title":"carla.LaneMarkingColor"},{"location":"python_api/#instance-variables_28","text":"Standard White by default. Blue Green Red White Yellow Other","title":"Instance Variables"},{"location":"python_api/#carlalanemarkingtype","text":"Class that defines the lane marking types accepted by OpenDRIVE 1.4. The snipet in carla.Map.get_waypoint shows how a waypoint can be used to retrieve the information about adjacent lane markings. Note on double types: Lane markings are defined under the OpenDRIVE standard that determines whereas a line will be considered \"BrokenSolid\" or \"SolidBroken\". For each road there is a center lane marking, defined from left to right regarding the lane's directions. The rest of the lane markings are defined in order from the center lane to the closest outside of the road.","title":"carla.LaneMarkingType"},{"location":"python_api/#instance-variables_29","text":"NONE Other Broken Solid SolidSolid SolidBroken BrokenSolid BrokenBroken BottsDots Grass Curb","title":"Instance Variables"},{"location":"python_api/#carlalanetype","text":"Class that defines the possible lane types accepted by OpenDRIVE 1.4. This standards define the road information. The snipet in carla.Map.get_waypoint makes use of a waypoint to get the current and adjacent lane types.","title":"carla.LaneType"},{"location":"python_api/#instance-variables_30","text":"NONE Driving Stop Shoulder Biking Sidewalk Border Restricted Parking Bidirectional Median Special1 Special2 Special3 RoadWorks Tram Rail Entry Exit OffRamp OnRamp Any Every type except for NONE.","title":"Instance Variables"},{"location":"python_api/#carlalidardetection","text":"Data contained inside a carla.LidarMeasurement . Each of these represents one of the points in the cloud with its location and its asociated intensity.","title":"carla.LidarDetection"},{"location":"python_api/#instance-variables_31","text":"point ( carla.Location - meters ) Point in xyz coordinates. intensity ( float ) Computed intensity for this point as a scalar value between [0.0 , 1.0].","title":"Instance Variables"},{"location":"python_api/#methods_22","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_17","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlalidarmeasurement","text":"Inherited from carla.SensorData Class that defines the LIDAR data retrieved by a sensor.lidar.ray_cast . This essentially simulates a rotating LIDAR using ray-casting. Learn more about this here .","title":"carla.LidarMeasurement"},{"location":"python_api/#instance-variables_32","text":"channels ( int ) Number of lasers shot. horizontal_angle ( float - radians ) Horizontal angle the LIDAR is rotated at the time of the measurement. raw_data ( bytes ) Received list of 4D points. Each point consists of [x,y,z] coordiantes plus the intensity computed for that point.","title":"Instance Variables"},{"location":"python_api/#methods_23","text":"save_to_disk ( self , path ) Saves the point cloud to disk as a .ply file describing data from 3D scanners. The files generated are ready to be used within MeshLab , an open source system for processing said files. Just take into account that axis may differ from Unreal Engine and so, need to be reallocated. Parameters: path ( str )","title":"Methods"},{"location":"python_api/#getters_7","text":"get_point_count ( self , channel ) Retrieves the number of points sorted by channel that are generated by this measure. Sorting by channel allows to identify the original channel for every point. Parameters: channel ( int )","title":"Getters"},{"location":"python_api/#dunder-methods_18","text":"__getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.LidarDetection retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , detection = carla.LidarDetection ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlalight","text":"This class exposes the lights that exist in the scene, except for vehicle lights. The properties of a light can be queried and changed at will. Lights are automatically turned on when the simulator enters night mode (sun altitude is below zero).","title":"carla.Light"},{"location":"python_api/#instance-variables_33","text":"color ( carla.Color ) Color of the light. id ( int ) Identifier of the light. intensity ( float - lumens ) Intensity of the light. is_on ( bool ) Switch of the light. It is True when the light is on. When the night mode starts, this is set to True . location ( carla.Location - meters ) Position of the light. light_group ( carla.LightGroup ) Group the light belongs to. light_state ( carla.LightState ) State of the light. Summarizes its attributes, group, and if it is on/off.","title":"Instance Variables"},{"location":"python_api/#methods_24","text":"turn_off ( self ) Switches off the light. turn_on ( self ) Switches on the light.","title":"Methods"},{"location":"python_api/#setters_3","text":"set_color ( self , color ) Changes the color of the light to color . Parameters: color ( carla.Color ) set_intensity ( self , intensity ) Changes the intensity of the light to intensity . Parameters: intensity ( float - lumens ) set_light_group ( self , light_group ) Changes the light to the group light_group . Parameters: light_group ( carla.LightGroup ) set_light_state ( self , light_state ) Changes the state of the light to light_state . This may change attributes, group and turn the light on/off all at once. Parameters: light_state ( carla.LightState )","title":"Setters"},{"location":"python_api/#carlalightgroup","text":"This class categorizes the lights on scene into different groups. These groups available are provided as a enum values that can be used as flags. Note. So far, though there is a vehicle group, vehicle lights are not available as carla.Light objects. These have to be managed using carla.Vehicle and carla.VehicleLightState .","title":"carla.LightGroup"},{"location":"python_api/#instance-variables_34","text":"None All lights. Vehicle Street Building Other","title":"Instance Variables"},{"location":"python_api/#carlalightmanager","text":"This class handles the lights in the scene. Its main use is to get and set the state of groups or lists of lights in one call. An instance of this class can be retrieved by the carla.World.get_lightmanager (). Note. So far, though there is a vehicle group, vehicle lights are not available as carla.Light objects. These have to be managed using carla.Vehicle and carla.VehicleLightState .","title":"carla.LightManager"},{"location":"python_api/#methods_25","text":"is_active ( self , lights ) Returns a list with booleans stating if the elements in lights are switched on/off. Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list(bool) turn_off ( self , lights ) Switches off all the lights in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be switched off. turn_on ( self , lights ) Switches on all the lights in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be switched on.","title":"Methods"},{"location":"python_api/#getters_8","text":"get_all_lights ( self , light_group = carla.LightGroup.None ) Returns a list containing the lights in a certain group. By default, the group is None . Parameters: light_group ( carla.LightGroup ) - Group to filter the lights returned. Default is None . Return: list( carla.Light ) get_color ( self , lights ) Returns a list with the colors of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list( carla.Color ) Setter: carla.LightManager.set_color get_intensity ( self , lights ) Returns a list with the intensity of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list(float) - lumens Setter: carla.LightManager.set_intensity get_light_group ( self , lights ) Returns a list with the group of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list( carla.LightGroup ) Setter: carla.LightManager.set_light_group get_light_state ( self , lights ) Returns a list with the state of all the attributes of every element in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be queried. Return: list( carla.LightState ) Setter: carla.LightManager.set_light_state get_turned_off_lights ( self , light_group ) Returns a list containing lights switched off in the scene, filtered by group. Parameters: light_group ( carla.LightGroup ) - List of lights to be queried. Return: list( carla.Light ) get_turned_on_lights ( self , light_group ) Returns a list containing lights switched on in the scene, filtered by group. Parameters: light_group ( carla.LightGroup ) - List of lights to be queried. Return: list( carla.Light )","title":"Getters"},{"location":"python_api/#setters_4","text":"set_active ( self , lights , active ) Switches on/off the elements in lights . Parameters: lights ( list( carla.Light ) ) - List of lights to be switched on/off. active ( list(bool) ) - List of booleans to be applied. set_color ( self , lights , color ) Changes the color of the elements in lights to color . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. color ( carla.Color ) - Color to be applied. Getter: carla.LightManager.get_color set_colors ( self , lights , colors ) Changes the color of each element in lights to the corresponding in colors . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. colors ( list( carla.Color ) ) - List of colors to be applied. set_intensities ( self , lights , intensities ) Changes the intensity of each element in lights to the corresponding in intensities . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. intensities ( list(float) - lumens ) - List of intensities to be applied. set_intensity ( self , lights , intensity ) Changes the intensity of every element in lights to intensity . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. intensity ( float - lumens ) - Intensity to be applied. Getter: carla.LightManager.get_intensity set_light_group ( self , lights , light_group ) Changes the group of every element in lights to light_group . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_group ( carla.LightGroup ) - Group to be applied. Getter: carla.LightManager.get_light_group set_light_groups ( self , lights , light_groups ) Changes the group of each element in lights to the corresponding in light_groups . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_groups ( list( carla.LightGroup ) ) - List of groups to be applied. set_light_state ( self , lights , light_state ) Changes the state of the attributes of every element in lights to light_state . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_state ( carla.LightState ) - State of the attributes to be applied. Getter: carla.LightManager.get_light_state set_light_states ( self , lights , light_states ) Changes the state of the attributes of each element in lights to the corresponding in light_states . Parameters: lights ( list( carla.Light ) ) - List of lights to be changed. light_states ( list( carla.LightState ) ) - List of state of the attributes to be applied.","title":"Setters"},{"location":"python_api/#carlalightstate","text":"This class represents all the light variables except the identifier and the location, which are should to be static. Using this class allows to manage all the parametrization of the light in one call.","title":"carla.LightState"},{"location":"python_api/#instance-variables_35","text":"intensity ( float - lumens ) Intensity of a light. color ( carla.Color ) Color of a light. group ( carla.LightGroup ) Group a light belongs to. active ( bool ) Switch of a light. It is True when the light is on.","title":"Instance Variables"},{"location":"python_api/#methods_26","text":"__init__ ( self , intensity =0.0 , color = carla.Color () , group = carla.LightGroup.None , active =False ) Parameters: intensity ( float - lumens ) - Intensity of the light. Default is 0.0 . color ( carla.Color ) - Color of the light. Default is black. group ( carla.LightGroup ) - Group the light belongs to. Default is the generic group None . active ( bool ) - Swith of the light. Default is False , light is off.","title":"Methods"},{"location":"python_api/#carlalocation","text":"Inherited from carla.Vector3D Represents a spot in the world.","title":"carla.Location"},{"location":"python_api/#instance-variables_36","text":"x ( float - meters ) Distance from origin to spot on X axis. y ( float - meters ) Distance from origin to spot on Y axis. z ( float - meters ) Distance from origin to spot on Z axis.","title":"Instance Variables"},{"location":"python_api/#methods_27","text":"__init__ ( self , x =0.0 , y =0.0 , z =0.0 ) Parameters: x ( float ) y ( float ) z ( float ) distance ( self , location ) Returns Euclidean distance from this location to another one. Parameters: location ( carla.Location ) - The other point to compute the distance with. Return: float - meters","title":"Methods"},{"location":"python_api/#dunder-methods_19","text":"__abs__ ( self ) Returns a Location with the absolute value of the components x, y and z. Return: carla.Location __eq__ ( self , other = carla.Location ) Returns True if both locations are the same point in space. Return: bool __ne__ ( self , other = carla.Location ) Returns True if both locations are different points in space. Return: bool __str__ ( self ) Parses the axis' values to string. Return: str","title":"Dunder methods"},{"location":"python_api/#carlamap","text":"Class containing the road information and waypoint managing. Data is retrieved from an OpenDRIVE file that describes the road. A query system is defined which works hand in hand with carla.Waypoint to translate geometrical information from the .xodr to natural world points. CARLA is currently working with OpenDRIVE 1.4 standard .","title":"carla.Map"},{"location":"python_api/#instance-variables_37","text":"name ( str ) The name of the map. It corresponds to the .umap from Unreal Engine that is loaded from a CARLA server, which then references to the .xodr road description.","title":"Instance Variables"},{"location":"python_api/#methods_28","text":"__init__ ( self , name , xodr_content ) Constructor for this class. Though a map is automatically generated when initializing the world, using this method in no-rendering mode facilitates working with an .xodr without any CARLA server running. Parameters: name ( str ) - Name of the current map. xodr_content ( str ) - .xodr content in string format. Return: list( carla.Transform ) generate_waypoints ( self , distance ) Returns a list of waypoints with a certain distance between them for every lane and centered inside of it. Waypoints are not listed in any particular order. Remember that waypoints closer than 2cm within the same road, section and lane will have the same identificator. Parameters: distance ( float - meters ) - Approximate distance between waypoints. Return: list( carla.Waypoint ) save_to_disk ( self , path ) Saves the .xodr OpenDRIVE file of the current map to disk. Parameters: path - Path where the file will be saved. to_opendrive ( self ) Returns the .xodr OpenDRIVe file of the current map as string. Return: str transform_to_geolocation ( self , location ) Converts a given location , a point in the simulation, to a carla.GeoLocation , which represents world coordinates. The geographical location of the map is defined inside OpenDRIVE within the tag . Parameters: location ( carla.Location ) Return: carla.GeoLocation","title":"Methods"},{"location":"python_api/#getters_9","text":"get_all_landmarks ( self ) Returns all the landmarks in the map. Landmarks retrieved using this method have a null waypoint. Return: list( carla.Landmark ) get_all_landmarks_from_id ( self , opendrive_id ) Returns the landmarks with a certain OpenDRIVE ID. Landmarks retrieved using this method have a null waypoint. Parameters: opendrive_id ( string ) - The OpenDRIVE ID of the landmarks. Return: list( carla.Landmark ) get_all_landmarks_of_type ( self , type ) Returns the landmarks of a specific type. Landmarks retrieved using this method have a null waypoint. Parameters: type ( string ) - The type of the landmarks. Return: list( carla.Landmark ) get_crosswalks ( self ) Returns a list of locations with all crosswalk zones in the form of closed polygons. The first point is repeated, symbolizing where the polygon begins and ends. Return: list( carla.Location ) get_landmark_group ( self , landmark ) Returns the landmarks in the same group as the specified landmark (including itself). Returns an empty list if the landmark does not belong to any group. Parameters: landmark ( carla.Landmark ) - A landmark that belongs to the group. Return: list( carla.Landmark ) get_spawn_points ( self ) Returns a list of recommendations made by the creators of the map to be used as spawning points for the vehicles. The list includes carla.Transform objects with certain location and orientation. Said locations are slightly on-air in order to avoid Z-collisions, so vehicles fall for a bit before starting their way. Return: list( carla.Transform ) get_topology ( self ) Returns a list of tuples describing a minimal graph of the topology of the OpenDRIVE file. The tuples contain pairs of waypoints located either at the point a road begins or ends. The first one is the origin and the second one represents another road end that can be reached. This graph can be loaded into NetworkX to work with. Output could look like this: [(w0, w1), (w0, w2), (w1, w3), (w2, w3), (w0, w4)] . Return: list(tuple( carla.Waypoint , carla.Waypoint )) get_waypoint ( self , location , project_to_road =True , lane_type = carla.LaneType.Driving ) snippet \u2192 Returns a waypoint that can be located in an exact location or translated to the center of the nearest lane. Said lane type can be defined using flags such as LaneType.Driving & LaneType.Shoulder . The method will return None if the waypoint is not found, which may happen only when trying to retrieve a waypoint for an exact location. That eases checking if a point is inside a certain road, as otherwise, it will return the corresponding waypoint. Parameters: location ( carla.Location - meters ) - Location used as reference for the carla.Waypoint . project_to_road ( bool ) - If True , the waypoint will be at the center of the closest lane. This is the default setting. If False , the waypoint will be exactly in location . None means said location does not belong to a road. lane_type ( carla.LaneType ) - Limits the search for nearest lane to one or various lane types that can be flagged. Return: carla.Waypoint get_waypoint_xodr ( self , road_id , lane_id , s ) Returns a waypoint if all the parameters passed are correct. Otherwise, returns None . Parameters: road_id ( int ) - ID of the road to get the waypoint. lane_id ( int ) - ID of the lane to get the waypoint. s ( float - meters ) - Specify the length from the road start. Return: carla.Waypoint","title":"Getters"},{"location":"python_api/#dunder-methods_20","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlamaplayer","text":"Class that represents each manageable layer of the map. Can be used as flags. WARNING: Only \"Opt\" maps are able to work with map layers. .","title":"carla.MapLayer"},{"location":"python_api/#instance-variables_38","text":"NONE No layers selected. Buildings Decals Foliage Ground ParkedVehicles Particles Props StreetLights Walls All All layers selected.","title":"Instance Variables"},{"location":"python_api/#carlamaterialparameter","text":"Class that represents material parameters. Not all objects in the scene contain all parameters.","title":"carla.MaterialParameter"},{"location":"python_api/#instance-variables_39","text":"Normal The Normal map of the object. Present in all objects. Diffuse The Diffuse texture of the object. Present in all objects. AO_Roughness_Metallic_Emissive A texture where each color channel represent a property of the material (R: Ambien oclusion, G: Roughness, B: Metallic, A: Emissive/Height map in some objects). Emissive Emissive texture. Present in a few objects.","title":"Instance Variables"},{"location":"python_api/#carlaobstacledetectionevent","text":"Inherited from carla.SensorData Class that defines the obstacle data for sensor.other.obstacle . Learn more about this here .","title":"carla.ObstacleDetectionEvent"},{"location":"python_api/#instance-variables_40","text":"actor ( carla.Actor ) The actor the sensor is attached to. other_actor ( carla.Actor ) The actor or object considered to be an obstacle. distance ( float - meters ) Distance between actor and other .","title":"Instance Variables"},{"location":"python_api/#methods_29","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_21","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaopendrivegenerationparameters","text":"This class defines the parameters used when generating a world using an OpenDRIVE file.","title":"carla.OpendriveGenerationParameters"},{"location":"python_api/#instance-variables_41","text":"vertex_distance ( float ) Distance between vertices of the mesh generated. Default is 2.0 . max_road_length ( float ) Max road length for a single mesh portion. The mesh of the map is divided into portions, in order to avoid propagating issues. Default is 50.0 . wall_height ( float ) Height of walls created on the boundaries of the road. These prevent vehicles from falling off the road. Default is 1.0 . additional_width ( float ) Additional with applied junction lanes. Complex situations tend to occur at junctions, and a little increase can prevent vehicles from falling off the road. Default is 0.6 . smooth_junctions ( bool ) If True , the mesh at junctions will be smoothed to prevent issues where roads blocked other roads. Default is True . enable_mesh_visibility ( bool ) If True , the road mesh will be rendered. Setting this to False should reduce the rendering overhead. Default is True . enable_pedestrian_navigation ( bool ) If True , Pedestrian navigation will be enabled using Recast tool. For very large maps it is recomended to disable this option. Default is True .","title":"Instance Variables"},{"location":"python_api/#carlaopticalflowimage","text":"Inherited from carla.SensorData Class that defines an optical flow image of 2-Dimension float (32-bit) vectors representing the optical flow detected in the field of view. The components of the vector represents the displacement of an object in the image plane. Each component outputs values in the normalized range [-2,2] which scales to [-2 size, 2 size] with size being the total resolution in the corresponding component.","title":"carla.OpticalFlowImage"},{"location":"python_api/#instance-variables_42","text":"fov ( float - degrees ) Horizontal field of view of the image. height ( int ) Image height in pixels. width ( int ) Image width in pixels. raw_data ( bytes )","title":"Instance Variables"},{"location":"python_api/#methods_30","text":"","title":"Methods"},{"location":"python_api/#getters_10","text":"get_color_coded_flow ( self ) Visualization helper. Converts the optical flow image to an RGB image. Return: carla.Image","title":"Getters"},{"location":"python_api/#dunder-methods_22","text":"__getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.OpticalFlowPixel that form the image. __len__ ( self ) __setitem__ ( self , pos =int , color = carla.Color ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaopticalflowpixel","text":"Class that defines a 2 dimensional vector representing an optical flow pixel.","title":"carla.OpticalFlowPixel"},{"location":"python_api/#instance-variables_43","text":"x ( float ) Optical flow in the x component. y ( float ) Optical flow in the y component.","title":"Instance Variables"},{"location":"python_api/#methods_31","text":"__init__ ( self , x =0 , y =0 ) Initializes the Optical Flow Pixel. Zero by default. Parameters: x ( float ) y ( float )","title":"Methods"},{"location":"python_api/#dunder-methods_23","text":"__eq__ ( self , other = carla.OpticalFlowPixel ) __ne__ ( self , other = carla.OpticalFlowPixel ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaosm2odr","text":"Class that converts an OpenStreetMap map to OpenDRIVE format, so that it can be loaded in CARLA. Find out more about this feature in the docs .","title":"carla.Osm2Odr"},{"location":"python_api/#methods_32","text":"convert ( osm_file , settings ) Takes the content of an .osm file (OpenStreetMap format) and returns the content of the .xodr (OpenDRIVE format) describing said map. Some parameterization is passed to do the conversion. Parameters: osm_file ( str ) - The content of the input OpenStreetMap file parsed as string. settings ( carla.OSM2ODRSettings ) - Parameterization for the conversion. Return: str","title":"Methods"},{"location":"python_api/#carlaosm2odrsettings","text":"Helper class that contains the parameterization that will be used by carla.Osm2Odr to convert an OpenStreetMap map to OpenDRIVE format. Find out more about this feature in the docs .","title":"carla.Osm2OdrSettings"},{"location":"python_api/#instance-variables_44","text":"use_offsets ( bool ) Enables the use of offset for the conversion. The offset will move the origin position of the map. Default value is False . offset_x ( float - meters ) Offset in the X axis. Default value is 0.0 . offset_y ( float - meters ) Offset in the Y axis. Default value is 0.0 . default_lane_width ( float - meters ) Width of the lanes described in the resulting XODR map. Default value is 4.0 . elevation_layer_height ( float - meters ) Defines the height separating two different OpenStreetMap layers . Default value is 0.0 . center_map ( bool ) When this option is enabled, the geometry of the map will be displaced so that the origin of coordinates matches the center of the bounding box of the entire road map. proj_string ( str ) Defines the proj4 string that will be used to compute the projection from geocoordinates to cartesian coordinates. This string will be written in the resulting OpenDRIVE unless the options use_offsets or center_map are enabled as these options override some of the definitions in the string. generate_traffic_lights ( bool ) Indicates wether to generate traffic light data in the OpenDRIVE. Road types defined by set_traffic_light_excluded_way_types(way_types) will not generate traffic lights. all_junctions_with_traffic_lights ( bool ) When disabled, the converter will generate traffic light data from the OpenStreetMaps data only. When enabled, all junctions will generate traffic lights.","title":"Instance Variables"},{"location":"python_api/#methods_33","text":"","title":"Methods"},{"location":"python_api/#setters_5","text":"set_osm_way_types ( self , way_types ) Defines the OpenStreetMaps road types that will be imported to OpenDRIVE. By default the road types imported are motorway, motorway_link, trunk, trunk_link, primary, primary_link, secondary, secondary_link, tertiary, tertiary_link, unclassified, residential . For a full list of road types check here . Parameters: way_types ( list(str) ) - The list of road types. set_traffic_light_excluded_way_types ( self , way_types ) Defines the OpenStreetMaps road types that will not generate traffic lights even if generate_traffic_lights is enabled. By default the road types excluded are motorway_link, primary_link, secondary_link, tertiary_link . Parameters: way_types ( list(str) ) - The list of road types.","title":"Setters"},{"location":"python_api/#carlaradardetection","text":"Data contained inside a carla.RadarMeasurement . Each of these represents one of the points in the cloud that a sensor.other.radar registers and contains the distance, angle and velocity in relation to the radar.","title":"carla.RadarDetection"},{"location":"python_api/#instance-variables_45","text":"altitude ( float - radians ) Altitude angle of the detection. azimuth ( float - radians ) Azimuth angle of the detection. depth ( float - meters ) Distance from the sensor to the detection position. velocity ( float - m/s ) The velocity of the detected object towards the sensor.","title":"Instance Variables"},{"location":"python_api/#methods_34","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_24","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaradarmeasurement","text":"Inherited from carla.SensorData Class that defines and gathers the measures registered by a sensor.other.radar , representing a wall of points in front of the sensor with a distance, angle and velocity in relation to it. The data consists of a carla.RadarDetection array. Learn more about this here .","title":"carla.RadarMeasurement"},{"location":"python_api/#instance-variables_46","text":"raw_data ( bytes ) The complete information of the carla.RadarDetection the radar has registered.","title":"Instance Variables"},{"location":"python_api/#methods_35","text":"","title":"Methods"},{"location":"python_api/#getters_11","text":"get_detection_count ( self ) Retrieves the number of entries generated, same as __str__() .","title":"Getters"},{"location":"python_api/#dunder-methods_25","text":"__getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.RadarDetection retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , detection = carla.RadarDetection ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlarotation","text":"Class that represents a 3D rotation and therefore, an orientation in space. CARLA uses the Unreal Engine coordinates system. This is a Z-up left-handed system. The constructor method follows a specific order of declaration: (pitch, yaw, roll) , which corresponds to (Y-rotation,Z-rotation,X-rotation) . Unreal Engine's coordinates system .","title":"carla.Rotation"},{"location":"python_api/#instance-variables_47","text":"pitch ( float - degrees ) Y-axis rotation angle. yaw ( float - degrees ) Z-axis rotation angle. roll ( float - degrees ) X-axis rotation angle.","title":"Instance Variables"},{"location":"python_api/#methods_36","text":"__init__ ( self , pitch =0.0 , yaw =0.0 , roll =0.0 ) Parameters: pitch ( float - degrees ) - Y-axis rotation angle. yaw ( float - degrees ) - Z-axis rotation angle. roll ( float - degrees ) - X-axis rotation angle. Warning: The declaration order is different in CARLA (pitch,yaw,roll) , and in the Unreal Engine Editor (roll,pitch,yaw) . When working in a build from source, don't mix up the axes' rotations.","title":"Methods"},{"location":"python_api/#getters_12","text":"get_forward_vector ( self ) Computes the vector pointing forward according to the rotation of the object. Return: carla.Vector3D get_right_vector ( self ) Computes the vector pointing to the right according to the rotation of the object. Return: carla.Vector3D get_up_vector ( self ) Computes the vector pointing upwards according to the rotation of the object. Return: carla.Vector3D","title":"Getters"},{"location":"python_api/#dunder-methods_26","text":"__eq__ ( self , other = carla.Rotation ) Returns True if both rotations represent the same orientation for every axis. Return: bool __ne__ ( self , other = carla.Rotation ) Returns True if both rotations represent the same orientation for every axis. Return: bool __str__ ( self ) Parses the axis' orientations to string.","title":"Dunder methods"},{"location":"python_api/#carlarssactorconstellationdata","text":"Data structure that is provided within the callback registered by RssSensor.register_actor_constellation_callback().","title":"carla.RssActorConstellationData"},{"location":"python_api/#instance-variables_48","text":"ego_match_object ( ad.map.match.Object ) The ego map matched information. ego_route ( ad.map.route.FullRoute ) The ego route. ego_dynamics_on_route ( carla.RssEgoDynamicsOnRoute ) Current ego vehicle dynamics regarding the route. other_match_object ( ad.map.match.Object ) The other object's map matched information. This is only valid if 'other_actor' is not 'None'. other_actor ( carla.Actor ) The other actor. This is 'None' in case of query of default parameters or articial objects of kind ad.rss.world.ObjectType.ArtificialObject with no dedicated ' carla.Actor ' (as e.g. for the road boundaries at the moment).","title":"Instance Variables"},{"location":"python_api/#methods_37","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_27","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlarssactorconstellationresult","text":"Data structure that should be returned by the callback registered by RssSensor.register_actor_constellation_callback().","title":"carla.RssActorConstellationResult"},{"location":"python_api/#instance-variables_49","text":"rss_calculation_mode ( ad.rss.map.RssMode ) The calculation mode to be applied with the actor. restrict_speed_limit_mode ( ad.rss.map.RestrictSpeedLimitMode ) The mode for restricting speed limit. ego_vehicle_dynamics ( ad.rss.world.RssDynamics ) The RSS dynamics to be applied for the ego vehicle. actor_object_type ( ad.rss.world.ObjectType ) The RSS object type to be used for the actor. actor_dynamics ( ad.rss.world.RssDynamics ) The RSS dynamics to be applied for the actor.","title":"Instance Variables"},{"location":"python_api/#methods_38","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_28","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlarssegodynamicsonroute","text":"Part of the data contained inside a carla.RssResponse describing the state of the vehicle. The parameters include its current dynamics, and how it is heading regarding the target route.","title":"carla.RssEgoDynamicsOnRoute"},{"location":"python_api/#instance-variables_50","text":"ego_speed ( ad.physics.Speed ) The ego vehicle's speed. min_stopping_distance ( ad.physics.Distance ) The current minimum stopping distance. ego_center ( ad.map.point.ENUPoint ) The considered enu position of the ego vehicle. ego_heading ( ad.map.point.ENUHeading ) The considered heading of the ego vehicle. ego_center_within_route ( bool ) States if the ego vehicle's center is within the route. crossing_border ( bool ) States if the vehicle is already crossing one of the lane borders. route_heading ( ad.map.point.ENUHeading ) The considered heading of the route. route_nominal_center ( ad.map.point.ENUPoint ) The considered nominal center of the current route. heading_diff ( ad.map.point.ENUHeading ) The considered heading diff towards the route. route_speed_lat ( ad.physics.Speed ) The ego vehicle's speed component lat regarding the route. route_speed_lon ( ad.physics.Speed ) The ego vehicle's speed component lon regarding the route. route_accel_lat ( ad.physics.Acceleration ) The ego vehicle's acceleration component lat regarding the route. route_accel_lon ( ad.physics.Acceleration ) The ego vehicle's acceleration component lon regarding the route. avg_route_accel_lat ( ad.physics.Acceleration ) The ego vehicle's acceleration component lat regarding the route smoothened by an average filter. avg_route_accel_lon ( ad.physics.Acceleration ) The ego acceleration component lon regarding the route smoothened by an average filter.","title":"Instance Variables"},{"location":"python_api/#methods_39","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_29","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlarssloglevel","text":"Enum declaration used in carla.RssSensor to set the log level.","title":"carla.RssLogLevel"},{"location":"python_api/#instance-variables_51","text":"trace debug info warn err critical off","title":"Instance Variables"},{"location":"python_api/#carlarssresponse","text":"Inherited from carla.SensorData Class that contains the output of a carla.RssSensor . This is the result of the RSS calculations performed for the parent vehicle of the sensor. A carla.RssRestrictor will use the data to modify the carla.VehicleControl of the vehicle.","title":"carla.RssResponse"},{"location":"python_api/#instance-variables_52","text":"response_valid ( bool ) States if the response is valid. It is False if calculations failed or an exception occured. proper_response ( ad.rss.state.ProperResponse ) The proper response that the RSS calculated for the vehicle. rss_state_snapshot ( ad.rss.state.RssStateSnapshot ) Detailed RSS states at the current moment in time. ego_dynamics_on_route ( carla.RssEgoDynamicsOnRoute ) Current ego vehicle dynamics regarding the route. world_model ( ad.rss.world.WorldModel ) World model used for calculations. situation_snapshot ( ad.rss.situation.SituationSnapshot ) Detailed RSS situations extracted from the world model.","title":"Instance Variables"},{"location":"python_api/#methods_40","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_30","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlarssrestrictor","text":"These objects apply restrictions to a carla.VehicleControl . It is part of the CARLA implementation of the C++ Library for Responsibility Sensitive Safety . This class works hand in hand with a rss sensor , which provides the data of the restrictions to be applied.","title":"carla.RssRestrictor"},{"location":"python_api/#methods_41","text":"restrict_vehicle_control ( self , vehicle_control , proper_response , ego_dynamics_on_route , vehicle_physics ) Applies the safety restrictions given by a carla.RssSensor to a carla.VehicleControl . Parameters: vehicle_control ( carla.VehicleControl ) - The input vehicle control to be restricted. proper_response ( ad.rss.state.ProperResponse ) - Part of the response generated by the sensor. Contains restrictions to be applied to the acceleration of the vehicle. ego_dynamics_on_route ( carla.RssEgoDynamicsOnRoute ) - Part of the response generated by the sensor. Contains dynamics and heading of the vehicle regarding its route. vehicle_physics ( carla.VehiclePhysicsControl ) - The current physics of the vehicle. Used to apply the restrictions properly. Return: carla.VehicleControl","title":"Methods"},{"location":"python_api/#setters_6","text":"set_log_level ( self , log_level ) Sets the log level. Parameters: log_level ( carla.RssLogLevel ) - New log level.","title":"Setters"},{"location":"python_api/#carlarssroadboundariesmode","text":"Enum declaration used in carla.RssSensor to enable or disable the stay on road feature. In summary, this feature considers the road boundaries as virtual objects. The minimum safety distance check is applied to these virtual walls, in order to make sure the vehicle does not drive off the road.","title":"carla.RssRoadBoundariesMode"},{"location":"python_api/#instance-variables_53","text":"On Enables the stay on road feature. Off Disables the stay on road feature.","title":"Instance Variables"},{"location":"python_api/#carlarsssensor","text":"Inherited from carla.Sensor This sensor works a bit differently than the rest. Take look at the specific documentation , and the rss sensor reference to gain full understanding of it. The RSS sensor uses world information, and a RSS library to make safety checks on a vehicle. The output retrieved by the sensor is a carla.RssResponse . This will be used by a carla.RssRestrictor to modify a carla.VehicleControl before applying it to a vehicle.","title":"carla.RssSensor"},{"location":"python_api/#instance-variables_54","text":"ego_vehicle_dynamics ( ad.rss.world.RssDynamics ) States the RSS parameters that the sensor will consider for the ego vehicle if no actor constellation callback is registered. other_vehicle_dynamics ( ad.rss.world.RssDynamics ) States the RSS parameters that the sensor will consider for the rest of vehicles if no actor constellation callback is registered. pedestrian_dynamics ( ad.rss.world.RssDynamics ) States the RSS parameters that the sensor will consider for pedestrians if no actor constellation callback is registered. road_boundaries_mode ( carla.RssRoadBoundariesMode ) Switches the stay on road feature. By default is Off . routing_targets ( vector< carla.Transform > ) The current list of targets considered to route the vehicle. If no routing targets are defined, a route is generated at random.","title":"Instance Variables"},{"location":"python_api/#methods_42","text":"append_routing_target ( self , routing_target ) Appends a new target position to the current route of the vehicle. Parameters: routing_target ( carla.Transform ) - New target point for the route. Choose these after the intersections to force the route to take the desired turn. drop_route ( self ) Discards the current route. If there are targets remaining in routing_targets , creates a new route using those. Otherwise, a new route is created at random. register_actor_constellation_callback ( self , callback ) Register a callback to customize a carla.RssActorConstellationResult . By this callback the settings of RSS parameters are done per actor constellation and the settings (ego_vehicle_dynamics, other_vehicle_dynamics and pedestrian_dynamics) have no effect. Parameters: callback - The function to be called whenever a RSS situation is about to be calculated. reset_routing_targets ( self ) Erases the targets that have been appended to the route.","title":"Methods"},{"location":"python_api/#setters_7","text":"set_log_level ( self , log_level ) Sets the log level. Parameters: log_level ( carla.RssLogLevel ) - New log level. set_map_log_level ( self , log_level ) Sets the map log level. Parameters: log_level ( carla.RssLogLevel ) - New map log level.","title":"Setters"},{"location":"python_api/#dunder-methods_31","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlasemanticlidardetection","text":"Data contained inside a carla.SemanticLidarMeasurement . Each of these represents one of the points in the cloud with its location, the cosine of the incident angle, index of the object hit, and its semantic tag.","title":"carla.SemanticLidarDetection"},{"location":"python_api/#instance-variables_55","text":"point ( carla.Location - meters ) [x,y,z] coordinates of the point. cos_inc_angle ( float ) Cosine of the incident angle between the ray, and the normal of the hit object. object_idx ( uint ) ID of the actor hit by the ray. object_tag ( uint ) Semantic tag of the component hit by the ray.","title":"Instance Variables"},{"location":"python_api/#methods_43","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_32","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlasemanticlidarmeasurement","text":"Inherited from carla.SensorData Class that defines the semantic LIDAR data retrieved by a sensor.lidar.ray_cast_semantic . This essentially simulates a rotating LIDAR using ray-casting. Learn more about this here .","title":"carla.SemanticLidarMeasurement"},{"location":"python_api/#instance-variables_56","text":"channels ( int ) Number of lasers shot. horizontal_angle ( float - radians ) Horizontal angle the LIDAR is rotated at the time of the measurement. raw_data ( bytes ) Received list of raw detection points. Each point consists of [x,y,z] coordinates plus the cosine of the incident angle, the index of the hit actor, and its semantic tag.","title":"Instance Variables"},{"location":"python_api/#methods_44","text":"save_to_disk ( self , path ) Saves the point cloud to disk as a .ply file describing data from 3D scanners. The files generated are ready to be used within MeshLab , an open-source system for processing said files. Just take into account that axis may differ from Unreal Engine and so, need to be reallocated. Parameters: path ( str )","title":"Methods"},{"location":"python_api/#getters_13","text":"get_point_count ( self , channel ) Retrieves the number of points sorted by channel that are generated by this measure. Sorting by channel allows to identify the original channel for every point. Parameters: channel ( int )","title":"Getters"},{"location":"python_api/#dunder-methods_33","text":"__getitem__ ( self , pos =int ) __iter__ ( self ) Iterate over the carla.SemanticLidarDetection retrieved as data. __len__ ( self ) __setitem__ ( self , pos =int , detection = carla.SemanticLidarDetection ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlasensor","text":"Inherited from carla.Actor Sensors compound a specific family of actors quite diverse and unique. They are normally spawned as attachment/sons of a vehicle (take a look at carla.World to learn about actor spawning). Sensors are thoroughly designed to retrieve different types of data that they are listening to. The data they receive is shaped as different subclasses inherited from carla.SensorData (depending on the sensor). Most sensors can be divided in two groups: those receiving data on every tick (cameras, point clouds and some specific sensors) and those who only receive under certain circumstances (trigger detectors). CARLA provides a specific set of sensors and their blueprint can be found in carla.BlueprintLibrary . All the information on their preferences and settlement can be found here , but the list of those available in CARLA so far goes as follow. Receive data on every tick. - Depth camera . - Gnss sensor . - IMU sensor . - Lidar raycast . - SemanticLidar raycast . - Radar . - RGB camera . - RSS sensor . - Semantic Segmentation camera . Only receive data when triggered. - Collision detector . - Lane invasion detector . - Obstacle detector .","title":"carla.Sensor"},{"location":"python_api/#instance-variables_57","text":"is_listening ( boolean ) When True the sensor will be waiting for data.","title":"Instance Variables"},{"location":"python_api/#methods_45","text":"listen ( self , callback ) snippet \u2192 The function the sensor will be calling to every time a new measurement is received. This function needs for an argument containing an object type carla.SensorData to work with. Parameters: callback ( function ) - The called function with one argument containing the sensor data. stop ( self ) Commands the sensor to stop listening for data.","title":"Methods"},{"location":"python_api/#dunder-methods_34","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlasensordata","text":"Base class for all the objects containing data generated by a carla.Sensor . This objects should be the argument of the function said sensor is listening to, in order to work with them. Each of these sensors needs for a specific type of sensor data. Hereunder is a list of the sensors and their corresponding data. - Cameras (RGB, depth and semantic segmentation): carla.Image . - Collision detector: carla.CollisionEvent . - GNSS sensor: carla.GnssMeasurement . - IMU sensor: carla.IMUMeasurement . - Lane invasion detector: carla.LaneInvasionEvent . - LIDAR sensor: carla.LidarMeasurement . - Obstacle detector: carla.ObstacleDetectionEvent . - Radar sensor: carla.RadarMeasurement . - RSS sensor: carla.RssResponse . - Semantic LIDAR sensor: carla.SemanticLidarMeasurement .","title":"carla.SensorData"},{"location":"python_api/#instance-variables_58","text":"frame ( int ) Frame count when the data was generated. timestamp ( float - seconds ) Simulation-time when the data was generated. transform ( carla.Transform ) Sensor's transform when the data was generated.","title":"Instance Variables"},{"location":"python_api/#carlatexturecolor","text":"Class representing a texture object to be uploaded to the server. Pixel format is RGBA, uint8 per channel.","title":"carla.TextureColor"},{"location":"python_api/#instance-variables_59","text":"width ( int ) X-coordinate size of the texture. height ( int ) Y-coordinate size of the texture.","title":"Instance Variables"},{"location":"python_api/#methods_46","text":"__init__ ( self , width , height ) Initializes a the texture with a ( width , height ) size. Parameters: width ( int ) height ( int ) get ( self , x , y ) Get the (x,y) pixel data. Parameters: x ( int ) y ( int ) Return: carla.Color set ( self , x , y , value ) Sets the (x,y) pixel data with value . Parameters: x ( int ) y ( int ) value ( carla.Color )","title":"Methods"},{"location":"python_api/#setters_8","text":"set_dimensions ( self , width , height ) Resizes the texture to te specified dimensions. Parameters: width ( int ) height ( int )","title":"Setters"},{"location":"python_api/#carlatexturefloatcolor","text":"Class representing a texture object to be uploaded to the server. Pixel format is RGBA, float per channel.","title":"carla.TextureFloatColor"},{"location":"python_api/#instance-variables_60","text":"width ( int ) X-coordinate size of the texture. height ( int ) Y-coordinate size of the texture.","title":"Instance Variables"},{"location":"python_api/#methods_47","text":"__init__ ( self , width , height ) Initializes a the texture with a ( width , height ) size. Parameters: width ( int ) height ( int ) get ( self , x , y ) Get the (x,y) pixel data. Parameters: x ( int ) y ( int ) Return: carla.FloatColor set ( self , x , y , value ) Sets the (x,y) pixel data with value . Parameters: x ( int ) y ( int ) value ( carla.FloatColor )","title":"Methods"},{"location":"python_api/#setters_9","text":"set_dimensions ( self , width , height ) Resizes the texture to te specified dimensions. Parameters: width ( int ) height ( int )","title":"Setters"},{"location":"python_api/#carlatimestamp","text":"Class that contains time information for simulated data. This information is automatically retrieved as part of the carla.WorldSnapshot the client gets on every frame, but might also be used in many other situations such as a carla.Sensor retrieveing data.","title":"carla.Timestamp"},{"location":"python_api/#instance-variables_61","text":"frame ( int ) The number of frames elapsed since the simulator was launched. elapsed_seconds ( float - seconds ) Simulated seconds elapsed since the beginning of the current episode. delta_seconds ( float - seconds ) Simulated seconds elapsed since the previous frame. platform_timestamp ( float - seconds ) Time register of the frame at which this measurement was taken given by the OS in seconds.","title":"Instance Variables"},{"location":"python_api/#methods_48","text":"__init__ ( self , frame , elapsed_seconds , delta_seconds , platform_timestamp ) Parameters: frame ( int ) elapsed_seconds ( float - seconds ) delta_seconds ( float - seconds ) platform_timestamp ( float - seconds )","title":"Methods"},{"location":"python_api/#dunder-methods_35","text":"__eq__ ( self , other = carla.Timestamp ) __ne__ ( self , other = carla.Timestamp ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlatrafficlight","text":"Inherited from carla.TrafficSign A traffic light actor, considered a specific type of traffic sign. As traffic lights will mostly appear at junctions, they belong to a group which contains the different traffic lights in it. Inside the group, traffic lights are differenciated by their pole index. Within a group the state of traffic lights is changed in a cyclic pattern: one index is chosen and it spends a few seconds in green, yellow and eventually red. The rest of the traffic lights remain frozen in red this whole time, meaning that there is a gap in the last seconds of the cycle where all the traffic lights are red. However, the state of a traffic light can be changed manually.","title":"carla.TrafficLight"},{"location":"python_api/#instance-variables_62","text":"state ( carla.TrafficLightState ) Current state of the traffic light.","title":"Instance Variables"},{"location":"python_api/#methods_49","text":"freeze ( self , freeze ) Stops all the traffic lights in the scene at their current state. Parameters: freeze ( bool ) is_frozen ( self ) The client returns True if a traffic light is frozen according to last tick. The method does not call the simulator. Return: bool reset_group ( self ) Resets the state of the traffic lights of the group to the initial state at the start of the simulation. Note: This method calls the simulator.","title":"Methods"},{"location":"python_api/#getters_14","text":"get_affected_lane_waypoints ( self ) Returns a list of waypoints indicating the positions and lanes where the traffic light is having an effect. Return: list( carla.Waypoint ) get_elapsed_time ( self ) The client returns the time in seconds since current light state started according to last tick. The method does not call the simulator. Return: float - seconds get_green_time ( self ) The client returns the time set for the traffic light to be green, according to last tick. The method does not call the simulator. Return: float - seconds Setter: carla.TrafficLight.set_green_time get_group_traffic_lights ( self ) Returns all traffic lights in the group this one belongs to. Return: list( carla.TrafficLight ) Note: This method calls the simulator. get_light_boxes ( self ) Returns a list of the bounding boxes encapsulating each light box of the traffic light. Return: list( carla.BoundingBox ) get_opendrive_id ( self ) Returns the OpenDRIVE id of this traffic light. Return: str get_pole_index ( self ) Returns the index of the pole that identifies it as part of the traffic light group of a junction. Return: int get_red_time ( self ) The client returns the time set for the traffic light to be red, according to last tick. The method does not call the simulator. Return: float - seconds Setter: carla.TrafficLight.set_red_time get_state ( self ) The client returns the state of the traffic light according to last tick. The method does not call the simulator. Return: carla.TrafficLightState Setter: carla.TrafficLight.set_state get_stop_waypoints ( self ) Returns a list of waypoints indicating the stop position for the traffic light. These waypoints are computed from the trigger boxes of the traffic light that indicate where a vehicle should stop. Return: list( carla.Waypoint ) get_yellow_time ( self ) The client returns the time set for the traffic light to be yellow, according to last tick. The method does not call the simulator. Return: float - seconds Setter: carla.TrafficLight.set_yellow_time","title":"Getters"},{"location":"python_api/#setters_10","text":"set_green_time ( self , green_time ) Parameters: green_time ( float - seconds ) - Sets a given time for the green light to be active. Getter: carla.TrafficLight.get_green_time set_red_time ( self , red_time ) Sets a given time for the red state to be active. Parameters: red_time ( float - seconds ) Getter: carla.TrafficLight.get_red_time set_state ( self , state ) snippet \u2192 Sets a given state to a traffic light actor. Parameters: state ( carla.TrafficLightState ) Getter: carla.TrafficLight.get_state set_yellow_time ( self , yellow_time ) Sets a given time for the yellow light to be active. Parameters: yellow_time ( float - seconds ) Getter: carla.TrafficLight.get_yellow_time","title":"Setters"},{"location":"python_api/#dunder-methods_36","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlatrafficlightstate","text":"All possible states for traffic lights. These can either change at a specific time step or be changed manually. The snipet in carla.TrafficLight.set_state changes the state of a traffic light on the fly.","title":"carla.TrafficLightState"},{"location":"python_api/#instance-variables_63","text":"Red Yellow Green Off Unknown","title":"Instance Variables"},{"location":"python_api/#carlatrafficmanager","text":"The traffic manager is a module built on top of the CARLA API in C++. It handles any group of vehicles set to autopilot mode to populate the simulation with realistic urban traffic conditions and give the chance to user to customize some behaviours. The architecture of the traffic manager is divided in five different goal-oriented stages and a PID controller where the information flows until eventually, a carla.VehicleControl is applied to every vehicle registered in a traffic manager. In order to learn more, visit the documentation regarding this module.","title":"carla.TrafficManager"},{"location":"python_api/#methods_50","text":"auto_lane_change ( self , actor , enable ) Turns on or off lane changing behaviour for a vehicle. Parameters: actor ( carla.Actor ) - The vehicle whose settings are changed. enable ( bool ) - True is default and enables lane changes. False will disable them. auto_update_lights ( self , actor , do_update ) Sets if the Traffic Manager is responsible of updating the vehicle lights, or not. Default is False . The traffic manager will not change the vehicle light status of a vehicle, unless its auto_update_status is st to True . Parameters: actor ( carla.Actor ) - Vehicle whose lights status is being changed. do_update ( bool ) - If True the traffic manager will manage the vehicle lights for the specified vehicle. collision_detection ( self , reference_actor , other_actor , detect_collision ) Tunes on/off collisions between a vehicle and another specific actor. In order to ignore all other vehicles, traffic lights or walkers, use the specific ignore methods described in this same section. Parameters: reference_actor ( carla.Actor ) - Vehicle that is going to ignore collisions. other_actor ( carla.Actor ) - The actor that reference_actor is going to ignore collisions with. detect_collision ( bool ) - True is default and enables collisions. False will disable them. distance_to_leading_vehicle ( self , actor , distance ) Sets the minimum distance in meters that a vehicle has to keep with the others. The distance is in meters and will affect the minimum moving distance. It is computed from front to back of the vehicle objects. Parameters: actor ( carla.Actor ) - Vehicle whose minimum distance is being changed. distance ( float - meters ) - Meters between both vehicles. force_lane_change ( self , actor , direction ) Forces a vehicle to change either to the lane on its left or right, if existing, as indicated in direction . This method applies the lane change no matter what, disregarding possible collisions. Parameters: actor ( carla.Actor ) - Vehicle being forced to change lanes. direction ( bool ) - Destination lane. True is the one on the right and False is the left one. global_percentage_speed_difference ( self , percentage ) Sets the difference the vehicle's intended speed and its current speed limit. Speed limits can be exceeded by setting the perc to a negative value. Default is 30. Exceeding a speed limit can be done using negative percentages. Parameters: percentage ( float ) - Percentage difference between intended speed and the current limit. ignore_lights_percentage ( self , actor , perc ) During the traffic light stage, which runs every frame, this method sets the percent chance that traffic lights will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The actor that is going to ignore traffic lights. perc ( float ) - Between 0 and 100. Amount of times traffic lights will be ignored. ignore_signs_percentage ( self , actor , perc ) During the traffic light stage, which runs every frame, this method sets the percent chance that stop signs will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The actor that is going to ignore stop signs. perc ( float ) - Between 0 and 100. Amount of times stop signs will be ignored. ignore_vehicles_percentage ( self , actor , perc ) During the collision detection stage, which runs every frame, this method sets a percent chance that collisions with another vehicle will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The vehicle that is going to ignore other vehicles. perc ( float ) - Between 0 and 100. Amount of times collisions will be ignored. ignore_walkers_percentage ( self , actor , perc ) During the collision detection stage, which runs every frame, this method sets a percent chance that collisions with walkers will be ignored for a vehicle. Parameters: actor ( carla.Actor ) - The vehicle that is going to ignore walkers on scene. perc ( float ) - Between 0 and 100. Amount of times collisions will be ignored. vehicle_percentage_speed_difference ( self , actor , percentage ) Sets the difference the vehicle's intended speed and its current speed limit. Speed limits can be exceeded by setting the perc to a negative value. Default is 30. Exceeding a speed limit can be done using negative percentages. Parameters: actor ( carla.Actor ) - Vehicle whose speed behaviour is being changed. percentage ( float ) - Percentage difference between intended speed and the current limit.","title":"Methods"},{"location":"python_api/#getters_15","text":"get_port ( self ) Returns the port where the Traffic Manager is connected. If the object is a TM-Client, it will return the port of its TM-Server. Read the documentation to learn the difference. Return: uint16","title":"Getters"},{"location":"python_api/#setters_11","text":"set_boundaries_respawn_dormant_vehicles ( self , lower_bound =25.0 , upper_bound =actor_active_distance ) Sets the upper and lower boundaries for dormant actors to be respawned near the hero vehicle. Parameters: lower_bound ( float ) - The minimum distance in meters from the hero vehicle that a dormant actor will be respawned. upper_bound ( float ) - The maximum distance in meters from the hero vehicle that a dormant actor will be respawned. Warning: The upper_bound cannot be higher than the actor_active_distance . The lower_bound cannot be less than 25. set_global_distance_to_leading_vehicle ( self , distance ) Sets the minimum distance in meters that vehicles have to keep with the rest. The distance is in meters and will affect the minimum moving distance. It is computed from center to center of the vehicle objects. Parameters: distance ( float - meters ) - Meters between vehicles. set_hybrid_physics_mode ( self , enabled =False ) Enables or disables the hybrid physics mode. In this mode, vehicle's farther than a certain radius from the ego vehicle will have their physics disabled. Computation cost will be reduced by not calculating vehicle dynamics. Vehicles will be teleported. Parameters: enabled ( bool ) - If True , enables the hybrid physics. set_hybrid_physics_radius ( self , r =50.0 ) With hybrid physics on, changes the radius of the area of influence where physics are enabled. Parameters: r ( float - meters ) - New radius where physics are enabled. set_osm_mode ( self , mode_switch =True ) Enables or disables the OSM mode. This mode allows the user to run TM in a map created with the OSM feature . These maps allow having dead-end streets. Normally, if vehicles cannot find the next waypoint, TM crashes. If OSM mode is enabled, it will show a warning, and destroy vehicles when necessary. Parameters: mode_switch ( bool ) \u2013 If True , the OSM mode is enabled. keep_right_rule_percentage ( self , actor , perc ) During the localization stage, this method sets a percent chance that vehicle will follow the keep right rule, and stay in the right lane. Parameters: actor ( carla.Actor ) - Vehicle whose behaviour is being changed. perc ( float ) - Between 0 and 100. Amount of times the vehicle will follow the keep right rule. set_random_device_seed ( self , value ) Sets a specific random seed for the Traffic Manager, thereby setting it to be deterministic. Parameters: value ( int ) - Seed value for the random number generation of the Traffic Manager. set_respawn_dormant_vehicles ( self , mode_switch =False ) If True , vehicles in large maps will respawn near the hero vehicle when they become dormant. Otherwise, they will stay dormant until they are within actor_active_distance of the hero vehicle again. Parameters: mode_switch ( bool ) set_synchronous_mode ( self , mode_switch =True ) Sets the Traffic Manager to synchronous mode . In a multiclient situation , only the TM-Server can tick. Similarly, in a multiTM situation , only one TM-Server must tick. Use this method in the client that does the world tick, and right after setting the world to synchronous mode, to set which TM will be the master while in sync. Parameters: mode_switch ( bool ) - If True , the TM synchronous mode is enabled. Warning: If the server is set to synchronous mode, the TM must be set to synchronous mode too in the same client that does the tick.","title":"Setters"},{"location":"python_api/#carlatrafficsign","text":"Inherited from carla.Actor Traffic signs appearing in the simulation except for traffic lights. These have their own class inherited from this in carla.TrafficLight . Right now, speed signs, stops and yields are mainly the ones implemented, but many others are borne in mind.","title":"carla.TrafficSign"},{"location":"python_api/#instance-variables_64","text":"trigger_volume A carla.BoundingBox situated near a traffic sign where the carla.Actor who is inside can know about it.","title":"Instance Variables"},{"location":"python_api/#carlatransform","text":"Class that defines a transformation, a combination of location and rotation, without scaling.","title":"carla.Transform"},{"location":"python_api/#instance-variables_65","text":"location ( carla.Location ) Describes a point in the coordinate system. rotation ( carla.Rotation - degrees (pitch, yaw, roll) ) Describes a rotation for an object according to Unreal Engine's axis system.","title":"Instance Variables"},{"location":"python_api/#methods_51","text":"__init__ ( self , location , rotation ) Parameters: location ( carla.Location ) rotation ( carla.Rotation - degrees (pitch, yaw, roll) ) transform ( self , in_point ) Translates a 3D point from local to global coordinates using the current transformation as frame of reference. Parameters: in_point ( carla.Location ) - Location in the space to which the transformation will be applied.","title":"Methods"},{"location":"python_api/#getters_16","text":"get_forward_vector ( self ) Computes a forward vector using the rotation of the object. Return: carla.Vector3D get_inverse_matrix ( self ) Computes the 4-matrix representation of the inverse transformation. Return: list(list(float)) get_matrix ( self ) Computes the 4-matrix representation of the transformation. Return: list(list(float)) get_right_vector ( self ) Computes a right vector using the rotatio of the object. Return: carla.Vector3D get_up_vector ( self ) Computes an up vector using the rotation of the object. Return: carla.Vector3D","title":"Getters"},{"location":"python_api/#dunder-methods_37","text":"__eq__ ( self , other = carla.Transform ) Returns True if both location and rotation are equal for this and other . Return: bool __ne__ ( self , other = carla.Transform ) Returns True if any location and rotation are not equal for this and other . Return: bool __str__ ( self ) Parses both location and rotation to string. Return: str","title":"Dunder methods"},{"location":"python_api/#carlavector2d","text":"Helper class to perform 2D operations.","title":"carla.Vector2D"},{"location":"python_api/#instance-variables_66","text":"x ( float ) X-axis value. y ( float ) Y-axis value.","title":"Instance Variables"},{"location":"python_api/#methods_52","text":"__init__ ( self , x =0.0 , y =0.0 ) Parameters: x ( float ) y ( float ) length ( self ) Computes the length of the vector. Return: float make_unit_vector ( self ) Returns a vector with the same direction and unitary length. Return: carla.Vector3D squared_length ( self ) Computes the squared length of the vector. Return: float","title":"Methods"},{"location":"python_api/#dunder-methods_38","text":"__add__ ( self , other = carla.Vector2D ) __eq__ ( self , other = carla.Vector2D ) Returns True if values for every axis are equal. Return: bool __mul__ ( self , other = carla.Vector2D ) __ne__ ( self , bool = carla.Vector2D ) Returns True if the value for any axis is different. Return: bool __str__ ( self ) Returns the axis values for the vector parsed as string. Return: str __sub__ ( self , other = carla.Vector2D ) __truediv__ ( self , other = carla.Vector2D )","title":"Dunder methods"},{"location":"python_api/#carlavector3d","text":"Helper class to perform 3D operations.","title":"carla.Vector3D"},{"location":"python_api/#instance-variables_67","text":"x ( float ) X-axis value. y ( float ) Y-axis value. z ( float ) Z-axis value.","title":"Instance Variables"},{"location":"python_api/#methods_53","text":"__init__ ( self , x =0.0 , y =0.0 , z =0.0 ) Parameters: x ( float ) y ( float ) z ( float ) cross ( self , vector ) Computes the cross product between two vectors. Parameters: vector ( carla.Vector3D ) Return: carla.Vector3D distance ( self , vector ) Computes the distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float distance_2d ( self , vector ) Computes the 2-dimensional distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float distance_squared ( self , vector ) Computes the squared distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float distance_squared_2d ( self , vector ) Computes the 2-dimensional squared distance between two vectors. Parameters: vector ( carla.Vector3D ) Return: float dot ( self , vector ) Computes the dot product between two vectors. Parameters: vector ( carla.Vector3D ) Return: float dot_2d ( self , vector ) Computes the 2-dimensional dot product between two vectors. Parameters: vector ( carla.Vector3D ) Return: float length ( self ) Computes the length of the vector. Return: float make_unit_vector ( self ) Returns a vector with the same direction and unitary length. Return: carla.Vector3D squared_length ( self ) Computes the squared length of the vector. Return: float","title":"Methods"},{"location":"python_api/#dunder-methods_39","text":"__abs__ ( self ) Returns a Vector3D with the absolute value of the components x, y and z. Return: carla.Vector3D __add__ ( self , other = carla.Vector3D ) __eq__ ( self , other = carla.Vector3D ) Returns True if values for every axis are equal. Return: bool __mul__ ( self , other = carla.Vector3D ) __ne__ ( self , other = carla.Vector3D ) Returns True if the value for any axis is different. Return: bool __str__ ( self ) Returns the axis values for the vector parsed as string. Return: str __sub__ ( self , other = carla.Vector3D ) __truediv__ ( self , other = carla.Vector3D )","title":"Dunder methods"},{"location":"python_api/#carlavehicle","text":"Inherited from carla.Actor One of the most important group of actors in CARLA. These include any type of vehicle from cars to trucks, motorbikes, vans, bycicles and also official vehicles such as police cars. A wide set of these actors is provided in carla.BlueprintLibrary to facilitate differente requirements. Vehicles can be either manually controlled or set to an autopilot mode that will be conducted client-side by the traffic manager .","title":"carla.Vehicle"},{"location":"python_api/#instance-variables_68","text":"bounding_box ( carla.BoundingBox ) Bounding box containing the geometry of the vehicle. Its location and rotation are relative to the vehicle it is attached to.","title":"Instance Variables"},{"location":"python_api/#methods_54","text":"apply_control ( self , control ) Applies a control object on the next tick, containing driving parameters such as throttle, steering or gear shifting. Parameters: control ( carla.VehicleControl ) apply_physics_control ( self , physics_control ) Applies a physics control object in the next tick containing the parameters that define the vehicle as a corporeal body. E.g.: moment of inertia, mass, drag coefficient and many more. Parameters: physics_control ( carla.VehiclePhysicsControl ) enable_carsim ( self , simfile_path ) Enables the CarSim physics solver for this particular vehicle. In order for this function to work, there needs to be a valid license manager running on the server side. The control inputs are redirected to CarSim which will provide the position and orientation of the vehicle for every frame. Parameters: simfile_path ( str ) - Path to the .simfile file with the parameters of the simulation. is_at_traffic_light ( self ) Vehicles will be affected by a traffic light when the light is red and the vehicle is inside its bounding box. The client returns whether a traffic light is affecting this vehicle according to last tick (it does not call the simulator). Return: bool use_carsim_road ( self , enabled ) Enables or disables the usage of CarSim vs terrain file specified in the .simfile . By default this option is disabled and CarSim uses unreal engine methods to process the geometry of the scene. Parameters: enabled ( bool )","title":"Methods"},{"location":"python_api/#getters_17","text":"get_control ( self ) The client returns the control applied in the last tick. The method does not call the simulator. Return: carla.VehicleControl get_light_state ( self ) Returns a flag representing the vehicle light state, this represents which lights are active or not. Return: carla.VehicleLightState Setter: carla.Vehicle.set_light_state get_physics_control ( self ) The simulator returns the last physics control applied to this vehicle. Return: carla.VehiclePhysicsControl Warning: This method does call the simulator to retrieve the value. get_speed_limit ( self ) The client returns the speed limit affecting this vehicle according to last tick (it does not call the simulator). The speed limit is updated when passing by a speed limit signal, so a vehicle might have none right after spawning. Return: float - m/s get_traffic_light ( self ) Retrieves the traffic light actor affecting this vehicle (if any) according to last tick. The method does not call the simulator. Return: carla.TrafficLight get_traffic_light_state ( self ) The client returns the state of the traffic light affecting this vehicle according to last tick. The method does not call the simulator. If no traffic light is currently affecting the vehicle, returns green . Return: carla.TrafficLightState get_wheel_steer_angle ( self , wheel_location ) Returns the physics angle in degrees of a vehicle's wheel. Parameters: wheel_location ( carla.VehicleWheelLocation ) Return: float Note: Returns the angle based on the physics of the wheel, not the visual angle.","title":"Getters"},{"location":"python_api/#setters_12","text":"set_autopilot ( self , enabled =True , port =8000 ) Registers or deletes the vehicle from a Traffic Manager's list. When True , the Traffic Manager passed as parameter will move the vehicle around. The autopilot takes place client-side. Parameters: enabled ( bool ) port ( uint16 ) - The port of the TM-Server where the vehicle is to be registered or unlisted. If None is passed, it will consider a TM at default port 8000 . set_light_state ( self , light_state ) Sets the light state of a vehicle using a flag that represents the lights that are on and off. Parameters: light_state ( carla.VehicleLightState ) Getter: carla.Vehicle.get_light_state set_wheel_steer_direction ( self , wheel_location , angle_in_deg ) snippet \u2192 Sets the angle of a vehicle's wheel visually. Parameters: wheel_location ( carla.VehicleWheelLocation ) angle_in_deg ( float ) Warning: Does not affect the physics of the vehicle.","title":"Setters"},{"location":"python_api/#dunder-methods_40","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlavehiclecontrol","text":"Manages the basic movement of a vehicle using typical driving controls.","title":"carla.VehicleControl"},{"location":"python_api/#instance-variables_69","text":"throttle ( float ) A scalar value to control the vehicle throttle [0.0, 1.0]. Default is 0.0. steer ( float ) A scalar value to control the vehicle steering [-1.0, 1.0]. Default is 0.0. brake ( float ) A scalar value to control the vehicle brake [0.0, 1.0]. Default is 0.0. hand_brake ( bool ) Determines whether hand brake will be used. Default is False . reverse ( bool ) Determines whether the vehicle will move backwards. Default is False . manual_gear_shift ( bool ) Determines whether the vehicle will be controlled by changing gears manually. Default is False . gear ( int ) States which gear is the vehicle running on.","title":"Instance Variables"},{"location":"python_api/#methods_55","text":"__init__ ( self , throttle =0.0 , steer =0.0 , brake =0.0 , hand_brake =False , reverse =False , manual_gear_shift =False , gear =0 ) Parameters: throttle ( float ) - Scalar value between [0.0,1.0]. steer ( float ) - Scalar value between [0.0,1.0]. brake ( float ) - Scalar value between [0.0,1.0]. hand_brake ( bool ) reverse ( bool ) manual_gear_shift ( bool ) gear ( int )","title":"Methods"},{"location":"python_api/#dunder-methods_41","text":"__eq__ ( self , other = carla.VehicleControl ) __ne__ ( self , other = carla.VehicleControl ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlavehicledoor","text":"Possible index representing the possible doors that can be open. Notice that not all possible doors are able to open in some vehicles.","title":"carla.VehicleDoor"},{"location":"python_api/#instance-variables_70","text":"FL Front left door. FR Front right door. RL Back left door. RR Back right door. All Represents all doors.","title":"Instance Variables"},{"location":"python_api/#carlavehiclelightstate","text":"Class that recaps the state of the lights of a vehicle, these can be used as a flags. E.g: VehicleLightState.HighBeam & VehicleLightState.Brake will return True when both are active. Lights are off by default in any situation and should be managed by the user via script. The blinkers blink automatically. Warning: Right now, not all vehicles have been prepared to work with this functionality, this will be added to all of them in later updates .","title":"carla.VehicleLightState"},{"location":"python_api/#instance-variables_71","text":"NONE All lights off. Position LowBeam HighBeam Brake RightBlinker LeftBlinker Reverse Fog Interior Special1 This is reserved for certain vehicles that can have special lights, like a siren. Special2 This is reserved for certain vehicles that can have special lights, like a siren. All All lights on.","title":"Instance Variables"},{"location":"python_api/#carlavehiclephysicscontrol","text":"Summarizes the parameters that will be used to simulate a carla.Vehicle as a physical object. The specific settings for the wheels though are stipulated using carla.WheelPhysicsControl .","title":"carla.VehiclePhysicsControl"},{"location":"python_api/#instance-variables_72","text":"torque_curve ( list( carla.Vector2D ) ) Curve that indicates the torque measured in Nm for a specific RPM of the vehicle's engine. max_rpm ( float ) The maximum RPM of the vehicle's engine. moi ( float - kg*m 2 ) The moment of inertia of the vehicle's engine. damping_rate_full_throttle ( float ) Damping ratio when the throttle is maximum. damping_rate_zero_throttle_clutch_engaged ( float ) Damping ratio when the throttle is zero with clutch engaged. damping_rate_zero_throttle_clutch_disengaged ( float ) Damping ratio when the throttle is zero with clutch disengaged. use_gear_autobox ( bool ) If True , the vehicle will have an automatic transmission. gear_switch_time ( float - seconds ) Switching time between gears. clutch_strength ( float - kg*m 2 /s ) Clutch strength of the vehicle. final_ratio ( float ) Fixed ratio from transmission to wheels. forward_gears ( list( carla.GearPhysicsControl ) ) List of objects defining the vehicle's gears. mass ( float - kilograms ) Mass of the vehicle. drag_coefficient ( float ) Drag coefficient of the vehicle's chassis. center_of_mass ( carla.Vector3D - meters ) Center of mass of the vehicle. steering_curve ( list( carla.Vector2D ) ) Curve that indicates the maximum steering for a specific forward speed. use_sweep_wheel_collision ( bool ) Enable the use of sweep for wheel collision. By default, it is disabled and it uses a simple raycast from the axis to the floor for each wheel. This option provides a better collision model in which the full volume of the wheel is checked against collisions. wheels ( list( carla.WheelPhysicsControl ) ) List of wheel physics objects. This list should have 4 elements, where index 0 corresponds to the front left wheel, index 1 corresponds to the front right wheel, index 2 corresponds to the back left wheel and index 3 corresponds to the back right wheel. For 2 wheeled vehicles, set the same values for both front and back wheels.","title":"Instance Variables"},{"location":"python_api/#methods_56","text":"__init__ ( self , torque_curve =[[0.0, 500.0], [5000.0, 500.0]] , max_rpm =5000.0 , moi =1.0 , damping_rate_full_throttle =0.15 , damping_rate_zero_throttle_clutch_engaged =2.0 , damping_rate_zero_throttle_clutch_disengaged =0.35 , use_gear_autobox =True , gear_switch_time =0.5 , clutch_strength =10.0 , final_ratio =4.0 , forward_gears =list() , drag_coefficient =0.3 , center_of_mass =[0.0, 0.0, 0.0] , steering_curve =[[0.0, 1.0], [10.0, 0.5]] , wheels =list() , use_sweep_wheel_collision =False , mass =1000.0 ) VehiclePhysicsControl constructor. Parameters: torque_curve ( list( carla.Vector2D ) ) max_rpm ( float ) moi ( float - kg*m 2 ) damping_rate_full_throttle ( float ) damping_rate_zero_throttle_clutch_engaged ( float ) damping_rate_zero_throttle_clutch_disengaged ( float ) use_gear_autobox ( bool ) gear_switch_time ( float - seconds ) clutch_strength ( float - kg*m 2 /s ) final_ratio ( float ) forward_gears ( list( carla.GearPhysicsControl ) ) drag_coefficient ( float ) center_of_mass ( carla.Vector3D ) steering_curve ( carla.Vector2D ) wheels ( list( carla.WheelPhysicsControl ) ) use_sweep_wheel_collision ( bool ) mass ( float - kilograms )","title":"Methods"},{"location":"python_api/#dunder-methods_42","text":"__eq__ ( self , other = carla.VehiclePhysicsControl ) __ne__ ( self , other = carla.VehiclePhysicsControl ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlavehiclewheellocation","text":"enum representing the position of each wheel on a vehicle. Used to identify the target wheel when setting an angle in carla.Vehicle.set_wheel_steer_direction or carla.Vehicle.get_wheel_steer_angle .","title":"carla.VehicleWheelLocation"},{"location":"python_api/#instance-variables_73","text":"FL_Wheel Front left wheel of a 4 wheeled vehicle. FR_Wheel Front right wheel of a 4 wheeled vehicle. BL_Wheel Back left wheel of a 4 wheeled vehicle. BR_Wheel Back right wheel of a 4 wheeled vehicle. Front_Wheel Front wheel of a 2 wheeled vehicle. Back_Wheel Back wheel of a 2 wheeled vehicle.","title":"Instance Variables"},{"location":"python_api/#carlawalker","text":"Inherited from carla.Actor This class inherits from the carla.Actor and defines pedestrians in the simulation. Walkers are a special type of actor that can be controlled either by an AI ( carla.WalkerAIController ) or manually via script, using a series of carla.WalkerControl to move these and their skeletons.","title":"carla.Walker"},{"location":"python_api/#instance-variables_74","text":"bounding_box ( carla.BoundingBox ) Bounding box containing the geometry of the walker. Its location and rotation are relative to the walker it is attached to.","title":"Instance Variables"},{"location":"python_api/#methods_57","text":"apply_control ( self , control ) On the next tick, the control will move the walker in a certain direction with a certain speed. Jumps can be commanded too. Parameters: control ( carla.WalkerControl ) blend_pose ( self , blend_value ) Set the blending value of the custom pose with the animation. The values can be: 0: will show only the animation 1: will show only the custom pose (set by the user with set_bones()) any other: will interpolate all the bone positions between animation and the custom pose. Parameters: blend_value ( float - value from 0 to 1 with the blend percentage ) hide_pose ( self ) Hide the custom pose and show the animation (same as calling blend_pose(0)). show_pose ( self ) Show the custom pose and hide the animation (same as calling blend_pose(1)).","title":"Methods"},{"location":"python_api/#getters_18","text":"get_bones ( self ) Return the structure with all the bone transformations from the actor. For each bone, we get the name and its transform in three different spaces: name: bone name world: transform in world coordinates component: transform based on the pivot of the actor relative: transform based on the bone parent. Return: carla.WalkerBoneControlOut Setter: carla.Walker.set_bones get_control ( self ) The client returns the control applied to this walker during last tick. The method does not call the simulator. Return: carla.WalkerControl get_pose_from_animation ( self ) Make a copy of the current animation frame as the custom pose. Initially the custom pose is the neutral pedestrian pose.","title":"Getters"},{"location":"python_api/#setters_13","text":"set_bones ( self , bones ) Set the bones of the actor. For each bone we want to set we use a relative transform. Only the bones in this list will be set. For each bone you need to setup this info: name: bone name relative: transform based on the bone parent. Parameters: bones ( carla.WalkerBoneControlIn - list of pairs (bone_name, transform) for the bones that we want to set ) Getter: carla.Walker.get_bones","title":"Setters"},{"location":"python_api/#dunder-methods_43","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlawalkeraicontroller","text":"Inherited from carla.Actor Class that conducts AI control for a walker. The controllers are defined as actors, but they are quite different from the rest. They need to be attached to a parent actor during their creation, which is the walker they will be controlling (take a look at carla.World if you are yet to learn on how to spawn actors). They also need for a special blueprint (already defined in carla.BlueprintLibrary as \"controller.ai.walker\"). This is an empty blueprint, as the AI controller will be invisible in the simulation but will follow its parent around to dictate every step of the way.","title":"carla.WalkerAIController"},{"location":"python_api/#methods_58","text":"go_to_location ( self , destination ) Sets the destination that the pedestrian will reach. Parameters: destination ( carla.Location - meters ) start ( self ) Enables AI control for its parent walker. stop ( self ) snippet \u2192 Disables AI control for its parent walker.","title":"Methods"},{"location":"python_api/#setters_14","text":"set_max_speed ( self , speed =1.4 ) Sets a speed for the walker in meters per second. Parameters: speed ( float - m/s ) - An easy walking speed is set by default.","title":"Setters"},{"location":"python_api/#dunder-methods_44","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlawalkerbonecontrolin","text":"This class grants bone specific manipulation for walker. The skeletons of walkers have been unified for clarity and the transform applied to each bone are always relative to its parent. Take a look here to learn more on how to create a walker and define its movement.","title":"carla.WalkerBoneControlIn"},{"location":"python_api/#instance-variables_75","text":"bone_transforms ( list([name,transform]) ) List with the data for each bone we want to set: name: bone name relative: transform based on the bone parent.","title":"Instance Variables"},{"location":"python_api/#methods_59","text":"__init__ ( self , list(name,transform) ) Initializes an object containing moves to be applied on tick. These are listed with the name of the bone and the transform that will be applied to it. Parameters: list(name,transform) ( tuple )","title":"Methods"},{"location":"python_api/#dunder-methods_45","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlawalkerbonecontrolout","text":"This class is used to return all bone positions of a pedestrian. For each bone we get its name and its transform in three different spaces (world, actor and relative).","title":"carla.WalkerBoneControlOut"},{"location":"python_api/#instance-variables_76","text":"bone_transforms ( list([name,world, actor, relative]) ) List of one entry per bone with this information: name: bone name world: transform in world coordinates component: transform based on the pivot of the actor relative: transform based on the bone parent.","title":"Instance Variables"},{"location":"python_api/#methods_60","text":"","title":"Methods"},{"location":"python_api/#dunder-methods_46","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlawalkercontrol","text":"This class defines specific directions that can be commanded to a carla.Walker to control it via script. AI control can be settled for walkers, but the control used to do so is carla.WalkerAIController .","title":"carla.WalkerControl"},{"location":"python_api/#instance-variables_77","text":"direction ( carla.Vector3D ) Vector using global coordinates that will correspond to the direction of the walker. speed ( float - m/s ) A scalar value to control the walker's speed. jump ( bool ) If True , the walker will perform a jump.","title":"Instance Variables"},{"location":"python_api/#methods_61","text":"__init__ ( self , direction =[1.0, 0.0, 0.0] , speed =0.0 , jump =False ) Parameters: direction ( carla.Vector3D ) speed ( float - m/s ) jump ( bool )","title":"Methods"},{"location":"python_api/#dunder-methods_47","text":"__eq__ ( self , other = carla.WalkerControl ) Compares every variable with other and returns True if these are all the same. __ne__ ( self , other = carla.WalkerControl ) Compares every variable with other and returns True if any of these differ. __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlawaypoint","text":"Waypoints in CARLA are described as 3D directed points. They have a carla.Transform which locates the waypoint in a road and orientates it according to the lane. They also store the road information belonging to said point regarding its lane and lane markings. All the information regarding waypoints and the waypoint API is retrieved as provided by the OpenDRIVE file. Once the client asks for the map object to the server, no longer communication will be needed.","title":"carla.Waypoint"},{"location":"python_api/#instance-variables_78","text":"id ( int ) The identificator is generated using a hash combination of the road , section , lane and s values that correspond to said point in the OpenDRIVE geometry. The s precision is set to 2 centimeters, so 2 waypoints closer than 2 centimeters in the same road, section and lane, will have the same identificator. transform ( carla.Transform ) Position and orientation of the waypoint according to the current lane information. This data is computed the first time it is accessed. It is not created right away in order to ease computing costs when lots of waypoints are created but their specific transform is not needed. road_id ( int ) OpenDRIVE road's id. section_id ( int ) OpenDRIVE section's id, based on the order that they are originally defined. lane_id ( int ) OpenDRIVE lane's id, this value can be positive or negative which represents the direction of the current lane with respect to the road. For more information refer to OpenDRIVE documentation . s ( float ) OpenDRIVE s value of the current position. is_junction ( bool ) True if the current Waypoint is on a junction as defined by OpenDRIVE. lane_width ( float ) Horizontal size of the road at current s . lane_change ( carla.LaneChange ) Lane change definition of the current Waypoint's location, based on the traffic rules defined in the OpenDRIVE file. It states if a lane change can be done and in which direction. lane_type ( carla.LaneType ) The lane type of the current Waypoint, based on OpenDRIVE 1.4 standard. right_lane_marking ( carla.LaneMarking ) The right lane marking information based on the direction of the Waypoint. left_lane_marking ( carla.LaneMarking ) The left lane marking information based on the direction of the Waypoint.","title":"Instance Variables"},{"location":"python_api/#methods_62","text":"next ( self , distance ) Returns a list of waypoints at a certain approximate distance from the current one. It takes into account the road and its possible deviations without performing any lane change and returns one waypoint per option. The list may be empty if the lane is not connected to any other at the specified distance. Parameters: distance ( float - meters ) - The approximate distance where to get the next waypoints. Return: list( carla.Waypoint ) next_until_lane_end ( self , distance ) Returns a list of waypoints from this to the end of the lane separated by a certain distance . Parameters: distance ( float - meters ) - The approximate distance between waypoints. Return: list( carla.Waypoint ) previous ( self , distance ) This method does not return the waypoint previously visited by an actor, but a list of waypoints at an approximate distance but in the opposite direction of the lane. Similarly to next() , it takes into account the road and its possible deviations without performing any lane change and returns one waypoint per option. The list may be empty if the lane is not connected to any other at the specified distance. Parameters: distance ( float - meters ) - The approximate distance where to get the previous waypoints. Return: list( carla.Waypoint ) previous_until_lane_start ( self , distance ) Returns a list of waypoints from this to the start of the lane separated by a certain distance . Parameters: distance ( float - meters ) - The approximate distance between waypoints. Return: list( carla.Waypoint )","title":"Methods"},{"location":"python_api/#getters_19","text":"get_junction ( self ) If the waypoint belongs to a junction this method returns the asociated junction object. Otherwise returns null. Return: carla.Junction get_landmarks ( self , distance , stop_at_junction =False ) Returns a list of landmarks in the road from the current waypoint until the specified distance. Parameters: distance ( float - meters ) - The maximum distance to search for landmarks from the current waypoint. stop_at_junction ( bool ) - Enables or disables the landmark search through junctions. Return: list( carla.Landmark ) get_landmarks_of_type ( self , distance , type , stop_at_junction =False ) Returns a list of landmarks in the road of a specified type from the current waypoint until the specified distance. Parameters: distance ( float - meters ) - The maximum distance to search for landmarks from the current waypoint. type ( str ) - The type of landmarks to search. stop_at_junction ( bool ) - Enables or disables the landmark search through junctions. Return: list( carla.Landmark ) get_left_lane ( self ) Generates a Waypoint at the center of the left lane based on the direction of the current Waypoint, taking into account if the lane change is allowed in this location. Will return None if the lane does not exist. Return: carla.Waypoint get_right_lane ( self ) Generates a waypoint at the center of the right lane based on the direction of the current waypoint, taking into account if the lane change is allowed in this location. Will return None if the lane does not exist. Return: carla.Waypoint","title":"Getters"},{"location":"python_api/#dunder-methods_48","text":"__str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaweatherparameters","text":"This class defines objects containing lighting and weather specifications that can later be applied in carla.World . So far, these conditions only intervene with sensor.camera.rgb . They neither affect the actor's physics nor other sensors. Each of these parameters acts indepently from the rest. Increasing the rainfall will not automatically create puddles nor change the road's humidity. That makes for a better customization but means that realistic conditions need to be scripted. However an example of dynamic weather conditions working realistically can be found here .","title":"carla.WeatherParameters"},{"location":"python_api/#instance-variables_79","text":"cloudiness ( float ) Values range from 0 to 100, being 0 a clear sky and 100 one completely covered with clouds. precipitation ( float ) Rain intensity values range from 0 to 100, being 0 none at all and 100 a heavy rain. precipitation_deposits ( float ) Determines the creation of puddles. Values range from 0 to 100, being 0 none at all and 100 a road completely capped with water. Puddles are created with static noise, meaning that they will always appear at the same locations. wind_intensity ( float ) Controls the strenght of the wind with values from 0, no wind at all, to 100, a strong wind. The wind does affect rain direction and leaves from trees, so this value is restricted to avoid animation issues. sun_azimuth_angle ( float - degrees ) The azimuth angle of the sun. Values range from 0 to 360. Zero is an origin point in a sphere determined by Unreal Engine. sun_altitude_angle ( float - degrees ) Altitude angle of the sun. Values range from -90 to 90 corresponding to midnight and midday each. fog_density ( float ) Fog concentration or thickness. It only affects the RGB camera sensor. Values range from 0 to 100. fog_distance ( float - meters ) Fog start distance. Values range from 0 to infinite. wetness ( float ) Wetness intensity. It only affects the RGB camera sensor. Values range from 0 to 100. fog_falloff ( float ) Density of the fog (as in specific mass) from 0 to infinity. The bigger the value, the more dense and heavy it will be, and the fog will reach smaller heights. Corresponds to Fog Height Falloff in the UE docs. If the value is 0, the fog will be lighter than air, and will cover the whole scene. A value of 1 is approximately as dense as the air, and reaches normal-sized buildings. For values greater than 5, the air will be so dense that it will be compressed on ground level. scattering_intensity ( float ) Controls how much the light will contribute to volumetric fog. When set to 0, there is no contribution. mie_scattering_scale ( float ) Controls interaction of light with large particles like pollen or air pollution resulting in a hazy sky with halos around the light sources. When set to 0, there is no contribution. rayleigh_scattering_scale ( float ) Controls interaction of light with small particles like air molecules. Dependent on light wavelength, resulting in a blue sky in the day or red sky in the evening.","title":"Instance Variables"},{"location":"python_api/#methods_63","text":"__init__ ( self , cloudiness =0.0 , precipitation =0.0 , precipitation_deposits =0.0 , wind_intensity =0.0 , sun_azimuth_angle =0.0 , sun_altitude_angle =0.0 , fog_density =0.0 , fog_distance =0.0 , wetness =0.0 , fog_falloff =0.0 , scattering_intensity =0.0 , mie_scattering_scale =0.0 , rayleigh_scattering_scale =0.0331 ) Method to initialize an object defining weather conditions. This class has some presets for different noon and sunset conditions listed in a note below. Parameters: cloudiness ( float ) - 0 is a clear sky, 100 complete overcast. precipitation ( float ) - 0 is no rain at all, 100 a heavy rain. precipitation_deposits ( float ) - 0 means no puddles on the road, 100 means roads completely capped by rain. wind_intensity ( float ) - 0 is calm, 100 a strong wind. sun_azimuth_angle ( float - degrees ) - 0 is an arbitrary North, 180 its corresponding South. sun_altitude_angle ( float - degrees ) - 90 is midday, -90 is midnight. fog_density ( float ) - Concentration or thickness of the fog, from 0 to 100. fog_distance ( float - meters ) - Distance where the fog starts in meters. wetness ( float ) - Humidity percentages of the road, from 0 to 100. fog_falloff ( float ) - Density (specific mass) of the fog, from 0 to infinity. scattering_intensity ( float ) - Controls how much the light will contribute to volumetric fog. When set to 0, there is no contribution. mie_scattering_scale ( float ) - Controls interaction of light with large particles like pollen or air pollution resulting in a hazy sky with halos around the light sources. When set to 0, there is no contribution. rayleigh_scattering_scale ( float ) - Controls interaction of light with small particles like air molecules. Dependent on light wavelength, resulting in a blue sky in the day or red sky in the evening. Note: ClearNoon, CloudyNoon, WetNoon, WetCloudyNoon, SoftRainNoon, MidRainyNoon, HardRainNoon, ClearSunset, CloudySunset, WetSunset, WetCloudySunset, SoftRainSunset, MidRainSunset, HardRainSunset.","title":"Methods"},{"location":"python_api/#dunder-methods_49","text":"__eq__ ( self , other ) Returns True if both objects' variables are the same. Return: bool __ne__ ( self , other ) Returns True if both objects' variables are different. Return: bool __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlawheelphysicscontrol","text":"Class that defines specific physical parameters for wheel objects that will be part of a carla.VehiclePhysicsControl to simulate vehicle it as a material object.","title":"carla.WheelPhysicsControl"},{"location":"python_api/#instance-variables_80","text":"tire_friction ( float ) A scalar value that indicates the friction of the wheel. damping_rate ( float ) Damping rate of the wheel. max_steer_angle ( float - degrees ) Maximum angle that the wheel can steer. radius ( float - centimeters ) Radius of the wheel. max_brake_torque ( float - N*m ) Maximum brake torque. max_handbrake_torque ( float - N*m ) Maximum handbrake torque. position ( carla.Vector3D ) World position of the wheel. This is a read-only parameter. long_stiff_value ( float - kg per radian ) Tire longitudinal stiffness per unit gravitational acceleration. Each vehicle has a custom value. lat_stiff_max_load ( float ) Maximum normalized tire load at which the tire can deliver no more lateral stiffness no matter how much extra load is applied to the tire. Each vehicle has a custom value. lat_stiff_value ( float ) Maximum stiffness per unit of lateral slip. Each vehicle has a custom value.","title":"Instance Variables"},{"location":"python_api/#methods_64","text":"__init__ ( self , tire_friction =2.0 , damping_rate =0.25 , max_steer_angle =70.0 , radius =30.0 , max_brake_torque =1500.0 , max_handbrake_torque =3000.0 , position =(0.0,0.0,0.0) ) Parameters: tire_friction ( float ) damping_rate ( float ) max_steer_angle ( float - degrees ) radius ( float - centimerers ) max_brake_torque ( float - N*m ) max_handbrake_torque ( float - N*m ) position ( carla.Vector3D - meters )","title":"Methods"},{"location":"python_api/#dunder-methods_50","text":"__eq__ ( self , other = carla.WheelPhysicsControl ) __ne__ ( self , other = carla.WheelPhysicsControl ) __str__ ( self )","title":"Dunder methods"},{"location":"python_api/#carlaworld","text":"World objects are created by the client to have a place for the simulation to happen. The world contains the map we can see, meaning the asset, not the navigation map. Navigation maps are part of the carla.Map class. It also manages the weather and actors present in it. There can only be one world per simulation, but it can be changed anytime.","title":"carla.World"},{"location":"python_api/#instance-variables_81","text":"id ( int ) The ID of the episode associated with this world. Episodes are different sessions of a simulation. These change everytime a world is disabled or reloaded. Keeping track is useful to avoid possible issues. debug ( carla.DebugHelper ) Responsible for creating different shapes for debugging. Take a look at its class to learn more about it.","title":"Instance Variables"},{"location":"python_api/#methods_65","text":"apply_color_texture_to_object ( self , object_name , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to object_name . Parameters: object_name ( str ) material_parameter ( carla.MaterialParameter ) texture ( TextureColor ) apply_color_texture_to_objects ( self , objects_name_list , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to all objects in objects_name_list . Parameters: objects_name_list ( list(str) ) material_parameter ( carla.MaterialParameter ) texture ( TextureColor ) apply_float_color_texture_to_object ( self , object_name , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to object_name . Parameters: object_name ( str ) material_parameter ( carla.MaterialParameter ) texture ( TextureFloatColor ) apply_float_color_texture_to_objects ( self , objects_name_list , material_parameter , texture ) Applies a texture object in the field corresponfing to material_parameter (normal, diffuse, etc) to the object in the scene corresponding to all objects in objects_name_list . Parameters: objects_name_list ( list(str) ) material_parameter ( carla.MaterialParameter ) texture ( TextureFloatColor ) apply_settings ( self , world_settings ) This method applies settings contained in an object to the simulation running and returns the ID of the frame they were implemented. Parameters: world_settings ( carla.WorldSettings ) Return: int Warning: If synchronous mode is enabled, and there is a Traffic Manager running, this must be set to sync mode too. Read this to learn how to do it. apply_textures_to_object ( self , object_name , diffuse_texture , emissive_texture , normal_texture , ao_roughness_metallic_emissive_texture ) Applies all texture fields in carla.MaterialParameter to the object object_name . Empty textures here will not be applied. Parameters: object_name ( str ) diffuse_texture ( TextureColor ) emissive_texture ( TextureFloatColor ) normal_texture ( TextureFloatColor ) ao_roughness_metallic_emissive_texture ( TextureFloatColor ) apply_textures_to_objects ( self , objects_name_list , diffuse_texture , emissive_texture , normal_texture , ao_roughness_metallic_emissive_texture ) Applies all texture fields in carla.MaterialParameter to all objects in objects_name_list . Empty textures here will not be applied. Parameters: objects_name_list ( list(str) ) diffuse_texture ( TextureColor ) emissive_texture ( TextureFloatColor ) normal_texture ( TextureFloatColor ) ao_roughness_metallic_emissive_texture ( TextureFloatColor ) cast_ray ( self , initial_location , final_location ) Casts a ray from the specified initial_location to final_location. The function then detects all geometries intersecting the ray and returns a list of carla.LabelledPoint in order. Parameters: initial_location ( carla.Location ) - The initial position of the ray. final_location ( carla.Location ) - The final position of the ray. Return: list( carla.LabelledPoint ) enable_environment_objects ( self , env_objects_ids , enable ) snippet \u2192 Enable or disable a set of EnvironmentObject identified by their id. These objects will appear or disappear from the level. Parameters: env_objects_ids ( set(int) ) - Set of EnvironmentObject ids to change. enable ( bool ) - State to be applied to all the EnvironmentObject of the set. freeze_all_traffic_lights ( self , frozen ) Freezes or unfreezes all traffic lights in the scene. Frozen traffic lights can be modified by the user but the time will not update them until unfrozen. Parameters: frozen ( bool ) ground_projection ( self , location , search_distance ) Projects the specified point downwards in the scene. The functions casts a ray from location in the direction (0,0,-1) (downwards) and returns a carla.Labelled object with the first geometry this ray intersects (usually the ground). If no geometry is found in the search_distance range the function returns None . Parameters: location ( carla.Location ) - The point to be projected. search_distance ( float ) - The maximum distance to perform the projection. Return: carla.LabelledPoint load_map_layer ( self , map_layers ) snippet \u2192 Loads the selected layers to the level. If the layer is already loaded the call has no effect. Parameters: map_layers ( carla.MapLayer ) - Mask of level layers to be loaded. Warning: This only affects \"Opt\" maps. The minimum layout includes roads, sidewalks, traffic lights and traffic signs. on_tick ( self , callback ) This method is used in asynchronous mode . It starts callbacks from the client for the function defined as callback , and returns the ID of the callback. The function will be called everytime the server ticks. It requires a carla.WorldSnapshot as argument, which can be retrieved from wait_for_tick() . Use remove_on_tick() to stop the callbacks. Parameters: callback ( carla.WorldSnapshot ) - Function with a snapshot as compulsory parameter that will be called when the client receives a tick. Return: int project_point ( self , location , direction , search_distance ) Projects the specified point to the desired direction in the scene. The functions casts a ray from location in a direction and returns a carla.Labelled object with the first geometry this ray intersects. If no geometry is found in the search_distance range the function returns None . Parameters: location ( carla.Location ) - The point to be projected. direction ( carla.Vector3D ) - The direction of projection. search_distance ( float ) - The maximum distance to perform the projection. Return: carla.LabelledPoint remove_on_tick ( self , callback_id ) Stops the callback for callback_id started with on_tick() . Parameters: callback_id ( callback ) - The callback to be removed. The ID is returned when creating the callback. reset_all_traffic_lights ( self ) Resets the cycle of all traffic lights in the map to the initial state. spawn_actor ( self , blueprint , transform , attach_to =None , attachment =Rigid ) snippet \u2192 The method will create, return and spawn an actor into the world. The actor will need an available blueprint to be created and a transform (location and rotation). It can also be attached to a parent with a certain attachment type. Parameters: blueprint ( carla.ActorBlueprint ) - The reference from which the actor will be created. transform ( carla.Transform ) - Contains the location and orientation the actor will be spawned with. attach_to ( carla.Actor ) - The parent object that the spawned actor will follow around. attachment ( carla.AttachmentType ) - Determines how fixed and rigorous should be the changes in position according to its parent object. Return: carla.Actor tick ( self , seconds =10.0 ) This method is used in synchronous mode , when the server waits for a client tick before computing the next frame. This method will send the tick, and give way to the server. It returns the ID of the new frame computed by the server. Parameters: seconds ( float - seconds ) - Maximum time the server should wait for a tick. It is set to 10.0 by default. Return: int Note: If no tick is received in synchronous mode, the simulation will freeze. Also, if many ticks are received from different clients, there may be synchronization issues. Please read the docs about synchronous mode to learn more. try_spawn_actor ( self , blueprint , transform , attach_to =None , attachment =Rigid ) Same as spawn_actor() but returns None on failure instead of throwing an exception. Parameters: blueprint ( carla.ActorBlueprint ) - The reference from which the actor will be created. transform ( carla.Transform ) - Contains the location and orientation the actor will be spawned with. attach_to ( carla.Actor ) - The parent object that the spawned actor will follow around. attachment ( carla.AttachmentType ) - Determines how fixed and rigorous should be the changes in position according to its parent object. Return: carla.Actor unload_map_layer ( self , map_layers ) snippet \u2192 Unloads the selected layers to the level. If the layer is already unloaded the call has no effect. Parameters: map_layers ( carla.MapLayer ) - Mask of level layers to be unloaded. Warning: This only affects \"Opt\" maps. The minimum layout includes roads, sidewalks, traffic lights and traffic signs. wait_for_tick ( self , seconds =10.0 ) This method is used in asynchronous mode . It makes the client wait for a server tick. When the next frame is computed, the server will tick and return a snapshot describing the new state of the world. Parameters: seconds ( float - seconds ) - Maximum time the server should wait for a tick. It is set to 10.0 by default. Return: carla.WorldSnapshot","title":"Methods"},{"location":"python_api/#getters_20","text":"get_actor ( self , actor_id ) Looks up for an actor by ID and returns None if not found. Parameters: actor_id ( int ) Return: carla.Actor get_actors ( self , actor_ids =None ) Retrieves a list of carla.Actor elements, either using a list of IDs provided or just listing everyone on stage. If an ID does not correspond with any actor, it will be excluded from the list returned, meaning that both the list of IDs and the list of actors may have different lengths. Parameters: actor_ids ( list ) - The IDs of the actors being searched. By default it is set to None and returns every actor on scene. Return: carla.ActorList get_blueprint_library ( self ) Returns a list of actor blueprints available to ease the spawn of these into the world. Return: carla.BlueprintLibrary get_environment_objects ( self , object_type =Any ) Returns a list of EnvironmentObject with the requested semantic tag. The method returns all the EnvironmentObjects in the level by default, but the query can be filtered by semantic tags with the argument object_type . Parameters: object_type ( carla.CityObjectLabel ) - Semantic tag of the EnvironmentObjects that are returned. Return: array( carla.EnvironmentObject ) get_level_bbs ( self , actor_type =Any ) Returns an array of bounding boxes with location and rotation in world space. The method returns all the bounding boxes in the level by default, but the query can be filtered by semantic tags with the argument actor_type . Parameters: actor_type ( carla.CityObjectLabel ) - Semantic tag of the elements contained in the bounding boxes that are returned. Return: array( carla.BoundingBox ) get_lightmanager ( self ) Returns an instance of carla.LightManager that can be used to handle the lights in the scene. Return: carla.LightManager get_map ( self ) Asks the server for the XODR containing the map file, and returns this parsed as a carla.Map . Return: carla.Map Warning: This method does call the simulation. It is expensive, and should only be called once. get_names_of_all_objects ( self ) Returns a list of the names of all objects in the scene that can be painted with the apply texture functions. Return: list(str) get_random_location_from_navigation ( self ) This can only be used with walkers. It retrieves a random location to be used as a destination using the go_to_location() method in carla.WalkerAIController . This location will be part of a sidewalk. Roads, crosswalks and grass zones are excluded. The method does not take into consideration locations of existing actors so if a collision happens when trying to spawn an actor, it will return an error. Take a look at generate_traffic.py for an example. Return: carla.Location get_settings ( self ) Returns an object containing some data about the simulation such as synchrony between client and server or rendering mode. Return: carla.WorldSettings get_snapshot ( self ) Returns a snapshot of the world at a certain moment comprising all the information about the actors. Return: carla.WorldSnapshot get_spectator ( self ) snippet \u2192 Returns the spectator actor. The spectator is a special type of actor created by Unreal Engine, usually with ID=0, that acts as a camera and controls the view in the simulator window. Return: carla.Actor get_traffic_light ( self , landmark ) Provided a landmark, returns the traffic light object it describes. Parameters: landmark ( carla.Landmark ) - The landmark object describing a traffic light. Return: carla.TrafficLight get_traffic_light_from_opendrive_id ( self , traffic_light_id ) Returns the traffic light actor corresponding to the indicated OpenDRIVE id. Parameters: traffic_light_id ( str ) - The OpenDRIVE id. Return: carla.TrafficLight get_traffic_lights_from_waypoint ( self , waypoint , distance ) This function performs a search along the road in front of the specified waypoint and returns a list of traffic light actors found in the specified search distance. Parameters: waypoint ( carla.Waypoint ) - The input waypoint. distance ( float ) - Search distance. Return: list( carla.TrafficLight ) get_traffic_lights_in_junction ( self , junction_id ) Returns the list of traffic light actors affecting the junction indicated in junction_id . Parameters: junction_id ( int ) - The id of the junction. Return: list( carla.TrafficLight ) get_traffic_sign ( self , landmark ) Provided a landmark, returns the traffic sign object it describes. Parameters: landmark ( carla.Landmark ) - The landmark object describing a traffic sign. Return: carla.TrafficSign get_vehicles_light_states ( self ) Returns a dict where the keys are carla.Actor IDs and the values are carla.VehicleLightState of that vehicle. Return: dict get_weather ( self ) Retrieves an object containing weather parameters currently active in the simulation, mainly cloudiness, precipitation, wind and sun position. Return: carla.WeatherParameters Setter: carla.World.set_weather","title":"Getters"},{"location":"python_api/#setters_15","text":"set_pedestrians_cross_factor ( self , percentage ) Parameters: percentage ( float ) - Sets the percentage of pedestrians that can walk on the road or cross at any point on the road. Value should be between 0.0 and 1.0 . For example, a value of 0.1 would allow 10% of pedestrians to walk on the road. Default is 0.0 . Note: Should be set before pedestrians are spawned. set_pedestrians_seed ( self , seed ) Parameters: seed ( int ) - Sets the seed to use for any random number generated in relation to pedestrians. Note: Should be set before pedestrians are spawned. If you want to repeat the same exact bodies (blueprint) for each pedestrian, then use the same seed in the Python code (where the blueprint is choosen randomly) and here, otherwise the pedestrians will repeat the same paths but the bodies will be different. set_weather ( self , weather ) Changes the weather parameteres ruling the simulation to another ones defined in an object. Parameters: weather ( carla.WeatherParameters ) - New conditions to be applied. Getter: carla.World.get_weather","title":"Setters"},{"location":"python_api/#dunder-methods_51","text":"__str__ ( self ) The content of the world is parsed and printed as a brief report of its current state. Return: string","title":"Dunder methods"},{"location":"python_api/#carlaworldsettings","text":"The simulation has some advanced configuration options that are contained in this class and can be managed using carla.World and its methods. These allow the user to choose between client-server synchrony/asynchrony, activation of \"no rendering mode\" and either if the simulation should run with a fixed or variable time-step. Check this out if you want to learn about it.","title":"carla.WorldSettings"},{"location":"python_api/#instance-variables_82","text":"synchronous_mode ( bool ) States the synchrony between client and server. When set to true, the server will wait for a client tick in order to move forward. It is false by default. no_rendering_mode ( bool ) When enabled, the simulation will run no rendering at all. This is mainly used to avoid overhead during heavy traffic simulations. It is false by default. fixed_delta_seconds ( float ) Ensures that the time elapsed between two steps of the simulation is fixed. Set this to 0.0 to work with a variable time-step, as happens by default. substepping ( bool ) Enable the physics substepping. This option allows computing some physics substeps between two render frames. If synchronous mode is set, the number of substeps and its time interval are fixed and computed are so they fulfilled the requirements of carla.WorldSettings.max_substep and carla.WorldSettings.max_substep_delta_time . These last two parameters need to be compatible with carla.WorldSettings.fixed_delta_seconds . Enabled by default. max_substep_delta_time ( float ) Maximum delta time of the substeps. If the carla.WorldSettingsmax_substep is high enough, the substep delta time would be always below or equal to this value. By default, the value is set to 0.01. max_substeps ( int ) The maximum number of physics substepping that are allowed. By default, the value is set to 10. max_culling_distance ( float ) Configure the max draw distance for each mesh of the level. deterministic_ragdolls ( bool ) Defines wether to use deterministic physics for pedestrian death animations or physical ragdoll simulation. When enabled, pedestrians have less realistic death animation but ensures determinism. When disabled, pedestrians are simulated as ragdolls with more realistic simulation and collision but no determinsm can be ensured. tile_stream_distance ( float ) Used for large maps only. Configures the maximum distance from the hero vehicle to stream tiled maps. Regions of the map within this range will be visible (and capable of simulating physics). Regions outside this region will not be loaded. actor_active_distance ( float ) Used for large maps only. Configures the distance from the hero vehicle to convert actors to dormant. Actors within this range will be active, and actors outside will become dormant.","title":"Instance Variables"},{"location":"python_api/#methods_66","text":"__init__ ( self , synchronous_mode =False , no_rendering_mode =False , fixed_delta_seconds =0.0 ) Creates an object containing desired settings that could later be applied through carla.World and its method apply_settings() . Parameters: synchronous_mode ( bool ) - Set this to true to enable client-server synchrony. no_rendering_mode ( bool ) - Set this to true to completely disable rendering in the simulation. fixed_delta_seconds ( float - seconds ) - Set a fixed time-step in between frames. 0.0 means variable time-step and it is the default mode.","title":"Methods"},{"location":"python_api/#dunder-methods_52","text":"__eq__ ( self , other = carla.WorldSettings ) Returns True if both objects' variables are the same. Return: bool __ne__ ( self , other = carla.WorldSettings ) Returns True if both objects' variables are different. Return: bool __str__ ( self ) Parses the established settings to a string and shows them in command line. Return: str","title":"Dunder methods"},{"location":"python_api/#carlaworldsnapshot","text":"This snapshot comprises all the information for every actor on scene at a certain moment of time. It creates and gives acces to a data structure containing a series of carla.ActorSnapshot . The client recieves a new snapshot on every tick that cannot be stored.","title":"carla.WorldSnapshot"},{"location":"python_api/#instance-variables_83","text":"id ( int ) A value unique for every snapshot to differenciate them. frame ( int ) Simulation frame in which the snapshot was taken. timestamp ( carla.Timestamp - seconds ) Precise moment in time when snapshot was taken. This class works in seconds as given by the operative system.","title":"Instance Variables"},{"location":"python_api/#methods_67","text":"find ( self , actor_id ) Given a certain actor ID, returns its corresponding snapshot or None if it is not found. Parameters: actor_id ( int ) Return: carla.ActorSnapshot has_actor ( self , actor_id ) Given a certain actor ID, checks if there is a snapshot corresponding it and so, if the actor was present at that moment. Parameters: actor_id ( int ) Return: bool","title":"Methods"},{"location":"python_api/#dunder-methods_53","text":"__eq__ ( self , other = carla.WorldSnapshot ) Returns True if both timestamp are the same. Return: bool __iter__ ( self ) Iterate over the carla.ActorSnapshot stored in the snapshot. __len__ ( self ) Returns the amount of carla.ActorSnapshot present in this snapshot. Return: int __ne__ ( self , other = carla.WorldSnapshot ) Returns True if both timestamp are different. Return: bool","title":"Dunder methods"},{"location":"python_api/#commandapplyangularimpulse","text":"Command adaptation of add_angular_impulse() in carla.Actor . Applies an angular impulse to an actor.","title":"command.ApplyAngularImpulse"},{"location":"python_api/#instance-variables_84","text":"actor_id ( int ) Actor affected by the command. impulse ( carla.Vector3D - degrees*s ) Angular impulse applied to the actor.","title":"Instance Variables"},{"location":"python_api/#methods_68","text":"__init__ ( self , actor , impulse ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. impulse ( carla.Vector3D - degrees*s )","title":"Methods"},{"location":"python_api/#commandapplyforce","text":"Command adaptation of add_force() in carla.Actor . Applies a force to an actor.","title":"command.ApplyForce"},{"location":"python_api/#instance-variables_85","text":"actor_id ( int ) Actor affected by the command. force ( carla.Vector3D - N ) Force applied to the actor over time.","title":"Instance Variables"},{"location":"python_api/#methods_69","text":"__init__ ( self , actor , force ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. force ( carla.Vector3D - N )","title":"Methods"},{"location":"python_api/#commandapplyimpulse","text":"Command adaptation of add_impulse() in carla.Actor . Applies an impulse to an actor.","title":"command.ApplyImpulse"},{"location":"python_api/#instance-variables_86","text":"actor_id ( int ) Actor affected by the command. impulse ( carla.Vector3D - N*s ) Impulse applied to the actor.","title":"Instance Variables"},{"location":"python_api/#methods_70","text":"__init__ ( self , actor , impulse ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. impulse ( carla.Vector3D - N*s )","title":"Methods"},{"location":"python_api/#commandapplytargetangularvelocity","text":"Command adaptation of set_target_angular_velocity() in carla.Actor . Sets the actor's angular velocity vector.","title":"command.ApplyTargetAngularVelocity"},{"location":"python_api/#instance-variables_87","text":"actor_id ( int ) Actor affected by the command. angular_velocity ( carla.Vector3D - deg/s ) The 3D angular velocity that will be applied to the actor.","title":"Instance Variables"},{"location":"python_api/#methods_71","text":"__init__ ( self , actor , angular_velocity ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. angular_velocity ( carla.Vector3D - deg/s ) - Angular velocity vector applied to the actor.","title":"Methods"},{"location":"python_api/#commandapplytargetvelocity","text":"Command adaptation of set_target_velocity() in carla.Actor .","title":"command.ApplyTargetVelocity"},{"location":"python_api/#instance-variables_88","text":"actor_id ( int ) Actor affected by the command. velocity ( carla.Vector3D - m/s ) The 3D velocity applied to the actor.","title":"Instance Variables"},{"location":"python_api/#methods_72","text":"__init__ ( self , actor , velocity ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. velocity ( carla.Vector3D - m/s ) - Velocity vector applied to the actor.","title":"Methods"},{"location":"python_api/#commandapplytorque","text":"Command adaptation of add_torque() in carla.Actor . Applies a torque to an actor.","title":"command.ApplyTorque"},{"location":"python_api/#instance-variables_89","text":"actor_id ( int ) Actor affected by the command. torque ( carla.Vector3D - degrees ) Torque applied to the actor over time.","title":"Instance Variables"},{"location":"python_api/#methods_73","text":"__init__ ( self , actor , torque ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. torque ( carla.Vector3D - degrees )","title":"Methods"},{"location":"python_api/#commandapplytransform","text":"Command adaptation of set_transform() in carla.Actor . Sets a new transform to an actor.","title":"command.ApplyTransform"},{"location":"python_api/#instance-variables_90","text":"actor_id ( int ) Actor affected by the command. transform ( carla.Transform ) Transformation to be applied.","title":"Instance Variables"},{"location":"python_api/#methods_74","text":"__init__ ( self , actor , transform ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. transform ( carla.Transform )","title":"Methods"},{"location":"python_api/#commandapplyvehiclecontrol","text":"Command adaptation of apply_control() in carla.Vehicle . Applies a certain control to a vehicle.","title":"command.ApplyVehicleControl"},{"location":"python_api/#instance-variables_91","text":"actor_id ( int ) Vehicle actor affected by the command. control ( carla.VehicleControl ) Vehicle control to be applied.","title":"Instance Variables"},{"location":"python_api/#methods_75","text":"__init__ ( self , actor , control ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. control ( carla.VehicleControl )","title":"Methods"},{"location":"python_api/#commandapplyvehiclephysicscontrol","text":"Command adaptation of apply_physics_control() in carla.Vehicle . Applies a new physics control to a vehicle, modifying its physical parameters.","title":"command.ApplyVehiclePhysicsControl"},{"location":"python_api/#instance-variables_92","text":"actor_id ( int ) Vehicle actor affected by the command. control ( carla.VehiclePhysicsControl ) Physics control to be applied.","title":"Instance Variables"},{"location":"python_api/#methods_76","text":"__init__ ( self , actor , control ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. control ( carla.VehiclePhysicsControl )","title":"Methods"},{"location":"python_api/#commandapplywalkercontrol","text":"Command adaptation of apply_control() in carla.Walker . Applies a control to a walker.","title":"command.ApplyWalkerControl"},{"location":"python_api/#instance-variables_93","text":"actor_id ( int ) Walker actor affected by the command. control ( carla.WalkerControl ) Walker control to be applied.","title":"Instance Variables"},{"location":"python_api/#methods_77","text":"__init__ ( self , actor , control ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. control ( carla.WalkerControl )","title":"Methods"},{"location":"python_api/#commandapplywalkerstate","text":"Apply a state to the walker actor. Specially useful to initialize an actor them with a specific location, orientation and speed.","title":"command.ApplyWalkerState"},{"location":"python_api/#instance-variables_94","text":"actor_id ( int ) Walker actor affected by the command. transform ( carla.Transform ) Transform to be applied. speed ( float - m/s ) Speed to be applied.","title":"Instance Variables"},{"location":"python_api/#methods_78","text":"__init__ ( self , actor , transform , speed ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. transform ( carla.Transform ) speed ( float - m/s )","title":"Methods"},{"location":"python_api/#commanddestroyactor","text":"Command adaptation of destroy() in carla.Actor that tells the simulator to destroy this actor. It has no effect if the actor was already destroyed. When executed with apply_batch_sync() in carla.Client there will be a command.Response that will return a boolean stating whether the actor was successfully destroyed.","title":"command.DestroyActor"},{"location":"python_api/#instance-variables_95","text":"actor_id ( int ) Actor affected by the command.","title":"Instance Variables"},{"location":"python_api/#methods_79","text":"__init__ ( self , actor ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to.","title":"Methods"},{"location":"python_api/#commandresponse","text":"States the result of executing a command as either the ID of the actor to whom the command was applied to (when succeeded) or an error string (when failed). actor ID, depending on whether or not the command succeeded. The method apply_batch_sync() in carla.Client returns a list of these to summarize the execution of a batch.","title":"command.Response"},{"location":"python_api/#instance-variables_96","text":"actor_id ( int ) Actor to whom the command was applied to. States that the command was successful. error ( str ) A string stating the command has failed.","title":"Instance Variables"},{"location":"python_api/#methods_80","text":"has_error ( self ) Returns True if the command execution fails, and False if it was successful. Return: bool","title":"Methods"},{"location":"python_api/#commandsetautopilot","text":"Command adaptation of set_autopilot() in carla.Vehicle . Turns on/off the vehicle's autopilot mode.","title":"command.SetAutopilot"},{"location":"python_api/#instance-variables_97","text":"actor_id ( int ) Actor that is affected by the command. enabled ( bool ) If autopilot should be activated or not. port ( uint16 ) Port of the Traffic Manager where the vehicle is to be registered or unlisted.","title":"Instance Variables"},{"location":"python_api/#methods_81","text":"__init__ ( self , actor , enabled , port =8000 ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. enabled ( bool ) port ( uint16 ) - The Traffic Manager port where the vehicle is to be registered or unlisted. If None is passed, it will consider a TM at default port 8000 .","title":"Methods"},{"location":"python_api/#commandsetenablegravity","text":"Command adaptation of set_enable_gravity() in carla.Actor . Enables or disables gravity on an actor.","title":"command.SetEnableGravity"},{"location":"python_api/#instance-variables_98","text":"actor_id ( carla.Actor or int ) Actor that is affected by the command. enabled ( bool )","title":"Instance Variables"},{"location":"python_api/#methods_82","text":"__init__ ( self , actor , enabled ) Parameters: actor ( carla.Actor or int ) - Actor or Actor ID to which the command will be applied to. enabled ( bool )","title":"Methods"},{"location":"python_api/#commandsetsimulatephysics","text":"Command adaptation of set_simulate_physics() in carla.Actor . Determines whether an actor will be affected by physics or not.","title":"command.SetSimulatePhysics"},{"location":"python_api/#instance-variables_99","text":"actor_id ( int ) Actor affected by the command. enabled ( bool ) If physics should be activated or not.","title":"Instance Variables"},{"location":"python_api/#methods_83","text":"__init__ ( self , actor , enabled ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. enabled ( bool )","title":"Methods"},{"location":"python_api/#commandsetvehiclelightstate","text":"Command adaptation of set_light_state() in carla.Vehicle . Sets the light state of a vehicle.","title":"command.SetVehicleLightState"},{"location":"python_api/#instance-variables_100","text":"actor_id ( int ) Actor that is affected by the command. light_state ( carla.VehicleLightState ) Defines the light state of a vehicle.","title":"Instance Variables"},{"location":"python_api/#methods_84","text":"__init__ ( self , actor , light_state ) Parameters: actor ( carla.Actor or int ) - Actor or its ID to whom the command will be applied to. light_state ( carla.VehicleLightState ) - Recaps the state of the lights of a vehicle, these can be used as a flags.","title":"Methods"},{"location":"python_api/#commandshowdebugtelemetry","text":"Command adaptation of show_debug_telemetry() in carla.Actor . Displays vehicle control telemetry data.","title":"command.ShowDebugTelemetry"},{"location":"python_api/#instance-variables_101","text":"actor_id ( carla.Actor or int ) Actor that is affected by the command. enabled ( bool )","title":"Instance Variables"},{"location":"python_api/#methods_85","text":"__init__ ( self , actor , enabled ) Parameters: actor ( carla.Actor or int ) - Actor or Actor ID to which the command will be applied to. enabled ( bool )","title":"Methods"},{"location":"python_api/#commandspawnactor","text":"Command adaptation of spawn_actor() in carla.World . Spawns an actor into the world based on the blueprint provided and the transform. If a parent is provided, the actor is attached to it.","title":"command.SpawnActor"},{"location":"python_api/#instance-variables_102","text":"transform ( carla.Transform ) Transform to be applied. parent_id ( int ) Identificator of the parent actor.","title":"Instance Variables"},{"location":"python_api/#methods_86","text":"__init__ ( self ) __init__ ( self , blueprint , transform ) Parameters: blueprint ( carla.ActorBlueprint ) transform ( carla.Transform ) __init__ ( self , blueprint , transform , parent ) Parameters: blueprint ( carla.ActorBlueprint ) transform ( carla.Transform ) parent ( carla.Actor or int ) then ( self , command ) Links another command to be executed right after. It allows to ease very common flows such as spawning a set of vehicles by command and then using this method to set them to autopilot automatically. Parameters: command ( any carla Command ) - a Carla command. function CopyToClipboard(containerid) { if (document.selection) { var range = document.body.createTextRange(); range.moveToElementText(document.getElementById(containerid)); range.select().createTextRange(); document.execCommand(\"copy\"); } else if (window.getSelection) { var range = document.createRange(); range.selectNode(document.getElementById(containerid)); window.getSelection().addRange(range); document.execCommand(\"copy\"); } } function CloseSnipet() { document.getElementById(\"snipets-container\").innerHTML = null; } Snippet for carla.World.load_map_layer # This recipe toggles on several layers in our \"_Opt\" maps # Load town one with only minimum layout (roads, sidewalks, traffic lights and traffic signs) world = client.load_world('Town01_Opt', carla.MapLayer.None) # Toggle all buildings on world.load_map_layer(carla.MapLayer.Buildings) # Toggle all foliage on world.load_map_layer(carla.MapLayer.Foliage) # Toggle all parked vehicles on world.load_map_layer(carla.MapLayer.ParkedVehicles) Copy snippet Close snippet Snippet for carla.ActorBlueprint.set_attribute # This recipe changes attributes of different type of blueprint actors. # ... walker_bp = world.get_blueprint_library().filter('walker.pedestrian.0002') walker_bp.set_attribute('is_invincible', True) # ... # Changes attribute randomly by the recommended value vehicle_bp = wolrd.get_blueprint_library().filter('vehicle.bmw.*') color = random.choice(vehicle_bp.get_attribute('color').recommended_values) vehicle_bp.set_attribute('color', color) # ... camera_bp = world.get_blueprint_library().filter('sensor.camera.rgb') camera_bp.set_attribute('image_size_x', 600) camera_bp.set_attribute('image_size_y', 600) # ... Copy snippet Close snippet Snippet for carla.Client.apply_batch_sync # 0. Choose a blueprint fo the walkers world = client.get_world() blueprintsWalkers = world.get_blueprint_library().filter(\"walker.pedestrian.*\") walker_bp = random.choice(blueprintsWalkers) # 1. Take all the random locations to spawn spawn_points = [] for i in range(50): spawn_point = carla.Transform() spawn_point.location = world.get_random_location_from_navigation() if (spawn_point.location != None): spawn_points.append(spawn_point) # 2. Build the batch of commands to spawn the pedestrians batch = [] for spawn_point in spawn_points: walker_bp = random.choice(blueprintsWalkers) batch.append(carla.command.SpawnActor(walker_bp, spawn_point)) # 2.1 apply the batch results = client.apply_batch_sync(batch, True) for i in range(len(results)): if results[i].error: logging.error(results[i].error) else: walkers_list.append({\"id\": results[i].actor_id}) # 3. Spawn walker AI controllers for each walker batch = [] walker_controller_bp = world.get_blueprint_library().find('controller.ai.walker') for i in range(len(walkers_list)): batch.append(carla.command.SpawnActor(walker_controller_bp, carla.Transform(), walkers_list[i][\"id\"])) # 3.1 apply the batch results = client.apply_batch_sync(batch, True) for i in range(len(results)): if results[i].error: logging.error(results[i].error) else: walkers_list[i][\"con\"] = results[i].actor_id # 4. Put altogether the walker and controller ids for i in range(len(walkers_list)): all_id.append(walkers_list[i][\"con\"]) all_id.append(walkers_list[i][\"id\"]) all_actors = world.get_actors(all_id) # wait for a tick to ensure client receives the last transform of the walkers we have just created world.wait_for_tick() # 5. initialize each controller and set target to walk to (list is [controller, actor, controller, actor ...]) for i in range(0, len(all_actors), 2): # start walker all_actors[i].start() # set walk to random point all_actors[i].go_to_location(world.get_random_location_from_navigation()) # random max speed all_actors[i].set_max_speed(1 + random.random()) # max speed between 1 and 2 (default is 1.4 m/s) Copy snippet Close snippet Snippet for carla.WalkerAIController.stop #To destroy the pedestrians, stop them from the navigation, and then destroy the objects (actor and controller). # stop pedestrians (list is [controller, actor, controller, actor ...]) for i in range(0, len(all_id), 2): all_actors[i].stop() # destroy pedestrian (actor and controller) client.apply_batch([carla.command.DestroyActor(x) for x in all_id]) Copy snippet Close snippet Snippet for carla.DebugHelper.draw_string # This recipe is a modification of lane_explorer.py example. # It draws the path of an actor through the world, printing information at each waypoint. # ... current_w = map.get_waypoint(vehicle.get_location()) while True: next_w = map.get_waypoint(vehicle.get_location(), lane_type=carla.LaneType.Driving | carla.LaneType.Shoulder | carla.LaneType.Sidewalk ) # Check if the vehicle is moving if next_w.id != current_w.id: vector = vehicle.get_velocity() # Check if the vehicle is on a sidewalk if current_w.lane_type == carla.LaneType.Sidewalk: draw_waypoint_union(debug, current_w, next_w, cyan if current_w.is_junction else red, 60) else: draw_waypoint_union(debug, current_w, next_w, cyan if current_w.is_junction else green, 60) debug.draw_string(current_w.transform.location, str('%15.0f km/h' % (3.6 * math.sqrt(vector.x**2 + vector.y**2 + vector.z**2))), False, orange, 60) draw_transform(debug, current_w.transform, white, 60) # Update the current waypoint and sleep for some time current_w = next_w time.sleep(args.tick_time) # ... Copy snippet Close snippet Snippet for carla.Map.get_waypoint # This recipe shows the current traffic rules affecting the vehicle. # Shows the current lane type and if a lane change can be done in the actual lane or the surrounding ones. # ... waypoint = world.get_map().get_waypoint(vehicle.get_location(),project_to_road=True, lane_type=(carla.LaneType.Driving | carla.LaneType.Shoulder | carla.LaneType.Sidewalk)) print(\"Current lane type: \" + str(waypoint.lane_type)) # Check current lane change allowed print(\"Current Lane change: \" + str(waypoint.lane_change)) # Left and Right lane markings print(\"L lane marking type: \" + str(waypoint.left_lane_marking.type)) print(\"L lane marking change: \" + str(waypoint.left_lane_marking.lane_change)) print(\"R lane marking type: \" + str(waypoint.right_lane_marking.type)) print(\"R lane marking change: \" + str(waypoint.right_lane_marking.lane_change)) # ... Copy snippet Close snippet Snippet for carla.TrafficLight.set_state # This recipe changes from red to green the traffic light that affects the vehicle. # This is done by detecting if the vehicle actor is at a traffic light. # ... world = client.get_world() spectator = world.get_spectator() vehicle_bp = random.choice(world.get_blueprint_library().filter('vehicle.bmw.*')) transform = random.choice(world.get_map().get_spawn_points()) vehicle = world.try_spawn_actor(vehicle_bp, transform) # Wait for world to get the vehicle actor world.tick() world_snapshot = world.wait_for_tick() actor_snapshot = world_snapshot.find(vehicle.id) # Set spectator at given transform (vehicle transform) spectator.set_transform(actor_snapshot.get_transform()) # ...# ... if vehicle_actor.is_at_traffic_light(): traffic_light = vehicle_actor.get_traffic_light() if traffic_light.get_state() == carla.TrafficLightState.Red: # world.hud.notification(\"Traffic light changed! Good to go!\") traffic_light.set_state(carla.TrafficLightState.Green) # ... Copy snippet Close snippet Snippet for carla.World.unload_map_layer # This recipe toggles off several layers in our \"_Opt\" maps # Load town one with minimum layout (roads, sidewalks, traffic lights and traffic signs) # as well as buildings and parked vehicles world = client.load_world('Town01_Opt', carla.MapLayer.Buildings | carla.MapLayer.ParkedVehicles) # Toggle all buildings off world.unload_map_layer(carla.MapLayer.Buildings) # Toggle all parked vehicles off world.unload_map_layer(carla.MapLayer.ParkedVehicles) Copy snippet Close snippet Snippet for carla.DebugHelper.draw_box # This recipe shows how to draw traffic light actor bounding boxes from a world snapshot. # .... debug = world.debug world_snapshot = world.get_snapshot() for actor_snapshot in world_snapshot: actual_actor = world.get_actor(actor_snapshot.id) if actual_actor.type_id == 'traffic.traffic_light': debug.draw_box(carla.BoundingBox(actor_snapshot.get_transform().location,carla.Vector3D(0.5,0.5,2)),actor_snapshot.get_transform().rotation, 0.05, carla.Color(255,0,0,0),0) # ... Copy snippet Close snippet Snippet for carla.Client.__init__ # This recipe shows in every script provided in PythonAPI/Examples # and it is used to parse the client creation arguments when running the script. argparser = argparse.ArgumentParser( description=__doc__) argparser.add_argument( '--host', metavar='H', default='127.0.0.1', help='IP of the host server (default: 127.0.0.1)') argparser.add_argument( '-p', '--port', metavar='P', default=2000, type=int, help='TCP port to listen to (default: 2000)') argparser.add_argument( '-s', '--speed', metavar='FACTOR', default=1.0, type=float, help='rate at which the weather changes (default: 1.0)') args = argparser.parse_args() speed_factor = args.speed update_freq = 0.1 / speed_factor client = carla.Client(args.host, args.port) Copy snippet Close snippet Snippet for carla.Vehicle.set_wheel_steer_direction # Sets the appearance of the vehicles front wheels to 40\u00b0. Vehicle physics will not be affected. vehicle.set_wheel_steer_direction(carla.VehicleWheelLocation.FR_Wheel, 40.0) vehicle.set_wheel_steer_direction(carla.VehicleWheelLocation.FL_Wheel, 40.0) Copy snippet Close snippet Snippet for carla.Sensor.listen # This recipe applies a color conversion to the image taken by a camera sensor, # so it is converted to a semantic segmentation image. # ... camera_bp = world.get_blueprint_library().filter('sensor.camera.semantic_segmentation') # ... cc = carla.ColorConverter.CityScapesPalette camera.listen(lambda image: image.save_to_disk('output/%06d.png' % image.frame, cc)) # ... Copy snippet Close snippet Snippet for carla.World.enable_environment_objects # This recipe turn visibility off and on for two specifc buildings on the map # Get the buildings in the world world = client.get_world() env_objs = world.get_environment_objects(carla.CityObjectLabel.Buildings) # Access individual building IDs and save in a set building_01 = env_objs[0] building_02 = env_objs[1] objects_to_toggle = {building_01.id, building_02.id} # Toggle buildings off world.enable_environment_objects(objects_to_toggle, False) # Toggle buildings on world.enable_environment_objects(objects_to_toggle, True) Copy snippet Close snippet Snippet for carla.World.spawn_actor # This recipe attaches different camera / sensors to a vehicle with different attachments. # ... camera = world.spawn_actor(rgb_camera_bp, transform, attach_to=vehicle, attachment_type=Attachment.Rigid) # Default attachment: Attachment.Rigid gnss_sensor = world.spawn_actor(sensor_gnss_bp, transform, attach_to=vehicle) collision_sensor = world.spawn_actor(sensor_collision_bp, transform, attach_to=vehicle) lane_invasion_sensor = world.spawn_actor(sensor_lane_invasion_bp, transform, attach_to=vehicle) # ... Copy snippet Close snippet Snippet for carla.World.get_spectator # This recipe spawns an actor and the spectator camera at the actor's location. # ... world = client.get_world() spectator = world.get_spectator() vehicle_bp = random.choice(world.get_blueprint_library().filter('vehicle.bmw.*')) transform = random.choice(world.get_map().get_spawn_points()) vehicle = world.try_spawn_actor(vehicle_bp, transform) # Wait for world to get the vehicle actor world.tick() world_snapshot = world.wait_for_tick() actor_snapshot = world_snapshot.find(vehicle.id) # Set spectator at given transform (vehicle transform) spectator.set_transform(actor_snapshot.get_transform()) # ... Copy snippet Close snippet function ButtonAction(container_name){ if(window_big){ snipet_name = container_name.replace('-snipet_button','-snipet'); document.getElementById(\"snipets-container\").innerHTML = document.getElementById(snipet_name).innerHTML; } else{ document.getElementById(\"snipets-container\").innerHTML = null;code_name = container_name.replace('-snipet_button','-code'); var range = document.createRange(); range.selectNode(document.getElementById(code_name)); alert(range); } } function WindowResize(){ if(window.innerWidth > 1200){ window_big = true; } else{ window_big = false; } } var window_big; if(window.innerWidth > 1200){ window_big = true; } else{ window_big = false; } buttons = document.getElementsByClassName('SnipetButton') for (let i = 0; i < buttons.length; i++) { buttons[i].addEventListener(\"click\",function(){ButtonAction(buttons[i].id);},true); } window.onresize = WindowResize;","title":"Methods"},{"location":"ref_cpp/","text":"C++ Reference We use Doxygen to generate the documentation of our C++ code: Libcarla/Source Unreal/CarlaUE4/Source Unreal/CarlaUE4/Carla/Plugins The generated documentation is available at this link http://carla.org/Doxygen/html/index.html Note Document updates are done automatically by GitHub. Create doxygen documentation Important Doxygen is required to generate the documentation and Graphviz for the graph drawing toolkit. 1- Install doxygen and graphviz with the following command: # linux > sudo apt-get install doxygen graphviz 2- Once installed, go to the project root folder where the Doxyfile file is situated and run the following command: > doxygen It will start to build the documentation webpage. The resulting webpage can be found at Doxygen/html/ 3- Open index.html in a browser. Now you have your local cpp documentation!","title":"C++ \u53c2\u8003"},{"location":"ref_cpp/#c-reference","text":"We use Doxygen to generate the documentation of our C++ code: Libcarla/Source Unreal/CarlaUE4/Source Unreal/CarlaUE4/Carla/Plugins The generated documentation is available at this link http://carla.org/Doxygen/html/index.html Note Document updates are done automatically by GitHub.","title":"C++ Reference"},{"location":"ref_cpp/#create-doxygen-documentation","text":"Important Doxygen is required to generate the documentation and Graphviz for the graph drawing toolkit. 1- Install doxygen and graphviz with the following command: # linux > sudo apt-get install doxygen graphviz 2- Once installed, go to the project root folder where the Doxyfile file is situated and run the following command: > doxygen It will start to build the documentation webpage. The resulting webpage can be found at Doxygen/html/ 3- Open index.html in a browser. Now you have your local cpp documentation!","title":"Create doxygen documentation"},{"location":"ref_recorder_binary_file_format/","text":"Recorder Binary File Format The recorder system saves all the info needed to replay the simulation in a binary file, using little endian byte order for the multibyte values. 1- Strings in binary 2- Info header 3- Packets Packet 0 - Frame Start Packet 1 - Frame End Packet 2 - Event Add Packet 3 - Event Del Packet 4 - Event Parent Packet 5 - Event Collision Packet 6 - Position Packet 7 - TrafficLight Packet 8 - Vehicle Animation Packet 9 - Walker Animation 4- Frame Layout 5- File Layout In the next image representing the file format, we can get a quick view of all the detailed information. Each part that is visualized in the image will be explained in the following sections: In summary, the file format has a small header with general info (version, magic string, date and the map used) and a collection of packets of different types (currently we use 10 types, but that will continue growing up in the future). 1- Strings in binary Strings are encoded first with the length of it, followed by its characters without null character ending. For example, the string 'Town06' will be saved as hex values: 06 00 54 6f 77 6e 30 36 2- Info header The info header has general information about the recorded file. Basically, it contains the version and a magic string to identify the file as a recorder file. If the header changes then the version will change also. Furthermore, it contains a date timestamp, with the number of seconds from the Epoch 1900, and also it contains a string with the name of the map that has been used for recording. A sample info header is: 3- Packets Each packet starts with a little header of two fields (5 bytes): id : The packet type size : Size of packet data Header information is then followed by the data . The data is optional, a size of 0 means there is no data in the packet. If the size is greater than 0 it means that the packet has data bytes. Therefore, the data needs to be reinterpreted depending on the type of the packet. The header of the packet is useful because we can just ignore those packets we are not interested in when doing playback. We only need to read the header (first 5 bytes) of the packet and jump to the next packet just skipping the data of the packet: The types of packets are: We suggest to use id over 100 for user custom packets, because this list will keep growing in the future. Packet 0 - Frame Start This packet marks the start of a new frame, and it will be the first one to start each frame. All packets need to be placed between a Frame Start and a Frame End . So, elapsed + durationThis = elapsed time for next frame Packet 1 - Frame End This frame has no data and it only marks the end of the current frame. That helps the replayer to know the end of each frame just before the new one starts. Usually, the next frame should be a Frame Start packet to start a new frame. Packet 2 - Event Add This packet says how many actors we need to create at current frame. The field total says how many records follow. Each record starts with the id field, that is the id the actor has when it was recorded (on playback that id could change internally, but we need to use this id ). The type of actor can have these possible values: 0 = Other 1 = Vehicle 2 = Walker 3 = TrafficLight 4 = INVALID After that, the location and the rotation where we want to create the actor is proceeded. Right after we have the description of the actor. The description uid is the numeric id of the description and the id is the textual id, like 'vehicle.seat.leon'. Then comes a collection of its attributes like color, number of wheels, role, etc. The number of attributes is variable and should look similar to this: number_of_wheels = 4 sticky_control = true color = 79,33,85 role_name = autopilot Packet 3 - Event Del This packet says how many actors need to be destroyed this frame. It has the total of records, and each record has the id of the actor to remove. For example, this packet could be like this: The number 3 identifies the packet as (Event Del). The number 16 is the size of the data of the packet (4 fields of 4 bytes each). So if we don't want to process this packet, we could skip the next 16 bytes and will be directly to the start of the next packet. The next 3 says the total records that follows, and each record is the id of the actor to remove. So, we need to remove at this frame the actors 100, 101 and 120. Packet 4 - Event Parent This packet says which actor is the child of another (the parent). The first id is the child actor, and the second one will be the parent actor. Packet 5 - Event Collision If a collision happens between two actors, it will be registered in this packet. Currently only actors with a collision sensor will report collisions, so currently only hero vehicles have that sensor attached automatically. The id is just a sequence to identify each collision internally. Several collisions between the same pair of actors can happen in the same frame, because physics frame rate is fixed and usually there are several physics substeps in the same rendered frame. Packet 6 - Position This packet records the position and orientation of all actors of type vehicle and walker that exist in the scene. Packet 7 - TrafficLight This packet records the state of all traffic lights in the scene. Which means that it stores the state (red, orange or green) and the time it is waiting to change to a new state. Packet 8 - Vehicle animation This packet records the animation of the vehicles, bikes and cycles. This packet stores the throttle , sterring , brake , handbrake and gear inputs, and then set them at playback. Packet 9 - Walker animation This packet records the animation of the walker. It just saves the speed of the walker that is used in the animation. 4- Frame Layout A frame consists of several packets, where all of them are optional, except the ones that have the start and end in that frame, that must be there always. Event packets exist only in the frame where they happen. Position and traffic light packets should exist in all frames, because they are required to move all actors and set the traffic lights to its state. They are optional but if they are not present then the replayer will not be able to move or set the state of traffic lights. The animation packets are also optional, but by default they are recorded. That way the walkers are animated and also the vehicle wheels follow the direction of the vehicles. 5- File Layout The layout of the file starts with the info header and then follows a collection of packets in groups. The first in each group is the Frame Start packet, and the last in the group is the Frame End packet. In between, we can find the rest of packets as well. Usually, it is a good idea to have all packets regarding events first, and then the packets regarding position and state later. The event packets are optional, since they appear when they happen, so we could have a layout like this one: In frame 1 some actors are created and reparented, so we can observe its events in the image. In frame 2 there are no events. In frame 3 some actors have collided so the collision event appears with that info. In frame 4 the actors are destroyed.","title":"Recorder \u4e8c\u8fdb\u5236\u6587\u4ef6\u683c\u5f0f"},{"location":"ref_recorder_binary_file_format/#recorder-binary-file-format","text":"The recorder system saves all the info needed to replay the simulation in a binary file, using little endian byte order for the multibyte values. 1- Strings in binary 2- Info header 3- Packets Packet 0 - Frame Start Packet 1 - Frame End Packet 2 - Event Add Packet 3 - Event Del Packet 4 - Event Parent Packet 5 - Event Collision Packet 6 - Position Packet 7 - TrafficLight Packet 8 - Vehicle Animation Packet 9 - Walker Animation 4- Frame Layout 5- File Layout In the next image representing the file format, we can get a quick view of all the detailed information. Each part that is visualized in the image will be explained in the following sections: In summary, the file format has a small header with general info (version, magic string, date and the map used) and a collection of packets of different types (currently we use 10 types, but that will continue growing up in the future).","title":"Recorder Binary File Format"},{"location":"ref_recorder_binary_file_format/#1-strings-in-binary","text":"Strings are encoded first with the length of it, followed by its characters without null character ending. For example, the string 'Town06' will be saved as hex values: 06 00 54 6f 77 6e 30 36","title":"1- Strings in binary"},{"location":"ref_recorder_binary_file_format/#2-info-header","text":"The info header has general information about the recorded file. Basically, it contains the version and a magic string to identify the file as a recorder file. If the header changes then the version will change also. Furthermore, it contains a date timestamp, with the number of seconds from the Epoch 1900, and also it contains a string with the name of the map that has been used for recording. A sample info header is:","title":"2- Info header"},{"location":"ref_recorder_binary_file_format/#3-packets","text":"Each packet starts with a little header of two fields (5 bytes): id : The packet type size : Size of packet data Header information is then followed by the data . The data is optional, a size of 0 means there is no data in the packet. If the size is greater than 0 it means that the packet has data bytes. Therefore, the data needs to be reinterpreted depending on the type of the packet. The header of the packet is useful because we can just ignore those packets we are not interested in when doing playback. We only need to read the header (first 5 bytes) of the packet and jump to the next packet just skipping the data of the packet: The types of packets are: We suggest to use id over 100 for user custom packets, because this list will keep growing in the future.","title":"3- Packets"},{"location":"ref_recorder_binary_file_format/#packet-0-frame-start","text":"This packet marks the start of a new frame, and it will be the first one to start each frame. All packets need to be placed between a Frame Start and a Frame End . So, elapsed + durationThis = elapsed time for next frame","title":"Packet 0 - Frame Start"},{"location":"ref_recorder_binary_file_format/#packet-1-frame-end","text":"This frame has no data and it only marks the end of the current frame. That helps the replayer to know the end of each frame just before the new one starts. Usually, the next frame should be a Frame Start packet to start a new frame.","title":"Packet 1 - Frame End"},{"location":"ref_recorder_binary_file_format/#packet-2-event-add","text":"This packet says how many actors we need to create at current frame. The field total says how many records follow. Each record starts with the id field, that is the id the actor has when it was recorded (on playback that id could change internally, but we need to use this id ). The type of actor can have these possible values: 0 = Other 1 = Vehicle 2 = Walker 3 = TrafficLight 4 = INVALID After that, the location and the rotation where we want to create the actor is proceeded. Right after we have the description of the actor. The description uid is the numeric id of the description and the id is the textual id, like 'vehicle.seat.leon'. Then comes a collection of its attributes like color, number of wheels, role, etc. The number of attributes is variable and should look similar to this: number_of_wheels = 4 sticky_control = true color = 79,33,85 role_name = autopilot","title":"Packet 2 - Event Add"},{"location":"ref_recorder_binary_file_format/#packet-3-event-del","text":"This packet says how many actors need to be destroyed this frame. It has the total of records, and each record has the id of the actor to remove. For example, this packet could be like this: The number 3 identifies the packet as (Event Del). The number 16 is the size of the data of the packet (4 fields of 4 bytes each). So if we don't want to process this packet, we could skip the next 16 bytes and will be directly to the start of the next packet. The next 3 says the total records that follows, and each record is the id of the actor to remove. So, we need to remove at this frame the actors 100, 101 and 120.","title":"Packet 3 - Event Del"},{"location":"ref_recorder_binary_file_format/#packet-4-event-parent","text":"This packet says which actor is the child of another (the parent). The first id is the child actor, and the second one will be the parent actor.","title":"Packet 4 - Event Parent"},{"location":"ref_recorder_binary_file_format/#packet-5-event-collision","text":"If a collision happens between two actors, it will be registered in this packet. Currently only actors with a collision sensor will report collisions, so currently only hero vehicles have that sensor attached automatically. The id is just a sequence to identify each collision internally. Several collisions between the same pair of actors can happen in the same frame, because physics frame rate is fixed and usually there are several physics substeps in the same rendered frame.","title":"Packet 5 - Event Collision"},{"location":"ref_recorder_binary_file_format/#packet-6-position","text":"This packet records the position and orientation of all actors of type vehicle and walker that exist in the scene.","title":"Packet 6 - Position"},{"location":"ref_recorder_binary_file_format/#packet-7-trafficlight","text":"This packet records the state of all traffic lights in the scene. Which means that it stores the state (red, orange or green) and the time it is waiting to change to a new state.","title":"Packet 7 - TrafficLight"},{"location":"ref_recorder_binary_file_format/#packet-8-vehicle-animation","text":"This packet records the animation of the vehicles, bikes and cycles. This packet stores the throttle , sterring , brake , handbrake and gear inputs, and then set them at playback.","title":"Packet 8 - Vehicle animation"},{"location":"ref_recorder_binary_file_format/#packet-9-walker-animation","text":"This packet records the animation of the walker. It just saves the speed of the walker that is used in the animation.","title":"Packet 9 - Walker animation"},{"location":"ref_recorder_binary_file_format/#4-frame-layout","text":"A frame consists of several packets, where all of them are optional, except the ones that have the start and end in that frame, that must be there always. Event packets exist only in the frame where they happen. Position and traffic light packets should exist in all frames, because they are required to move all actors and set the traffic lights to its state. They are optional but if they are not present then the replayer will not be able to move or set the state of traffic lights. The animation packets are also optional, but by default they are recorded. That way the walkers are animated and also the vehicle wheels follow the direction of the vehicles.","title":"4- Frame Layout"},{"location":"ref_recorder_binary_file_format/#5-file-layout","text":"The layout of the file starts with the info header and then follows a collection of packets in groups. The first in each group is the Frame Start packet, and the last in the group is the Frame End packet. In between, we can find the rest of packets as well. Usually, it is a good idea to have all packets regarding events first, and then the packets regarding position and state later. The event packets are optional, since they appear when they happen, so we could have a layout like this one: In frame 1 some actors are created and reparented, so we can observe its events in the image. In frame 2 there are no events. In frame 3 some actors have collided so the collision event appears with that info. In frame 4 the actors are destroyed.","title":"5- File Layout"},{"location":"ref_sensors/","text":"Sensors reference Collision detector Depth camera GNSS sensor IMU sensor Lane invasion detector LIDAR sensor Obstacle detector Radar sensor RGB camera RSS sensor Semantic LIDAR sensor Semantic segmentation camera DVS camera Optical Flow camera Important All the sensors use the UE coordinate system ( x - forward , y - right , z - up ), and return coordinates in local space. When using any visualization software, pay attention to its coordinate system. Many invert the Y-axis, so visualizing the sensor data directly may result in mirrored outputs. Collision detector Blueprint: sensor.other.collision Output: carla.CollisionEvent per collision. This sensor registers an event each time its parent actor collisions against something in the world. Several collisions may be detected during a single simulation step. To ensure that collisions with any kind of object are detected, the server creates \"fake\" actors for elements such as buildings or bushes so the semantic tag can be retrieved to identify it. Collision detectors do not have any configurable attribute. Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. actor carla.Actor Actor that measured the collision (sensor's parent). other_actor carla.Actor Actor against whom the parent collided. normal_impulse carla.Vector3D Normal impulse result of the collision. Depth camera Blueprint: sensor.camera.depth Output: carla.Image per step (unless sensor_tick says otherwise). The camera provides a raw data of the scene codifying the distance of each pixel to the camera (also known as depth buffer or z-buffer ) to create a depth map of the elements. The image codifies depth value per pixel using 3 channels of the RGB color space, from less to more significant bytes: R -> G -> B . The actual distance in meters can be decoded with: normalized = (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1) in_meters = 1000 * normalized The output carla.Image should then be saved to disk using a carla.colorConverter that will turn the distance stored in RGB channels into a [0,1] float containing the distance and then translate this to grayscale. There are two options in carla.colorConverter to get a depth view: Depth and Logaritmic depth . The precision is milimetric in both, but the logarithmic approach provides better results for closer objects. ... raw_image.save_to_disk(\"path/to/save/converted/image\",carla.Depth) Basic camera attributes Blueprint attribute Type Default Description image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. fov float 90.0 Horizontal field of view in degrees. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). Camera lens distortion attributes Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0] Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels. height int Image height in pixels. fov float Horizontal field of view in degrees. raw_data bytes Array of BGRA 32-bit pixels. GNSS sensor Blueprint: sensor.other.gnss Output: carla.GNSSMeasurement per step (unless sensor_tick says otherwise). Reports current gnss position of its parent object. This is calculated by adding the metric position to an initial geo reference location defined within the OpenDRIVE map definition. GNSS attributes Blueprint attribute Type Default Description noise_alt_bias float 0.0 Mean parameter in the noise model for altitude. noise_alt_stddev float 0.0 Standard deviation parameter in the noise model for altitude. noise_lat_bias float 0.0 Mean parameter in the noise model for latitude. noise_lat_stddev float 0.0 Standard deviation parameter in the noise model for latitude. noise_lon_bias float 0.0 Mean parameter in the noise model for longitude. noise_lon_stddev float 0.0 Standard deviation parameter in the noise model for longitude. noise_seed int 0 Initializer for a pseudorandom number generator. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. latitude double Latitude of the actor. longitude double Longitude of the actor. altitude double Altitude of the actor. IMU sensor Blueprint: sensor.other.imu Output: carla.IMUMeasurement per step (unless sensor_tick says otherwise). Provides measures that accelerometer, gyroscope and compass would retrieve for the parent object. The data is collected from the object's current state. IMU attributes Blueprint attribute Type Default Description noise_accel_stddev_x float 0.0 Standard deviation parameter in the noise model for acceleration (X axis). noise_accel_stddev_y float 0.0 Standard deviation parameter in the noise model for acceleration (Y axis). noise_accel_stddev_z float 0.0 Standard deviation parameter in the noise model for acceleration (Z axis). noise_gyro_bias_x float 0.0 Mean parameter in the noise model for the gyroscope (X axis). noise_gyro_bias_y float 0.0 Mean parameter in the noise model for the gyroscope (Y axis). noise_gyro_bias_z float 0.0 Mean parameter in the noise model for the gyroscope (Z axis). noise_gyro_stddev_x float 0.0 Standard deviation parameter in the noise model for the gyroscope (X axis). noise_gyro_stddev_y float 0.0 Standard deviation parameter in the noise model for the gyroscope (Y axis). noise_gyro_stddev_z float 0.0 Standard deviation parameter in the noise model for the gyroscope (Z axis). noise_seed int 0 Initializer for a pseudorandom number generator. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. accelerometer carla.Vector3D Measures linear acceleration in m/s^2 . gyroscope carla.Vector3D Measures angular velocity in rad/sec . compass float Orientation in radians. North is (0.0, -1.0, 0.0) in UE. Lane invasion detector Blueprint: sensor.other.lane_invasion Output: carla.LaneInvasionEvent per crossing. Registers an event each time its parent crosses a lane marking. The sensor uses road data provided by the OpenDRIVE description of the map to determine whether the parent vehicle is invading another lane by considering the space between wheels. However there are some things to be taken into consideration: Discrepancies between the OpenDRIVE file and the map will create irregularities such as crossing lanes that are not visible in the map. The output retrieves a list of crossed lane markings: the computation is done in OpenDRIVE and considering the whole space between the four wheels as a whole. Thus, there may be more than one lane being crossed at the same time. This sensor does not have any configurable attribute. Important This sensor works fully on the client-side. Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. actor carla.Actor Vehicle that invaded another lane (parent actor). crossed_lane_markings list( carla.LaneMarking ) List of lane markings that have been crossed. LIDAR sensor Blueprint: sensor.lidar.ray_cast Output: carla.LidarMeasurement per step (unless sensor_tick says otherwise). This sensor simulates a rotating LIDAR implemented using ray-casting. The points are computed by adding a laser for each channel distributed in the vertical FOV. The rotation is simulated computing the horizontal angle that the Lidar rotated in a frame. The point cloud is calculated by doing a ray-cast for each laser in every step. points_per_channel_each_step = points_per_second / (FPS * channels) A LIDAR measurement contains a package with all the points generated during a 1/FPS interval. During this interval the physics are not updated so all the points in a measurement reflect the same \"static picture\" of the scene. This output contains a cloud of simulation points and thus, it can be iterated to retrieve a list of their carla.Location : for location in lidar_measurement: print(location) The information of the LIDAR measurement is enconded 4D points. Being the first three, the space points in xyz coordinates and the last one intensity loss during the travel. This intensity is computed by the following formula. a \u2014 Attenuation coefficient. This may depend on the sensor's wavelenght, and the conditions of the atmosphere. It can be modified with the LIDAR attribute atmosphere_attenuation_rate . d \u2014 Distance from the hit point to the sensor. For a better realism, points in the cloud can be dropped off. This is an easy way to simulate loss due to external perturbations. This can done combining two different. General drop-off \u2014 Proportion of points that are dropped off randomly. This is done before the tracing, meaning the points being dropped are not calculated, and therefore improves the performance. If dropoff_general_rate = 0.5 , half of the points will be dropped. Instensity-based drop-off \u2014 For each point detected, and extra drop-off is performed with a probability based in the computed intensity. This probability is determined by two parameters. dropoff_zero_intensity is the probability of points with zero intensity to be dropped. dropoff_intensity_limit is a threshold intensity above which no points will be dropped. The probability of a point within the range to be dropped is a linear proportion based on these two parameters. Additionally, the noise_stddev attribute makes for a noise model to simulate unexpected deviations that appear in real-life sensors. For positive values, each point is randomly perturbed along the vector of the laser ray. The result is a LIDAR sensor with perfect angular positioning, but noisy distance measurement. The rotation of the LIDAR can be tuned to cover a specific angle on every simulation step (using a fixed time-step ). For example, to rotate once per step (full circle output, as in the picture below), the rotation frequency and the simulated FPS should be equal. 1. Set the sensor's frequency sensors_bp['lidar'][0].set_attribute('rotation_frequency','10') . 2. Run the simulation using python3 config.py --fps=10 . Lidar attributes Blueprint attribute Type Default Description channels int 32 Number of lasers. range float 10.0 Maximum distance to measure/raycast in meters (centimeters for CARLA 0.9.6 or previous). points_per_second int 56000 Points generated by all lasers per second. rotation_frequency float 10.0 LIDAR rotation frequency. upper_fov float 10.0 Angle in degrees of the highest laser. lower_fov float -30.0 Angle in degrees of the lowest laser. horizontal_fov float 360.0 Horizontal field of view in degrees, 0 - 360. atmosphere_attenuation_rate float 0.004 Coefficient that measures the LIDAR instensity loss per meter. Check the intensity computation above. dropoff_general_rate float 0.45 General proportion of points that are randomy dropped. dropoff_intensity_limit float 0.8 For the intensity based drop-off, the threshold intensity value above which no points are dropped. dropoff_zero_intensity float 0.4 For the intensity based drop-off, the probability of each point with zero intensity being dropped. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). noise_stddev float 0.0 Standard deviation of the noise model to disturb each point along the vector of its raycast. Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. horizontal_angle float Angle (radians) in the XY plane of the LIDAR in the current frame. channels int Number of channels (lasers) of the LIDAR. get_point_count(channel) int Number of points per channel captured this frame. raw_data bytes Array of 32-bits floats (XYZI of each point). Obstacle detector Blueprint: sensor.other.obstacle Output: carla.ObstacleDetectionEvent per obstacle (unless sensor_tick says otherwise). Registers an event every time the parent actor has an obstacle ahead. In order to anticipate obstacles, the sensor creates a capsular shape ahead of the parent vehicle and uses it to check for collisions. To ensure that collisions with any kind of object are detected, the server creates \"fake\" actors for elements such as buildings or bushes so the semantic tag can be retrieved to identify it. Blueprint attribute Type Default Description distance float 5 Distance to trace. hit_radius float 0.5 Radius of the trace. only_dynamics bool False If true, the trace will only consider dynamic objects. debug_linetrace bool False If true, the trace will be visible. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. actor carla.Actor Actor that detected the obstacle (parent actor). other_actor carla.Actor Actor detected as an obstacle. distance float Distance from actor to other_actor . Radar sensor Blueprint: sensor.other.radar Output: carla.RadarMeasurement per step (unless sensor_tick says otherwise). The sensor creates a conic view that is translated to a 2D point map of the elements in sight and their speed regarding the sensor. This can be used to shape elements and evaluate their movement and direction. Due to the use of polar coordinates, the points will concentrate around the center of the view. Points measured are contained in carla.RadarMeasurement as an array of carla.RadarDetection , which specifies their polar coordinates, distance and velocity. This raw data provided by the radar sensor can be easily converted to a format manageable by numpy : # To get a numpy [[vel, azimuth, altitude, depth],...[,,,]]: points = np.frombuffer(radar_data.raw_data, dtype=np.dtype('f4')) points = np.reshape(points, (len(radar_data), 4)) The provided script manual_control.py uses this sensor to show the points being detected and paint them white when static, red when moving towards the object and blue when moving away: Blueprint attribute Type Default Description horizontal_fov float 30.0 Horizontal field of view in degrees. points_per_second int 1500 Points generated by all lasers per second. range float 100 Maximum distance to measure/raycast in meters. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). vertical_fov float 30.0 Vertical field of view in degrees. Output attributes Sensor data attribute Type Description raw_data carla.RadarDetection The list of points detected. RadarDetection attributes Type Description altitude float Altitude angle in radians. azimuth float Azimuth angle in radians. depth float Distance in meters. velocity float Velocity towards the sensor. RGB camera Blueprint: sensor.camera.rgb Output: carla.Image per step (unless sensor_tick says otherwise).. The \"RGB\" camera acts as a regular camera capturing images from the scene. carla.colorConverter If enable_postprocess_effects is enabled, a set of post-process effects is applied to the image for the sake of realism: Vignette: darkens the border of the screen. Grain jitter: adds some noise to the render. Bloom: intense lights burn the area around them. Auto exposure: modifies the image gamma to simulate the eye adaptation to darker or brighter areas. Lens flares: simulates the reflection of bright objects on the lens. Depth of field: blurs objects near or very far away of the camera. The sensor_tick tells how fast we want the sensor to capture the data. A value of 1.5 means that we want the sensor to capture data each second and a half. By default a value of 0.0 means as fast as possible. Basic camera attributes Blueprint attribute Type Default Description bloom_intensity float 0.675 Intensity for the bloom post-process effect, 0.0 for disabling it. fov float 90.0 Horizontal field of view in degrees. fstop float 1.4 Opening of the camera lens. Aperture is 1/fstop with typical lens going down to f/1.2 (larger opening). Larger numbers will reduce the Depth of Field effect. image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. iso float 100.0 The camera sensor sensitivity. gamma float 2.2 Target gamma value of the camera. lens_flare_intensity float 0.1 Intensity for the lens flare post-process effect, 0.0 for disabling it. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). shutter_speed float 200.0 The camera shutter speed in seconds (1.0/s). Camera lens distortion attributes Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0] Advanced camera attributes Since these effects are provided by UE, please make sure to check their documentation: Automatic Exposure Cinematic Depth of Field Method Color Grading and Filmic Tonemapper Blueprint attribute Type Default Description min_fstop float 1.2 Maximum aperture. blade_count int 5 Number of blades that make up the diaphragm mechanism. exposure_mode str histogram Can be manual or histogram . More in UE4 docs . exposure_compensation float Linux: +0.75 Windows: 0.0 Logarithmic adjustment for the exposure. 0: no adjustment, -1:2x darker, -2:4 darker, 1:2x brighter, 2:4x brighter. exposure_min_bright float 10.0 In exposure_mode: \"histogram\" . Minimum brightness for auto exposure. The lowest the eye can adapt within. Must be greater than 0 and less than or equal to exposure_max_bright . exposure_max_bright float 12.0 In `exposure_mode: \"histogram\"`. Maximum brightness for auto exposure. The highestthe eye can adapt within. Must be greater than 0 and greater than or equal to `exposure_min_bright`. exposure_speed_up float 3.0 In exposure_mode: \"histogram\" . Speed at which the adaptation occurs from dark to bright environment. exposure_speed_down float 1.0 In exposure_mode: \"histogram\" . Speed at which the adaptation occurs from bright to dark environment. calibration_constant float 16.0 Calibration constant for 18% albedo. focal_distance float 1000.0 Distance at which the depth of field effect should be sharp. Measured in cm (UE units). blur_amount float 1.0 Strength/intensity of motion blur. blur_radius float 0.0 Radius in pixels at 1080p resolution to emulate atmospheric scattering according to distance from camera. motion_blur_intensity float 0.45 Strength of motion blur [0,1]. motion_blur_max_distortion float 0.35 Max distortion caused by motion blur. Percentage of screen width. motion_blur_min_object_screen_size float 0.1 Percentage of screen width objects must have for motion blur, lower value means less draw calls. slope float 0.88 Steepness of the S-curve for the tonemapper. Larger values make the slope steeper (darker) [0.0, 1.0]. toe float 0.55 Adjusts dark color in the tonemapper [0.0, 1.0]. shoulder float 0.26 Adjusts bright color in the tonemapper [0.0, 1.0]. black_clip float 0.0 This should NOT be adjusted. Sets where the crossover happens and black tones start to cut off their value [0.0, 1.0]. white_clip float 0.04 Set where the crossover happens and white tones start to cut off their value. Subtle change in most cases [0.0, 1.0]. temp float 6500.0 White balance in relation to the temperature of the light in the scene. White light: when this matches light temperature. Warm light: When higher than the light in the scene, it is a yellowish color. Cool light: When lower than the light. Blueish color. tint float 0.0 White balance temperature tint. Adjusts cyan and magenta color ranges. This should be used along with the white balance Temp property to get accurate colors. Under some light temperatures, the colors may appear to be more yellow or blue. This can be used to balance the resulting color to look more natural. chromatic_aberration_intensity float 0.0 Scaling factor to control color shifting, more noticeable on the screen borders. chromatic_aberration_offset float 0.0 Normalized distance to the center of the image where the effect takes place. enable_postprocess_effects bool True Post-process effects activation. Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels. height int Image height in pixels. fov float Horizontal field of view in degrees. raw_data bytes Array of BGRA 32-bit pixels. RSS sensor Blueprint: sensor.other.rss Output: carla.RssResponse per step (unless sensor_tick says otherwise). Important It is highly recommended to read the specific rss documentation before reading this. This sensor integrates the C++ Library for Responsibility Sensitive Safety in CARLA. It is disabled by default in CARLA, and it has to be explicitly built in order to be used. The RSS sensor calculates the RSS state of a vehicle and retrieves the current RSS Response as sensor data. The carla.RssRestrictor will use this data to adapt a carla.VehicleControl before applying it to a vehicle. These controllers can be generated by an Automated Driving stack or user input. For instance, hereunder there is a fragment of code from PythonAPI/examples/rss/manual_control_rss.py , where the user input is modified using RSS when necessary. 1. Checks if the RssSensor generates a valid response containing restrictions. 2. Gathers the current dynamics of the vehicle and the vehicle physics. 3. Applies restrictions to the vehicle control using the response from the RssSensor, and the current dynamics and physicis of the vehicle. rss_proper_response = self._world.rss_sensor.proper_response if self._world.rss_sensor and self._world.rss_sensor.response_valid else None if rss_proper_response: ... vehicle_control = self._restrictor.restrict_vehicle_control( vehicle_control, rss_proper_response, self._world.rss_sensor.ego_dynamics_on_route, self._vehicle_physics) The carla.RssSensor class The blueprint for this sensor has no modifiable attributes. However, the carla.RssSensor object that it instantiates has attributes and methods that are detailed in the Python API reference. Here is a summary of them. carla.RssSensor variables Type Description ego_vehicle_dynamics ad.rss.world.RssDynamics RSS parameters to be applied for the ego vehicle other_vehicle_dynamics ad.rss.world.RssDynamics RSS parameters to be applied for the other vehicles pedestrian_dynamics ad.rss.world.RssDynamics RSS parameters to be applied for pedestrians road_boundaries_mode carla.RssRoadBoundariesMode Enables/Disables the stay on road feature. Default is Off . # Fragment of rss_sensor.py # The carla.RssSensor is updated when listening for a new carla.RssResponse def _on_rss_response(weak_self, response): ... self.timestamp = response.timestamp self.response_valid = response.response_valid self.proper_response = response.proper_response self.ego_dynamics_on_route = response.ego_dynamics_on_route self.rss_state_snapshot = response.rss_state_snapshot self.situation_snapshot = response.situation_snapshot self.world_model = response.world_model Warning This sensor works fully on the client side. There is no blueprint in the server. Changes on the attributes will have effect after the listen() has been called. The methods available in this class are related to the routing of the vehicle. RSS calculations are always based on a route of the ego vehicle through the road network. The sensor allows to control the considered route by providing some key points, which could be the carla.Transform in a carla.Waypoint . These points are best selected after the intersections to force the route to take the desired turn. carla.RssSensor methods Description routing_targets Get the current list of routing targets used for route. append_routing_target Append an additional position to the current routing targets. reset_routing_targets Deletes the appended routing targets. drop_route Discards the current route and creates a new one. register_actor_constellation_callback Register a callback to customize the calculations. set_log_level Sets the log level. set_map_log_level Sets the log level used for map related logs. # Update the current route self.sensor.reset_routing_targets() if routing_targets: for target in routing_targets: self.sensor.append_routing_target(target) Note If no routing targets are defined, a random route is created. Output attributes carla.RssResponse attributes Type Description response_valid bool Validity of the response data. proper_response ad.rss.state.ProperResponse Proper response that the RSS calculated for the vehicle including acceleration restrictions. rss_state_snapshot ad.rss.state.RssStateSnapshot RSS states at the current point in time. This is the detailed individual output of the RSS calclulations. situation_snapshot ad.rss.situation.SituationSnapshot RSS situation at the current point in time. This is the processed input data for the RSS calclulations. world_model ad.rss.world.WorldModel RSS world model at the current point in time. This is the input data for the RSS calculations. ego_dynamics_on_route carla.RssEgoDynamicsOnRoute Current ego vehicle dynamics regarding the route. In case a actor_constellation_callback is registered, a call is triggered for: default calculation ( actor_constellation_data.other_actor=None ) per-actor calculation # Fragment of rss_sensor.py # The function is registered as actor_constellation_callback def _on_actor_constellation_request(self, actor_constellation_data): actor_constellation_result = carla.RssActorConstellationResult() actor_constellation_result.rss_calculation_mode = ad.rss.map.RssMode.NotRelevant actor_constellation_result.restrict_speed_limit_mode = ad.rss.map.RssSceneCreation.RestrictSpeedLimitMode.IncreasedSpeedLimit10 actor_constellation_result.ego_vehicle_dynamics = self.current_vehicle_parameters actor_constellation_result.actor_object_type = ad.rss.world.ObjectType.Invalid actor_constellation_result.actor_dynamics = self.current_vehicle_parameters actor_id = -1 actor_type_id = \"none\" if actor_constellation_data.other_actor != None: # customize actor_constellation_result for specific actor ... else: # default ... return actor_constellation_result Semantic LIDAR sensor Blueprint: sensor.lidar.ray_cast_semantic Output: carla.SemanticLidarMeasurement per step (unless sensor_tick says otherwise). This sensor simulates a rotating LIDAR implemented using ray-casting that exposes all the information about the raycast hit. Its behaviour is quite similar to the LIDAR sensor , but there are two main differences between them. The raw data retrieved by the semantic LIDAR includes more data per point. Coordinates of the point (as the normal LIDAR does). The cosine between the angle of incidence and the normal of the surface hit. Instance and semantic ground-truth. Basically the index of the CARLA object hit, and its semantic tag. The semantic LIDAR does not include neither intensity, drop-off nor noise model attributes. The points are computed by adding a laser for each channel distributed in the vertical FOV. The rotation is simulated computing the horizontal angle that the LIDAR rotated in a frame. The point cloud is calculated by doing a ray-cast for each laser in every step. points_per_channel_each_step = points_per_second / (FPS * channels) A LIDAR measurement contains a package with all the points generated during a 1/FPS interval. During this interval the physics are not updated so all the points in a measurement reflect the same \"static picture\" of the scene. This output contains a cloud of lidar semantic detections and therefore, it can be iterated to retrieve a list of their carla.SemanticLidarDetection : for detection in semantic_lidar_measurement: print(detection) The rotation of the LIDAR can be tuned to cover a specific angle on every simulation step (using a fixed time-step ). For example, to rotate once per step (full circle output, as in the picture below), the rotation frequency and the simulated FPS should be equal. 1. Set the sensor's frequency sensors_bp['lidar'][0].set_attribute('rotation_frequency','10') . 2. Run the simulation using python3 config.py --fps=10 . SemanticLidar attributes Blueprint attribute Type Default Description channels int 32 Number of lasers. range float 10.0 Maximum distance to measure/raycast in meters (centimeters for CARLA 0.9.6 or previous). points_per_second int 56000 Points generated by all lasers per second. rotation_frequency float 10.0 LIDAR rotation frequency. upper_fov float 10.0 Angle in degrees of the highest laser. lower_fov float -30.0 Angle in degrees of the lowest laser. horizontal_fov float 360.0 Horizontal field of view in degrees, 0 - 360. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. horizontal_angle float Angle (radians) in the XY plane of the LIDAR in the current frame. channels int Number of channels (lasers) of the LIDAR. get_point_count(channel) int Number of points per channel captured in the current frame. raw_data bytes Array containing the point cloud with instance and semantic information. For each point, four 32-bits floats are stored. XYZ coordinates. cosine of the incident angle. Unsigned int containing the index of the object hit. Unsigned int containing the semantic tag of the object it. Semantic segmentation camera Blueprint: sensor.camera.semantic_segmentation Output: carla.Image per step (unless sensor_tick says otherwise). This camera classifies every object in sight by displaying it in a different color according to its tags (e.g., pedestrians in a different color than vehicles). When the simulation starts, every element in scene is created with a tag. So it happens when an actor is spawned. The objects are classified by their relative file path in the project. For example, meshes stored in Unreal/CarlaUE4/Content/Static/Pedestrians are tagged as Pedestrian . The server provides an image with the tag information encoded in the red channel : A pixel with a red value of x belongs to an object with tag x . This raw carla.Image can be stored and converted it with the help of CityScapesPalette in carla.ColorConverter to apply the tags information and show picture with the semantic segmentation. ... raw_image.save_to_disk(\"path/to/save/converted/image\",carla.cityScapesPalette) The following tags are currently available: Value Tag Converted color Description 0 Unlabeled (0, 0, 0) Elements that have not been categorized are considered Unlabeled . This category is meant to be empty or at least contain elements with no collisions. 1 Building (70, 70, 70) Buildings like houses, skyscrapers,... and the elements attached to them. E.g. air conditioners, scaffolding, awning or ladders and much more. 2 Fence (100, 40, 40) Barriers, railing, or other upright structures. Basically wood or wire assemblies that enclose an area of ground. 3 Other (55, 90, 80) Everything that does not belong to any other category. 4 Pedestrian (220, 20, 60) Humans that walk or ride/drive any kind of vehicle or mobility system. E.g. bicycles or scooters, skateboards, horses, roller-blades, wheel-chairs, etc. 5 Pole (153, 153, 153) Small mainly vertically oriented pole. If the pole has a horizontal part (often for traffic light poles) this is also considered pole. E.g. sign pole, traffic light poles. 6 RoadLine (157, 234, 50) The markings on the road. 7 Road (128, 64, 128) Part of ground on which cars usually drive. E.g. lanes in any directions, and streets. 8 SideWalk (244, 35, 232) Part of ground designated for pedestrians or cyclists. Delimited from the road by some obstacle (such as curbs or poles), not only by markings. This label includes a possibly delimiting curb, traffic islands (the walkable part), and pedestrian zones. 9 Vegetation (107, 142, 35) Trees, hedges, all kinds of vertical vegetation. Ground-level vegetation is considered Terrain . 10 Vehicles (0, 0, 142) Cars, vans, trucks, motorcycles, bikes, buses, trains. 11 Wall (102, 102, 156) Individual standing walls. Not part of a building. 12 TrafficSign (220, 220, 0) Signs installed by the state/city authority, usually for traffic regulation. This category does not include the poles where signs are attached to. E.g. traffic- signs, parking signs, direction signs... 13 Sky (70, 130, 180) Open sky. Includes clouds and the sun. 14 Ground (81, 0, 81) Any horizontal ground-level structures that does not match any other category. For example areas shared by vehicles and pedestrians, or flat roundabouts delimited from the road by a curb. 15 Bridge (150, 100, 100) Only the structure of the bridge. Fences, people, vehicles, an other elements on top of it are labeled separately. 16 RailTrack (230, 150, 140) All kind of rail tracks that are non-drivable by cars. E.g. subway and train rail tracks. 17 GuardRail (180, 165, 180) All types of guard rails/crash barriers. 18 TrafficLight (250, 170, 30) Traffic light boxes without their poles. 19 Static (110, 190, 160) Elements in the scene and props that are immovable. E.g. fire hydrants, fixed benches, fountains, bus stops, etc. 20 Dynamic (170, 120, 50) Elements whose position is susceptible to change over time. E.g. Movable trash bins, buggies, bags, wheelchairs, animals, etc. 21 Water (45, 60, 150) Horizontal water surfaces. E.g. Lakes, sea, rivers. 22 Terrain (145, 170, 100) Grass, ground-level vegetation, soil or sand. These areas are not meant to be driven on. This label includes a possibly delimiting curb. Note Read this tutorial to create new semantic tags. Basic camera attributes Blueprint attribute Type Default Description fov float 90.0 Horizontal field of view in degrees. image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). Camera lens distortion attributes Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0] Output attributes Sensor data attribute Type Description fov float Horizontal field of view in degrees. frame int Frame number when the measurement took place. height int Image height in pixels. raw_data bytes Array of BGRA 32-bit pixels. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels. DVS camera Blueprint: sensor.camera.dvs Output: carla.DVSEventArray per step (unless sensor_tick says otherwise). A Dynamic Vision Sensor (DVS) or Event camera is a sensor that works radically differently from a conventional camera. Instead of capturing intensity images at a fixed rate, event cameras measure changes of intensity asynchronously, in the form of a stream of events, which encode per-pixel brightness changes. Event cameras possess distinct properties when compared to standard cameras. They have a very high dynamic range (140 dB versus 60 dB), no motion blur, and high temporal resolution (in the order of microseconds). Event cameras are thus sensors that can provide high-quality visual information even in challenging high-speed scenarios and high dynamic range environments, enabling new application domains for vision-based algorithms. The DVS camera outputs a stream of events. An event e=(x,y,t,pol) is triggered at a pixel x , y at a timestamp t when the change in logarithmic intensity L reaches a predefined constant threshold C (typically between 15% and 30%). L(x,y,t) - L(x,y,t-\\delta t) = pol C t-\\delta t is the time when the last event at that pixel was triggered and pol is the polarity of the event according to the sign of the brightness change. The polarity is positive +1 when there is increment in brightness and negative -1 when a decrement in brightness occurs. The working principles depicted in the following figure. The standard camera outputs frames at a fixed rate, thus sending redundant information when no motion is present in the scene. In contrast, event cameras are data-driven sensors that respond to brightness changes with microsecond latency. At the plot, a positive (resp. negative) event (blue dot, resp. red dot) is generated whenever the (signed) brightness change exceeds the contrast threshold C for one dimension x over time t . Observe how the event rate grows when the signal changes rapidly. The current implementation of the DVS camera works in a uniform sampling manner between two consecutive synchronous frames. Therefore, in order to emulate the high temporal resolution (order of microseconds) of a real event camera, the sensor requires to execute at a high frequency (much higher frequency than a conventional camera). Effectively, the number of events increases the faster a CARLA car drives. Therefore, the sensor frequency should increase accordingly with the dynamics of the scene. The user should find a balance between time accuracy and computational cost. The provided script manual_control.py uses the DVS camera in order to show how to configure the sensor, how to get the stream of events and how to depict such events in an image format, usually called event frame. Note that due to the sampling method of the DVS camera, if there is no pixel difference between two consecutive synchronous frames the camera will not return an image. This will always occur in the first frame, as there is no previous frame to compare to and also in the event that there has been no movement between frames. DVS is a camera and therefore has all the attributes available in the RGB camera. Nevertheless, there are few attributes exclusive to the working principle of an Event camera. DVS camera attributes Blueprint attribute Type Default Description positive_threshold float 0.3 Positive threshold C associated to a increment in brightness change (0-1). negative_threshold float 0.3 Negative threshold C associated to a decrement in brightness change (0-1). sigma_positive_threshold float 0 White noise standard deviation for positive events (0-1). sigma_negative_threshold float 0 White noise standard deviation for negative events (0-1). refractory_period_ns int 0.0 Refractory period (time during which a pixel cannot fire events just after it fired one), in nanoseconds. It limits the highest frequency of triggering events. use_log bool true Whether to work in the logarithmic intensity scale. log_eps float 0.001 Epsilon value used to convert images to log: L = log(eps + I / 255.0) . Where I is the grayscale value of the RGB image: I = 0.2989*R + 0.5870*G + 0.1140*B . Optical Flow Camera The Optical Flow camera captures the motion perceived from the point of view of the camera. Every pixel recorded by this sensor encodes the velocity of that point projected to the image plane. The velocity of a pixel is encoded in the range [-2,2]. To obtain the motion in pixel units, this information can be scaled with the image size to [-2 * image_size, 2 * image_size]. Optical Flow camera attributes Blueprint attribute Type Default Description image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. fov float 90.0 Horizontal field of view in degrees. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). Optical Flow camera lens distortion attributes Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0] Output attributes Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels. height int Image height in pixels. fov float Horizontal field of view in degrees. raw_data bytes Array of BGRA 64-bit pixels containing two float values.","title":"Sensors reference"},{"location":"ref_sensors/#sensors-reference","text":"Collision detector Depth camera GNSS sensor IMU sensor Lane invasion detector LIDAR sensor Obstacle detector Radar sensor RGB camera RSS sensor Semantic LIDAR sensor Semantic segmentation camera DVS camera Optical Flow camera Important All the sensors use the UE coordinate system ( x - forward , y - right , z - up ), and return coordinates in local space. When using any visualization software, pay attention to its coordinate system. Many invert the Y-axis, so visualizing the sensor data directly may result in mirrored outputs.","title":"Sensors reference"},{"location":"ref_sensors/#collision-detector","text":"Blueprint: sensor.other.collision Output: carla.CollisionEvent per collision. This sensor registers an event each time its parent actor collisions against something in the world. Several collisions may be detected during a single simulation step. To ensure that collisions with any kind of object are detected, the server creates \"fake\" actors for elements such as buildings or bushes so the semantic tag can be retrieved to identify it. Collision detectors do not have any configurable attribute.","title":"Collision detector"},{"location":"ref_sensors/#output-attributes","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. actor carla.Actor Actor that measured the collision (sensor's parent). other_actor carla.Actor Actor against whom the parent collided. normal_impulse carla.Vector3D Normal impulse result of the collision.","title":"Output attributes"},{"location":"ref_sensors/#depth-camera","text":"Blueprint: sensor.camera.depth Output: carla.Image per step (unless sensor_tick says otherwise). The camera provides a raw data of the scene codifying the distance of each pixel to the camera (also known as depth buffer or z-buffer ) to create a depth map of the elements. The image codifies depth value per pixel using 3 channels of the RGB color space, from less to more significant bytes: R -> G -> B . The actual distance in meters can be decoded with: normalized = (R + G * 256 + B * 256 * 256) / (256 * 256 * 256 - 1) in_meters = 1000 * normalized The output carla.Image should then be saved to disk using a carla.colorConverter that will turn the distance stored in RGB channels into a [0,1] float containing the distance and then translate this to grayscale. There are two options in carla.colorConverter to get a depth view: Depth and Logaritmic depth . The precision is milimetric in both, but the logarithmic approach provides better results for closer objects. ... raw_image.save_to_disk(\"path/to/save/converted/image\",carla.Depth)","title":"Depth camera"},{"location":"ref_sensors/#basic-camera-attributes","text":"Blueprint attribute Type Default Description image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. fov float 90.0 Horizontal field of view in degrees. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks).","title":"Basic camera attributes"},{"location":"ref_sensors/#camera-lens-distortion-attributes","text":"Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0]","title":"Camera lens distortion attributes"},{"location":"ref_sensors/#output-attributes_1","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels. height int Image height in pixels. fov float Horizontal field of view in degrees. raw_data bytes Array of BGRA 32-bit pixels.","title":"Output attributes"},{"location":"ref_sensors/#gnss-sensor","text":"Blueprint: sensor.other.gnss Output: carla.GNSSMeasurement per step (unless sensor_tick says otherwise). Reports current gnss position of its parent object. This is calculated by adding the metric position to an initial geo reference location defined within the OpenDRIVE map definition.","title":"GNSS sensor"},{"location":"ref_sensors/#gnss-attributes","text":"Blueprint attribute Type Default Description noise_alt_bias float 0.0 Mean parameter in the noise model for altitude. noise_alt_stddev float 0.0 Standard deviation parameter in the noise model for altitude. noise_lat_bias float 0.0 Mean parameter in the noise model for latitude. noise_lat_stddev float 0.0 Standard deviation parameter in the noise model for latitude. noise_lon_bias float 0.0 Mean parameter in the noise model for longitude. noise_lon_stddev float 0.0 Standard deviation parameter in the noise model for longitude. noise_seed int 0 Initializer for a pseudorandom number generator. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks).","title":"GNSS attributes"},{"location":"ref_sensors/#output-attributes_2","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. latitude double Latitude of the actor. longitude double Longitude of the actor. altitude double Altitude of the actor.","title":"Output attributes"},{"location":"ref_sensors/#imu-sensor","text":"Blueprint: sensor.other.imu Output: carla.IMUMeasurement per step (unless sensor_tick says otherwise). Provides measures that accelerometer, gyroscope and compass would retrieve for the parent object. The data is collected from the object's current state.","title":"IMU sensor"},{"location":"ref_sensors/#imu-attributes","text":"Blueprint attribute Type Default Description noise_accel_stddev_x float 0.0 Standard deviation parameter in the noise model for acceleration (X axis). noise_accel_stddev_y float 0.0 Standard deviation parameter in the noise model for acceleration (Y axis). noise_accel_stddev_z float 0.0 Standard deviation parameter in the noise model for acceleration (Z axis). noise_gyro_bias_x float 0.0 Mean parameter in the noise model for the gyroscope (X axis). noise_gyro_bias_y float 0.0 Mean parameter in the noise model for the gyroscope (Y axis). noise_gyro_bias_z float 0.0 Mean parameter in the noise model for the gyroscope (Z axis). noise_gyro_stddev_x float 0.0 Standard deviation parameter in the noise model for the gyroscope (X axis). noise_gyro_stddev_y float 0.0 Standard deviation parameter in the noise model for the gyroscope (Y axis). noise_gyro_stddev_z float 0.0 Standard deviation parameter in the noise model for the gyroscope (Z axis). noise_seed int 0 Initializer for a pseudorandom number generator. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks).","title":"IMU attributes"},{"location":"ref_sensors/#output-attributes_3","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. accelerometer carla.Vector3D Measures linear acceleration in m/s^2 . gyroscope carla.Vector3D Measures angular velocity in rad/sec . compass float Orientation in radians. North is (0.0, -1.0, 0.0) in UE.","title":"Output attributes"},{"location":"ref_sensors/#lane-invasion-detector","text":"Blueprint: sensor.other.lane_invasion Output: carla.LaneInvasionEvent per crossing. Registers an event each time its parent crosses a lane marking. The sensor uses road data provided by the OpenDRIVE description of the map to determine whether the parent vehicle is invading another lane by considering the space between wheels. However there are some things to be taken into consideration: Discrepancies between the OpenDRIVE file and the map will create irregularities such as crossing lanes that are not visible in the map. The output retrieves a list of crossed lane markings: the computation is done in OpenDRIVE and considering the whole space between the four wheels as a whole. Thus, there may be more than one lane being crossed at the same time. This sensor does not have any configurable attribute. Important This sensor works fully on the client-side.","title":"Lane invasion detector"},{"location":"ref_sensors/#output-attributes_4","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. actor carla.Actor Vehicle that invaded another lane (parent actor). crossed_lane_markings list( carla.LaneMarking ) List of lane markings that have been crossed.","title":"Output attributes"},{"location":"ref_sensors/#lidar-sensor","text":"Blueprint: sensor.lidar.ray_cast Output: carla.LidarMeasurement per step (unless sensor_tick says otherwise). This sensor simulates a rotating LIDAR implemented using ray-casting. The points are computed by adding a laser for each channel distributed in the vertical FOV. The rotation is simulated computing the horizontal angle that the Lidar rotated in a frame. The point cloud is calculated by doing a ray-cast for each laser in every step. points_per_channel_each_step = points_per_second / (FPS * channels) A LIDAR measurement contains a package with all the points generated during a 1/FPS interval. During this interval the physics are not updated so all the points in a measurement reflect the same \"static picture\" of the scene. This output contains a cloud of simulation points and thus, it can be iterated to retrieve a list of their carla.Location : for location in lidar_measurement: print(location) The information of the LIDAR measurement is enconded 4D points. Being the first three, the space points in xyz coordinates and the last one intensity loss during the travel. This intensity is computed by the following formula. a \u2014 Attenuation coefficient. This may depend on the sensor's wavelenght, and the conditions of the atmosphere. It can be modified with the LIDAR attribute atmosphere_attenuation_rate . d \u2014 Distance from the hit point to the sensor. For a better realism, points in the cloud can be dropped off. This is an easy way to simulate loss due to external perturbations. This can done combining two different. General drop-off \u2014 Proportion of points that are dropped off randomly. This is done before the tracing, meaning the points being dropped are not calculated, and therefore improves the performance. If dropoff_general_rate = 0.5 , half of the points will be dropped. Instensity-based drop-off \u2014 For each point detected, and extra drop-off is performed with a probability based in the computed intensity. This probability is determined by two parameters. dropoff_zero_intensity is the probability of points with zero intensity to be dropped. dropoff_intensity_limit is a threshold intensity above which no points will be dropped. The probability of a point within the range to be dropped is a linear proportion based on these two parameters. Additionally, the noise_stddev attribute makes for a noise model to simulate unexpected deviations that appear in real-life sensors. For positive values, each point is randomly perturbed along the vector of the laser ray. The result is a LIDAR sensor with perfect angular positioning, but noisy distance measurement. The rotation of the LIDAR can be tuned to cover a specific angle on every simulation step (using a fixed time-step ). For example, to rotate once per step (full circle output, as in the picture below), the rotation frequency and the simulated FPS should be equal. 1. Set the sensor's frequency sensors_bp['lidar'][0].set_attribute('rotation_frequency','10') . 2. Run the simulation using python3 config.py --fps=10 .","title":"LIDAR sensor"},{"location":"ref_sensors/#lidar-attributes","text":"Blueprint attribute Type Default Description channels int 32 Number of lasers. range float 10.0 Maximum distance to measure/raycast in meters (centimeters for CARLA 0.9.6 or previous). points_per_second int 56000 Points generated by all lasers per second. rotation_frequency float 10.0 LIDAR rotation frequency. upper_fov float 10.0 Angle in degrees of the highest laser. lower_fov float -30.0 Angle in degrees of the lowest laser. horizontal_fov float 360.0 Horizontal field of view in degrees, 0 - 360. atmosphere_attenuation_rate float 0.004 Coefficient that measures the LIDAR instensity loss per meter. Check the intensity computation above. dropoff_general_rate float 0.45 General proportion of points that are randomy dropped. dropoff_intensity_limit float 0.8 For the intensity based drop-off, the threshold intensity value above which no points are dropped. dropoff_zero_intensity float 0.4 For the intensity based drop-off, the probability of each point with zero intensity being dropped. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). noise_stddev float 0.0 Standard deviation of the noise model to disturb each point along the vector of its raycast.","title":"Lidar attributes"},{"location":"ref_sensors/#output-attributes_5","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. horizontal_angle float Angle (radians) in the XY plane of the LIDAR in the current frame. channels int Number of channels (lasers) of the LIDAR. get_point_count(channel) int Number of points per channel captured this frame. raw_data bytes Array of 32-bits floats (XYZI of each point).","title":"Output attributes"},{"location":"ref_sensors/#obstacle-detector","text":"Blueprint: sensor.other.obstacle Output: carla.ObstacleDetectionEvent per obstacle (unless sensor_tick says otherwise). Registers an event every time the parent actor has an obstacle ahead. In order to anticipate obstacles, the sensor creates a capsular shape ahead of the parent vehicle and uses it to check for collisions. To ensure that collisions with any kind of object are detected, the server creates \"fake\" actors for elements such as buildings or bushes so the semantic tag can be retrieved to identify it. Blueprint attribute Type Default Description distance float 5 Distance to trace. hit_radius float 0.5 Radius of the trace. only_dynamics bool False If true, the trace will only consider dynamic objects. debug_linetrace bool False If true, the trace will be visible. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks).","title":"Obstacle detector"},{"location":"ref_sensors/#output-attributes_6","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. actor carla.Actor Actor that detected the obstacle (parent actor). other_actor carla.Actor Actor detected as an obstacle. distance float Distance from actor to other_actor .","title":"Output attributes"},{"location":"ref_sensors/#radar-sensor","text":"Blueprint: sensor.other.radar Output: carla.RadarMeasurement per step (unless sensor_tick says otherwise). The sensor creates a conic view that is translated to a 2D point map of the elements in sight and their speed regarding the sensor. This can be used to shape elements and evaluate their movement and direction. Due to the use of polar coordinates, the points will concentrate around the center of the view. Points measured are contained in carla.RadarMeasurement as an array of carla.RadarDetection , which specifies their polar coordinates, distance and velocity. This raw data provided by the radar sensor can be easily converted to a format manageable by numpy : # To get a numpy [[vel, azimuth, altitude, depth],...[,,,]]: points = np.frombuffer(radar_data.raw_data, dtype=np.dtype('f4')) points = np.reshape(points, (len(radar_data), 4)) The provided script manual_control.py uses this sensor to show the points being detected and paint them white when static, red when moving towards the object and blue when moving away: Blueprint attribute Type Default Description horizontal_fov float 30.0 Horizontal field of view in degrees. points_per_second int 1500 Points generated by all lasers per second. range float 100 Maximum distance to measure/raycast in meters. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). vertical_fov float 30.0 Vertical field of view in degrees.","title":"Radar sensor"},{"location":"ref_sensors/#output-attributes_7","text":"Sensor data attribute Type Description raw_data carla.RadarDetection The list of points detected. RadarDetection attributes Type Description altitude float Altitude angle in radians. azimuth float Azimuth angle in radians. depth float Distance in meters. velocity float Velocity towards the sensor.","title":"Output attributes"},{"location":"ref_sensors/#rgb-camera","text":"Blueprint: sensor.camera.rgb Output: carla.Image per step (unless sensor_tick says otherwise).. The \"RGB\" camera acts as a regular camera capturing images from the scene. carla.colorConverter If enable_postprocess_effects is enabled, a set of post-process effects is applied to the image for the sake of realism: Vignette: darkens the border of the screen. Grain jitter: adds some noise to the render. Bloom: intense lights burn the area around them. Auto exposure: modifies the image gamma to simulate the eye adaptation to darker or brighter areas. Lens flares: simulates the reflection of bright objects on the lens. Depth of field: blurs objects near or very far away of the camera. The sensor_tick tells how fast we want the sensor to capture the data. A value of 1.5 means that we want the sensor to capture data each second and a half. By default a value of 0.0 means as fast as possible.","title":"RGB camera"},{"location":"ref_sensors/#basic-camera-attributes_1","text":"Blueprint attribute Type Default Description bloom_intensity float 0.675 Intensity for the bloom post-process effect, 0.0 for disabling it. fov float 90.0 Horizontal field of view in degrees. fstop float 1.4 Opening of the camera lens. Aperture is 1/fstop with typical lens going down to f/1.2 (larger opening). Larger numbers will reduce the Depth of Field effect. image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. iso float 100.0 The camera sensor sensitivity. gamma float 2.2 Target gamma value of the camera. lens_flare_intensity float 0.1 Intensity for the lens flare post-process effect, 0.0 for disabling it. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks). shutter_speed float 200.0 The camera shutter speed in seconds (1.0/s).","title":"Basic camera attributes"},{"location":"ref_sensors/#camera-lens-distortion-attributes_1","text":"Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0]","title":"Camera lens distortion attributes"},{"location":"ref_sensors/#advanced-camera-attributes","text":"Since these effects are provided by UE, please make sure to check their documentation: Automatic Exposure Cinematic Depth of Field Method Color Grading and Filmic Tonemapper Blueprint attribute Type Default Description min_fstop float 1.2 Maximum aperture. blade_count int 5 Number of blades that make up the diaphragm mechanism. exposure_mode str histogram Can be manual or histogram . More in UE4 docs . exposure_compensation float Linux: +0.75 Windows: 0.0 Logarithmic adjustment for the exposure. 0: no adjustment, -1:2x darker, -2:4 darker, 1:2x brighter, 2:4x brighter. exposure_min_bright float 10.0 In exposure_mode: \"histogram\" . Minimum brightness for auto exposure. The lowest the eye can adapt within. Must be greater than 0 and less than or equal to exposure_max_bright . exposure_max_bright float 12.0 In `exposure_mode: \"histogram\"`. Maximum brightness for auto exposure. The highestthe eye can adapt within. Must be greater than 0 and greater than or equal to `exposure_min_bright`. exposure_speed_up float 3.0 In exposure_mode: \"histogram\" . Speed at which the adaptation occurs from dark to bright environment. exposure_speed_down float 1.0 In exposure_mode: \"histogram\" . Speed at which the adaptation occurs from bright to dark environment. calibration_constant float 16.0 Calibration constant for 18% albedo. focal_distance float 1000.0 Distance at which the depth of field effect should be sharp. Measured in cm (UE units). blur_amount float 1.0 Strength/intensity of motion blur. blur_radius float 0.0 Radius in pixels at 1080p resolution to emulate atmospheric scattering according to distance from camera. motion_blur_intensity float 0.45 Strength of motion blur [0,1]. motion_blur_max_distortion float 0.35 Max distortion caused by motion blur. Percentage of screen width. motion_blur_min_object_screen_size float 0.1 Percentage of screen width objects must have for motion blur, lower value means less draw calls. slope float 0.88 Steepness of the S-curve for the tonemapper. Larger values make the slope steeper (darker) [0.0, 1.0]. toe float 0.55 Adjusts dark color in the tonemapper [0.0, 1.0]. shoulder float 0.26 Adjusts bright color in the tonemapper [0.0, 1.0]. black_clip float 0.0 This should NOT be adjusted. Sets where the crossover happens and black tones start to cut off their value [0.0, 1.0]. white_clip float 0.04 Set where the crossover happens and white tones start to cut off their value. Subtle change in most cases [0.0, 1.0]. temp float 6500.0 White balance in relation to the temperature of the light in the scene. White light: when this matches light temperature. Warm light: When higher than the light in the scene, it is a yellowish color. Cool light: When lower than the light. Blueish color. tint float 0.0 White balance temperature tint. Adjusts cyan and magenta color ranges. This should be used along with the white balance Temp property to get accurate colors. Under some light temperatures, the colors may appear to be more yellow or blue. This can be used to balance the resulting color to look more natural. chromatic_aberration_intensity float 0.0 Scaling factor to control color shifting, more noticeable on the screen borders. chromatic_aberration_offset float 0.0 Normalized distance to the center of the image where the effect takes place. enable_postprocess_effects bool True Post-process effects activation.","title":"Advanced camera attributes"},{"location":"ref_sensors/#output-attributes_8","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels. height int Image height in pixels. fov float Horizontal field of view in degrees. raw_data bytes Array of BGRA 32-bit pixels.","title":"Output attributes"},{"location":"ref_sensors/#rss-sensor","text":"Blueprint: sensor.other.rss Output: carla.RssResponse per step (unless sensor_tick says otherwise). Important It is highly recommended to read the specific rss documentation before reading this. This sensor integrates the C++ Library for Responsibility Sensitive Safety in CARLA. It is disabled by default in CARLA, and it has to be explicitly built in order to be used. The RSS sensor calculates the RSS state of a vehicle and retrieves the current RSS Response as sensor data. The carla.RssRestrictor will use this data to adapt a carla.VehicleControl before applying it to a vehicle. These controllers can be generated by an Automated Driving stack or user input. For instance, hereunder there is a fragment of code from PythonAPI/examples/rss/manual_control_rss.py , where the user input is modified using RSS when necessary. 1. Checks if the RssSensor generates a valid response containing restrictions. 2. Gathers the current dynamics of the vehicle and the vehicle physics. 3. Applies restrictions to the vehicle control using the response from the RssSensor, and the current dynamics and physicis of the vehicle. rss_proper_response = self._world.rss_sensor.proper_response if self._world.rss_sensor and self._world.rss_sensor.response_valid else None if rss_proper_response: ... vehicle_control = self._restrictor.restrict_vehicle_control( vehicle_control, rss_proper_response, self._world.rss_sensor.ego_dynamics_on_route, self._vehicle_physics)","title":"RSS sensor"},{"location":"ref_sensors/#the-carlarsssensor-class","text":"The blueprint for this sensor has no modifiable attributes. However, the carla.RssSensor object that it instantiates has attributes and methods that are detailed in the Python API reference. Here is a summary of them. carla.RssSensor variables Type Description ego_vehicle_dynamics ad.rss.world.RssDynamics RSS parameters to be applied for the ego vehicle other_vehicle_dynamics ad.rss.world.RssDynamics RSS parameters to be applied for the other vehicles pedestrian_dynamics ad.rss.world.RssDynamics RSS parameters to be applied for pedestrians road_boundaries_mode carla.RssRoadBoundariesMode Enables/Disables the stay on road feature. Default is Off . # Fragment of rss_sensor.py # The carla.RssSensor is updated when listening for a new carla.RssResponse def _on_rss_response(weak_self, response): ... self.timestamp = response.timestamp self.response_valid = response.response_valid self.proper_response = response.proper_response self.ego_dynamics_on_route = response.ego_dynamics_on_route self.rss_state_snapshot = response.rss_state_snapshot self.situation_snapshot = response.situation_snapshot self.world_model = response.world_model Warning This sensor works fully on the client side. There is no blueprint in the server. Changes on the attributes will have effect after the listen() has been called. The methods available in this class are related to the routing of the vehicle. RSS calculations are always based on a route of the ego vehicle through the road network. The sensor allows to control the considered route by providing some key points, which could be the carla.Transform in a carla.Waypoint . These points are best selected after the intersections to force the route to take the desired turn. carla.RssSensor methods Description routing_targets Get the current list of routing targets used for route. append_routing_target Append an additional position to the current routing targets. reset_routing_targets Deletes the appended routing targets. drop_route Discards the current route and creates a new one. register_actor_constellation_callback Register a callback to customize the calculations. set_log_level Sets the log level. set_map_log_level Sets the log level used for map related logs. # Update the current route self.sensor.reset_routing_targets() if routing_targets: for target in routing_targets: self.sensor.append_routing_target(target) Note If no routing targets are defined, a random route is created.","title":"The carla.RssSensor class"},{"location":"ref_sensors/#output-attributes_9","text":"carla.RssResponse attributes Type Description response_valid bool Validity of the response data. proper_response ad.rss.state.ProperResponse Proper response that the RSS calculated for the vehicle including acceleration restrictions. rss_state_snapshot ad.rss.state.RssStateSnapshot RSS states at the current point in time. This is the detailed individual output of the RSS calclulations. situation_snapshot ad.rss.situation.SituationSnapshot RSS situation at the current point in time. This is the processed input data for the RSS calclulations. world_model ad.rss.world.WorldModel RSS world model at the current point in time. This is the input data for the RSS calculations. ego_dynamics_on_route carla.RssEgoDynamicsOnRoute Current ego vehicle dynamics regarding the route. In case a actor_constellation_callback is registered, a call is triggered for: default calculation ( actor_constellation_data.other_actor=None ) per-actor calculation # Fragment of rss_sensor.py # The function is registered as actor_constellation_callback def _on_actor_constellation_request(self, actor_constellation_data): actor_constellation_result = carla.RssActorConstellationResult() actor_constellation_result.rss_calculation_mode = ad.rss.map.RssMode.NotRelevant actor_constellation_result.restrict_speed_limit_mode = ad.rss.map.RssSceneCreation.RestrictSpeedLimitMode.IncreasedSpeedLimit10 actor_constellation_result.ego_vehicle_dynamics = self.current_vehicle_parameters actor_constellation_result.actor_object_type = ad.rss.world.ObjectType.Invalid actor_constellation_result.actor_dynamics = self.current_vehicle_parameters actor_id = -1 actor_type_id = \"none\" if actor_constellation_data.other_actor != None: # customize actor_constellation_result for specific actor ... else: # default ... return actor_constellation_result","title":"Output attributes"},{"location":"ref_sensors/#semantic-lidar-sensor","text":"Blueprint: sensor.lidar.ray_cast_semantic Output: carla.SemanticLidarMeasurement per step (unless sensor_tick says otherwise). This sensor simulates a rotating LIDAR implemented using ray-casting that exposes all the information about the raycast hit. Its behaviour is quite similar to the LIDAR sensor , but there are two main differences between them. The raw data retrieved by the semantic LIDAR includes more data per point. Coordinates of the point (as the normal LIDAR does). The cosine between the angle of incidence and the normal of the surface hit. Instance and semantic ground-truth. Basically the index of the CARLA object hit, and its semantic tag. The semantic LIDAR does not include neither intensity, drop-off nor noise model attributes. The points are computed by adding a laser for each channel distributed in the vertical FOV. The rotation is simulated computing the horizontal angle that the LIDAR rotated in a frame. The point cloud is calculated by doing a ray-cast for each laser in every step. points_per_channel_each_step = points_per_second / (FPS * channels) A LIDAR measurement contains a package with all the points generated during a 1/FPS interval. During this interval the physics are not updated so all the points in a measurement reflect the same \"static picture\" of the scene. This output contains a cloud of lidar semantic detections and therefore, it can be iterated to retrieve a list of their carla.SemanticLidarDetection : for detection in semantic_lidar_measurement: print(detection) The rotation of the LIDAR can be tuned to cover a specific angle on every simulation step (using a fixed time-step ). For example, to rotate once per step (full circle output, as in the picture below), the rotation frequency and the simulated FPS should be equal. 1. Set the sensor's frequency sensors_bp['lidar'][0].set_attribute('rotation_frequency','10') . 2. Run the simulation using python3 config.py --fps=10 .","title":"Semantic LIDAR sensor"},{"location":"ref_sensors/#semanticlidar-attributes","text":"Blueprint attribute Type Default Description channels int 32 Number of lasers. range float 10.0 Maximum distance to measure/raycast in meters (centimeters for CARLA 0.9.6 or previous). points_per_second int 56000 Points generated by all lasers per second. rotation_frequency float 10.0 LIDAR rotation frequency. upper_fov float 10.0 Angle in degrees of the highest laser. lower_fov float -30.0 Angle in degrees of the lowest laser. horizontal_fov float 360.0 Horizontal field of view in degrees, 0 - 360. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks).","title":"SemanticLidar attributes"},{"location":"ref_sensors/#output-attributes_10","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. horizontal_angle float Angle (radians) in the XY plane of the LIDAR in the current frame. channels int Number of channels (lasers) of the LIDAR. get_point_count(channel) int Number of points per channel captured in the current frame. raw_data bytes Array containing the point cloud with instance and semantic information. For each point, four 32-bits floats are stored. XYZ coordinates. cosine of the incident angle. Unsigned int containing the index of the object hit. Unsigned int containing the semantic tag of the object it.","title":"Output attributes"},{"location":"ref_sensors/#semantic-segmentation-camera","text":"Blueprint: sensor.camera.semantic_segmentation Output: carla.Image per step (unless sensor_tick says otherwise). This camera classifies every object in sight by displaying it in a different color according to its tags (e.g., pedestrians in a different color than vehicles). When the simulation starts, every element in scene is created with a tag. So it happens when an actor is spawned. The objects are classified by their relative file path in the project. For example, meshes stored in Unreal/CarlaUE4/Content/Static/Pedestrians are tagged as Pedestrian . The server provides an image with the tag information encoded in the red channel : A pixel with a red value of x belongs to an object with tag x . This raw carla.Image can be stored and converted it with the help of CityScapesPalette in carla.ColorConverter to apply the tags information and show picture with the semantic segmentation. ... raw_image.save_to_disk(\"path/to/save/converted/image\",carla.cityScapesPalette) The following tags are currently available: Value Tag Converted color Description 0 Unlabeled (0, 0, 0) Elements that have not been categorized are considered Unlabeled . This category is meant to be empty or at least contain elements with no collisions. 1 Building (70, 70, 70) Buildings like houses, skyscrapers,... and the elements attached to them. E.g. air conditioners, scaffolding, awning or ladders and much more. 2 Fence (100, 40, 40) Barriers, railing, or other upright structures. Basically wood or wire assemblies that enclose an area of ground. 3 Other (55, 90, 80) Everything that does not belong to any other category. 4 Pedestrian (220, 20, 60) Humans that walk or ride/drive any kind of vehicle or mobility system. E.g. bicycles or scooters, skateboards, horses, roller-blades, wheel-chairs, etc. 5 Pole (153, 153, 153) Small mainly vertically oriented pole. If the pole has a horizontal part (often for traffic light poles) this is also considered pole. E.g. sign pole, traffic light poles. 6 RoadLine (157, 234, 50) The markings on the road. 7 Road (128, 64, 128) Part of ground on which cars usually drive. E.g. lanes in any directions, and streets. 8 SideWalk (244, 35, 232) Part of ground designated for pedestrians or cyclists. Delimited from the road by some obstacle (such as curbs or poles), not only by markings. This label includes a possibly delimiting curb, traffic islands (the walkable part), and pedestrian zones. 9 Vegetation (107, 142, 35) Trees, hedges, all kinds of vertical vegetation. Ground-level vegetation is considered Terrain . 10 Vehicles (0, 0, 142) Cars, vans, trucks, motorcycles, bikes, buses, trains. 11 Wall (102, 102, 156) Individual standing walls. Not part of a building. 12 TrafficSign (220, 220, 0) Signs installed by the state/city authority, usually for traffic regulation. This category does not include the poles where signs are attached to. E.g. traffic- signs, parking signs, direction signs... 13 Sky (70, 130, 180) Open sky. Includes clouds and the sun. 14 Ground (81, 0, 81) Any horizontal ground-level structures that does not match any other category. For example areas shared by vehicles and pedestrians, or flat roundabouts delimited from the road by a curb. 15 Bridge (150, 100, 100) Only the structure of the bridge. Fences, people, vehicles, an other elements on top of it are labeled separately. 16 RailTrack (230, 150, 140) All kind of rail tracks that are non-drivable by cars. E.g. subway and train rail tracks. 17 GuardRail (180, 165, 180) All types of guard rails/crash barriers. 18 TrafficLight (250, 170, 30) Traffic light boxes without their poles. 19 Static (110, 190, 160) Elements in the scene and props that are immovable. E.g. fire hydrants, fixed benches, fountains, bus stops, etc. 20 Dynamic (170, 120, 50) Elements whose position is susceptible to change over time. E.g. Movable trash bins, buggies, bags, wheelchairs, animals, etc. 21 Water (45, 60, 150) Horizontal water surfaces. E.g. Lakes, sea, rivers. 22 Terrain (145, 170, 100) Grass, ground-level vegetation, soil or sand. These areas are not meant to be driven on. This label includes a possibly delimiting curb. Note Read this tutorial to create new semantic tags.","title":"Semantic segmentation camera"},{"location":"ref_sensors/#basic-camera-attributes_2","text":"Blueprint attribute Type Default Description fov float 90.0 Horizontal field of view in degrees. image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks).","title":"Basic camera attributes"},{"location":"ref_sensors/#camera-lens-distortion-attributes_2","text":"Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0]","title":"Camera lens distortion attributes"},{"location":"ref_sensors/#output-attributes_11","text":"Sensor data attribute Type Description fov float Horizontal field of view in degrees. frame int Frame number when the measurement took place. height int Image height in pixels. raw_data bytes Array of BGRA 32-bit pixels. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels.","title":"Output attributes"},{"location":"ref_sensors/#dvs-camera","text":"Blueprint: sensor.camera.dvs Output: carla.DVSEventArray per step (unless sensor_tick says otherwise). A Dynamic Vision Sensor (DVS) or Event camera is a sensor that works radically differently from a conventional camera. Instead of capturing intensity images at a fixed rate, event cameras measure changes of intensity asynchronously, in the form of a stream of events, which encode per-pixel brightness changes. Event cameras possess distinct properties when compared to standard cameras. They have a very high dynamic range (140 dB versus 60 dB), no motion blur, and high temporal resolution (in the order of microseconds). Event cameras are thus sensors that can provide high-quality visual information even in challenging high-speed scenarios and high dynamic range environments, enabling new application domains for vision-based algorithms. The DVS camera outputs a stream of events. An event e=(x,y,t,pol) is triggered at a pixel x , y at a timestamp t when the change in logarithmic intensity L reaches a predefined constant threshold C (typically between 15% and 30%). L(x,y,t) - L(x,y,t-\\delta t) = pol C t-\\delta t is the time when the last event at that pixel was triggered and pol is the polarity of the event according to the sign of the brightness change. The polarity is positive +1 when there is increment in brightness and negative -1 when a decrement in brightness occurs. The working principles depicted in the following figure. The standard camera outputs frames at a fixed rate, thus sending redundant information when no motion is present in the scene. In contrast, event cameras are data-driven sensors that respond to brightness changes with microsecond latency. At the plot, a positive (resp. negative) event (blue dot, resp. red dot) is generated whenever the (signed) brightness change exceeds the contrast threshold C for one dimension x over time t . Observe how the event rate grows when the signal changes rapidly. The current implementation of the DVS camera works in a uniform sampling manner between two consecutive synchronous frames. Therefore, in order to emulate the high temporal resolution (order of microseconds) of a real event camera, the sensor requires to execute at a high frequency (much higher frequency than a conventional camera). Effectively, the number of events increases the faster a CARLA car drives. Therefore, the sensor frequency should increase accordingly with the dynamics of the scene. The user should find a balance between time accuracy and computational cost. The provided script manual_control.py uses the DVS camera in order to show how to configure the sensor, how to get the stream of events and how to depict such events in an image format, usually called event frame. Note that due to the sampling method of the DVS camera, if there is no pixel difference between two consecutive synchronous frames the camera will not return an image. This will always occur in the first frame, as there is no previous frame to compare to and also in the event that there has been no movement between frames. DVS is a camera and therefore has all the attributes available in the RGB camera. Nevertheless, there are few attributes exclusive to the working principle of an Event camera.","title":"DVS camera"},{"location":"ref_sensors/#dvs-camera-attributes","text":"Blueprint attribute Type Default Description positive_threshold float 0.3 Positive threshold C associated to a increment in brightness change (0-1). negative_threshold float 0.3 Negative threshold C associated to a decrement in brightness change (0-1). sigma_positive_threshold float 0 White noise standard deviation for positive events (0-1). sigma_negative_threshold float 0 White noise standard deviation for negative events (0-1). refractory_period_ns int 0.0 Refractory period (time during which a pixel cannot fire events just after it fired one), in nanoseconds. It limits the highest frequency of triggering events. use_log bool true Whether to work in the logarithmic intensity scale. log_eps float 0.001 Epsilon value used to convert images to log: L = log(eps + I / 255.0) . Where I is the grayscale value of the RGB image: I = 0.2989*R + 0.5870*G + 0.1140*B .","title":"DVS camera attributes"},{"location":"ref_sensors/#optical-flow-camera","text":"The Optical Flow camera captures the motion perceived from the point of view of the camera. Every pixel recorded by this sensor encodes the velocity of that point projected to the image plane. The velocity of a pixel is encoded in the range [-2,2]. To obtain the motion in pixel units, this information can be scaled with the image size to [-2 * image_size, 2 * image_size].","title":"Optical Flow Camera"},{"location":"ref_sensors/#optical-flow-camera-attributes","text":"Blueprint attribute Type Default Description image_size_x int 800 Image width in pixels. image_size_y int 600 Image height in pixels. fov float 90.0 Horizontal field of view in degrees. sensor_tick float 0.0 Simulation seconds between sensor captures (ticks).","title":"Optical Flow camera attributes"},{"location":"ref_sensors/#optical-flow-camera-lens-distortion-attributes","text":"Blueprint attribute Type Default Description lens_circle_falloff float 5.0 Range: [0.0, 10.0] lens_circle_multiplier float 0.0 Range: [0.0, 10.0] lens_k float -1.0 Range: [-inf, inf] lens_kcube float 0.0 Range: [-inf, inf] lens_x_size float 0.08 Range: [0.0, 1.0] lens_y_size float 0.08 Range: [0.0, 1.0]","title":"Optical Flow camera lens distortion attributes"},{"location":"ref_sensors/#output-attributes_12","text":"Sensor data attribute Type Description frame int Frame number when the measurement took place. timestamp double Simulation time of the measurement in seconds since the beginning of the episode. transform carla.Transform Location and rotation in world coordinates of the sensor at the time of the measurement. width int Image width in pixels. height int Image height in pixels. fov float Horizontal field of view in degrees. raw_data bytes Array of BGRA 64-bit pixels containing two float values.","title":"Output attributes"},{"location":"release_readme/","text":"CARLA Simulator Thanks for downloading CARLA! http://carla.org/ How to run CARLA Launch a terminal in this folder and execute the simulator by running ./CarlaUE4.sh this will launch a window with a view over the city. This is the \"spectator\" view, you can fly around the city using the mouse and WASD keys, but you cannot interact with the world in this view. The simulator is now running as a server, waiting for a client app to connect and interact with the world. Let's start by adding some live to the city, open a new terminal window and execute ./generate_traffic.py -n 80 This adds 80 vehicles to the world driving in \"autopilot\" mode. Back to the simulator window we should see these vehicles driving around the city. They will keep driving randomly until we stop the script. Let's leave them there for now. Now, it's nice and sunny in CARLA, but that's not a very interesting driving condition. One of the cool features of CARLA is that you can control the weather and lighting conditions of the world. We'll launch now a script that dynamically controls the weather and time of the day, open yet another terminal window and execute ./dynamic_weather.py The city is now ready for us to drive, we can finally run ./manual_control.py This should open a new window with a 3rd person view of a car, you can drive this car with the WASD/arrow keys. Press 'h' to see all the options available. For more details and running options please refer to our online documentation http://carla.readthedocs.io","title":"Release readme"},{"location":"release_readme/#carla-simulator","text":"Thanks for downloading CARLA! http://carla.org/","title":"CARLA Simulator"},{"location":"release_readme/#how-to-run-carla","text":"Launch a terminal in this folder and execute the simulator by running ./CarlaUE4.sh this will launch a window with a view over the city. This is the \"spectator\" view, you can fly around the city using the mouse and WASD keys, but you cannot interact with the world in this view. The simulator is now running as a server, waiting for a client app to connect and interact with the world. Let's start by adding some live to the city, open a new terminal window and execute ./generate_traffic.py -n 80 This adds 80 vehicles to the world driving in \"autopilot\" mode. Back to the simulator window we should see these vehicles driving around the city. They will keep driving randomly until we stop the script. Let's leave them there for now. Now, it's nice and sunny in CARLA, but that's not a very interesting driving condition. One of the cool features of CARLA is that you can control the weather and lighting conditions of the world. We'll launch now a script that dynamically controls the weather and time of the day, open yet another terminal window and execute ./dynamic_weather.py The city is now ready for us to drive, we can finally run ./manual_control.py This should open a new window with a 3rd person view of a car, you can drive this car with the WASD/arrow keys. Press 'h' to see all the options available. For more details and running options please refer to our online documentation http://carla.readthedocs.io","title":"How to run CARLA"},{"location":"ros_documentation/","text":"ROS Bridge Full documentation of the ROS bridge is found here . The ROS bridge enables two-way communication between ROS and CARLA. The information from the CARLA server is translated to ROS topics. In the same way, the messages sent between nodes in ROS get translated to commands to be applied in CARLA. The ROS bridge is compatible with both ROS 1 and ROS 2. The ROS bridge boasts the following features: Provides sensor data for LIDAR, Semantic LIDAR, Cameras (depth, segmentation, rgb, dvs), GNSS, Radar and IMU. Provides object data such as transforms, traffic light status, visualisation markers, collision and lane invasion. Control of AD agents through steering, throttle and brake. Control of aspects of the CARLA simulation like synchronous mode, playing and pausing the simulation and setting simulation parameters.","title":"ROS \u6865\u6587\u6863"},{"location":"ros_documentation/#ros-bridge","text":"Full documentation of the ROS bridge is found here . The ROS bridge enables two-way communication between ROS and CARLA. The information from the CARLA server is translated to ROS topics. In the same way, the messages sent between nodes in ROS get translated to commands to be applied in CARLA. The ROS bridge is compatible with both ROS 1 and ROS 2. The ROS bridge boasts the following features: Provides sensor data for LIDAR, Semantic LIDAR, Cameras (depth, segmentation, rgb, dvs), GNSS, Radar and IMU. Provides object data such as transforms, traffic light status, visualisation markers, collision and lane invasion. Control of AD agents through steering, throttle and brake. Control of aspects of the CARLA simulation like synchronous mode, playing and pausing the simulation and setting simulation parameters.","title":"ROS Bridge"},{"location":"start_introduction/","text":"CARLA Important This document refers to the latest version of CARLA. For documentation of previous versions, select the required version in the bottom right hand corner where you see this button: CARLA is an open-source autonomous driving simulator. It was built from scratch to serve as a modular and flexible API to address a range of tasks involved in the problem of autonomous driving. One of the main goals of CARLA is to help democratize autonomous driving R&D, serving as a tool that can be easily accessed and customized by users. To do so, the simulator has to meet the requirements of different use cases within the general problem of driving (e.g. learning driving policies, training perception algorithms, etc.). CARLA is grounded on Unreal Engine to run the simulation and uses the OpenDRIVE standard (1.4 as today) to define roads and urban settings. Control over the simulation is granted through an API handled in Python and C++ that is constantly growing as the project does. In order to smooth the process of developing, training and validating driving systems, CARLA evolved to become an ecosystem of projects, built around the main platform by the community. In this context, it is important to understand some things about how does CARLA work, so as to fully comprehend its capabilities. The simulator The CARLA simulator consists of a scalable client-server architecture. The server is responsible for everything related with the simulation itself: sensor rendering, computation of physics, updates on the world-state and its actors and much more. As it aims for realistic results, the best fit would be running the server with a dedicated GPU, especially when dealing with machine learning. The client side consists of a sum of client modules controlling the logic of actors on scene and setting world conditions. This is achieved by leveraging the CARLA API (in Python or C++), a layer that mediates between server and client that is constantly evolving to provide new functionalities. That summarizes the basic structure of the simulator. Understanding CARLA though is much more than that, as many different features and elements coexist within it. Some of these are listed hereunder, as to gain perspective on the capabilities of what CARLA can achieve. Traffic manager. A built-in system that takes control of the vehicles besides the one used for learning. It acts as a conductor provided by CARLA to recreate urban-like environments with realistic behaviours. Sensors. Vehicles rely on them to dispense information of their surroundings. In CARLA they are a specific kind of actor attached the vehicle and the data they receive can be retrieved and stored to ease the process. Currently the project supports different types of these, from cameras to radars, lidar and many more. Recorder. This feature is used to reenact a simulation step by step for every actor in the world. It grants access to any moment in the timeline anywhere in the world, making for a great tracing tool. ROS bridge and Autoware implementation. As a matter of universalization, the CARLA project ties knots and works for the integration of the simulator within other learning environments. Open assets. CARLA facilitates different maps for urban settings with control over weather conditions and a blueprint library with a wide set of actors to be used. However, these elements can be customized and new can be generated following simple guidelines. Scenario runner. In order to ease the learning process for vehicles, CARLA provides a series of routes describing different situations to iterate on. These also set the basis for the CARLA challenge , open for everybody to test their solutions and make it to the leaderboard. The project CARLA grows fast and steady, widening the range of solutions provided and opening the way for the different approaches to autonomous driving. It does so while never forgetting its open-source nature. The project is transparent, acting as a white box where anybody is granted access to the tools and the development community. In that democratization is where CARLA finds its value. Talking about how CARLA grows means talking about a community of developers who dive together into the thorough question of autonomous driving. Everybody is free to explore with CARLA, find their own solutions and then share their achievements with the rest of the community. This documentation will be a companion along the way. The next page contains Quick start instructions for those eager to install a CARLA release. There is also a build guide for Linux and Windows. This will make CARLA from repository and allow to dive full-length into its features. Welcome to CARLA. Linux build Windows build","title":"\u4ecb\u7ecd"},{"location":"start_introduction/#carla","text":"Important This document refers to the latest version of CARLA. For documentation of previous versions, select the required version in the bottom right hand corner where you see this button: CARLA is an open-source autonomous driving simulator. It was built from scratch to serve as a modular and flexible API to address a range of tasks involved in the problem of autonomous driving. One of the main goals of CARLA is to help democratize autonomous driving R&D, serving as a tool that can be easily accessed and customized by users. To do so, the simulator has to meet the requirements of different use cases within the general problem of driving (e.g. learning driving policies, training perception algorithms, etc.). CARLA is grounded on Unreal Engine to run the simulation and uses the OpenDRIVE standard (1.4 as today) to define roads and urban settings. Control over the simulation is granted through an API handled in Python and C++ that is constantly growing as the project does. In order to smooth the process of developing, training and validating driving systems, CARLA evolved to become an ecosystem of projects, built around the main platform by the community. In this context, it is important to understand some things about how does CARLA work, so as to fully comprehend its capabilities.","title":"CARLA"},{"location":"start_introduction/#the-simulator","text":"The CARLA simulator consists of a scalable client-server architecture. The server is responsible for everything related with the simulation itself: sensor rendering, computation of physics, updates on the world-state and its actors and much more. As it aims for realistic results, the best fit would be running the server with a dedicated GPU, especially when dealing with machine learning. The client side consists of a sum of client modules controlling the logic of actors on scene and setting world conditions. This is achieved by leveraging the CARLA API (in Python or C++), a layer that mediates between server and client that is constantly evolving to provide new functionalities. That summarizes the basic structure of the simulator. Understanding CARLA though is much more than that, as many different features and elements coexist within it. Some of these are listed hereunder, as to gain perspective on the capabilities of what CARLA can achieve. Traffic manager. A built-in system that takes control of the vehicles besides the one used for learning. It acts as a conductor provided by CARLA to recreate urban-like environments with realistic behaviours. Sensors. Vehicles rely on them to dispense information of their surroundings. In CARLA they are a specific kind of actor attached the vehicle and the data they receive can be retrieved and stored to ease the process. Currently the project supports different types of these, from cameras to radars, lidar and many more. Recorder. This feature is used to reenact a simulation step by step for every actor in the world. It grants access to any moment in the timeline anywhere in the world, making for a great tracing tool. ROS bridge and Autoware implementation. As a matter of universalization, the CARLA project ties knots and works for the integration of the simulator within other learning environments. Open assets. CARLA facilitates different maps for urban settings with control over weather conditions and a blueprint library with a wide set of actors to be used. However, these elements can be customized and new can be generated following simple guidelines. Scenario runner. In order to ease the learning process for vehicles, CARLA provides a series of routes describing different situations to iterate on. These also set the basis for the CARLA challenge , open for everybody to test their solutions and make it to the leaderboard.","title":"The simulator"},{"location":"start_introduction/#the-project","text":"CARLA grows fast and steady, widening the range of solutions provided and opening the way for the different approaches to autonomous driving. It does so while never forgetting its open-source nature. The project is transparent, acting as a white box where anybody is granted access to the tools and the development community. In that democratization is where CARLA finds its value. Talking about how CARLA grows means talking about a community of developers who dive together into the thorough question of autonomous driving. Everybody is free to explore with CARLA, find their own solutions and then share their achievements with the rest of the community. This documentation will be a companion along the way. The next page contains Quick start instructions for those eager to install a CARLA release. There is also a build guide for Linux and Windows. This will make CARLA from repository and allow to dive full-length into its features. Welcome to CARLA. Linux build Windows build","title":"The project"},{"location":"start_quickstart/","text":"Quick start package installation This guide shows how to download and install the packaged version of CARLA. The package includes the CARLA server and two options for the client library. There are additional assets that can be downloaded and imported into the package. Advanced customization and development options that require use of the Unreal Engine editor are not available but these can be accessed by using the build version of CARLA for either Windows or Linux . Before you begin CARLA installation A. Debian CARLA installation B. Package installation Import additional assets Install client library CARLA versions prior to 0.9.12 CARLA 0.9.12+ Running CARLA Command-line options Updating CARLA Follow-up Before you begin The following requirements should be fulfilled before installing CARLA: System requirements. CARLA is built for Windows and Linux systems. An adequate GPU. CARLA aims for realistic simulations, so the server needs at least a 6 GB GPU although we would recommend 8 GB. A dedicated GPU is highly recommended for machine learning. Disk space. CARLA will use about 20 GB of space. Python. Python is the main scripting language in CARLA. CARLA supports Python 2.7 and Python 3 on Linux, and Python 3 on Windows. Pip. Some installation methods of the CARLA client library require pip or pip3 (depending on your Python version) version 20.3 or higher. To check your pip version: # For Python 3 pip3 -V # For Python 2 pip -V If you need to upgrade: # For Python 3 pip3 install --upgrade pip # For Python 2 pip install --upgrade pip Two TCP ports and good internet connection. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications. Other requirements. CARLA requires some Python dependencies. Install the dependencies according to your operating system: Windows pip3 install --user pygame numpy Linux pip install --user pygame numpy && pip3 install --user pygame numpy CARLA installation There are two methods to download and install CARLA as a package: A) Download the Debian package. B) Download the package from GitHub. A. Debian CARLA installation The Debain package is available for both Ubuntu 18.04 and Ubuntu 20.04, however the officially supported platform is Ubuntu 18.04 . 1. Set up the Debian repository in the system: sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 1AF1527DE64CB8D9 sudo add-apt-repository \"deb [arch=amd64] http://dist.carla.org/carla $(lsb_release -sc) main\" 2. Install CARLA and check for the installation in the /opt/ folder: sudo apt-get update # Update the Debian package index sudo apt-get install carla-simulator # Install the latest CARLA version, or update the current installation cd /opt/carla-simulator # Open the folder where CARLA is installed This repository contains CARLA 0.9.10 and later versions. To install a specific version add the version tag to the installation command: apt-cache madison carla-simulator # List the available versions of Carla sudo apt-get install carla-simulator=0.9.10-1 # In this case, \"0.9.10\" refers to a CARLA version, and \"1\" to the Debian revision Important To install CARLA versions prior to 0.9.10, change to a previous version of the documentation using the panel in the bottom right corner of the window, and follow the old instructions. B. Package installation CARLA repository This repository contains different versions of CARLA. You will find options to download the current release with all the most recent fixes and features, previous releases and a nightly build with all the developmental fixes and features (the nightly build is the most unstable version of CARLA). The package is a compressed file named CARLA_version.number . Download and extract the release file. It contains a precompiled version of the simulator, the Python API module and some scripts to be used as examples. Import additional assets Each release has it's own additional package of extra assets and maps. This additional package includes the maps Town06 , Town07 , and Town10 . These are stored separately to reduce the size of the build, so they can only be imported after the main package has been installed. 1. Download the appropriate package for your desired version of CARLA. 2. Extract the package: On Linux : move the package to the Import folder and run the following script to extract the contents: cd path/to/carla/root ./ImportAssets.sh On Windows : Extract the contents directly in the root folder. Install client library CARLA versions prior to 0.9.12 Previous versions of CARLA did not require the Python library to be installed, they came with an .egg file that was ready to use out of the box. CARLA versions 0.9.12+ change this behavior significantly; there are several options available to install the client library. If you are using a version of CARLA prior to 0.9.12, please select that version in the bottom right corner of the screen to see the relevant documentation. Otherwise, read on below about the available options in CARLA 0.9.12+. CARLA 0.9.12+ There are several options available to install and use the CARLA client library: .egg file .whl file Downloadable Python package Read more below about the requirements and limitations of each method before deciding which one to use. Please note that mixing the different methods can lead to incompatibilities, so use virtual environments when possible or uninstall a previously installed library before using a new one. A. .egg files CARLA provides .egg files in PythonAPI/carla/dist/ for different Python versions that are ready to use out of the box. Each of the example scripts in PythonAPI/examples includes a code snippet that looks for this file automatically. In Linux, you may need to add this file to your PYTHONPATH . Read more about .egg files in CARLA here . If you have previously installed the client library with pip , this will take precedence over the .egg file . You will need to uninstall the previous library first. B. .whl files CARLA provides .whl files for different Python versions. You will need to install the .whl file. The .whl file is found in PythonAPI/carla/dist/ . There is one file per supported Python version, indicated by the file name (e.g., carla-0.9.12- cp36 -cp36m-manylinux_2_27_x86_64.whl indicates Python 3.6). It is recommended to install the CARLA client library in a virtual environment to avoid conflicts when working with multiple versions. To install the CARLA client library, run the following command, choosing the file appropriate to your desired Python version. You will need pip/pip3 version 20.3 or above. See the Before you begin section for how to check the version and upgrade pip/pip3 : # Python 3 pip3 install <wheel-file-name>.whl # Python 2 pip install <wheel-file-name>.whl If you previously installed the client library, you should uninstall the old one before installing the new one. C. Downloadable Python package The CARLA client library can be downloaded from PyPi . This library is compatible with Python versions 2.7, 3.6, 3.7, and 3.8. To install it you will need pip/pip3 version 20.3 or above. See the Before you begin section for how to check the version and upgrade pip/pip3 . It is recommended to install the CARLA client library in a virtual environment to avoid conflicts when working with multiple versions. To install the client library from PyPi, run the following command: # Python 3 pip3 install carla # Python 2 pip install carla The PyPi download is suitable for use with CARLA packages only (i.e., not with a version built from source). Since the PyPi download only contains the client library , it is most useful in situations where you will be communicating with a remote CARLA server where you do not require downloading a full CARLA package. Running CARLA The method to start a CARLA server depends on the installation method you used and your operating system: Debian installation: cd /opt/carla-simulator/bin/ ./CarlaUE4.sh Linux package installation: cd path/to/carla/root ./CarlaUE4.sh Windows package installation: cd path/to/carla/root CarlaUE4.exe A window containing a view over the city will pop up. This is the spectator view . To fly around the city use the mouse and WASD keys, holding down the right mouse button to control the direction. This is the server simulator which is now running and waiting for a client to connect and interact with the world. You can try some of the example scripts to spawn life into the city and drive a car: # Terminal A cd PythonAPI\\examples python3 -m pip install -r requirements.txt # Support for Python2 is provided in the CARLA release packages python3 generate_traffic.py # Terminal B cd PythonAPI\\examples python3 manual_control.py Command-line options There are some configuration options available when launching CARLA and they can be used as follows: ./CarlaUE4.sh -carla-rpc-port=3000 -carla-rpc-port=N Listen for client connections at port N . Streaming port is set to N+1 by default. -carla-streaming-port=N Specify the port for sensor data streaming. Use 0 to get a random unused port. The second port will be automatically set to N+1 . -quality-level={Low,Epic} Change graphics quality level. Find out more in rendering options . List of Unreal Engine 4 command-line arguments . There are a lot of options provided by Unreal Engine however not all of these are available in CARLA. The script PythonAPI/util/config.py provides more configuration options and should be run when the server has been started: ./config.py --no-rendering # Disable rendering ./config.py --map Town05 # Change map ./config.py --weather ClearNoon # Change weather ./config.py --help # Check all the available configuration options Updating CARLA There is no way to update the packaged version of CARLA. When a new version is released, the repository is updated and you will need to delete the previous version and install the new version. If you installed the client library using pip/pip3 , you should uninstall it by running: # Python 3 pip3 uninstall carla # Python 2 pip uninstall carla Follow-up By now you should have a packaged version of CARLA up and running. If you came across any difficulties during the installation process, feel free to post in the CARLA forum or in the Discord channel. The next step is to learn more about the core concepts in CARLA. Read the First steps section to start learning. You can also find all the information about the Python API classes and methods in the Python API reference . Go to: First steps","title":"\u5feb\u901f\u542f\u52a8\u5305\u5b89\u88c5"},{"location":"start_quickstart/#quick-start-package-installation","text":"This guide shows how to download and install the packaged version of CARLA. The package includes the CARLA server and two options for the client library. There are additional assets that can be downloaded and imported into the package. Advanced customization and development options that require use of the Unreal Engine editor are not available but these can be accessed by using the build version of CARLA for either Windows or Linux . Before you begin CARLA installation A. Debian CARLA installation B. Package installation Import additional assets Install client library CARLA versions prior to 0.9.12 CARLA 0.9.12+ Running CARLA Command-line options Updating CARLA Follow-up","title":"Quick start package installation"},{"location":"start_quickstart/#before-you-begin","text":"The following requirements should be fulfilled before installing CARLA: System requirements. CARLA is built for Windows and Linux systems. An adequate GPU. CARLA aims for realistic simulations, so the server needs at least a 6 GB GPU although we would recommend 8 GB. A dedicated GPU is highly recommended for machine learning. Disk space. CARLA will use about 20 GB of space. Python. Python is the main scripting language in CARLA. CARLA supports Python 2.7 and Python 3 on Linux, and Python 3 on Windows. Pip. Some installation methods of the CARLA client library require pip or pip3 (depending on your Python version) version 20.3 or higher. To check your pip version: # For Python 3 pip3 -V # For Python 2 pip -V If you need to upgrade: # For Python 3 pip3 install --upgrade pip # For Python 2 pip install --upgrade pip Two TCP ports and good internet connection. 2000 and 2001 by default. Make sure that these ports are not blocked by firewalls or any other applications. Other requirements. CARLA requires some Python dependencies. Install the dependencies according to your operating system:","title":"Before you begin"},{"location":"start_quickstart/#windows","text":"pip3 install --user pygame numpy","title":"Windows"},{"location":"start_quickstart/#linux","text":"pip install --user pygame numpy && pip3 install --user pygame numpy","title":"Linux"},{"location":"start_quickstart/#carla-installation","text":"There are two methods to download and install CARLA as a package: A) Download the Debian package. B) Download the package from GitHub.","title":"CARLA installation"},{"location":"start_quickstart/#a-debian-carla-installation","text":"The Debain package is available for both Ubuntu 18.04 and Ubuntu 20.04, however the officially supported platform is Ubuntu 18.04 . 1. Set up the Debian repository in the system: sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 1AF1527DE64CB8D9 sudo add-apt-repository \"deb [arch=amd64] http://dist.carla.org/carla $(lsb_release -sc) main\" 2. Install CARLA and check for the installation in the /opt/ folder: sudo apt-get update # Update the Debian package index sudo apt-get install carla-simulator # Install the latest CARLA version, or update the current installation cd /opt/carla-simulator # Open the folder where CARLA is installed This repository contains CARLA 0.9.10 and later versions. To install a specific version add the version tag to the installation command: apt-cache madison carla-simulator # List the available versions of Carla sudo apt-get install carla-simulator=0.9.10-1 # In this case, \"0.9.10\" refers to a CARLA version, and \"1\" to the Debian revision Important To install CARLA versions prior to 0.9.10, change to a previous version of the documentation using the panel in the bottom right corner of the window, and follow the old instructions.","title":"A. Debian CARLA installation"},{"location":"start_quickstart/#b-package-installation","text":"CARLA repository This repository contains different versions of CARLA. You will find options to download the current release with all the most recent fixes and features, previous releases and a nightly build with all the developmental fixes and features (the nightly build is the most unstable version of CARLA). The package is a compressed file named CARLA_version.number . Download and extract the release file. It contains a precompiled version of the simulator, the Python API module and some scripts to be used as examples.","title":"B. Package installation"},{"location":"start_quickstart/#import-additional-assets","text":"Each release has it's own additional package of extra assets and maps. This additional package includes the maps Town06 , Town07 , and Town10 . These are stored separately to reduce the size of the build, so they can only be imported after the main package has been installed. 1. Download the appropriate package for your desired version of CARLA. 2. Extract the package: On Linux : move the package to the Import folder and run the following script to extract the contents: cd path/to/carla/root ./ImportAssets.sh On Windows : Extract the contents directly in the root folder.","title":"Import additional assets"},{"location":"start_quickstart/#install-client-library","text":"","title":"Install client library"},{"location":"start_quickstart/#carla-versions-prior-to-0912","text":"Previous versions of CARLA did not require the Python library to be installed, they came with an .egg file that was ready to use out of the box. CARLA versions 0.9.12+ change this behavior significantly; there are several options available to install the client library. If you are using a version of CARLA prior to 0.9.12, please select that version in the bottom right corner of the screen to see the relevant documentation. Otherwise, read on below about the available options in CARLA 0.9.12+.","title":"CARLA versions prior to 0.9.12"},{"location":"start_quickstart/#carla-0912","text":"There are several options available to install and use the CARLA client library: .egg file .whl file Downloadable Python package Read more below about the requirements and limitations of each method before deciding which one to use. Please note that mixing the different methods can lead to incompatibilities, so use virtual environments when possible or uninstall a previously installed library before using a new one. A. .egg files CARLA provides .egg files in PythonAPI/carla/dist/ for different Python versions that are ready to use out of the box. Each of the example scripts in PythonAPI/examples includes a code snippet that looks for this file automatically. In Linux, you may need to add this file to your PYTHONPATH . Read more about .egg files in CARLA here . If you have previously installed the client library with pip , this will take precedence over the .egg file . You will need to uninstall the previous library first. B. .whl files CARLA provides .whl files for different Python versions. You will need to install the .whl file. The .whl file is found in PythonAPI/carla/dist/ . There is one file per supported Python version, indicated by the file name (e.g., carla-0.9.12- cp36 -cp36m-manylinux_2_27_x86_64.whl indicates Python 3.6). It is recommended to install the CARLA client library in a virtual environment to avoid conflicts when working with multiple versions. To install the CARLA client library, run the following command, choosing the file appropriate to your desired Python version. You will need pip/pip3 version 20.3 or above. See the Before you begin section for how to check the version and upgrade pip/pip3 : # Python 3 pip3 install <wheel-file-name>.whl # Python 2 pip install <wheel-file-name>.whl If you previously installed the client library, you should uninstall the old one before installing the new one. C. Downloadable Python package The CARLA client library can be downloaded from PyPi . This library is compatible with Python versions 2.7, 3.6, 3.7, and 3.8. To install it you will need pip/pip3 version 20.3 or above. See the Before you begin section for how to check the version and upgrade pip/pip3 . It is recommended to install the CARLA client library in a virtual environment to avoid conflicts when working with multiple versions. To install the client library from PyPi, run the following command: # Python 3 pip3 install carla # Python 2 pip install carla The PyPi download is suitable for use with CARLA packages only (i.e., not with a version built from source). Since the PyPi download only contains the client library , it is most useful in situations where you will be communicating with a remote CARLA server where you do not require downloading a full CARLA package.","title":"CARLA 0.9.12+"},{"location":"start_quickstart/#running-carla","text":"The method to start a CARLA server depends on the installation method you used and your operating system: Debian installation: cd /opt/carla-simulator/bin/ ./CarlaUE4.sh Linux package installation: cd path/to/carla/root ./CarlaUE4.sh Windows package installation: cd path/to/carla/root CarlaUE4.exe A window containing a view over the city will pop up. This is the spectator view . To fly around the city use the mouse and WASD keys, holding down the right mouse button to control the direction. This is the server simulator which is now running and waiting for a client to connect and interact with the world. You can try some of the example scripts to spawn life into the city and drive a car: # Terminal A cd PythonAPI\\examples python3 -m pip install -r requirements.txt # Support for Python2 is provided in the CARLA release packages python3 generate_traffic.py # Terminal B cd PythonAPI\\examples python3 manual_control.py","title":"Running CARLA"},{"location":"start_quickstart/#command-line-options","text":"There are some configuration options available when launching CARLA and they can be used as follows: ./CarlaUE4.sh -carla-rpc-port=3000 -carla-rpc-port=N Listen for client connections at port N . Streaming port is set to N+1 by default. -carla-streaming-port=N Specify the port for sensor data streaming. Use 0 to get a random unused port. The second port will be automatically set to N+1 . -quality-level={Low,Epic} Change graphics quality level. Find out more in rendering options . List of Unreal Engine 4 command-line arguments . There are a lot of options provided by Unreal Engine however not all of these are available in CARLA. The script PythonAPI/util/config.py provides more configuration options and should be run when the server has been started: ./config.py --no-rendering # Disable rendering ./config.py --map Town05 # Change map ./config.py --weather ClearNoon # Change weather ./config.py --help # Check all the available configuration options","title":"Command-line options"},{"location":"start_quickstart/#updating-carla","text":"There is no way to update the packaged version of CARLA. When a new version is released, the repository is updated and you will need to delete the previous version and install the new version. If you installed the client library using pip/pip3 , you should uninstall it by running: # Python 3 pip3 uninstall carla # Python 2 pip uninstall carla","title":"Updating CARLA"},{"location":"start_quickstart/#follow-up","text":"By now you should have a packaged version of CARLA up and running. If you came across any difficulties during the installation process, feel free to post in the CARLA forum or in the Discord channel. The next step is to learn more about the core concepts in CARLA. Read the First steps section to start learning. You can also find all the information about the Python API classes and methods in the Python API reference . Go to: First steps","title":"Follow-up"},{"location":"ts_traffic_simulation_overview/","text":"Traffic Simulation in CARLA Traffic simulation is integral to the accurate and efficient training and testing of autonomous driving stacks. CARLA provides a number of different options to simulate traffic and specific traffic scenarios. This section is an overview of the options available to help decide which is the best fit for your use case. Scenario Runner and OpenScenario Traffic Manager Scenic SUMO Scenario Runner and OpenScenario Scenario Runner provides predefined traffic scenarios out of the box and also allows users to define their own scenarios using either Python or the OpenSCENARIO 1.0 standard . The primary use of OpenSCENARIO is the description of complex maneuvers that involve multiple vehicles. Users can see which features of OpenSCENARIO are supported by Scenario Runner here . These features include Maneuvers, Actions, Conditions, Stories and the Storyboard. Scenario Runner has to be installed separately from the main CARLA package. Useful for: Creating complex traffic scenarios and routes to prepare AD agents for evaluation in the CARLA leaderboard . Defining bespoke metrics that can be run against recordings of the scenario simulation, foregoing the need to run simulations repeatedly. Go to Scenario Runner Traffic Manager Traffic Manager is a module within CARLA that controls certain vehicles in a simulation from the client side. Vehicles are registered to Traffic Manager via the carla.Vehicle.set_autopilot method or command.SetAutopilot class. Control of each vehicle is managed through a cycle of distinct stages which each run on a different thread. Useful for: Populating a simulation with realistic urban traffic conditions. Customizing traffic behaviours to set specific learning circumstances. Developing phase-related functionalities and data structures while improving computational efficiency. Go to Traffic Manager Scenic Scenic is a domain-specific probabilistic programming language for modeling the environments of cyber-physical systems like robots and autonomous cars. Scenic provides an specialized domain to facilitate execution of Scenic scripts on the CARLA simulator. Scenic scenario definitions are easy to read and construct. A tutorial to create a simple scenario is provided here . Useful for: Generating multiple, diverse scenarios with a single scenario definition. Defining probabilistic policies for dynamic agents to take actions over time in response to the state of the world. Go to Scenic Tutorial SUMO SUMO is an open source, microscopic, multi-modal traffic simulation. In SUMO, each vehicle is modelled explicitly, has its own route, and moves individually through the network. Simulations are deterministic by default but there are various options for introducing randomness. CARLA provides a co-simulation feature with SUMO that allows distribution of tasks between the two simulators. Vehicles can be spawned in CARLA through SUMO, and managed by SUMO much as the Traffic Manager would do. Useful for: Exploitation of the capabilities of both CARLA and SUMO in one package. Go to SUMO Co-Simulation If you have any doubts about the different options available to simulate traffic in CARLA, feel free to post in the forum or in Discord . CARLA forum","title":"\u4ea4\u901a\u6a21\u62df\u6982\u8ff0"},{"location":"ts_traffic_simulation_overview/#traffic-simulation-in-carla","text":"Traffic simulation is integral to the accurate and efficient training and testing of autonomous driving stacks. CARLA provides a number of different options to simulate traffic and specific traffic scenarios. This section is an overview of the options available to help decide which is the best fit for your use case. Scenario Runner and OpenScenario Traffic Manager Scenic SUMO","title":"Traffic Simulation in CARLA"},{"location":"ts_traffic_simulation_overview/#scenario-runner-and-openscenario","text":"Scenario Runner provides predefined traffic scenarios out of the box and also allows users to define their own scenarios using either Python or the OpenSCENARIO 1.0 standard . The primary use of OpenSCENARIO is the description of complex maneuvers that involve multiple vehicles. Users can see which features of OpenSCENARIO are supported by Scenario Runner here . These features include Maneuvers, Actions, Conditions, Stories and the Storyboard. Scenario Runner has to be installed separately from the main CARLA package. Useful for: Creating complex traffic scenarios and routes to prepare AD agents for evaluation in the CARLA leaderboard . Defining bespoke metrics that can be run against recordings of the scenario simulation, foregoing the need to run simulations repeatedly. Go to Scenario Runner","title":"Scenario Runner and OpenScenario"},{"location":"ts_traffic_simulation_overview/#traffic-manager","text":"Traffic Manager is a module within CARLA that controls certain vehicles in a simulation from the client side. Vehicles are registered to Traffic Manager via the carla.Vehicle.set_autopilot method or command.SetAutopilot class. Control of each vehicle is managed through a cycle of distinct stages which each run on a different thread. Useful for: Populating a simulation with realistic urban traffic conditions. Customizing traffic behaviours to set specific learning circumstances. Developing phase-related functionalities and data structures while improving computational efficiency. Go to Traffic Manager","title":"Traffic Manager"},{"location":"ts_traffic_simulation_overview/#scenic","text":"Scenic is a domain-specific probabilistic programming language for modeling the environments of cyber-physical systems like robots and autonomous cars. Scenic provides an specialized domain to facilitate execution of Scenic scripts on the CARLA simulator. Scenic scenario definitions are easy to read and construct. A tutorial to create a simple scenario is provided here . Useful for: Generating multiple, diverse scenarios with a single scenario definition. Defining probabilistic policies for dynamic agents to take actions over time in response to the state of the world. Go to Scenic Tutorial","title":"Scenic"},{"location":"ts_traffic_simulation_overview/#sumo","text":"SUMO is an open source, microscopic, multi-modal traffic simulation. In SUMO, each vehicle is modelled explicitly, has its own route, and moves individually through the network. Simulations are deterministic by default but there are various options for introducing randomness. CARLA provides a co-simulation feature with SUMO that allows distribution of tasks between the two simulators. Vehicles can be spawned in CARLA through SUMO, and managed by SUMO much as the Traffic Manager would do. Useful for: Exploitation of the capabilities of both CARLA and SUMO in one package. Go to SUMO Co-Simulation If you have any doubts about the different options available to simulate traffic in CARLA, feel free to post in the forum or in Discord . CARLA forum","title":"SUMO"},{"location":"tuto_A_add_props/","text":"Add new props Props are the assets that populate the scene, besides the map, and the vehicles. That includes streetlights, buildings, trees, and much more. The simulator can ingest new props anytime in a simple process. This is really useful to create customized environments in a map. Prepare the package Create the folder structure Create the JSON description Ingestion in a CARLA package Ingestion in a build from source Prepare the package Create the folder structure 1. Create a folder inside carla/Import . The name of the folder is not relevant. 2. Create the subfolders. There should be one general subfolder for all the props, and inside of it, as many subfolders as props to import. 3. Move the files of each prop to the corresponding subfolder. A prop subfolder will contain the .fbx mesh, and optionally, the textures required by it. For instance, an Import folder with two separate packages should have a structure similar to the one below. Import \u2502 \u251c\u2500\u2500 Package01 \u2502 \u251c\u2500\u2500 Package01.json \u2502 \u2514\u2500\u2500 Props \u2502 \u251c\u2500\u2500 Prop01 \u2502 \u2502 \u251c\u2500\u2500 Prop01_Diff.png \u2502 \u2502 \u251c\u2500\u2500 Prop01_Norm.png \u2502 \u2502 \u251c\u2500\u2500 Prop01_Spec.png \u2502 \u2502 \u2514\u2500\u2500 Prop01.fbx \u2502 \u2514\u2500\u2500 Prop02 \u2502 \u2514\u2500\u2500 Prop02.fbx \u2514\u2500\u2500 Package02 \u251c\u2500\u2500 Packag02.json \u2514\u2500\u2500 Props \u2514\u2500\u2500 Prop03 \u2514\u2500\u2500 Prop03.fbx Create the JSON description Create a .json file in the root folder of the package. Name the file after the package. Note that this will be the distribution name. The content of the file will describe a JSON array of maps and props with basic information for each of them. Maps are not part of this tutorial, so this definition will be empty. There is a specific tutorial to add a new map . Props need the following parameters. name of the prop. This must be the same as the .fbx . source path to the .fbx . size estimation of the prop. The possible values are listed here. tiny small medium big huge tag value for the semantic segmentation. If the tag is misspelled, it will be read as Unlabeled . Bridge Building Dynamic Fence Ground GuardRail Other Pedestrian Pole RailTrack Road RoadLine SideWalk Sky Static Terrain TrafficLight TrafficSign Unlabeled Vegetation Vehicles Wall Water In the end, the .json should look similar to the one below. { \"maps\": [ ], \"props\": [ { \"name\": \"MyProp01\", \"size\": \"medium\", \"source\": \"./Props/Prop01/Prop01.fbx\", \"tag\": \"SemanticSegmentationTag01\" }, { \"name\": \"MyProp02\", \"size\": \"small\", \"source\": \"./Props/Prop02/Prop02.fbx\", \"tag\": \"SemanticSegmentationTag02\" } ] } Warning Packages with the same name will produce an error. Ingestion in a CARLA package This is the method used to ingest the props into a CARLA package such as CARLA 0.9.8. A Docker image of Unreal Engine will be created. It acts as a black box that automatically imports the package into the CARLA image, and generates a ditribution package. The Docker image takes 4h and 400GB to be built. However, this is only needed the first time. 1. Build a Docker image of Unreal Engine. Follow these instructions to build the image. 2. Run the script to cook the props. In the folder ~/carla/Util/Docker there is a script that connects with the Docker image previously created, and makes the ingestion automatically. It only needs the path for the input and output files, and the name of the package to be ingested. python3 docker_tools.py --input ~/path_to_package --output ~/path_for_output_assets --package=Package01 3. Locate the package . The Docker should have generated the package Package01.tar.gz in the output path. This is the standalone package for the assets. 4. Import the package into CARLA. On Windows extract the package in the WindowsNoEditor folder. On Linux move the package to the Import folder, and run the script to import it. cd Util ./ImportAssets.sh Note There is an alternative on Linux. Move the package to the Import folder and run the script Util/ImportAssets.sh to extract the package. Ingestion in a build from source This is the method to import the props into a CARLA build from source. The JSON file will be read to place the props inside the Content in Unreal Engine. Furthermore, it will create a Package1.Package.json file inside the package's Config folder. This will be used to define the props in the blueprint library, and expose them in the Python API. It will also be used if the package is exported as a standalone package . When everything is ready, run the command. make import Warning Make sure that the package is inside the Import folder in CARLA. That is all there is to know about the different ways to import new props into CARLA. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"\u6dfb\u52a0\u65b0\u9053\u5177"},{"location":"tuto_A_add_props/#add-new-props","text":"Props are the assets that populate the scene, besides the map, and the vehicles. That includes streetlights, buildings, trees, and much more. The simulator can ingest new props anytime in a simple process. This is really useful to create customized environments in a map. Prepare the package Create the folder structure Create the JSON description Ingestion in a CARLA package Ingestion in a build from source","title":"Add new props"},{"location":"tuto_A_add_props/#prepare-the-package","text":"","title":"Prepare the package"},{"location":"tuto_A_add_props/#create-the-folder-structure","text":"1. Create a folder inside carla/Import . The name of the folder is not relevant. 2. Create the subfolders. There should be one general subfolder for all the props, and inside of it, as many subfolders as props to import. 3. Move the files of each prop to the corresponding subfolder. A prop subfolder will contain the .fbx mesh, and optionally, the textures required by it. For instance, an Import folder with two separate packages should have a structure similar to the one below. Import \u2502 \u251c\u2500\u2500 Package01 \u2502 \u251c\u2500\u2500 Package01.json \u2502 \u2514\u2500\u2500 Props \u2502 \u251c\u2500\u2500 Prop01 \u2502 \u2502 \u251c\u2500\u2500 Prop01_Diff.png \u2502 \u2502 \u251c\u2500\u2500 Prop01_Norm.png \u2502 \u2502 \u251c\u2500\u2500 Prop01_Spec.png \u2502 \u2502 \u2514\u2500\u2500 Prop01.fbx \u2502 \u2514\u2500\u2500 Prop02 \u2502 \u2514\u2500\u2500 Prop02.fbx \u2514\u2500\u2500 Package02 \u251c\u2500\u2500 Packag02.json \u2514\u2500\u2500 Props \u2514\u2500\u2500 Prop03 \u2514\u2500\u2500 Prop03.fbx","title":"Create the folder structure"},{"location":"tuto_A_add_props/#create-the-json-description","text":"Create a .json file in the root folder of the package. Name the file after the package. Note that this will be the distribution name. The content of the file will describe a JSON array of maps and props with basic information for each of them. Maps are not part of this tutorial, so this definition will be empty. There is a specific tutorial to add a new map . Props need the following parameters. name of the prop. This must be the same as the .fbx . source path to the .fbx . size estimation of the prop. The possible values are listed here. tiny small medium big huge tag value for the semantic segmentation. If the tag is misspelled, it will be read as Unlabeled . Bridge Building Dynamic Fence Ground GuardRail Other Pedestrian Pole RailTrack Road RoadLine SideWalk Sky Static Terrain TrafficLight TrafficSign Unlabeled Vegetation Vehicles Wall Water In the end, the .json should look similar to the one below. { \"maps\": [ ], \"props\": [ { \"name\": \"MyProp01\", \"size\": \"medium\", \"source\": \"./Props/Prop01/Prop01.fbx\", \"tag\": \"SemanticSegmentationTag01\" }, { \"name\": \"MyProp02\", \"size\": \"small\", \"source\": \"./Props/Prop02/Prop02.fbx\", \"tag\": \"SemanticSegmentationTag02\" } ] } Warning Packages with the same name will produce an error.","title":"Create the JSON description"},{"location":"tuto_A_add_props/#ingestion-in-a-carla-package","text":"This is the method used to ingest the props into a CARLA package such as CARLA 0.9.8. A Docker image of Unreal Engine will be created. It acts as a black box that automatically imports the package into the CARLA image, and generates a ditribution package. The Docker image takes 4h and 400GB to be built. However, this is only needed the first time. 1. Build a Docker image of Unreal Engine. Follow these instructions to build the image. 2. Run the script to cook the props. In the folder ~/carla/Util/Docker there is a script that connects with the Docker image previously created, and makes the ingestion automatically. It only needs the path for the input and output files, and the name of the package to be ingested. python3 docker_tools.py --input ~/path_to_package --output ~/path_for_output_assets --package=Package01 3. Locate the package . The Docker should have generated the package Package01.tar.gz in the output path. This is the standalone package for the assets. 4. Import the package into CARLA. On Windows extract the package in the WindowsNoEditor folder. On Linux move the package to the Import folder, and run the script to import it. cd Util ./ImportAssets.sh Note There is an alternative on Linux. Move the package to the Import folder and run the script Util/ImportAssets.sh to extract the package.","title":"Ingestion in a CARLA package"},{"location":"tuto_A_add_props/#ingestion-in-a-build-from-source","text":"This is the method to import the props into a CARLA build from source. The JSON file will be read to place the props inside the Content in Unreal Engine. Furthermore, it will create a Package1.Package.json file inside the package's Config folder. This will be used to define the props in the blueprint library, and expose them in the Python API. It will also be used if the package is exported as a standalone package . When everything is ready, run the command. make import Warning Make sure that the package is inside the Import folder in CARLA. That is all there is to know about the different ways to import new props into CARLA. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"Ingestion in a build from source"},{"location":"tuto_A_add_vehicle/","text":"Add a new vehicle This tutorial details how to add a new vehicle to CARLA. There are two sections, one for 4 wheeled vehicles and one for 2 wheeled vehicles. There is an outline of the basic requirements that must be fulfilled when modeling your vehicle to ensure that it works well in CARLA and instructions on configurations required after the vehicle has been imported into Unreal Engine. Add a 4 wheeled vehicle Bind and model the vehicle Import and configure the vehicle Add a 2 wheeled vehicle Important This tutorial only applies to users that work with a build from source, and have access to the Unreal Engine Editor. Add a 4 wheeled vehicle Vehicles added to CARLA need to use a common base skeleton which is found here . This link will download a folder called VehicleSkeleton.rar which contains the base skeleton in two different .fbx formats, one in ASCII and the other in binary. The format you use will depend on your 3D modeling software requirements. The positions of the skeleton bones can be changed but any other manipulation such as rotation, addition of new bones, or changing the current hierarchy will lead to errors. Bind and model the vehicle This section details the minimum requirements in the modeling stage of your vehicle to make sure it can be used successfully in CARLA. The process involves binding the skeleton correctly to the base and wheels of the vehicle, creating Physical Asset and raycast sensor meshes, and exporting to the correct format. 1. Import the base skeleton. Import the base skeleton into your preferred 3D modeling software. Common editors include Maya and Blender. 2. Bind the bones. Bind the bones to the corresponding portions of the vehicle mesh according to the nomenclature below. Make sure to center the wheels' bones within the mesh. Front left wheel: Wheel_Front_Left Front right wheel: Wheel_Front_Right Rear left wheel: Wheel_Rear_Left Rear right wheel: Wheel_Rear_Right Rest of the mesh: VehicleBase Warning Do not make any changes to the bone names or the hierarchy nor add any new bones. 3. Model your vehicle. Vehicles should have between approximately 50,000 - 100,000 tris. We model the vehicles using the size and scale of actual cars. We recommend that you divide the vehicle into the following materials: Bodywork : The metallic part of the vehicle. This material is changed to Unreal Engine material. Logos and details can be added but, to be visible, they must be painted in a different color by using the alpha channels in the Unreal Engine editor. Glass_Ext : A layer of glass that allows visibility from the outside to the inside of the vehicle. Glass_Int : A layer of glass that allows visibility from the inside to the outside of the vehicle. Lights : Headlights, indicator lights, etc. LightGlass_Ext : A layer of glass that allows visibility from the outside to the inside of the light. LightGlass_Int : A layer of glass that allows visibility from the inside to the outside of the light. LicensePlate : A rectangular plane of 29x12 cm. You can use the CARLA provided .fbx for best results, download it here . The texture will be assigned automatically in Unreal Engine. Interior : Any other details that don't fit in the above sections can go into Interior . Materials should be named using the format M_CarPart_CarName , e.g., M_Bodywork_Mustang . Textures should be named using the format T_CarPart_CarName , e.g., T_Bodywork_Mustang . Textures should be sized as 2048x2048. Unreal Engine automatically creates LODs but you can also create them manually in your 3D editor. Tri counts are as follows: LOD 0 : 100,000 tris LOD 1 : 80,000 tris LOD 2 : 60,000 tris LOD 3 : 30,000 tris 4. Create the Physical Asset mesh. The Physical Asset mesh is an additional mesh that allows Unreal Engine to calculate the vehicle's physics. It should be as simple as possible, with a reduced number of polygons, and should cover the whole vehicle except for the wheels. See the image below for an example. The Physical Asset mesh should be exported as a separate .fbx file. The final file should fulfill the following requirements: Have a base mesh. This should be a copy of the Physical Asset mesh. It should have the same name as the original vehicle. The Physical Asset mesh must be named using the format UCX_<vehicle_name>_<number_of_mesh> , otherwise it will not be recognized by Unreal Engine. The mesh must not extend beyond the boundaries of the original model. The mesh should have the same position as the original model. Export the final mesh as an .fbx file with the name SMC_<vehicle_name>.fbx . 5. Create the mesh for the raycast sensor. The raycast sensor mesh sets up the vehicle's shape that will be detected by the raycast sensors (RADAR, LiDAR, and Semantic LiDAR). This mesh should have a slightly more defined geometry than the Physical Asset mesh in order to increase the realism of sensor simulation but not as detailed as the car mesh for performance reasons. Consider the following points when creating the raycast sensor mesh: The mesh should cover all aspects of the vehicle, including wheels, side mirrors, and grilles. The wheels should be cylinders of no more than 16 loops. Various meshes can be joined together if required. The mesh(es) must not extend beyond the boundaries of the original model. The mesh(es) should have the same position as the original. Export the final mesh as an .fbx file with the name SM_sc_<vehicle_name>.fbx . 5. Export the vehicle mesh(es). Select all the main vehicle mesh(es) and the skeleton base and export as .fbx . Import and configure the vehicle This section details the process of importing the vehicle into Unreal Engine for use in CARLA. Perform these steps in the Unreal Engine editor. 1. Create the vehicle folder. Create a new folder named <vehicle_name> in Content/Carla/Static/Vehicles/4Wheeled . 2. Import the .fbx . Inside the new vehicle folder, import your main vehicle skeleton .fbx by right-clicking in the Content Browser and selecting Import into Game/Carla/Static/Vehicles/4Wheeled/<vehicle_name> . In the dialogue box that pops up: Set Import Content Type to Geometry and Skinning Weights . Set Normal Import Method to Import Normals . Optionally set Material Import Method to Do not create materials . Uncheck Import Textures to avoid Unreal Engine creating default materials. The Skeletal Mesh will appear along with two new files, <vehicle_name>_PhysicsAssets and <vehicle_name>_Skeleton . Import the rest of your .fbx files separately from the main vehicle skeleton .fbx file. 3. Set the physical asset mesh. Open <vehicle_name>_PhysicsAssets from the Content Browser . Right-click on the Vehicle_Base mesh in the Skeleton Tree panel and go to Copy Collision from StaticMesh . Search for and select your SMC_<vehicle_name> file. You should see the outline of the physical asset mesh appear in the viewport. Delete the default capsule shape from the Vehicle_Base . Select all the wheels: Go to the Tools panel and change the Primitive Type to Sphere . Go to the Details panel and change Physics Type to Kinematic . Set Linear Damping to 0 . This will eliminate any extra friction on the wheels. Enable Simulation Generates Hit Event for all meshes. Click Re-generate Bodies . Adjust the wheel sphere to the size of the wheel. Save and close the window. 4. Create the Animation Blueprint. In the Content Browser , right-click inside your vehicle folder and select Animation -> Animation Blueprint . In Parent Class search for and select VehicleAnimInstance . In Target Skeleton search for and select <vehicle_name>_Skeleton . Press OK and rename the blueprint as AnimBP_<vehicle_name> . 5. Configure the Animation Blueprint. To ease the process of configuring the animation blueprint, we will copy an existing one from a native CARLA vehicle: Go to Content/Carla/Static/Vehicle and choose any CARLA vehicle folder. Open its Animation Blueprint. In the My Blueprint panel, double click on AnimGraph . You will see the graph come up in the viewport. Click and drag to select the Mesh Space Ref Pose , Wheel Handler , and Component To Local components. Right-click and select Copy . Go back to your own vehicle Animation Blueprint and paste the copied contents into the graph area. Click and drag from the standing figure in the Component To Local component to the figure in Output Pose to join the components together. Click Compile in the top left corner. You should now see a pulsating line flowing through the entire sequence. Save and close the window. 6. Prepare the vehicle and wheel blueprints. In the Content Browser , go to Content/Carla/Blueprints/Vehicles and create a new folder <vehicle_name> . Inside the folder, right-click and go to Blueprint Class . Open the All Classes section in the pop-up. Search for BaseVehiclePawn and press Select . Rename the file as BP_<vehicle_name> . Go to the folder of any of the native CARLA vehicles in Carla/Blueprints/Vehicles . From the Content Browser , copy the four wheel blueprints into the blueprint folder for your own vehicle. Rename the files to replace the old vehicle name with your own vehicle name. 7. Configure the wheel blueprints. In your vehicle blueprint folder, open all four of the wheel blueprints. In the Class Defaults panel, set Collision Mesh to Wheel_Shape . Omitting this step will cause the vehicle wheels to sink into the ground . Adjust the values for wheel shape radius, width, mass, and damping rate according to your vehicle specifications. Set Tire Config to CommonTireConfig On the front wheels set Steer Angle according to your preferences (default is 70 ). Uncheck Affected by Handbrake . On the rear wheels set Steer Angle to 0 . Check Affected by Handbrake . When setting the suspension values, you can use the values here as a guide. Compile and save. 8. Configure vehicle blueprint. From the Content Browser , open your BP_<vehicle_name> . In the Components panel, select Mesh (VehicleMesh) (Inherited) . In the Details panel, go to Skeletal Mesh and search for and select the base skeleton file of your vehicle (located in the Carla/Static/Vehicles/4Wheeled/<vehicle_name> folder). Go to Anim Class in the Details panel. Search for and select your AnimBP_<vehicle_name> file. In the Components panel, select Custom Collision (Inherited) . Select Static Mesh in the Details panel and search for your SM_sc_<vehicle_name> raycast sensor mesh. In the Components panel, select VehicleMovement (MovementComp) (Inherited) . In the Details panel, search for wheel . You will find settings for each of the wheels. For each one, click on Wheel Class and search for the BP_<vehicle_name>_<wheel_name> file that corresponds to the correct wheel position. If you have any additional meshes for your vehicle (doors, lights, etc.,) separate from the base mesh: Drag them into the Mesh (VehicleMesh) (Inherited) hierarchy in the Components panel. Select the extra meshes in the hierarchy and search for Collision in the Details panel. Set Collision Presets to NoCollision . Select any lights meshes in the hierarchy. Search for Tag in the Details panel and add the tag emissive . Click Save and Compile . 9. Add the vehicle to the Blueprint Library . In Content/Carla/Blueprint/Vehicle , open the VehicleFactory file. In the Generate Definitions tab, double click Vehicles . In the Details panel, expand the Default Value section and add a new element to the vehicles array. Fill in the Make and Model of your vehicle. Fill in the Class value with your BP_<vehicle_name> file. Optionally, provide a set of recommended colors for the vehicle. Compile and save. 10. Test the vehicle . Launch CARLA, open a terminal in PythonAPI/examples and run the following command: python3 manual_control.py --filter <model_name> # The make or model defined in step 9 Note Even if you used upper case characters in your make and model, they need to be converted to lower case when passed to the filter. Add a 2 wheeled vehicle Adding 2 wheeled vehicles is similar to adding a 4 wheeled one but due to the complexity of the animation you'll need to set up aditional bones to guide the driver's animation. Here is the link to the reference skeleton for 2 wheeled vehicles. As with the 4 wheeled vehicles, orient the model towards positive \"x\" and every bone axis towards positive x and with the z axis facing upwards. Bone Setup: - Bike_Rig: # The origin point of the mesh. Place it in the point 0 of the scenecomment - BikeBody: # The model's body centre. - Pedals: # If the vehicle is a bike bind the pedalier to this bone, will rotate with the bike acceleration. - RightPedal: # Sets the driver's feet position and rotates with the pedalier if the vehicle is a bike. - LeftPedal: # ^ - RearWheel: # Rear Wheel of the vehicle - Handler: # Rotates with the frontal wheel of the vehicle bind the vehicle handler to it. - HandlerMidBone: # Positioned over the front wheel bone to orient the handler with the wheel - HandlerRight: # Sets the position of the driver's hand, no need to bind it to anything. - HandlerLeft: # ^ - Frontwheel: # Frontal wheel of the vehicle. - RightHelperRotator: # This four additional bones are here for an obsolete system of making the bike stable by using aditional invisible wheels - RightHelprWheel: # ^ - LeftHelperRotator: # ^ - LeftHelperWheel: # ^ - Seat: # Sets the position of the drivers hip bone. No need to bind it to anything but place it carefully. 1. Import fbx as Skelletal Mesh to its own folder inside Content/Carla/Static/Vehicles/2Wheeled . When importing select \"General2WheeledVehicleSkeleton\" as skelleton A Physics asset should be automatically created and linked. 2. Tune the Physics asset. Delete the automatically created ones and add boxes to the BikeBody bone trying to match the shape as possible, make sure generate hit events is enabled. Add a sphere for each wheel and set their \"Physics Type\" to \"Kinematic\". 3. Create folder Content/Blueprints/Vehicles/<vehicle-model> 4. Inside that folder create two blueprint classes derived from \"VehicleWheel\" class. Call them <vehicle-model>_FrontWheel and <vehicle-model>_RearWheel . Set their \"Shape Radius\" to exactly match the mesh wheel radius (careful, radius not diameter). Set their \"Tire Config\" to \"CommonTireConfig\". On the front wheel uncheck \"Affected by Handbrake\" and on the rear wheel set \"Steer Angle\" to zero. 5. Inside the same folder create a blueprint class derived from Base2WheeledVehicle call it <vehicle-model> . Open it for edit and select component \"Mesh\", setup the \"Skeletal Mesh\" and the \"Anim Class\" to the corresponding ones. Then select the VehicleBounds component and set the size to cover vehicle's area as seen from above. 6. Select component \"VehicleMovement\", under \"Vehicle Setup\" expand \"Wheel Setups\", setup each wheel. 0: Wheel Class= <vehicle-model>_FrontWheel , Bone Name= FrontWheel 1: Wheel Class= <vehicle-model>_FrontWheel , Bone Name= FrontWheel 2: Wheel Class= <vehicle-model>_RearWheel , Bone Name= RearWheel 3: Wheel Class= <vehicle-model>_RearWheel , Bone Name= RearWheel (You'll notice that we are basically placing two wheels in each bone. The vehicle class unreal provides does not support vehicles with wheel numbers different from 4 so we had to make it believe the vehicle has 4 wheels) 7. Select the variable \"is bike\" and tick it if your model is a bike. This will activate the pedalier rotation. Leave unmarked if you are setting up a motorbike. 8. Find the variable back Rotation and set it as it fit better select the component SkeletalMesh (The driver) and move it along x axis until its in the seat position. 9. Test it, go to CarlaGameMode blueprint and change \"Default Pawn Class\" to the newly created bike blueprint.","title":"\u6dfb\u52a0\u65b0\u8f66\u8f86"},{"location":"tuto_A_add_vehicle/#add-a-new-vehicle","text":"This tutorial details how to add a new vehicle to CARLA. There are two sections, one for 4 wheeled vehicles and one for 2 wheeled vehicles. There is an outline of the basic requirements that must be fulfilled when modeling your vehicle to ensure that it works well in CARLA and instructions on configurations required after the vehicle has been imported into Unreal Engine. Add a 4 wheeled vehicle Bind and model the vehicle Import and configure the vehicle Add a 2 wheeled vehicle Important This tutorial only applies to users that work with a build from source, and have access to the Unreal Engine Editor.","title":"Add a new vehicle"},{"location":"tuto_A_add_vehicle/#add-a-4-wheeled-vehicle","text":"Vehicles added to CARLA need to use a common base skeleton which is found here . This link will download a folder called VehicleSkeleton.rar which contains the base skeleton in two different .fbx formats, one in ASCII and the other in binary. The format you use will depend on your 3D modeling software requirements. The positions of the skeleton bones can be changed but any other manipulation such as rotation, addition of new bones, or changing the current hierarchy will lead to errors.","title":"Add a 4 wheeled vehicle"},{"location":"tuto_A_add_vehicle/#bind-and-model-the-vehicle","text":"This section details the minimum requirements in the modeling stage of your vehicle to make sure it can be used successfully in CARLA. The process involves binding the skeleton correctly to the base and wheels of the vehicle, creating Physical Asset and raycast sensor meshes, and exporting to the correct format. 1. Import the base skeleton. Import the base skeleton into your preferred 3D modeling software. Common editors include Maya and Blender. 2. Bind the bones. Bind the bones to the corresponding portions of the vehicle mesh according to the nomenclature below. Make sure to center the wheels' bones within the mesh. Front left wheel: Wheel_Front_Left Front right wheel: Wheel_Front_Right Rear left wheel: Wheel_Rear_Left Rear right wheel: Wheel_Rear_Right Rest of the mesh: VehicleBase Warning Do not make any changes to the bone names or the hierarchy nor add any new bones. 3. Model your vehicle. Vehicles should have between approximately 50,000 - 100,000 tris. We model the vehicles using the size and scale of actual cars. We recommend that you divide the vehicle into the following materials: Bodywork : The metallic part of the vehicle. This material is changed to Unreal Engine material. Logos and details can be added but, to be visible, they must be painted in a different color by using the alpha channels in the Unreal Engine editor. Glass_Ext : A layer of glass that allows visibility from the outside to the inside of the vehicle. Glass_Int : A layer of glass that allows visibility from the inside to the outside of the vehicle. Lights : Headlights, indicator lights, etc. LightGlass_Ext : A layer of glass that allows visibility from the outside to the inside of the light. LightGlass_Int : A layer of glass that allows visibility from the inside to the outside of the light. LicensePlate : A rectangular plane of 29x12 cm. You can use the CARLA provided .fbx for best results, download it here . The texture will be assigned automatically in Unreal Engine. Interior : Any other details that don't fit in the above sections can go into Interior . Materials should be named using the format M_CarPart_CarName , e.g., M_Bodywork_Mustang . Textures should be named using the format T_CarPart_CarName , e.g., T_Bodywork_Mustang . Textures should be sized as 2048x2048. Unreal Engine automatically creates LODs but you can also create them manually in your 3D editor. Tri counts are as follows: LOD 0 : 100,000 tris LOD 1 : 80,000 tris LOD 2 : 60,000 tris LOD 3 : 30,000 tris 4. Create the Physical Asset mesh. The Physical Asset mesh is an additional mesh that allows Unreal Engine to calculate the vehicle's physics. It should be as simple as possible, with a reduced number of polygons, and should cover the whole vehicle except for the wheels. See the image below for an example. The Physical Asset mesh should be exported as a separate .fbx file. The final file should fulfill the following requirements: Have a base mesh. This should be a copy of the Physical Asset mesh. It should have the same name as the original vehicle. The Physical Asset mesh must be named using the format UCX_<vehicle_name>_<number_of_mesh> , otherwise it will not be recognized by Unreal Engine. The mesh must not extend beyond the boundaries of the original model. The mesh should have the same position as the original model. Export the final mesh as an .fbx file with the name SMC_<vehicle_name>.fbx . 5. Create the mesh for the raycast sensor. The raycast sensor mesh sets up the vehicle's shape that will be detected by the raycast sensors (RADAR, LiDAR, and Semantic LiDAR). This mesh should have a slightly more defined geometry than the Physical Asset mesh in order to increase the realism of sensor simulation but not as detailed as the car mesh for performance reasons. Consider the following points when creating the raycast sensor mesh: The mesh should cover all aspects of the vehicle, including wheels, side mirrors, and grilles. The wheels should be cylinders of no more than 16 loops. Various meshes can be joined together if required. The mesh(es) must not extend beyond the boundaries of the original model. The mesh(es) should have the same position as the original. Export the final mesh as an .fbx file with the name SM_sc_<vehicle_name>.fbx . 5. Export the vehicle mesh(es). Select all the main vehicle mesh(es) and the skeleton base and export as .fbx .","title":"Bind and model the vehicle"},{"location":"tuto_A_add_vehicle/#import-and-configure-the-vehicle","text":"This section details the process of importing the vehicle into Unreal Engine for use in CARLA. Perform these steps in the Unreal Engine editor. 1. Create the vehicle folder. Create a new folder named <vehicle_name> in Content/Carla/Static/Vehicles/4Wheeled . 2. Import the .fbx . Inside the new vehicle folder, import your main vehicle skeleton .fbx by right-clicking in the Content Browser and selecting Import into Game/Carla/Static/Vehicles/4Wheeled/<vehicle_name> . In the dialogue box that pops up: Set Import Content Type to Geometry and Skinning Weights . Set Normal Import Method to Import Normals . Optionally set Material Import Method to Do not create materials . Uncheck Import Textures to avoid Unreal Engine creating default materials. The Skeletal Mesh will appear along with two new files, <vehicle_name>_PhysicsAssets and <vehicle_name>_Skeleton . Import the rest of your .fbx files separately from the main vehicle skeleton .fbx file. 3. Set the physical asset mesh. Open <vehicle_name>_PhysicsAssets from the Content Browser . Right-click on the Vehicle_Base mesh in the Skeleton Tree panel and go to Copy Collision from StaticMesh . Search for and select your SMC_<vehicle_name> file. You should see the outline of the physical asset mesh appear in the viewport. Delete the default capsule shape from the Vehicle_Base . Select all the wheels: Go to the Tools panel and change the Primitive Type to Sphere . Go to the Details panel and change Physics Type to Kinematic . Set Linear Damping to 0 . This will eliminate any extra friction on the wheels. Enable Simulation Generates Hit Event for all meshes. Click Re-generate Bodies . Adjust the wheel sphere to the size of the wheel. Save and close the window. 4. Create the Animation Blueprint. In the Content Browser , right-click inside your vehicle folder and select Animation -> Animation Blueprint . In Parent Class search for and select VehicleAnimInstance . In Target Skeleton search for and select <vehicle_name>_Skeleton . Press OK and rename the blueprint as AnimBP_<vehicle_name> . 5. Configure the Animation Blueprint. To ease the process of configuring the animation blueprint, we will copy an existing one from a native CARLA vehicle: Go to Content/Carla/Static/Vehicle and choose any CARLA vehicle folder. Open its Animation Blueprint. In the My Blueprint panel, double click on AnimGraph . You will see the graph come up in the viewport. Click and drag to select the Mesh Space Ref Pose , Wheel Handler , and Component To Local components. Right-click and select Copy . Go back to your own vehicle Animation Blueprint and paste the copied contents into the graph area. Click and drag from the standing figure in the Component To Local component to the figure in Output Pose to join the components together. Click Compile in the top left corner. You should now see a pulsating line flowing through the entire sequence. Save and close the window. 6. Prepare the vehicle and wheel blueprints. In the Content Browser , go to Content/Carla/Blueprints/Vehicles and create a new folder <vehicle_name> . Inside the folder, right-click and go to Blueprint Class . Open the All Classes section in the pop-up. Search for BaseVehiclePawn and press Select . Rename the file as BP_<vehicle_name> . Go to the folder of any of the native CARLA vehicles in Carla/Blueprints/Vehicles . From the Content Browser , copy the four wheel blueprints into the blueprint folder for your own vehicle. Rename the files to replace the old vehicle name with your own vehicle name. 7. Configure the wheel blueprints. In your vehicle blueprint folder, open all four of the wheel blueprints. In the Class Defaults panel, set Collision Mesh to Wheel_Shape . Omitting this step will cause the vehicle wheels to sink into the ground . Adjust the values for wheel shape radius, width, mass, and damping rate according to your vehicle specifications. Set Tire Config to CommonTireConfig On the front wheels set Steer Angle according to your preferences (default is 70 ). Uncheck Affected by Handbrake . On the rear wheels set Steer Angle to 0 . Check Affected by Handbrake . When setting the suspension values, you can use the values here as a guide. Compile and save. 8. Configure vehicle blueprint. From the Content Browser , open your BP_<vehicle_name> . In the Components panel, select Mesh (VehicleMesh) (Inherited) . In the Details panel, go to Skeletal Mesh and search for and select the base skeleton file of your vehicle (located in the Carla/Static/Vehicles/4Wheeled/<vehicle_name> folder). Go to Anim Class in the Details panel. Search for and select your AnimBP_<vehicle_name> file. In the Components panel, select Custom Collision (Inherited) . Select Static Mesh in the Details panel and search for your SM_sc_<vehicle_name> raycast sensor mesh. In the Components panel, select VehicleMovement (MovementComp) (Inherited) . In the Details panel, search for wheel . You will find settings for each of the wheels. For each one, click on Wheel Class and search for the BP_<vehicle_name>_<wheel_name> file that corresponds to the correct wheel position. If you have any additional meshes for your vehicle (doors, lights, etc.,) separate from the base mesh: Drag them into the Mesh (VehicleMesh) (Inherited) hierarchy in the Components panel. Select the extra meshes in the hierarchy and search for Collision in the Details panel. Set Collision Presets to NoCollision . Select any lights meshes in the hierarchy. Search for Tag in the Details panel and add the tag emissive . Click Save and Compile . 9. Add the vehicle to the Blueprint Library . In Content/Carla/Blueprint/Vehicle , open the VehicleFactory file. In the Generate Definitions tab, double click Vehicles . In the Details panel, expand the Default Value section and add a new element to the vehicles array. Fill in the Make and Model of your vehicle. Fill in the Class value with your BP_<vehicle_name> file. Optionally, provide a set of recommended colors for the vehicle. Compile and save. 10. Test the vehicle . Launch CARLA, open a terminal in PythonAPI/examples and run the following command: python3 manual_control.py --filter <model_name> # The make or model defined in step 9 Note Even if you used upper case characters in your make and model, they need to be converted to lower case when passed to the filter.","title":"Import and configure the vehicle"},{"location":"tuto_A_add_vehicle/#add-a-2-wheeled-vehicle","text":"Adding 2 wheeled vehicles is similar to adding a 4 wheeled one but due to the complexity of the animation you'll need to set up aditional bones to guide the driver's animation. Here is the link to the reference skeleton for 2 wheeled vehicles. As with the 4 wheeled vehicles, orient the model towards positive \"x\" and every bone axis towards positive x and with the z axis facing upwards. Bone Setup: - Bike_Rig: # The origin point of the mesh. Place it in the point 0 of the scenecomment - BikeBody: # The model's body centre. - Pedals: # If the vehicle is a bike bind the pedalier to this bone, will rotate with the bike acceleration. - RightPedal: # Sets the driver's feet position and rotates with the pedalier if the vehicle is a bike. - LeftPedal: # ^ - RearWheel: # Rear Wheel of the vehicle - Handler: # Rotates with the frontal wheel of the vehicle bind the vehicle handler to it. - HandlerMidBone: # Positioned over the front wheel bone to orient the handler with the wheel - HandlerRight: # Sets the position of the driver's hand, no need to bind it to anything. - HandlerLeft: # ^ - Frontwheel: # Frontal wheel of the vehicle. - RightHelperRotator: # This four additional bones are here for an obsolete system of making the bike stable by using aditional invisible wheels - RightHelprWheel: # ^ - LeftHelperRotator: # ^ - LeftHelperWheel: # ^ - Seat: # Sets the position of the drivers hip bone. No need to bind it to anything but place it carefully. 1. Import fbx as Skelletal Mesh to its own folder inside Content/Carla/Static/Vehicles/2Wheeled . When importing select \"General2WheeledVehicleSkeleton\" as skelleton A Physics asset should be automatically created and linked. 2. Tune the Physics asset. Delete the automatically created ones and add boxes to the BikeBody bone trying to match the shape as possible, make sure generate hit events is enabled. Add a sphere for each wheel and set their \"Physics Type\" to \"Kinematic\". 3. Create folder Content/Blueprints/Vehicles/<vehicle-model> 4. Inside that folder create two blueprint classes derived from \"VehicleWheel\" class. Call them <vehicle-model>_FrontWheel and <vehicle-model>_RearWheel . Set their \"Shape Radius\" to exactly match the mesh wheel radius (careful, radius not diameter). Set their \"Tire Config\" to \"CommonTireConfig\". On the front wheel uncheck \"Affected by Handbrake\" and on the rear wheel set \"Steer Angle\" to zero. 5. Inside the same folder create a blueprint class derived from Base2WheeledVehicle call it <vehicle-model> . Open it for edit and select component \"Mesh\", setup the \"Skeletal Mesh\" and the \"Anim Class\" to the corresponding ones. Then select the VehicleBounds component and set the size to cover vehicle's area as seen from above. 6. Select component \"VehicleMovement\", under \"Vehicle Setup\" expand \"Wheel Setups\", setup each wheel. 0: Wheel Class= <vehicle-model>_FrontWheel , Bone Name= FrontWheel 1: Wheel Class= <vehicle-model>_FrontWheel , Bone Name= FrontWheel 2: Wheel Class= <vehicle-model>_RearWheel , Bone Name= RearWheel 3: Wheel Class= <vehicle-model>_RearWheel , Bone Name= RearWheel (You'll notice that we are basically placing two wheels in each bone. The vehicle class unreal provides does not support vehicles with wheel numbers different from 4 so we had to make it believe the vehicle has 4 wheels) 7. Select the variable \"is bike\" and tick it if your model is a bike. This will activate the pedalier rotation. Leave unmarked if you are setting up a motorbike. 8. Find the variable back Rotation and set it as it fit better select the component SkeletalMesh (The driver) and move it along x axis until its in the seat position. 9. Test it, go to CarlaGameMode blueprint and change \"Default Pawn Class\" to the newly created bike blueprint.","title":"Add a 2 wheeled vehicle"},{"location":"tuto_A_create_standalone/","text":"Create distribution packages for assets It is a common practice in CARLA to manage assets with standalone packages. Keeping them aside allows to reduce the size of the build. These asset packages can be easily imported into a CARLA package anytime. They also become really useful to easily distribute assets in an organized way. Export a package from the UE4 Editor Export a package using Docker Import assets into a CARLA package Export a package in a CARLA build from source Once assets are imported into Unreal, users can generate a standalone package for them. This will be used to distribute the content to CARLA packages such as 0.9.8. To export packages, simply run the command below. make package ARGS=\"--packages=Package1,Package2\" This will create a standalone package compressed in a .tar.gz file for each of the packages listed. The files will be saved in Dist folder on Linux, and /Build/UE4Carla/ on Windows. Export a package using Docker Unreal Engine and CARLA can be built in a Docker image which can then be used to create a package or export assets for use in a package. To create the Docker image, follow the tutorial here . When you have the image ready: Navigate to Util/Docker . Create a CARLA package or prepare assets for use in a package by running one of the following commands: # To create a standalone package ./docker_tools.py --output /output/path #To cook assets to be consumed in a CARLA package ./docker_tools.py --input /assets/to/import/path --output /output/path --packages PkgeName1,PkgeName2 Import assets into a CARLA package A standalone package is contained in a .tar.gz file. The way this is extracted depends on the platform. On Windows extract the compressed file in the main root CARLA folder. On Linux move the compressed file to the Import folder and run the following script. cd Import ./ImportAssets.sh Note Standalone packages cannot be directly imported into a CARLA build. Follow the tutorials to import props , maps or vehicles . That sumps up how to create and use standalone packages in CARLA. If there is any unexpected issue, feel free to post in the forum. CARLA forum","title":"\u521b\u5efa\u72ec\u7acb\u5305"},{"location":"tuto_A_create_standalone/#create-distribution-packages-for-assets","text":"It is a common practice in CARLA to manage assets with standalone packages. Keeping them aside allows to reduce the size of the build. These asset packages can be easily imported into a CARLA package anytime. They also become really useful to easily distribute assets in an organized way. Export a package from the UE4 Editor Export a package using Docker Import assets into a CARLA package","title":"Create distribution packages for assets"},{"location":"tuto_A_create_standalone/#export-a-package-in-a-carla-build-from-source","text":"Once assets are imported into Unreal, users can generate a standalone package for them. This will be used to distribute the content to CARLA packages such as 0.9.8. To export packages, simply run the command below. make package ARGS=\"--packages=Package1,Package2\" This will create a standalone package compressed in a .tar.gz file for each of the packages listed. The files will be saved in Dist folder on Linux, and /Build/UE4Carla/ on Windows.","title":"Export a package in a CARLA build from source"},{"location":"tuto_A_create_standalone/#export-a-package-using-docker","text":"Unreal Engine and CARLA can be built in a Docker image which can then be used to create a package or export assets for use in a package. To create the Docker image, follow the tutorial here . When you have the image ready: Navigate to Util/Docker . Create a CARLA package or prepare assets for use in a package by running one of the following commands: # To create a standalone package ./docker_tools.py --output /output/path #To cook assets to be consumed in a CARLA package ./docker_tools.py --input /assets/to/import/path --output /output/path --packages PkgeName1,PkgeName2","title":"Export a package using Docker"},{"location":"tuto_A_create_standalone/#import-assets-into-a-carla-package","text":"A standalone package is contained in a .tar.gz file. The way this is extracted depends on the platform. On Windows extract the compressed file in the main root CARLA folder. On Linux move the compressed file to the Import folder and run the following script. cd Import ./ImportAssets.sh Note Standalone packages cannot be directly imported into a CARLA build. Follow the tutorials to import props , maps or vehicles . That sumps up how to create and use standalone packages in CARLA. If there is any unexpected issue, feel free to post in the forum. CARLA forum","title":"Import assets into a CARLA package"},{"location":"tuto_A_material_customization/","text":"Material customization The CARLA team prepares every asset to run under certain default settings. However, users that work in a build from source can modify these to best suit their needs. Car materials Customize car materials Exterior properties Building materials Customize a building material Important This tutorial only applies to users that work with a build from source, and have access to the Unreal Editor. Car materials In CARLA, there is a set of master materials that are used as templates for the different parts of the vehicle. An instance of these is created for each vehicle model, and then changed to the desired result. The master materials can be found in Content/Carla/Static/GenericMaterials/Vehicles , and these are the following. Master materials applied to cars. M_CarExterior_Master \u2014 Material applied to the body of the car. M_CarInterior_Master \u2014 Material applied to the inside of the car. M_CarLightsGlass_Master \u2014 Material applied to the glass covering car lights. M_CarWindows_Master \u2014 Material applied to the windows. M_CarLicensePlate_Master \u2014 Material applied to the license plate. M_CarVehicleLights_Master \u2014 Material applied to the car lights as an emissive texure. M_CarVehicleLigthsSirens_Master \u2014 Material applied to the sirens, if applicable. Customize car materials Create instances of the master materials and store them in the corresponding folder for the new model. Here is an example of the instances created for the police car available in the blueprint library, vehicle.dodge_charger.police . Instanced materials for the police car blueprint. Generic documentation for materials and how to work with them can be found in the UE Docs . All the materials can be modified to a great extent, but only the exterior one has properties worth mentioning. Others have certain properties that can be changed, such as opacity and color in glass materials, but it is not recommended to do so, except for specific purposes. Exterior properties The exterior material is applied to the body of the car, and it is the one that can be customized the most. Base color \u2014 Base color of the bodywork. Tint shade \u2014 Tint color which visibility varies depending on the angle of visualization. Red car with pink tint. On the left, tint is disabled, on the right, enabled. Dust \u2014 A texture of dirt applied to the car. Dust is meant to pile on top of the geometry, and it is barely noticeable in the bottom parts. If the geometry is rotated, the dust will appear on the parts of the vehicle that are on top. Amount \u2014 Opacity of the texture. Color \u2014 Base color of the dust texture. Tiling \u2014 Size and repetition of the dust texture pattern. Thickness \u2014 Density of the dust. Roughness \u2014 Decrease of the car's metallic reflections due to dust. Dust property in a car's material. Flakes \u2014 Sparkling flakes to the metallic paint of the car. On/Off \u2014 Enables or disables the feature. Scale \u2014 Size of the flakes. Brightness \u2014 Intensity of the sparkle. Color \u2014 Base color of the particles. Flakes property in a car's material. Gain \u2014 Noise to the base paint of the car. On/Off \u2014 Enables or disables the feature. Scale \u2014 Size of the gain. Color \u2014 Base color of the gain. Gain property in a car's material. Mud \u2014 A texture of mud applied to the car. Mud appears from the bottom to top of the car. Height \u2014 Portion of the car where mud appears. Mud_Color \u2014 Base color of the mud texture. Mud_Tiling \u2014 Size and repetition of the mud texture pattern. Mud_Thickness \u2014 Density of the mud. Mud property in a car's material. Noise \u2014 Noise applied to the normal of the material. Creates an orange peel effect. On/Off \u2014 Enables or disables the feature. Scale \u2014 Size of the bumps created by the alteration of the normal map. Noise property in a car's material. Surface \u2014 Gloss and transparent coating applied to the vehicle's paint. This last step in automotive paint . ClearCoat \u2014 Opacity of the coating. ClearCoat_Brightness \u2014 Glossiness of the resulting material. ClearCoat_Metallic \u2014 Reflection of the resulting material. Visualization of the Surface coating applied to a material. Building materials The materials applied to buildings are made of four basic textures that are combined to determine the basic properties of the material. Diffuse \u2014 Contains the basic painting of the material. RGB \u2014 Channels with the base colors. Alpha \u2014 This channel defines a mask that allows to modify the color of the portions in white. This is useful to create some variations from the same material. ORME \u2014 Maps different properties of the material using specific channels. Ambient occlusion \u2014 Contained in the R channel. Roughness \u2014 Contained in the G channel. Metallic map \u2014 Contained in the B channel. Emissive mask \u2014 Contained in the Alpha channel. This mask allows to change the emissive color and intensity of the portions in white. Normal \u2014 Contains the normal map of the material. RGB \u2014 The normal map information. Emissive \u2014 If applicable, this texture is used to set the emissive base colors of the texture. RGB \u2014 Color information for the emissive elements in the texture. Customize a building material Similarly to car materials, a building material can be greatly changed if desired, but it is only recommended if the user has some expertise with Unreal Engine. However, there is some customization available for the two main shaders that buildings use. Glass shader \u2014 M_GlassMaster . Opacity \u2014 Enable color changes on the white area on the Diffuse Alpha texture. Color \u2014 Tint to be applied based on the white area on the Diffuse Alpha texture. Building shader \u2014 M_MaterialMaster Change Color \u2014 Enable color changes on the white area on the Diffuse Alpha texture. Color \u2014 Tint to be applied based on the white area on the Diffuse Alpha texture. Emissive Texture \u2014 Enable the usage of an Emissive texture. EmissiveColor \u2014 Tint to be applied based on the white area on the ORME Emissive mask texture. Emissive atenuance \u2014 Factor that divides the intensity stated in BP_Lights to obtain proper emissive values. RoughnessCorrection \u2014 Changes the intensity of the roughness map. MetallicCorrection \u2014 Changes the intensity of the metallic map. NormalFlatness \u2014 Changes the intensity of the normal map. That is a wrap on the most remarkable ways users can customize the materials of vehicles and buildings. Any doubts that may arise are more than welcomed in the forum. CARLA forum","title":"\u6750\u6599\u5b9a\u5236"},{"location":"tuto_A_material_customization/#material-customization","text":"The CARLA team prepares every asset to run under certain default settings. However, users that work in a build from source can modify these to best suit their needs. Car materials Customize car materials Exterior properties Building materials Customize a building material Important This tutorial only applies to users that work with a build from source, and have access to the Unreal Editor.","title":"Material customization"},{"location":"tuto_A_material_customization/#car-materials","text":"In CARLA, there is a set of master materials that are used as templates for the different parts of the vehicle. An instance of these is created for each vehicle model, and then changed to the desired result. The master materials can be found in Content/Carla/Static/GenericMaterials/Vehicles , and these are the following. Master materials applied to cars. M_CarExterior_Master \u2014 Material applied to the body of the car. M_CarInterior_Master \u2014 Material applied to the inside of the car. M_CarLightsGlass_Master \u2014 Material applied to the glass covering car lights. M_CarWindows_Master \u2014 Material applied to the windows. M_CarLicensePlate_Master \u2014 Material applied to the license plate. M_CarVehicleLights_Master \u2014 Material applied to the car lights as an emissive texure. M_CarVehicleLigthsSirens_Master \u2014 Material applied to the sirens, if applicable.","title":"Car materials"},{"location":"tuto_A_material_customization/#customize-car-materials","text":"Create instances of the master materials and store them in the corresponding folder for the new model. Here is an example of the instances created for the police car available in the blueprint library, vehicle.dodge_charger.police . Instanced materials for the police car blueprint. Generic documentation for materials and how to work with them can be found in the UE Docs . All the materials can be modified to a great extent, but only the exterior one has properties worth mentioning. Others have certain properties that can be changed, such as opacity and color in glass materials, but it is not recommended to do so, except for specific purposes.","title":"Customize car materials"},{"location":"tuto_A_material_customization/#exterior-properties","text":"The exterior material is applied to the body of the car, and it is the one that can be customized the most. Base color \u2014 Base color of the bodywork. Tint shade \u2014 Tint color which visibility varies depending on the angle of visualization. Red car with pink tint. On the left, tint is disabled, on the right, enabled. Dust \u2014 A texture of dirt applied to the car. Dust is meant to pile on top of the geometry, and it is barely noticeable in the bottom parts. If the geometry is rotated, the dust will appear on the parts of the vehicle that are on top. Amount \u2014 Opacity of the texture. Color \u2014 Base color of the dust texture. Tiling \u2014 Size and repetition of the dust texture pattern. Thickness \u2014 Density of the dust. Roughness \u2014 Decrease of the car's metallic reflections due to dust. Dust property in a car's material. Flakes \u2014 Sparkling flakes to the metallic paint of the car. On/Off \u2014 Enables or disables the feature. Scale \u2014 Size of the flakes. Brightness \u2014 Intensity of the sparkle. Color \u2014 Base color of the particles. Flakes property in a car's material. Gain \u2014 Noise to the base paint of the car. On/Off \u2014 Enables or disables the feature. Scale \u2014 Size of the gain. Color \u2014 Base color of the gain. Gain property in a car's material. Mud \u2014 A texture of mud applied to the car. Mud appears from the bottom to top of the car. Height \u2014 Portion of the car where mud appears. Mud_Color \u2014 Base color of the mud texture. Mud_Tiling \u2014 Size and repetition of the mud texture pattern. Mud_Thickness \u2014 Density of the mud. Mud property in a car's material. Noise \u2014 Noise applied to the normal of the material. Creates an orange peel effect. On/Off \u2014 Enables or disables the feature. Scale \u2014 Size of the bumps created by the alteration of the normal map. Noise property in a car's material. Surface \u2014 Gloss and transparent coating applied to the vehicle's paint. This last step in automotive paint . ClearCoat \u2014 Opacity of the coating. ClearCoat_Brightness \u2014 Glossiness of the resulting material. ClearCoat_Metallic \u2014 Reflection of the resulting material. Visualization of the Surface coating applied to a material.","title":"Exterior properties"},{"location":"tuto_A_material_customization/#building-materials","text":"The materials applied to buildings are made of four basic textures that are combined to determine the basic properties of the material. Diffuse \u2014 Contains the basic painting of the material. RGB \u2014 Channels with the base colors. Alpha \u2014 This channel defines a mask that allows to modify the color of the portions in white. This is useful to create some variations from the same material. ORME \u2014 Maps different properties of the material using specific channels. Ambient occlusion \u2014 Contained in the R channel. Roughness \u2014 Contained in the G channel. Metallic map \u2014 Contained in the B channel. Emissive mask \u2014 Contained in the Alpha channel. This mask allows to change the emissive color and intensity of the portions in white. Normal \u2014 Contains the normal map of the material. RGB \u2014 The normal map information. Emissive \u2014 If applicable, this texture is used to set the emissive base colors of the texture. RGB \u2014 Color information for the emissive elements in the texture.","title":"Building materials"},{"location":"tuto_A_material_customization/#customize-a-building-material","text":"Similarly to car materials, a building material can be greatly changed if desired, but it is only recommended if the user has some expertise with Unreal Engine. However, there is some customization available for the two main shaders that buildings use. Glass shader \u2014 M_GlassMaster . Opacity \u2014 Enable color changes on the white area on the Diffuse Alpha texture. Color \u2014 Tint to be applied based on the white area on the Diffuse Alpha texture. Building shader \u2014 M_MaterialMaster Change Color \u2014 Enable color changes on the white area on the Diffuse Alpha texture. Color \u2014 Tint to be applied based on the white area on the Diffuse Alpha texture. Emissive Texture \u2014 Enable the usage of an Emissive texture. EmissiveColor \u2014 Tint to be applied based on the white area on the ORME Emissive mask texture. Emissive atenuance \u2014 Factor that divides the intensity stated in BP_Lights to obtain proper emissive values. RoughnessCorrection \u2014 Changes the intensity of the roughness map. MetallicCorrection \u2014 Changes the intensity of the metallic map. NormalFlatness \u2014 Changes the intensity of the normal map. That is a wrap on the most remarkable ways users can customize the materials of vehicles and buildings. Any doubts that may arise are more than welcomed in the forum. CARLA forum","title":"Customize a building material"},{"location":"tuto_D_contribute_assets/","text":"How to upgrade content Our content resides on a separate Git LFS repository . As part of our build system, we generate and upload a package containing the latest version of this content tagged with the current date and commit. Regularly, we upgrade the CARLA repository with a link to the latest version of the content package. This document contains the manual steps necessary to update this link to the latest version. Copy the tag of the content package you wish to link. This tag can be found by looking at the package name generated in the artifacts section of the latest Jenkins build , e.g., 20190617_086f97f.tar.gz . Paste the tag in ContentVersions.txt. Edit ContentVersions.txt by pasting the tag at the end of the file, e.g. Latest: 20190617_086f97f (without the .tar.gz part). Open a Pull Request. Commit the changes and open a new Pull Request.","title":"\u5982\u4f55\u5347\u7ea7\u5185\u5bb9"},{"location":"tuto_D_contribute_assets/#how-to-upgrade-content","text":"Our content resides on a separate Git LFS repository . As part of our build system, we generate and upload a package containing the latest version of this content tagged with the current date and commit. Regularly, we upgrade the CARLA repository with a link to the latest version of the content package. This document contains the manual steps necessary to update this link to the latest version. Copy the tag of the content package you wish to link. This tag can be found by looking at the package name generated in the artifacts section of the latest Jenkins build , e.g., 20190617_086f97f.tar.gz . Paste the tag in ContentVersions.txt. Edit ContentVersions.txt by pasting the tag at the end of the file, e.g. Latest: 20190617_086f97f (without the .tar.gz part). Open a Pull Request. Commit the changes and open a new Pull Request.","title":"How to upgrade content"},{"location":"tuto_D_create_semantic_tags/","text":"Create semantic tags Learn how to define customized tags for semantic segmentation. These can additionally be added to carla.CityObjectLabel to filter the bounding boxes that carla.World retrieves. Create a new semantic tag 1. Create the tag ID 2. Create the UE folder for assets 3. Create two-way correspondence between UE and the code tag 4. Define a color code 5. Add the tagged elements Add a tag to carla.CityObjectLabel Create a new semantic tag 1. Create the tag ID Open ObjectLabel.h in LibCarla/source/carla/rpc . Add your new tag by the end of the enum using the same formatting as the rest. Note Tags do not have to appear in order. However, it is good practice to list them in order. 2. Create the UE folder for assets Open the Unreal Engine Editor and go to Carla/Static . Create a new folder named as your tag. Note The UE folder and the tag do not necessarily have to be named the same. However, it is good practice to do so. 3. Create two-way correspondence between UE and the code tag 3.1. Open Tagger.cpp in Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Game . Go to GetLabelByFolderName Add the your tag by the end of the list. The string being compared is the name of the UE folder used in 2. , so use the exact same name here. 3.2. Go to GetTagAsString in the same Tagger.cpp . Add the new tag by the end of the switch. 4. Define a color code Open CityScapesPalette.h in LibCarla/source/carla/image . Add the color code of your new tag by the end of the array. Warning The position in the array must correspond with the tag ID, in this case, 23u . 5. Add the tagged meshes The new semantic tag is ready to be used. Only the meshes stored inside the UE folder of a tag are tagged as such. Move or import the corresponding meshes to the new folder, in order for the to be tagged properly. Add a tag to carla.CityObjectLabel This step is not directly related with semantic segmentation. However, these tags can be used to filter the bounding box query in carla.World . In order to do this, the tag must be added to the carla.CityObjectLabel enum in the PythonAPI. Open World.cpp in carla/PythonAPI/carla/source/libcarla and add the new tag by the end of the enum. Read the F.A.Q. page or post in the CARLA forum for any issues, doubts or suggestions. What's next? Sensors reference Add new props","title":"\u521b\u5efa\u8bed\u4e49\u6807\u7b7e"},{"location":"tuto_D_create_semantic_tags/#create-semantic-tags","text":"Learn how to define customized tags for semantic segmentation. These can additionally be added to carla.CityObjectLabel to filter the bounding boxes that carla.World retrieves. Create a new semantic tag 1. Create the tag ID 2. Create the UE folder for assets 3. Create two-way correspondence between UE and the code tag 4. Define a color code 5. Add the tagged elements Add a tag to carla.CityObjectLabel","title":"Create semantic tags"},{"location":"tuto_D_create_semantic_tags/#create-a-new-semantic-tag","text":"","title":"Create a new semantic tag"},{"location":"tuto_D_create_semantic_tags/#1-create-the-tag-id","text":"Open ObjectLabel.h in LibCarla/source/carla/rpc . Add your new tag by the end of the enum using the same formatting as the rest. Note Tags do not have to appear in order. However, it is good practice to list them in order.","title":"1. Create the tag ID"},{"location":"tuto_D_create_semantic_tags/#2-create-the-ue-folder-for-assets","text":"Open the Unreal Engine Editor and go to Carla/Static . Create a new folder named as your tag. Note The UE folder and the tag do not necessarily have to be named the same. However, it is good practice to do so.","title":"2. Create the UE folder for assets"},{"location":"tuto_D_create_semantic_tags/#3-create-two-way-correspondence-between-ue-and-the-code-tag","text":"3.1. Open Tagger.cpp in Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Game . Go to GetLabelByFolderName Add the your tag by the end of the list. The string being compared is the name of the UE folder used in 2. , so use the exact same name here. 3.2. Go to GetTagAsString in the same Tagger.cpp . Add the new tag by the end of the switch.","title":"3. Create two-way correspondence between UE and the code tag"},{"location":"tuto_D_create_semantic_tags/#4-define-a-color-code","text":"Open CityScapesPalette.h in LibCarla/source/carla/image . Add the color code of your new tag by the end of the array. Warning The position in the array must correspond with the tag ID, in this case, 23u .","title":"4. Define a color code"},{"location":"tuto_D_create_semantic_tags/#5-add-the-tagged-meshes","text":"The new semantic tag is ready to be used. Only the meshes stored inside the UE folder of a tag are tagged as such. Move or import the corresponding meshes to the new folder, in order for the to be tagged properly.","title":"5. Add the tagged meshes"},{"location":"tuto_D_create_semantic_tags/#add-a-tag-to-carlacityobjectlabel","text":"This step is not directly related with semantic segmentation. However, these tags can be used to filter the bounding box query in carla.World . In order to do this, the tag must be added to the carla.CityObjectLabel enum in the PythonAPI. Open World.cpp in carla/PythonAPI/carla/source/libcarla and add the new tag by the end of the enum. Read the F.A.Q. page or post in the CARLA forum for any issues, doubts or suggestions. What's next? Sensors reference Add new props","title":"Add a tag to carla.CityObjectLabel"},{"location":"tuto_D_create_sensor/","text":"How to add a new sensor This tutorial explains the basics for adding a new sensor to CARLA. It provides the necessary steps to implement a sensor in Unreal Engine 4 (UE4) and expose its data via CARLA's Python API. We'll follow all the steps by creating a new sensor as an example. Prerequisites Introduction Creating a new sensor 1- Sensor actor 2- Sensor data serializer 3- Sensor data object 4- Register your sensor 5- Usage example Appendix Reusing buffers Sending data asynchronously Client-side sensors Prerequisites In order to implement a new sensor, you'll need to compile CARLA source code, for detailed instructions on how to achieve this see Building from source . This tutorial also assumes the reader is fluent in C++ programming. Introduction Sensors in CARLA are a special type of actor that produce a stream of data. Some sensors produce data continuously, every time the sensor is updated, other produce data only after certain events. For instance, a camera produces an image on every update, but a collision sensor is only triggered in the event of a collision. Although most sensors compute their measurements in the server side (UE4), it's worth noticing that some sensors run in the client-side only. An example of such sensor is the LaneInvasion, it notifies every time a lane mark has been crossed. For further details see Appendix: Client-side sensors . In this tutorial, we'll be focusing on server-side sensors. In order to have a sensor running inside UE4 sending data all the way to a Python client, we need to cover the whole communication pipeline. Thus we'll need the following classes covering the different steps of the pipeline Sensor actor Actor in charge of measuring and/or simulating data. Running in Carla plugin using UE4 framework. Accessible by the user as Sensor actor. Serializer Object containing methods for serializing and deserializing the data generated by the sensor. Running in LibCarla, both server and client. Sensor data Object representing the data generated by the sensor. This is the object that will be passed to the final user, both in C++ and Python APIs. Note To ensure best performance, sensors are registered and dispatched using a sort of \"compile-time plugin system\" based on template meta-programming. Most likely, the code won't compile until all the pieces are present. Creating a new sensor Full source code here. We're going to create a sensor that detects other actors around our vehicle. For that we'll create a trigger box that detects objects within, and we'll be reporting status to the client every time a vehicle is inside our trigger box. Let's call it Safe Distance Sensor . For the sake of simplicity we're not going to take into account all the edge cases, nor it will be implemented in the most efficient way. This is just an illustrative example. 1- Sensor actor This is the most complicated class we're going to create. Here we're running inside Unreal Engine framework, knowledge of UE4 API will be very helpful but not indispensable, we'll assume the reader has never worked with UE4 before. Inside UE4, we have a similar hierarchy as we have in the client-side, ASensor derives from AActor , and an actor is roughly any object that can be dropped into the world. AActor has a virtual function called Tick that we can use to update our sensor on every simulator update. Higher in the hierarchy we have UObject , base class for most of UE4 classes. It is important to know that objects deriving from UObject are handle via pointers and are garbage collected when they're no longer referenced. Class members pointing to UObject s need to be marked with UPROPERTY macros or they'll be garbage collected. Let's start. This class has to be located inside Carla plugin, we'll create two files for our new C++ class Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/SafeDistanceSensor.h Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/SafeDistanceSensor.cpp At the very minimum, the sensor is required to inherit ASensor , and provide a static method GetSensorDefinition ; but we'll be overriding also the Set , SetOwner , and Tick methods. This sensor also needs a trigger box that will be detecting other actors around us. With this and some required boiler-plate UE4 code, the header file looks like #pragma once #include \"Carla/Sensor/Sensor.h\" #include \"Carla/Actor/ActorDefinition.h\" #include \"Carla/Actor/ActorDescription.h\" #include \"Components/BoxComponent.h\" #include \"SafeDistanceSensor.generated.h\" UCLASS() class CARLA_API ASafeDistanceSensor : public ASensor { GENERATED_BODY() public: ASafeDistanceSensor(const FObjectInitializer &ObjectInitializer); static FActorDefinition GetSensorDefinition(); void Set(const FActorDescription &ActorDescription) override; void SetOwner(AActor *Owner) override; void Tick(float DeltaSeconds) override; private: UPROPERTY() UBoxComponent *Box = nullptr; }; In the cpp file, first we'll need some includes #include \"Carla.h\" #include \"Carla/Sensor/SafeDistanceSensor.h\" #include \"Carla/Actor/ActorBlueprintFunctionLibrary.h\" #include \"Carla/Game/CarlaEpisode.h\" #include \"Carla/Util/BoundingBoxCalculator.h\" #include \"Carla/Vehicle/CarlaWheeledVehicle.h\" Then we can proceed to implement the functionality. The constructor will create the trigger box, and tell UE4 that we want our tick function to be called. If our sensor were not using the tick function, we can disable it here to avoid unnecessary ticks ASafeDistanceSensor::ASafeDistanceSensor(const FObjectInitializer &ObjectInitializer) : Super(ObjectInitializer) { Box = CreateDefaultSubobject<UBoxComponent>(TEXT(\"BoxOverlap\")); Box->SetupAttachment(RootComponent); Box->SetHiddenInGame(true); // Disable for debugging. Box->SetCollisionProfileName(FName(\"OverlapAll\")); PrimaryActorTick.bCanEverTick = true; } Now we need to tell Carla what attributes this sensor has, this is going to be used to create a new blueprint in our blueprint library, users can use this blueprint to configure and spawn this sensor. We're going to define here the attributes of our trigger box, in this example we'll expose only X and Y safe distances FActorDefinition ASafeDistanceSensor::GetSensorDefinition() { auto Definition = UActorBlueprintFunctionLibrary::MakeGenericSensorDefinition( TEXT(\"other\"), TEXT(\"safe_distance\")); FActorVariation Front; Front.Id = TEXT(\"safe_distance_front\"); Front.Type = EActorAttributeType::Float; Front.RecommendedValues = { TEXT(\"1.0\") }; Front.bRestrictToRecommended = false; FActorVariation Back; Back.Id = TEXT(\"safe_distance_back\"); Back.Type = EActorAttributeType::Float; Back.RecommendedValues = { TEXT(\"0.5\") }; Back.bRestrictToRecommended = false; FActorVariation Lateral; Lateral.Id = TEXT(\"safe_distance_lateral\"); Lateral.Type = EActorAttributeType::Float; Lateral.RecommendedValues = { TEXT(\"0.5\") }; Lateral.bRestrictToRecommended = false; Definition.Variations.Append({ Front, Back, Lateral }); return Definition; } With this, the sensor factory is able to create a Safe Distance Sensor on user demand. Immediately after the sensor is created, the Set function is called with the parameters that the user requested void ASafeDistanceSensor::Set(const FActorDescription &Description) { Super::Set(Description); float Front = UActorBlueprintFunctionLibrary::RetrieveActorAttributeToFloat( \"safe_distance_front\", Description.Variations, 1.0f); float Back = UActorBlueprintFunctionLibrary::RetrieveActorAttributeToFloat( \"safe_distance_back\", Description.Variations, 0.5f); float Lateral = UActorBlueprintFunctionLibrary::RetrieveActorAttributeToFloat( \"safe_distance_lateral\", Description.Variations, 0.5f); constexpr float M_TO_CM = 100.0f; // Unit conversion. float LocationX = M_TO_CM * (Front - Back) / 2.0f; float ExtentX = M_TO_CM * (Front + Back) / 2.0f; float ExtentY = M_TO_CM * Lateral; Box->SetRelativeLocation(FVector{LocationX, 0.0f, 0.0f}); Box->SetBoxExtent(FVector{ExtentX, ExtentY, 0.0f}); } Note that the set function is called before UE4's BeginPlay , we won't use this virtual function here, but it's important for other sensors. Now we're going to extend the box volume based on the bounding box of the actor that we're attached to. For that, the most convenient method is to use the SetOwner virtual function. This function is called when our sensor is attached to another actor. void ASafeDistanceSensor::SetOwner(AActor *Owner) { Super::SetOwner(Owner); auto BoundingBox = UBoundingBoxCalculator::GetActorBoundingBox(Owner); Box->SetBoxExtent(BoundingBox.Extent + Box->GetUnscaledBoxExtent()); } The only thing left to do is the actual measurement, for that we'll use the Tick function. We're going to look for all the vehicles currently overlapping our box, and we'll send this list to client void ASafeDistanceSensor::Tick(float DeltaSeconds) { Super::Tick(DeltaSeconds); TSet<AActor *> DetectedActors; Box->GetOverlappingActors(DetectedActors, ACarlaWheeledVehicle::StaticClass()); DetectedActors.Remove(GetOwner()); if (DetectedActors.Num() > 0) { auto Stream = GetDataStream(*this); Stream.Send(*this, GetEpisode(), DetectedActors); } } Note In production-ready sensors, the Tick function should be very optimized, specially if the sensor sends big chunks of data. This function is called every update in the game thread thus significantly affects the performance of the simulator. Ok, a couple of things going on here that we haven't mentioned yet, what's this stream? Every sensor has a data stream associated. This stream is used to send data down to the client, and this is the stream you subscribe to when you use the sensor.listen(callback) method in the Python API. Every time you send here some data, the callback on the client-side is going to be triggered. But before that, the data is going to travel through several layers. First of them will be the serializer that we have to create next. We'll fully understand this part once we have completed the Serialize function in the next section. 2- Sensor data serializer This class is actually rather simple, it's only required to have two static methods, Serialize and Deserialize . We'll add two files for it, this time to LibCarla LibCarla/source/carla/sensor/s11n/SafeDistanceSerializer.h LibCarla/source/carla/sensor/s11n/SafeDistanceSerializer.cpp Let's start with the Serialize function. This function is going to receive as arguments whatever we pass to the Stream.Send(...) function, with the only condition that the first argument has to be a sensor and it has to return a buffer. static Buffer Serialize(const Sensor &, ...); A carla::Buffer is just a dynamically allocated piece of raw memory with some convenient functionality, we're going to use it to send raw data to the client. In this example, we need to write the list of detected actors to a buffer in a way that it can be meaningful in the client-side. That's why we passed the episode object to this function. The UCarlaEpisode class represent the current episode running in the simulator, i.e. the state of the simulation since last time we loaded a map. It contains all the relevant information to Carla, and among other things, it allows searching for actor IDs. We can send these IDs to the client and the client will be able to recognise these as actors template <typename SensorT, typename EpisodeT, typename ActorListT> static Buffer Serialize( const SensorT &, const EpisodeT &episode, const ActorListT &detected_actors) { const uint32_t size_in_bytes = sizeof(ActorId) * detected_actors.Num(); Buffer buffer{size_in_bytes}; unsigned char *it = buffer.data(); for (auto *actor : detected_actors) { ActorId id = episode.FindActor(actor).GetActorId(); std::memcpy(it, &id, sizeof(ActorId)); it += sizeof(ActorId); } return buffer; } Note that we templatize the UE4 classes to avoid including these files within LibCarla. This buffer we're returning is going to come back to us, except that this time in the client-side, in the Deserialize function packed in a RawData object static SharedPtr<SensorData> Deserialize(RawData &&data); We'll implement this method in the cpp file, and it's rather simple SharedPtr<SensorData> SafeDistanceSerializer::Deserialize(RawData &&data) { return SharedPtr<SensorData>(new data::SafeDistanceEvent(std::move(data))); } except for the fact that we haven't defined yet what's a SafeDistanceEvent . 3- Sensor data object We need to create a data object for the users of this sensor, representing the data of a safe distance event . We'll add this file to LibCarla/source/carla/sensor/data/SafeDistanceEvent.h This object is going to be equivalent to a list of actor IDs. For that, we'll derive from the Array template #pragma once #include \"carla/rpc/ActorId.h\" #include \"carla/sensor/data/Array.h\" namespace carla { namespace sensor { namespace data { class SafeDistanceEvent : public Array<rpc::ActorId> { public: explicit SafeDistanceEvent(RawData &&data) : Array<rpc::ActorId>(std::move(data)) {} }; } // namespace data } // namespace sensor } // namespace carla The Array template is going to reinterpret the buffer we created in the Serialize method as an array of actor IDs, and it's able to do so directly from the buffer we received, without allocating any new memory. Although for this small example may seem a bit overkill, this mechanism is also used for big chunks of data; imagine we're sending HD images, we save a lot by reusing the raw memory. Now we need to expose this class to Python. In our example, we haven't add any extra methods, so we'll just expose the methods related to Array. We do so by using Boost.Python bindings, add the following to PythonAPI/carla/source/libcarla/SensorData.cpp . class_< csd::SafeDistanceEvent, // actual type. bases<cs::SensorData>, // parent type. boost::noncopyable, // disable copy. boost::shared_ptr<csd::SafeDistanceEvent> // use as shared_ptr. >(\"SafeDistanceEvent\", no_init) // name, and disable construction. .def(\"__len__\", &csd::SafeDistanceEvent::size) .def(\"__iter__\", iterator<csd::SafeDistanceEvent>()) .def(\"__getitem__\", +[](const csd::SafeDistanceEvent &self, size_t pos) -> cr::ActorId { return self.at(pos); }) ; Note that csd is an alias for the namespace carla::sensor::data . What we're doing here is exposing some C++ methods in Python. Just with this, the Python API will be able to recognise our new event and it'll behave similar to an array in Python, except that cannot be modified. 4- Register your sensor Now that the pipeline is complete, we're ready to register our new sensor. We do so in LibCarla/source/carla/sensor/SensorRegistry.h . Follow the instruction in this header file to add the different includes and forward declarations, and add the following pair to the registry std::pair<ASafeDistanceSensor *, s11n::SafeDistanceSerializer> With this, the sensor registry now can do its magic to dispatch the right data to the right serializer. Now recompile CARLA, hopefully everything goes ok and no errors. Unfortunately, most of the errors here will be related to templates and the error messages can be a bit cryptic. make rebuild 5- Usage example Finally, we have the sensor included and we have finished recompiling, our sensor by now should be available in Python. To spawn this sensor, we simply need to find it in the blueprint library, if everything went right, the sensor factory should have added our sensor to the library blueprint = blueprint_library.find('sensor.other.safe_distance') sensor = world.spawn_actor(blueprint, carla.Transform(), attach_to=vehicle) and now we can start listening for events by registering a callback function world_ref = weakref.ref(world) def callback(event): for actor_id in event: vehicle = world_ref().get_actor(actor_id) print('Vehicle too close: %s' % vehicle.type_id) sensor.listen(callback) This callback is going to execute every update that another vehicle is inside our safety distance box, e.g. Vehicle too close: vehicle.audi.a2 Vehicle too close: vehicle.mercedes-benz.coupe That's it, we have a new sensor working! Appendix Reusing buffers In order to optimize memory usage, we can use the fact that each sensor sends buffers of similar size; in particularly, in the case of cameras, the size of the image is constant during execution. In those cases, we can save a lot by reusing the allocated memory between frames. Each stream contains a buffer pool that can be used to avoid unnecessary memory allocations. Remember that each sensor has a stream associated thus each sensor has its own buffer pool. Use the following to retrieve a buffer from the pool auto Buffer = Stream.PopBufferFromPool(); If the pool is empty, it returns an empty buffer, i.e. a buffer with no memory allocated. In that case, when you resize the buffer new memory will be allocated. This will happen a few times during the first frames. However, if a buffer was retrieved from the pool, its memory will go back to the pool once the buffer goes out of the scope. Next time you get another buffer from the pool, it'll contain the allocated piece of memory from the previous buffer. As you can see, a buffer object acts actually as an smart pointer to a contiguous piece of raw memory. As long as you don't request more memory than the currently allocated, the buffer reuses the memory. If you request more, then it'll have to delete the current memory and allocate a bigger chunk. The following snippet illustrates how buffers work Buffer buffer; buffer.reset(1024u); // (size 1024 bytes, capacity 1024 bytes) -> allocates buffer.reset(512u); // (size 512 bytes, capacity 1024 bytes) buffer.reset(2048u); // (size 2048 bytes, capacity 2048 bytes) -> allocates Sending data asynchronously Some sensors may require to send data asynchronously, either for performance or because the data is generated in a different thread, for instance, camera sensors send the images from the render thread. Using the data stream asynchronously is perfectly fine, as long as the stream itself is created in the game thread. For instance void MySensor::Tick(float DeltaSeconds) { Super::Tick(DeltaSeconds); auto Stream = GetDataStream(*this); std::async(std::launch::async, [Stream=std::move(Stream)]() { auto Data = ComputeData(); Stream.Send(*this, Data); }); } Client-side sensors Some sensors do not require the simulator to do their measurements, those sensors may run completely in the client-side freeing the simulator from extra computations. Examples of such sensors is the LaneInvasion sensors. The usual approach is to create a \"dummy\" sensor in the server-side, just so the simulator is aware that such actor exists. However, this dummy sensor doesn't tick nor sends any sort of data. Its counterpart on the client-side however, registers a \"on tick\" callback to execute some code on every new update. For instance, the LaneInvasion sensor registers a callback that notifies every time a lane mark has been crossed. It is very important to take into account that the \"on tick\" callback in the client-side is executed concurrently, i.e., the same method may be executed simultaneously by different threads. Any data accessed must be properly synchronized, either with a mutex, using atomics, or even better making sure all the members accessed remain constant.","title":"\u521b\u5efa\u4e00\u4e2a\u4f20\u611f\u5668"},{"location":"tuto_D_create_sensor/#how-to-add-a-new-sensor","text":"This tutorial explains the basics for adding a new sensor to CARLA. It provides the necessary steps to implement a sensor in Unreal Engine 4 (UE4) and expose its data via CARLA's Python API. We'll follow all the steps by creating a new sensor as an example. Prerequisites Introduction Creating a new sensor 1- Sensor actor 2- Sensor data serializer 3- Sensor data object 4- Register your sensor 5- Usage example Appendix Reusing buffers Sending data asynchronously Client-side sensors","title":"How to add a new sensor"},{"location":"tuto_D_create_sensor/#prerequisites","text":"In order to implement a new sensor, you'll need to compile CARLA source code, for detailed instructions on how to achieve this see Building from source . This tutorial also assumes the reader is fluent in C++ programming.","title":"Prerequisites"},{"location":"tuto_D_create_sensor/#introduction","text":"Sensors in CARLA are a special type of actor that produce a stream of data. Some sensors produce data continuously, every time the sensor is updated, other produce data only after certain events. For instance, a camera produces an image on every update, but a collision sensor is only triggered in the event of a collision. Although most sensors compute their measurements in the server side (UE4), it's worth noticing that some sensors run in the client-side only. An example of such sensor is the LaneInvasion, it notifies every time a lane mark has been crossed. For further details see Appendix: Client-side sensors . In this tutorial, we'll be focusing on server-side sensors. In order to have a sensor running inside UE4 sending data all the way to a Python client, we need to cover the whole communication pipeline. Thus we'll need the following classes covering the different steps of the pipeline Sensor actor Actor in charge of measuring and/or simulating data. Running in Carla plugin using UE4 framework. Accessible by the user as Sensor actor. Serializer Object containing methods for serializing and deserializing the data generated by the sensor. Running in LibCarla, both server and client. Sensor data Object representing the data generated by the sensor. This is the object that will be passed to the final user, both in C++ and Python APIs. Note To ensure best performance, sensors are registered and dispatched using a sort of \"compile-time plugin system\" based on template meta-programming. Most likely, the code won't compile until all the pieces are present.","title":"Introduction"},{"location":"tuto_D_create_sensor/#creating-a-new-sensor","text":"Full source code here. We're going to create a sensor that detects other actors around our vehicle. For that we'll create a trigger box that detects objects within, and we'll be reporting status to the client every time a vehicle is inside our trigger box. Let's call it Safe Distance Sensor . For the sake of simplicity we're not going to take into account all the edge cases, nor it will be implemented in the most efficient way. This is just an illustrative example.","title":"Creating a new sensor"},{"location":"tuto_D_create_sensor/#1-sensor-actor","text":"This is the most complicated class we're going to create. Here we're running inside Unreal Engine framework, knowledge of UE4 API will be very helpful but not indispensable, we'll assume the reader has never worked with UE4 before. Inside UE4, we have a similar hierarchy as we have in the client-side, ASensor derives from AActor , and an actor is roughly any object that can be dropped into the world. AActor has a virtual function called Tick that we can use to update our sensor on every simulator update. Higher in the hierarchy we have UObject , base class for most of UE4 classes. It is important to know that objects deriving from UObject are handle via pointers and are garbage collected when they're no longer referenced. Class members pointing to UObject s need to be marked with UPROPERTY macros or they'll be garbage collected. Let's start. This class has to be located inside Carla plugin, we'll create two files for our new C++ class Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/SafeDistanceSensor.h Unreal/CarlaUE4/Plugins/Carla/Source/Carla/Sensor/SafeDistanceSensor.cpp At the very minimum, the sensor is required to inherit ASensor , and provide a static method GetSensorDefinition ; but we'll be overriding also the Set , SetOwner , and Tick methods. This sensor also needs a trigger box that will be detecting other actors around us. With this and some required boiler-plate UE4 code, the header file looks like #pragma once #include \"Carla/Sensor/Sensor.h\" #include \"Carla/Actor/ActorDefinition.h\" #include \"Carla/Actor/ActorDescription.h\" #include \"Components/BoxComponent.h\" #include \"SafeDistanceSensor.generated.h\" UCLASS() class CARLA_API ASafeDistanceSensor : public ASensor { GENERATED_BODY() public: ASafeDistanceSensor(const FObjectInitializer &ObjectInitializer); static FActorDefinition GetSensorDefinition(); void Set(const FActorDescription &ActorDescription) override; void SetOwner(AActor *Owner) override; void Tick(float DeltaSeconds) override; private: UPROPERTY() UBoxComponent *Box = nullptr; }; In the cpp file, first we'll need some includes #include \"Carla.h\" #include \"Carla/Sensor/SafeDistanceSensor.h\" #include \"Carla/Actor/ActorBlueprintFunctionLibrary.h\" #include \"Carla/Game/CarlaEpisode.h\" #include \"Carla/Util/BoundingBoxCalculator.h\" #include \"Carla/Vehicle/CarlaWheeledVehicle.h\" Then we can proceed to implement the functionality. The constructor will create the trigger box, and tell UE4 that we want our tick function to be called. If our sensor were not using the tick function, we can disable it here to avoid unnecessary ticks ASafeDistanceSensor::ASafeDistanceSensor(const FObjectInitializer &ObjectInitializer) : Super(ObjectInitializer) { Box = CreateDefaultSubobject<UBoxComponent>(TEXT(\"BoxOverlap\")); Box->SetupAttachment(RootComponent); Box->SetHiddenInGame(true); // Disable for debugging. Box->SetCollisionProfileName(FName(\"OverlapAll\")); PrimaryActorTick.bCanEverTick = true; } Now we need to tell Carla what attributes this sensor has, this is going to be used to create a new blueprint in our blueprint library, users can use this blueprint to configure and spawn this sensor. We're going to define here the attributes of our trigger box, in this example we'll expose only X and Y safe distances FActorDefinition ASafeDistanceSensor::GetSensorDefinition() { auto Definition = UActorBlueprintFunctionLibrary::MakeGenericSensorDefinition( TEXT(\"other\"), TEXT(\"safe_distance\")); FActorVariation Front; Front.Id = TEXT(\"safe_distance_front\"); Front.Type = EActorAttributeType::Float; Front.RecommendedValues = { TEXT(\"1.0\") }; Front.bRestrictToRecommended = false; FActorVariation Back; Back.Id = TEXT(\"safe_distance_back\"); Back.Type = EActorAttributeType::Float; Back.RecommendedValues = { TEXT(\"0.5\") }; Back.bRestrictToRecommended = false; FActorVariation Lateral; Lateral.Id = TEXT(\"safe_distance_lateral\"); Lateral.Type = EActorAttributeType::Float; Lateral.RecommendedValues = { TEXT(\"0.5\") }; Lateral.bRestrictToRecommended = false; Definition.Variations.Append({ Front, Back, Lateral }); return Definition; } With this, the sensor factory is able to create a Safe Distance Sensor on user demand. Immediately after the sensor is created, the Set function is called with the parameters that the user requested void ASafeDistanceSensor::Set(const FActorDescription &Description) { Super::Set(Description); float Front = UActorBlueprintFunctionLibrary::RetrieveActorAttributeToFloat( \"safe_distance_front\", Description.Variations, 1.0f); float Back = UActorBlueprintFunctionLibrary::RetrieveActorAttributeToFloat( \"safe_distance_back\", Description.Variations, 0.5f); float Lateral = UActorBlueprintFunctionLibrary::RetrieveActorAttributeToFloat( \"safe_distance_lateral\", Description.Variations, 0.5f); constexpr float M_TO_CM = 100.0f; // Unit conversion. float LocationX = M_TO_CM * (Front - Back) / 2.0f; float ExtentX = M_TO_CM * (Front + Back) / 2.0f; float ExtentY = M_TO_CM * Lateral; Box->SetRelativeLocation(FVector{LocationX, 0.0f, 0.0f}); Box->SetBoxExtent(FVector{ExtentX, ExtentY, 0.0f}); } Note that the set function is called before UE4's BeginPlay , we won't use this virtual function here, but it's important for other sensors. Now we're going to extend the box volume based on the bounding box of the actor that we're attached to. For that, the most convenient method is to use the SetOwner virtual function. This function is called when our sensor is attached to another actor. void ASafeDistanceSensor::SetOwner(AActor *Owner) { Super::SetOwner(Owner); auto BoundingBox = UBoundingBoxCalculator::GetActorBoundingBox(Owner); Box->SetBoxExtent(BoundingBox.Extent + Box->GetUnscaledBoxExtent()); } The only thing left to do is the actual measurement, for that we'll use the Tick function. We're going to look for all the vehicles currently overlapping our box, and we'll send this list to client void ASafeDistanceSensor::Tick(float DeltaSeconds) { Super::Tick(DeltaSeconds); TSet<AActor *> DetectedActors; Box->GetOverlappingActors(DetectedActors, ACarlaWheeledVehicle::StaticClass()); DetectedActors.Remove(GetOwner()); if (DetectedActors.Num() > 0) { auto Stream = GetDataStream(*this); Stream.Send(*this, GetEpisode(), DetectedActors); } } Note In production-ready sensors, the Tick function should be very optimized, specially if the sensor sends big chunks of data. This function is called every update in the game thread thus significantly affects the performance of the simulator. Ok, a couple of things going on here that we haven't mentioned yet, what's this stream? Every sensor has a data stream associated. This stream is used to send data down to the client, and this is the stream you subscribe to when you use the sensor.listen(callback) method in the Python API. Every time you send here some data, the callback on the client-side is going to be triggered. But before that, the data is going to travel through several layers. First of them will be the serializer that we have to create next. We'll fully understand this part once we have completed the Serialize function in the next section.","title":"1- Sensor actor"},{"location":"tuto_D_create_sensor/#2-sensor-data-serializer","text":"This class is actually rather simple, it's only required to have two static methods, Serialize and Deserialize . We'll add two files for it, this time to LibCarla LibCarla/source/carla/sensor/s11n/SafeDistanceSerializer.h LibCarla/source/carla/sensor/s11n/SafeDistanceSerializer.cpp Let's start with the Serialize function. This function is going to receive as arguments whatever we pass to the Stream.Send(...) function, with the only condition that the first argument has to be a sensor and it has to return a buffer. static Buffer Serialize(const Sensor &, ...); A carla::Buffer is just a dynamically allocated piece of raw memory with some convenient functionality, we're going to use it to send raw data to the client. In this example, we need to write the list of detected actors to a buffer in a way that it can be meaningful in the client-side. That's why we passed the episode object to this function. The UCarlaEpisode class represent the current episode running in the simulator, i.e. the state of the simulation since last time we loaded a map. It contains all the relevant information to Carla, and among other things, it allows searching for actor IDs. We can send these IDs to the client and the client will be able to recognise these as actors template <typename SensorT, typename EpisodeT, typename ActorListT> static Buffer Serialize( const SensorT &, const EpisodeT &episode, const ActorListT &detected_actors) { const uint32_t size_in_bytes = sizeof(ActorId) * detected_actors.Num(); Buffer buffer{size_in_bytes}; unsigned char *it = buffer.data(); for (auto *actor : detected_actors) { ActorId id = episode.FindActor(actor).GetActorId(); std::memcpy(it, &id, sizeof(ActorId)); it += sizeof(ActorId); } return buffer; } Note that we templatize the UE4 classes to avoid including these files within LibCarla. This buffer we're returning is going to come back to us, except that this time in the client-side, in the Deserialize function packed in a RawData object static SharedPtr<SensorData> Deserialize(RawData &&data); We'll implement this method in the cpp file, and it's rather simple SharedPtr<SensorData> SafeDistanceSerializer::Deserialize(RawData &&data) { return SharedPtr<SensorData>(new data::SafeDistanceEvent(std::move(data))); } except for the fact that we haven't defined yet what's a SafeDistanceEvent .","title":"2- Sensor data serializer"},{"location":"tuto_D_create_sensor/#3-sensor-data-object","text":"We need to create a data object for the users of this sensor, representing the data of a safe distance event . We'll add this file to LibCarla/source/carla/sensor/data/SafeDistanceEvent.h This object is going to be equivalent to a list of actor IDs. For that, we'll derive from the Array template #pragma once #include \"carla/rpc/ActorId.h\" #include \"carla/sensor/data/Array.h\" namespace carla { namespace sensor { namespace data { class SafeDistanceEvent : public Array<rpc::ActorId> { public: explicit SafeDistanceEvent(RawData &&data) : Array<rpc::ActorId>(std::move(data)) {} }; } // namespace data } // namespace sensor } // namespace carla The Array template is going to reinterpret the buffer we created in the Serialize method as an array of actor IDs, and it's able to do so directly from the buffer we received, without allocating any new memory. Although for this small example may seem a bit overkill, this mechanism is also used for big chunks of data; imagine we're sending HD images, we save a lot by reusing the raw memory. Now we need to expose this class to Python. In our example, we haven't add any extra methods, so we'll just expose the methods related to Array. We do so by using Boost.Python bindings, add the following to PythonAPI/carla/source/libcarla/SensorData.cpp . class_< csd::SafeDistanceEvent, // actual type. bases<cs::SensorData>, // parent type. boost::noncopyable, // disable copy. boost::shared_ptr<csd::SafeDistanceEvent> // use as shared_ptr. >(\"SafeDistanceEvent\", no_init) // name, and disable construction. .def(\"__len__\", &csd::SafeDistanceEvent::size) .def(\"__iter__\", iterator<csd::SafeDistanceEvent>()) .def(\"__getitem__\", +[](const csd::SafeDistanceEvent &self, size_t pos) -> cr::ActorId { return self.at(pos); }) ; Note that csd is an alias for the namespace carla::sensor::data . What we're doing here is exposing some C++ methods in Python. Just with this, the Python API will be able to recognise our new event and it'll behave similar to an array in Python, except that cannot be modified.","title":"3- Sensor data object"},{"location":"tuto_D_create_sensor/#4-register-your-sensor","text":"Now that the pipeline is complete, we're ready to register our new sensor. We do so in LibCarla/source/carla/sensor/SensorRegistry.h . Follow the instruction in this header file to add the different includes and forward declarations, and add the following pair to the registry std::pair<ASafeDistanceSensor *, s11n::SafeDistanceSerializer> With this, the sensor registry now can do its magic to dispatch the right data to the right serializer. Now recompile CARLA, hopefully everything goes ok and no errors. Unfortunately, most of the errors here will be related to templates and the error messages can be a bit cryptic. make rebuild","title":"4- Register your sensor"},{"location":"tuto_D_create_sensor/#5-usage-example","text":"Finally, we have the sensor included and we have finished recompiling, our sensor by now should be available in Python. To spawn this sensor, we simply need to find it in the blueprint library, if everything went right, the sensor factory should have added our sensor to the library blueprint = blueprint_library.find('sensor.other.safe_distance') sensor = world.spawn_actor(blueprint, carla.Transform(), attach_to=vehicle) and now we can start listening for events by registering a callback function world_ref = weakref.ref(world) def callback(event): for actor_id in event: vehicle = world_ref().get_actor(actor_id) print('Vehicle too close: %s' % vehicle.type_id) sensor.listen(callback) This callback is going to execute every update that another vehicle is inside our safety distance box, e.g. Vehicle too close: vehicle.audi.a2 Vehicle too close: vehicle.mercedes-benz.coupe That's it, we have a new sensor working!","title":"5- Usage example"},{"location":"tuto_D_create_sensor/#appendix","text":"","title":"Appendix"},{"location":"tuto_D_create_sensor/#reusing-buffers","text":"In order to optimize memory usage, we can use the fact that each sensor sends buffers of similar size; in particularly, in the case of cameras, the size of the image is constant during execution. In those cases, we can save a lot by reusing the allocated memory between frames. Each stream contains a buffer pool that can be used to avoid unnecessary memory allocations. Remember that each sensor has a stream associated thus each sensor has its own buffer pool. Use the following to retrieve a buffer from the pool auto Buffer = Stream.PopBufferFromPool(); If the pool is empty, it returns an empty buffer, i.e. a buffer with no memory allocated. In that case, when you resize the buffer new memory will be allocated. This will happen a few times during the first frames. However, if a buffer was retrieved from the pool, its memory will go back to the pool once the buffer goes out of the scope. Next time you get another buffer from the pool, it'll contain the allocated piece of memory from the previous buffer. As you can see, a buffer object acts actually as an smart pointer to a contiguous piece of raw memory. As long as you don't request more memory than the currently allocated, the buffer reuses the memory. If you request more, then it'll have to delete the current memory and allocate a bigger chunk. The following snippet illustrates how buffers work Buffer buffer; buffer.reset(1024u); // (size 1024 bytes, capacity 1024 bytes) -> allocates buffer.reset(512u); // (size 512 bytes, capacity 1024 bytes) buffer.reset(2048u); // (size 2048 bytes, capacity 2048 bytes) -> allocates","title":"Reusing buffers"},{"location":"tuto_D_create_sensor/#sending-data-asynchronously","text":"Some sensors may require to send data asynchronously, either for performance or because the data is generated in a different thread, for instance, camera sensors send the images from the render thread. Using the data stream asynchronously is perfectly fine, as long as the stream itself is created in the game thread. For instance void MySensor::Tick(float DeltaSeconds) { Super::Tick(DeltaSeconds); auto Stream = GetDataStream(*this); std::async(std::launch::async, [Stream=std::move(Stream)]() { auto Data = ComputeData(); Stream.Send(*this, Data); }); }","title":"Sending data asynchronously"},{"location":"tuto_D_create_sensor/#client-side-sensors","text":"Some sensors do not require the simulator to do their measurements, those sensors may run completely in the client-side freeing the simulator from extra computations. Examples of such sensors is the LaneInvasion sensors. The usual approach is to create a \"dummy\" sensor in the server-side, just so the simulator is aware that such actor exists. However, this dummy sensor doesn't tick nor sends any sort of data. Its counterpart on the client-side however, registers a \"on tick\" callback to execute some code on every new update. For instance, the LaneInvasion sensor registers a callback that notifies every time a lane mark has been crossed. It is very important to take into account that the \"on tick\" callback in the client-side is executed concurrently, i.e., the same method may be executed simultaneously by different threads. Any data accessed must be properly synchronized, either with a mutex, using atomics, or even better making sure all the members accessed remain constant.","title":"Client-side sensors"},{"location":"tuto_D_customize_vehicle_suspension/","text":"Customize vehicle suspension This tutorial covers the basics of the suspension system for CARLA vehicles, and how are these implemented for the different vehicles available. Use this information to access the suspension parameterization of a vehicle in Unreal Engine, and customize it at will. Basics of the suspension system Suspension groups Coupe Off-road Truck Urban Van Basics of the suspension system The suspension system of a vehicle is defined by the wheels of said vehicle. Each wheel has an independent blueprint with some parameterization, which includes the suspension system. These blueprints can be found in Content/Carla/Blueprints/Vehicles/<vehicle_name> . They are named such as: BP_<vehicle_name>_<F/R><R/L>W . F or R is used for front or rear wheels correspondingly. R or L is used for right or left wheels correspondingly. In this example, the blueprint of the front left wheel of the Audi A2 is named as BP_AudiA2_FLW . shape_radius for the wheel to rest over the road, neither hovering nor inside of it. Inside the blueprint, there is a section with some parameterization regarding the suspension of the wheel. Here are their definitions as described in Unreal Engine. Suspension Force Offset \u2014 Vertical offset from where suspension forces are applied (along Z axis). Suspension Max Raise \u2014 How far the wheel can go above the resting position. Suspension Max Drop \u2014 How far the wheel can drop below the resting position. Suspension Natural Frequency \u2014 Oscillation frequency of the suspension. Standard cars have values between 5 and 10 . Suspension Damping Ratio \u2014 The rate at which energy is dissipated from the spring. Standard cars have values between 0.8 and 1.2 . Values <1 are more sluggish, values >1 are more twitchy. Sweep Type \u2014 Wether wheel suspension considers simple, complex or both. The Suspension panel inside a wheel blueprint. Note By default, all the wheels of a vehicle have the same parameterization in CARLA. The following explanations will be covered per vehicle, instead of per wheel. Suspension groups According to their system suspension, vehicles in CARLA can be classified in five groups. All the vehicles in a group have the same parameterization, as they are expected to have a similar behaviour on the road. The suspension of a vehicle can be modified at will, and is no subject to these five groups. However understanding these, and observing their behaviour in the simulation can be of great use to define a custom suspension. The five groups are: Coupe , Off-road , Truck , Urban , and Van . In closer observation, the parameterization of these groups follows a specific pattern. Stiff suspension Coupe Urban Van Off-road Truck Soft suspension When moving from a soft to a stiff suspension, there are some clear tendencies in the parameterization. Decrease of Suspension Max Raise and Suspension Max Drop \u2014 Stiff vehicles are meant to drive over plane roads with no bumps. For the sake of aerodynamics, the chassis is not supposed to move greatly, but remain constantly close to the ground. Increase of Suspension Damping Ratio \u2014 The absortion of the bouncing by the dampers is greater for stiff vehicles. Coupe Vehicles with the stiffest suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 7.5 Suspension Max Drop \u2014 7.5 Suspension Natural Frequency \u2014 9.5 Suspension Damping Ratio \u2014 1.0 Sweep Type \u2014 SimpleAndComplex vehicle.audi.tt vehicle.lincoln.mkz2017 vehicle.mercedes-benz.coupe vehicle.seat.leon vehicle.tesla.model3 Off-road Vehicles with a soft suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 15.0 Suspension Max Drop \u2014 15.0 Suspension Natural Frequency \u2014 7.0 Suspension Damping Ratio \u2014 0.5 Sweep Type \u2014 SimpleAndComplex vehicle.audi.etron vehicle.jeep.wrangler_rubicon vehicle.nissan.patrol vehicle.tesla.cybertruck Truck Vehicles with the softest suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 17.0 Suspension Max Drop \u2014 17.0 Suspension Natural Frequency \u2014 6.0 Suspension Damping Ratio \u2014 0.4 Sweep Type \u2014 SimpleAndComplex vehicle.carlamotors.carlacola Urban Vehicles with a soft suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 8.0 Suspension Max Drop \u2014 8.0 Suspension Natural Frequency \u2014 9.0 Suspension Damping Ratio \u2014 0.8 Sweep Type \u2014 SimpleAndComplex vehicle.audi.a2 vehicle.bmw.grandtourer vehicle.chevrolet.impala vehicle.citroen.c3 vehicle.dodge_charger.police vehicle.mini.cooperst vehicle.mustang.mustang vehicle.nissan.micra vehicle.toyota.prius Van Vehicles with a middle-ground suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 9.0 Suspension Max Drop \u2014 9.0 Suspension Natural Frequency \u2014 8.0 Suspension Damping Ratio \u2014 0.8 Sweep Type \u2014 SimpleAndComplex vehicle.volkswagen.t2 Use the forum to post any doubts, issues or suggestions regarding this topic. CARLA forum Here are some advised readings after this one. Control vehicle physics Add friction triggers Generate detailed colliders","title":"\u81ea\u5b9a\u4e49\u8f66\u8f86\u60ac\u67b6"},{"location":"tuto_D_customize_vehicle_suspension/#customize-vehicle-suspension","text":"This tutorial covers the basics of the suspension system for CARLA vehicles, and how are these implemented for the different vehicles available. Use this information to access the suspension parameterization of a vehicle in Unreal Engine, and customize it at will. Basics of the suspension system Suspension groups Coupe Off-road Truck Urban Van","title":"Customize vehicle suspension"},{"location":"tuto_D_customize_vehicle_suspension/#basics-of-the-suspension-system","text":"The suspension system of a vehicle is defined by the wheels of said vehicle. Each wheel has an independent blueprint with some parameterization, which includes the suspension system. These blueprints can be found in Content/Carla/Blueprints/Vehicles/<vehicle_name> . They are named such as: BP_<vehicle_name>_<F/R><R/L>W . F or R is used for front or rear wheels correspondingly. R or L is used for right or left wheels correspondingly. In this example, the blueprint of the front left wheel of the Audi A2 is named as BP_AudiA2_FLW . shape_radius for the wheel to rest over the road, neither hovering nor inside of it. Inside the blueprint, there is a section with some parameterization regarding the suspension of the wheel. Here are their definitions as described in Unreal Engine. Suspension Force Offset \u2014 Vertical offset from where suspension forces are applied (along Z axis). Suspension Max Raise \u2014 How far the wheel can go above the resting position. Suspension Max Drop \u2014 How far the wheel can drop below the resting position. Suspension Natural Frequency \u2014 Oscillation frequency of the suspension. Standard cars have values between 5 and 10 . Suspension Damping Ratio \u2014 The rate at which energy is dissipated from the spring. Standard cars have values between 0.8 and 1.2 . Values <1 are more sluggish, values >1 are more twitchy. Sweep Type \u2014 Wether wheel suspension considers simple, complex or both. The Suspension panel inside a wheel blueprint. Note By default, all the wheels of a vehicle have the same parameterization in CARLA. The following explanations will be covered per vehicle, instead of per wheel.","title":"Basics of the suspension system"},{"location":"tuto_D_customize_vehicle_suspension/#suspension-groups","text":"According to their system suspension, vehicles in CARLA can be classified in five groups. All the vehicles in a group have the same parameterization, as they are expected to have a similar behaviour on the road. The suspension of a vehicle can be modified at will, and is no subject to these five groups. However understanding these, and observing their behaviour in the simulation can be of great use to define a custom suspension. The five groups are: Coupe , Off-road , Truck , Urban , and Van . In closer observation, the parameterization of these groups follows a specific pattern. Stiff suspension Coupe Urban Van Off-road Truck Soft suspension When moving from a soft to a stiff suspension, there are some clear tendencies in the parameterization. Decrease of Suspension Max Raise and Suspension Max Drop \u2014 Stiff vehicles are meant to drive over plane roads with no bumps. For the sake of aerodynamics, the chassis is not supposed to move greatly, but remain constantly close to the ground. Increase of Suspension Damping Ratio \u2014 The absortion of the bouncing by the dampers is greater for stiff vehicles.","title":"Suspension groups"},{"location":"tuto_D_customize_vehicle_suspension/#coupe","text":"Vehicles with the stiffest suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 7.5 Suspension Max Drop \u2014 7.5 Suspension Natural Frequency \u2014 9.5 Suspension Damping Ratio \u2014 1.0 Sweep Type \u2014 SimpleAndComplex vehicle.audi.tt vehicle.lincoln.mkz2017 vehicle.mercedes-benz.coupe vehicle.seat.leon vehicle.tesla.model3","title":"Coupe"},{"location":"tuto_D_customize_vehicle_suspension/#off-road","text":"Vehicles with a soft suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 15.0 Suspension Max Drop \u2014 15.0 Suspension Natural Frequency \u2014 7.0 Suspension Damping Ratio \u2014 0.5 Sweep Type \u2014 SimpleAndComplex vehicle.audi.etron vehicle.jeep.wrangler_rubicon vehicle.nissan.patrol vehicle.tesla.cybertruck","title":"Off-road"},{"location":"tuto_D_customize_vehicle_suspension/#truck","text":"Vehicles with the softest suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 17.0 Suspension Max Drop \u2014 17.0 Suspension Natural Frequency \u2014 6.0 Suspension Damping Ratio \u2014 0.4 Sweep Type \u2014 SimpleAndComplex vehicle.carlamotors.carlacola","title":"Truck"},{"location":"tuto_D_customize_vehicle_suspension/#urban","text":"Vehicles with a soft suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 8.0 Suspension Max Drop \u2014 8.0 Suspension Natural Frequency \u2014 9.0 Suspension Damping Ratio \u2014 0.8 Sweep Type \u2014 SimpleAndComplex vehicle.audi.a2 vehicle.bmw.grandtourer vehicle.chevrolet.impala vehicle.citroen.c3 vehicle.dodge_charger.police vehicle.mini.cooperst vehicle.mustang.mustang vehicle.nissan.micra vehicle.toyota.prius","title":"Urban"},{"location":"tuto_D_customize_vehicle_suspension/#van","text":"Vehicles with a middle-ground suspension. Parameterization Vehicles Suspension Force Offset \u2014 0.0 Suspension Max Raise \u2014 9.0 Suspension Max Drop \u2014 9.0 Suspension Natural Frequency \u2014 8.0 Suspension Damping Ratio \u2014 0.8 Sweep Type \u2014 SimpleAndComplex vehicle.volkswagen.t2 Use the forum to post any doubts, issues or suggestions regarding this topic. CARLA forum Here are some advised readings after this one. Control vehicle physics Add friction triggers Generate detailed colliders","title":"Van"},{"location":"tuto_D_generate_colliders/","text":"Generate detailed colliders This tutorial explains how to create more accurate collision boundaries for vehicles (relative to the original shape of the object). These can be used as physics collider, compatible with collision detection, or as a secondary collider used by raycast-based sensors such a the LIDAR to retrieve more accurate data. New colliders can be integrated into CARLA so that all the community can benefit from these. Find out more about how to contribute to the content repository here . There are two approaches to create the new colliders, but they are not completely equivalent. Raycast colliders \u2014 This approach requires some basic 3D modelling skills. A secondary collider is added to the vehicle so that raycast-based sensors such as the LIDAR retrieve more precise data. Physics colliders \u2014 This approach follows the tutorial created by the contributor Yan Kaganovsky / yankagan to create a mesh with no need of manual modelling. This mesh is then used as main collider for the vehicle, for physics and sensor detection (unless a secondary collider is added). Raycast colliders 1-Export the vehicle FBX 2-Generate a low density mesh 3-Import the mesh into UE 4-Add the mesh as collider Physics colliders 0-Prerequisites 1-Define custom collision for wheels in Unreal Editor 2-Export the vehicle as FBX 3 to 4-Import to Blender and create custom boundary 5-Export from Blender to FBX 6 to 8-Import collider and define physics Raycast colliders 1-Export the vehicle FBX First of all, the original mesh of the vehicle is necessary to be used as reference. For the sake of learning, this tutorial exports the mesh of a CARLA vehicle. 1.1 open CARLA in UE and go to Content/Carla/Static/Vehicles/4Wheeled/<model_of_vehicle> . 1.2 Press right-click on SM_<model_of_vehicle> to export the vehicle mesh as FBX. 2-Generate a low density mesh 2.1 Open a 3D modelling software and, using the original mesh as reference, model a low density mesh that stays reliable to the original. 2.2 Save the new mesh as FBX. Name de mesh as sm_sc_<model_of_vehicle>.fbx . E.g. sm_sc_audiTT.fbx . Note As for the wheels and additional elements such as roofs, mudguards, etc. the new mesh should follow the geometry quite accurately. Placing simple cubes will not do it. 3-Import the mesh into UE 3.1 Open CARLA in UE and go to Content/Carla/Static/Vehicles/4Wheeled/<model_of_vehicle> . 3.2 Press right-click to import the new mesh SM_sc_<model_of_vehicle>.fbx . 4-Add the mesh as collider 4.1 Go to Content/Carla/Blueprints/Vehicles/<model_of_vehicle> and open the blueprint of the vehicle named as BP_<model_of_vehicle> . 4.2 Select the CustomCollision element and add the SM_sc_<model_of_vehicle>.fbx in the Static mesh property. 4.3 Press Compile in the toolbar above and save the changes. Note For vehicles such as motorbikes and bicycles, change the collider mesh of the vehicle itself using the same component, CustomCollision . Physics colliders Important This tutorial is based on a contribution made by yankagan ! The contributor also wants to aknowledge Francisco E for the tutorial on how to import custom collisions in UE . This video shows the results achieved after following this tutorial. 0-Prerequisites Build CARLA from source on Linux or Windows . Blender 2.80 or newer from the official site for free (open-source 3D modelling software). VHACD Plugin for Blender following the using the instructions in here . This plugin automatically creates an approximation of a selected object using a collection of convex hulls. Read more . Note This series and Udemy course may be a good introduction to Blender for newcomers. 1-Define custom collision for wheels in Unreal Editor Step 1. (in UE) \u2014 Add collision boundaries for the wheels. The steps are detailed in the following video. 2-Export the vehicle as FBX Step 2. (in UE) \u2014 Export the skeletal mesh of a vehicle to an FBX file. 2.1 Go to Content/Carla/Static/Vehicles/4Wheeled/<model_of_vehicle> . 2.2 Press right-click on SM_<model_of_vehicle> to export the vehicle mesh as FBX. 3 to 4-Import to Blender and create custom boundary Step 3. (in Blender) \u2014 Import the FBX file into Blender. Step 4. (in Blender) \u2014 Add convex hull meshes to form the new collision boundary (UE requirement for computational efficiency). This is the hardest step. If the entire car is selected, the collision boundary created by VHACD will be imprecise and messy. It will contain sharp edges which will mess-up the drive on the road. It's important that the wheels have smooth boundaries around them. Using convex decomposition on the car's body the mirrors would still not look right. For computer vision, the details of the vehicle are important. For said reason, these step has been divided into two parts. 4.1 Cut out the bottom parts of the wheels, the side mirrors and the top part of the car's body to create the first boundary using the VHACD tool. Cut out the bottom half of the car to create the second boundary (top part of the car) using the VHACD tool. 4.2 Create separate boundaries for side mirrors using the VHACD tool. Warning Be very careful about naming the object. Each boundary should have begin with UCX_ , and the rest of the name has to be exactly the same as the original mesh. 5-Export from Blender to FBX Step 5. (in Blender) \u2014 Export the custom collision boundaries into an FBX file. 5.1 Select only the original vehicle and all the newly added objects for collision. 5.2 In the export menu, check selected objects and select only \"Mesh\". 6 to 8-Import collider and define physics Step 6. (in UE) \u2014 Import the new FBX into CARLA as an Unreal asset file (static mesh). Step 7. (in UE) \u2014 Import the custom collider into the physics asset for the specific vehicle, so that it is used for computations. Step 8. (in UE) \u2014 Create constraints that connect the different joints and define the physics of all parts. That is a wrap on how to change the default colliders for vehicles in CARLA. Open CARLA and mess around for a while. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"\u751f\u6210\u8be6\u7ec6\u78b0\u649e"},{"location":"tuto_D_generate_colliders/#generate-detailed-colliders","text":"This tutorial explains how to create more accurate collision boundaries for vehicles (relative to the original shape of the object). These can be used as physics collider, compatible with collision detection, or as a secondary collider used by raycast-based sensors such a the LIDAR to retrieve more accurate data. New colliders can be integrated into CARLA so that all the community can benefit from these. Find out more about how to contribute to the content repository here . There are two approaches to create the new colliders, but they are not completely equivalent. Raycast colliders \u2014 This approach requires some basic 3D modelling skills. A secondary collider is added to the vehicle so that raycast-based sensors such as the LIDAR retrieve more precise data. Physics colliders \u2014 This approach follows the tutorial created by the contributor Yan Kaganovsky / yankagan to create a mesh with no need of manual modelling. This mesh is then used as main collider for the vehicle, for physics and sensor detection (unless a secondary collider is added). Raycast colliders 1-Export the vehicle FBX 2-Generate a low density mesh 3-Import the mesh into UE 4-Add the mesh as collider Physics colliders 0-Prerequisites 1-Define custom collision for wheels in Unreal Editor 2-Export the vehicle as FBX 3 to 4-Import to Blender and create custom boundary 5-Export from Blender to FBX 6 to 8-Import collider and define physics","title":"Generate detailed colliders"},{"location":"tuto_D_generate_colliders/#raycast-colliders","text":"","title":"Raycast colliders"},{"location":"tuto_D_generate_colliders/#1-export-the-vehicle-fbx","text":"First of all, the original mesh of the vehicle is necessary to be used as reference. For the sake of learning, this tutorial exports the mesh of a CARLA vehicle. 1.1 open CARLA in UE and go to Content/Carla/Static/Vehicles/4Wheeled/<model_of_vehicle> . 1.2 Press right-click on SM_<model_of_vehicle> to export the vehicle mesh as FBX.","title":"1-Export the vehicle FBX"},{"location":"tuto_D_generate_colliders/#2-generate-a-low-density-mesh","text":"2.1 Open a 3D modelling software and, using the original mesh as reference, model a low density mesh that stays reliable to the original. 2.2 Save the new mesh as FBX. Name de mesh as sm_sc_<model_of_vehicle>.fbx . E.g. sm_sc_audiTT.fbx . Note As for the wheels and additional elements such as roofs, mudguards, etc. the new mesh should follow the geometry quite accurately. Placing simple cubes will not do it.","title":"2-Generate a low density mesh"},{"location":"tuto_D_generate_colliders/#3-import-the-mesh-into-ue","text":"3.1 Open CARLA in UE and go to Content/Carla/Static/Vehicles/4Wheeled/<model_of_vehicle> . 3.2 Press right-click to import the new mesh SM_sc_<model_of_vehicle>.fbx .","title":"3-Import the mesh into UE"},{"location":"tuto_D_generate_colliders/#4-add-the-mesh-as-collider","text":"4.1 Go to Content/Carla/Blueprints/Vehicles/<model_of_vehicle> and open the blueprint of the vehicle named as BP_<model_of_vehicle> . 4.2 Select the CustomCollision element and add the SM_sc_<model_of_vehicle>.fbx in the Static mesh property. 4.3 Press Compile in the toolbar above and save the changes. Note For vehicles such as motorbikes and bicycles, change the collider mesh of the vehicle itself using the same component, CustomCollision .","title":"4-Add the mesh as collider"},{"location":"tuto_D_generate_colliders/#physics-colliders","text":"Important This tutorial is based on a contribution made by yankagan ! The contributor also wants to aknowledge Francisco E for the tutorial on how to import custom collisions in UE . This video shows the results achieved after following this tutorial.","title":"Physics colliders"},{"location":"tuto_D_generate_colliders/#0-prerequisites","text":"Build CARLA from source on Linux or Windows . Blender 2.80 or newer from the official site for free (open-source 3D modelling software). VHACD Plugin for Blender following the using the instructions in here . This plugin automatically creates an approximation of a selected object using a collection of convex hulls. Read more . Note This series and Udemy course may be a good introduction to Blender for newcomers.","title":"0-Prerequisites"},{"location":"tuto_D_generate_colliders/#1-define-custom-collision-for-wheels-in-unreal-editor","text":"Step 1. (in UE) \u2014 Add collision boundaries for the wheels. The steps are detailed in the following video.","title":"1-Define custom collision for wheels in Unreal Editor"},{"location":"tuto_D_generate_colliders/#2-export-the-vehicle-as-fbx","text":"Step 2. (in UE) \u2014 Export the skeletal mesh of a vehicle to an FBX file. 2.1 Go to Content/Carla/Static/Vehicles/4Wheeled/<model_of_vehicle> . 2.2 Press right-click on SM_<model_of_vehicle> to export the vehicle mesh as FBX.","title":"2-Export the vehicle as FBX"},{"location":"tuto_D_generate_colliders/#3-to-4-import-to-blender-and-create-custom-boundary","text":"Step 3. (in Blender) \u2014 Import the FBX file into Blender. Step 4. (in Blender) \u2014 Add convex hull meshes to form the new collision boundary (UE requirement for computational efficiency). This is the hardest step. If the entire car is selected, the collision boundary created by VHACD will be imprecise and messy. It will contain sharp edges which will mess-up the drive on the road. It's important that the wheels have smooth boundaries around them. Using convex decomposition on the car's body the mirrors would still not look right. For computer vision, the details of the vehicle are important. For said reason, these step has been divided into two parts. 4.1 Cut out the bottom parts of the wheels, the side mirrors and the top part of the car's body to create the first boundary using the VHACD tool. Cut out the bottom half of the car to create the second boundary (top part of the car) using the VHACD tool. 4.2 Create separate boundaries for side mirrors using the VHACD tool. Warning Be very careful about naming the object. Each boundary should have begin with UCX_ , and the rest of the name has to be exactly the same as the original mesh.","title":"3 to 4-Import to Blender and create custom boundary"},{"location":"tuto_D_generate_colliders/#5-export-from-blender-to-fbx","text":"Step 5. (in Blender) \u2014 Export the custom collision boundaries into an FBX file. 5.1 Select only the original vehicle and all the newly added objects for collision. 5.2 In the export menu, check selected objects and select only \"Mesh\".","title":"5-Export from Blender to FBX"},{"location":"tuto_D_generate_colliders/#6-to-8-import-collider-and-define-physics","text":"Step 6. (in UE) \u2014 Import the new FBX into CARLA as an Unreal asset file (static mesh). Step 7. (in UE) \u2014 Import the custom collider into the physics asset for the specific vehicle, so that it is used for computations. Step 8. (in UE) \u2014 Create constraints that connect the different joints and define the physics of all parts. That is a wrap on how to change the default colliders for vehicles in CARLA. Open CARLA and mess around for a while. If there are any doubts, feel free to post these in the forum. CARLA forum","title":"6 to 8-Import collider and define physics"},{"location":"tuto_D_make_release/","text":"How to make a release This document is meant for developers that want to publish a new release. Make sure content is up-to-date. See Upgrade the content . Increase CARLA version where necessary. Increase version in the following files: DefaultGame.ini , Carla.uplugin , setup.py , ContentVersions.txt . Grep for the current version to make sure you don't miss any references. Clean up CHANGELOG.md. Make sure the change log is up-to-date, reword and reorganize if necessary; take into account which items can be more important to the users. Commit changes and add a new tag. Once all your changes are committed, add a new tag with git tag -a X.X.X (replacing X.X.X by latest version). Add the changelog of this version as tag message. Tag content repo. Add a similar tag to the content repository at the exact commit as in ContentVersions.txt . Push changes. Push all the changes to both repositories, to push tags you may need to use git push --tags . Create a Pull Request if necessary. Edit GitHub release. Go to GitHub releases and create a new release on top of the newly created tag. Wait until Jenkins has finished publishing the builds with the latest version and add the download links to the newly created release.","title":"\u53d1\u5e03\u7248\u672c"},{"location":"tuto_D_make_release/#how-to-make-a-release","text":"This document is meant for developers that want to publish a new release. Make sure content is up-to-date. See Upgrade the content . Increase CARLA version where necessary. Increase version in the following files: DefaultGame.ini , Carla.uplugin , setup.py , ContentVersions.txt . Grep for the current version to make sure you don't miss any references. Clean up CHANGELOG.md. Make sure the change log is up-to-date, reword and reorganize if necessary; take into account which items can be more important to the users. Commit changes and add a new tag. Once all your changes are committed, add a new tag with git tag -a X.X.X (replacing X.X.X by latest version). Add the changelog of this version as tag message. Tag content repo. Add a similar tag to the content repository at the exact commit as in ContentVersions.txt . Push changes. Push all the changes to both repositories, to push tags you may need to use git push --tags . Create a Pull Request if necessary. Edit GitHub release. Go to GitHub releases and create a new release on top of the newly created tag. Wait until Jenkins has finished publishing the builds with the latest version and add the download links to the newly created release.","title":"How to make a release"},{"location":"tuto_G_add_friction_triggers/","text":"How to add friction triggers Friction Triggers are box triggers that can be added on runtime and let users define a different friction of the vehicles' wheels when being inside those type of triggers. For example, this could be useful for making slippery surfaces in certain regions of a map dynamically. In order to spawn a friction trigger using PythonAPI, users must first get the static.trigger.friction blueprint definition, and then set the following necessary attributes to that blueprint definition: friction : The friction of the trigger box when vehicles are inside it. extent_x : The extent of the bounding box in the X coordinate in centimeters. extent_y : The extent of the bounding box in the Y coordinate in centimeters. extent_z : The extent of the bounding box in the Z coordinate in centimeters. Once done that, define a transform to specify the location and rotation for the friction trigger and spawn it. Example import carla def main(): # Connect to client client = carla.Client('127.0.0.1', 2000) client.set_timeout(2.0) # Get World and Actors world = client.get_world() actors = world.get_actors() # Find Trigger Friction Blueprint friction_bp = world.get_blueprint_library().find('static.trigger.friction') extent = carla.Location(700.0, 700.0, 700.0) friction_bp.set_attribute('friction', str(0.0)) friction_bp.set_attribute('extent_x', str(extent.x)) friction_bp.set_attribute('extent_y', str(extent.y)) friction_bp.set_attribute('extent_z', str(extent.z)) # Spawn Trigger Friction transform = carla.Transform() transform.location = carla.Location(100.0, 0.0, 0.0) world.spawn_actor(friction_bp, transform) # Optional for visualizing trigger world.debug.draw_box(box=carla.BoundingBox(transform.location, extent * 1e-2), rotation=transform.rotation, life_time=100, thickness=0.5, color=carla.Color(r=255,g=0,b=0)) if __name__ == '__main__': main()","title":"\u6dfb\u52a0\u6469\u64e6\u89e6\u53d1\u5668"},{"location":"tuto_G_add_friction_triggers/#how-to-add-friction-triggers","text":"Friction Triggers are box triggers that can be added on runtime and let users define a different friction of the vehicles' wheels when being inside those type of triggers. For example, this could be useful for making slippery surfaces in certain regions of a map dynamically. In order to spawn a friction trigger using PythonAPI, users must first get the static.trigger.friction blueprint definition, and then set the following necessary attributes to that blueprint definition: friction : The friction of the trigger box when vehicles are inside it. extent_x : The extent of the bounding box in the X coordinate in centimeters. extent_y : The extent of the bounding box in the Y coordinate in centimeters. extent_z : The extent of the bounding box in the Z coordinate in centimeters. Once done that, define a transform to specify the location and rotation for the friction trigger and spawn it.","title":"How to add friction triggers"},{"location":"tuto_G_add_friction_triggers/#example","text":"import carla def main(): # Connect to client client = carla.Client('127.0.0.1', 2000) client.set_timeout(2.0) # Get World and Actors world = client.get_world() actors = world.get_actors() # Find Trigger Friction Blueprint friction_bp = world.get_blueprint_library().find('static.trigger.friction') extent = carla.Location(700.0, 700.0, 700.0) friction_bp.set_attribute('friction', str(0.0)) friction_bp.set_attribute('extent_x', str(extent.x)) friction_bp.set_attribute('extent_y', str(extent.y)) friction_bp.set_attribute('extent_z', str(extent.z)) # Spawn Trigger Friction transform = carla.Transform() transform.location = carla.Location(100.0, 0.0, 0.0) world.spawn_actor(friction_bp, transform) # Optional for visualizing trigger world.debug.draw_box(box=carla.BoundingBox(transform.location, extent * 1e-2), rotation=transform.rotation, life_time=100, thickness=0.5, color=carla.Color(r=255,g=0,b=0)) if __name__ == '__main__': main()","title":"Example"},{"location":"tuto_G_carsim_integration/","text":"CarSim Integration CARLA's integration with CarSim allows vehicle controls in CARLA to be forwarded to CarSim. CarSim will do all required physics calculations of the vehicle and return the new state to CARLA. This page shows you how to generate a .sim file, explains how vehicle dimensions relate between CARLA and CarSim and how to run a simulation on CARLA using the CarSim integration. Before you begin Set up CarSim Generate the .sim file On Windows On Ubuntu Vehicle sizes Run the simulation Before you begin You will need a license for CarSim and to have the software up and running. If you don't currently have a license for CarSim, you can contact the team here for information. To allow communication with Unreal Engine you will need to install the VehicleSim Dynamics plugin (version 2020.0) for Unreal Engine 4.24. For information on finding specific versions of the plugin, check this link . Installation of the plugin will depend on your operating system: For Windows : Get the plugin here . For Ubuntu : Download the plugin here . Replace the file CarSim.Build.cs with the file found here in order to use the correct solver for Ubuntu. This step can be skipped if you are using the packaged version of CARLA. The packaged version has already been compiled using this flag but if you are building CARLA from source then you will need to compile the server with the --carsim flag. If you are building CARLA from source, run the following command in the root folder to compile the server with the --carsim flag: make launch ARGS=\"--carsim\" Set up CarSim The following section details how to generate the .sim file which is required to run the simulation. There is also important information detailed regarding the relationship of vehicle sizes between CARLA and CarSim. Generate the .sim file The .sim file describes the simulation to be run in both CARLA and CarSim. This file is required by the plugin to run the simulation. There is currently no way to generate this file on Ubuntu, however we will describe below how to use a previously generated file to run the simulation on Ubuntu. On Windows After you have configured all the parameters on CarSim, use the GUI to generate the .sim file as highlighted below: The resulting .sim file should look something like this: SIMFILE SET_MACRO $(ROOT_FILE_NAME)$ Run_dd7a828d-4b14-4c77-9d09-1974401d6b25 SET_MACRO $(OUTPUT_PATH)$ D:\\carsim\\Data\\Results SET_MACRO $(WORK_DIR)$ D:\\carsim\\Data\\ SET_MACRO $(OUTPUT_FILE_PREFIX)$ $(WORK_DIR)$Results\\Run_dd7a828d-4b14-4c77-9d09-1974401d6b25\\LastRun FILEBASE $(OUTPUT_FILE_PREFIX)$ INPUT $(WORK_DIR)$Results\\$(ROOT_FILE_NAME)$\\Run_all.par INPUTARCHIVE $(OUTPUT_FILE_PREFIX)$_all.par ECHO $(OUTPUT_FILE_PREFIX)$_echo.par FINAL $(OUTPUT_FILE_PREFIX)$_end.par LOGFILE $(OUTPUT_FILE_PREFIX)$_log.txt ERDFILE $(OUTPUT_FILE_PREFIX)$.vs PROGDIR D:\\carsim\\ DATADIR D:\\carsim\\Data\\ GUI_REFRESH_V CarSim_RefreshEvent_7760 RESOURCEDIR D:\\carsim\\\\Resources\\ PRODUCT_ID CarSim PRODUCT_VER 2020.0 ANIFILE D:\\carsim\\Data\\runs\\animator.par VEHICLE_CODE i_i EXT_MODEL_STEP 0.00050000 PORTS_IMP 0 PORTS_EXP 0 DLLFILE D:\\carsim\\Programs\\solvers\\carsim_64.dll END On Ubuntu There is no way to create the .sim file via GUI on Ubuntu. In order to proceed you will need to follow these steps: Generate the .sim file in Windows or use the file template below. Modify the .sim file so the variables INPUT , INPUTARCHIVE , LOGFILE and so on point towards the corresponding files in your Ubuntu system. Replace the DLLFILE line to point towards the CarSim solver which, in the default installation, will be SOFILE /opt/carsim_2020.0/lib64/libcarsim.so.2020.0 . The resulting file should be similar to this: SIMFILE FILEBASE /path/to/LastRun INPUT /path/to/Run_all.par INPUTARCHIVE /path/to/LastRun_all.par ECHO /path/to/LastRun_echo.par FINAL /path/to/LastRun_end.par LOGFILE /path/to/LastRun_log.txt ERDFILE /path/to/LastRun.vs PROGDIR /opt/carsim_2020.0/lib64/ DATADIR . PRODUCT_ID CarSim PRODUCT_VER 2020.0 VEHICLE_CODE i_i SOFILE /opt/carsim_2020.0/lib64/libcarsim.so.2020.0 END Vehicle sizes Although CarSim lets you specify the dimensions of the vehicle to use in the simulation, there is currently no correlation between a CarSim vehicle and a CARLA vehicle. This means that the vehicles in both programmes will have different dimensions. The role of the CARLA vehicle is only to act as a placeholder during the simulation. Note There is no correlation between vehicle size in CARLA and CarSim. The CARLA vehicle is only a simulation placeholder. Run the simulation All that is needed when running the simulation is to enable CarSim when you spawn a vehicle. This can be done by passing the path to the .sim file to the following method of the Python API: vehicle.enable_carsim(<path_to_ue4simfile.sim>) All input controls sent to the vehicle will be forwarded to CarSim. CarSim will update the physics and send back the status of the vehicle (the transform) to the CARLA vehicle. Once the simulation has finished you can analyze all the data in CarSim as usual.","title":"CarSim \u96c6\u6210"},{"location":"tuto_G_carsim_integration/#carsim-integration","text":"CARLA's integration with CarSim allows vehicle controls in CARLA to be forwarded to CarSim. CarSim will do all required physics calculations of the vehicle and return the new state to CARLA. This page shows you how to generate a .sim file, explains how vehicle dimensions relate between CARLA and CarSim and how to run a simulation on CARLA using the CarSim integration. Before you begin Set up CarSim Generate the .sim file On Windows On Ubuntu Vehicle sizes Run the simulation","title":"CarSim Integration"},{"location":"tuto_G_carsim_integration/#before-you-begin","text":"You will need a license for CarSim and to have the software up and running. If you don't currently have a license for CarSim, you can contact the team here for information. To allow communication with Unreal Engine you will need to install the VehicleSim Dynamics plugin (version 2020.0) for Unreal Engine 4.24. For information on finding specific versions of the plugin, check this link . Installation of the plugin will depend on your operating system: For Windows : Get the plugin here . For Ubuntu : Download the plugin here . Replace the file CarSim.Build.cs with the file found here in order to use the correct solver for Ubuntu. This step can be skipped if you are using the packaged version of CARLA. The packaged version has already been compiled using this flag but if you are building CARLA from source then you will need to compile the server with the --carsim flag. If you are building CARLA from source, run the following command in the root folder to compile the server with the --carsim flag: make launch ARGS=\"--carsim\"","title":"Before you begin"},{"location":"tuto_G_carsim_integration/#set-up-carsim","text":"The following section details how to generate the .sim file which is required to run the simulation. There is also important information detailed regarding the relationship of vehicle sizes between CARLA and CarSim.","title":"Set up CarSim"},{"location":"tuto_G_carsim_integration/#generate-the-sim-file","text":"The .sim file describes the simulation to be run in both CARLA and CarSim. This file is required by the plugin to run the simulation. There is currently no way to generate this file on Ubuntu, however we will describe below how to use a previously generated file to run the simulation on Ubuntu.","title":"Generate the .sim file"},{"location":"tuto_G_carsim_integration/#on-windows","text":"After you have configured all the parameters on CarSim, use the GUI to generate the .sim file as highlighted below: The resulting .sim file should look something like this: SIMFILE SET_MACRO $(ROOT_FILE_NAME)$ Run_dd7a828d-4b14-4c77-9d09-1974401d6b25 SET_MACRO $(OUTPUT_PATH)$ D:\\carsim\\Data\\Results SET_MACRO $(WORK_DIR)$ D:\\carsim\\Data\\ SET_MACRO $(OUTPUT_FILE_PREFIX)$ $(WORK_DIR)$Results\\Run_dd7a828d-4b14-4c77-9d09-1974401d6b25\\LastRun FILEBASE $(OUTPUT_FILE_PREFIX)$ INPUT $(WORK_DIR)$Results\\$(ROOT_FILE_NAME)$\\Run_all.par INPUTARCHIVE $(OUTPUT_FILE_PREFIX)$_all.par ECHO $(OUTPUT_FILE_PREFIX)$_echo.par FINAL $(OUTPUT_FILE_PREFIX)$_end.par LOGFILE $(OUTPUT_FILE_PREFIX)$_log.txt ERDFILE $(OUTPUT_FILE_PREFIX)$.vs PROGDIR D:\\carsim\\ DATADIR D:\\carsim\\Data\\ GUI_REFRESH_V CarSim_RefreshEvent_7760 RESOURCEDIR D:\\carsim\\\\Resources\\ PRODUCT_ID CarSim PRODUCT_VER 2020.0 ANIFILE D:\\carsim\\Data\\runs\\animator.par VEHICLE_CODE i_i EXT_MODEL_STEP 0.00050000 PORTS_IMP 0 PORTS_EXP 0 DLLFILE D:\\carsim\\Programs\\solvers\\carsim_64.dll END","title":"On Windows"},{"location":"tuto_G_carsim_integration/#on-ubuntu","text":"There is no way to create the .sim file via GUI on Ubuntu. In order to proceed you will need to follow these steps: Generate the .sim file in Windows or use the file template below. Modify the .sim file so the variables INPUT , INPUTARCHIVE , LOGFILE and so on point towards the corresponding files in your Ubuntu system. Replace the DLLFILE line to point towards the CarSim solver which, in the default installation, will be SOFILE /opt/carsim_2020.0/lib64/libcarsim.so.2020.0 . The resulting file should be similar to this: SIMFILE FILEBASE /path/to/LastRun INPUT /path/to/Run_all.par INPUTARCHIVE /path/to/LastRun_all.par ECHO /path/to/LastRun_echo.par FINAL /path/to/LastRun_end.par LOGFILE /path/to/LastRun_log.txt ERDFILE /path/to/LastRun.vs PROGDIR /opt/carsim_2020.0/lib64/ DATADIR . PRODUCT_ID CarSim PRODUCT_VER 2020.0 VEHICLE_CODE i_i SOFILE /opt/carsim_2020.0/lib64/libcarsim.so.2020.0 END","title":"On Ubuntu"},{"location":"tuto_G_carsim_integration/#vehicle-sizes","text":"Although CarSim lets you specify the dimensions of the vehicle to use in the simulation, there is currently no correlation between a CarSim vehicle and a CARLA vehicle. This means that the vehicles in both programmes will have different dimensions. The role of the CARLA vehicle is only to act as a placeholder during the simulation. Note There is no correlation between vehicle size in CARLA and CarSim. The CARLA vehicle is only a simulation placeholder.","title":"Vehicle sizes"},{"location":"tuto_G_carsim_integration/#run-the-simulation","text":"All that is needed when running the simulation is to enable CarSim when you spawn a vehicle. This can be done by passing the path to the .sim file to the following method of the Python API: vehicle.enable_carsim(<path_to_ue4simfile.sim>) All input controls sent to the vehicle will be forwarded to CarSim. CarSim will update the physics and send back the status of the vehicle (the transform) to the CARLA vehicle. Once the simulation has finished you can analyze all the data in CarSim as usual.","title":"Run the simulation"},{"location":"tuto_G_chrono/","text":"Chrono Integration This guide outlines what Chrono is, how to use it in CARLA, and the limitations involved in the integration. Project Chrono Using Chrono on CARLA Configuring the server Enabling Chrono physics Limitations Project Chrono Project Chrono is an open-source, multi-physics simulation engine that provides highly realistic vehicle dynamics using a template-based approach. The integration in CARLA allows users to utilize Chrono templates to simulate vehicle dynamics while navigating a map. Using Chrono on CARLA To use the Chrono integration, you must first configure the server with a tag on startup and then use the PythonAPI to enable it on a spawned vehicle. Read on for more details. Configuring the server Chrono will only work if the CARLA server is compiled with the Chrono tag. In the build from source version of CARLA , run the following command to start the server: make launch ARGS=\"--chrono\" Enabling Chrono physics Chrono physics is enabled using the enable_chrono_physics method available through the Actor class. As well as values for substeps and substep delta time, it requires three template files and a base path to locate those files: base_path : Path of the directory which contains the template files. This is necessary to ensure that auxiliary files referenced from the template files have a common base path from which to search. vehicle_json : Path of the vehicle template file relative to the base_path . tire_json : Path of the tire template file relative to the base_path . powertrain_json : Path of the powertrain template file relative to the base_path . Important Double-check your paths. Incorrect or missing paths can cause Unreal Engine to crash. There are a variety of example template files for different vehicles available in Build/chrono-install/share/chrono/data/vehicle . Read the Project Chrono documentation to find out more about their vehicle examples and how to create templates. See below for an example of how to enable Chrono physics: # Spawn your vehicle vehicle = world.spawn_actor(bp, spawn_point) # Set the base path base_path = \"/path/to/carla/Build/chrono-install/share/chrono/data/vehicle/\" # Set the template files vehicle_json = \"sedan/vehicle/Sedan_Vehicle.json\" powertrain_json = \"sedan/powertrain/Sedan_SimpleMapPowertrain.json\" tire_json = \"sedan/tire/Sedan_TMeasyTire.json\" # Enable Chrono physics vehicle.enable_chrono_physics(5000, 0.002, vehicle_json, powertrain_json, tire_json, base_path) You can try the Chrono physics integration using the example script manual_control_chrono.py found in PythonAPI/examples . After running the script, press Ctrl + o to enable Chrono. Limitations This integration does not support collisions. When a collision occurs, the vehicle will revert to CARLA default physics.","title":"Chrono \u96c6\u6210"},{"location":"tuto_G_chrono/#chrono-integration","text":"This guide outlines what Chrono is, how to use it in CARLA, and the limitations involved in the integration. Project Chrono Using Chrono on CARLA Configuring the server Enabling Chrono physics Limitations","title":"Chrono Integration"},{"location":"tuto_G_chrono/#project-chrono","text":"Project Chrono is an open-source, multi-physics simulation engine that provides highly realistic vehicle dynamics using a template-based approach. The integration in CARLA allows users to utilize Chrono templates to simulate vehicle dynamics while navigating a map.","title":"Project Chrono"},{"location":"tuto_G_chrono/#using-chrono-on-carla","text":"To use the Chrono integration, you must first configure the server with a tag on startup and then use the PythonAPI to enable it on a spawned vehicle. Read on for more details.","title":"Using Chrono on CARLA"},{"location":"tuto_G_chrono/#configuring-the-server","text":"Chrono will only work if the CARLA server is compiled with the Chrono tag. In the build from source version of CARLA , run the following command to start the server: make launch ARGS=\"--chrono\"","title":"Configuring the server"},{"location":"tuto_G_chrono/#enabling-chrono-physics","text":"Chrono physics is enabled using the enable_chrono_physics method available through the Actor class. As well as values for substeps and substep delta time, it requires three template files and a base path to locate those files: base_path : Path of the directory which contains the template files. This is necessary to ensure that auxiliary files referenced from the template files have a common base path from which to search. vehicle_json : Path of the vehicle template file relative to the base_path . tire_json : Path of the tire template file relative to the base_path . powertrain_json : Path of the powertrain template file relative to the base_path . Important Double-check your paths. Incorrect or missing paths can cause Unreal Engine to crash. There are a variety of example template files for different vehicles available in Build/chrono-install/share/chrono/data/vehicle . Read the Project Chrono documentation to find out more about their vehicle examples and how to create templates. See below for an example of how to enable Chrono physics: # Spawn your vehicle vehicle = world.spawn_actor(bp, spawn_point) # Set the base path base_path = \"/path/to/carla/Build/chrono-install/share/chrono/data/vehicle/\" # Set the template files vehicle_json = \"sedan/vehicle/Sedan_Vehicle.json\" powertrain_json = \"sedan/powertrain/Sedan_SimpleMapPowertrain.json\" tire_json = \"sedan/tire/Sedan_TMeasyTire.json\" # Enable Chrono physics vehicle.enable_chrono_physics(5000, 0.002, vehicle_json, powertrain_json, tire_json, base_path) You can try the Chrono physics integration using the example script manual_control_chrono.py found in PythonAPI/examples . After running the script, press Ctrl + o to enable Chrono.","title":"Enabling Chrono physics"},{"location":"tuto_G_chrono/#limitations","text":"This integration does not support collisions. When a collision occurs, the vehicle will revert to CARLA default physics.","title":"Limitations"},{"location":"tuto_G_control_vehicle_physics/","text":"Control and monitor vehicle physics Physics properties can be tuned for vehicles and their wheels. These changes are applied only on runtime, and values are set back to default when the execution ends. These properties are controlled through a carla.VehiclePhysicsControl object, which also provides the control of each wheel's physics through a carla.WheelPhysicsControl object. Vehicle control code example Viewing vehicle telemetry Vehicle control code example import carla import random def main(): # Connect to client client = carla.Client('127.0.0.1', 2000) client.set_timeout(2.0) # Get World and Actors world = client.get_world() actors = world.get_actors() # Get a random vehicle from world (there should be one at least) vehicle = random.choice([actor for actor in actors if 'vehicle' in actor.type_id]) # Create Wheels Physics Control front_left_wheel = carla.WheelPhysicsControl(tire_friction=2.0, damping_rate=1.5, max_steer_angle=70.0, long_stiff_value=1000) front_right_wheel = carla.WheelPhysicsControl(tire_friction=2.0, damping_rate=1.5, max_steer_angle=70.0, long_stiff_value=1000) rear_left_wheel = carla.WheelPhysicsControl(tire_friction=3.0, damping_rate=1.5, max_steer_angle=0.0, long_stiff_value=1000) rear_right_wheel = carla.WheelPhysicsControl(tire_friction=3.0, damping_rate=1.5, max_steer_angle=0.0, long_stiff_value=1000) wheels = [front_left_wheel, front_right_wheel, rear_left_wheel, rear_right_wheel] # Change Vehicle Physics Control parameters of the vehicle physics_control = vehicle.get_physics_control() physics_control.torque_curve = [carla.Vector2D(x=0, y=400), carla.Vector2D(x=1300, y=600)] physics_control.max_rpm = 10000 physics_control.moi = 1.0 physics_control.damping_rate_full_throttle = 0.0 physics_control.use_gear_autobox = True physics_control.gear_switch_time = 0.5 physics_control.clutch_strength = 10 physics_control.mass = 10000 physics_control.drag_coefficient = 0.25 physics_control.steering_curve = [carla.Vector2D(x=0, y=1), carla.Vector2D(x=100, y=1), carla.Vector2D(x=300, y=1)] physics_control.use_sweep_wheel_collision = True physics_control.wheels = wheels # Apply Vehicle Physics Control for the vehicle vehicle.apply_physics_control(physics_control) print(physics_control) if __name__ == '__main__': main() Viewing vehicle telemetry Vehicle telemetry can be visualised by calling the Actor.enable_debug_telemetry method. This will provide graph views of several metrics on the server window as well as vehicle reference points on the simulation window. You can try the telemetry visualisation tool in the example script manual_control.py located in PythonAPI/examples . Activate the telemetry view by pressing T .","title":"\u63a7\u5236\u8f66\u8f86\u7269\u7406\u6a21\u578b"},{"location":"tuto_G_control_vehicle_physics/#control-and-monitor-vehicle-physics","text":"Physics properties can be tuned for vehicles and their wheels. These changes are applied only on runtime, and values are set back to default when the execution ends. These properties are controlled through a carla.VehiclePhysicsControl object, which also provides the control of each wheel's physics through a carla.WheelPhysicsControl object. Vehicle control code example Viewing vehicle telemetry","title":"Control and monitor vehicle physics"},{"location":"tuto_G_control_vehicle_physics/#vehicle-control-code-example","text":"import carla import random def main(): # Connect to client client = carla.Client('127.0.0.1', 2000) client.set_timeout(2.0) # Get World and Actors world = client.get_world() actors = world.get_actors() # Get a random vehicle from world (there should be one at least) vehicle = random.choice([actor for actor in actors if 'vehicle' in actor.type_id]) # Create Wheels Physics Control front_left_wheel = carla.WheelPhysicsControl(tire_friction=2.0, damping_rate=1.5, max_steer_angle=70.0, long_stiff_value=1000) front_right_wheel = carla.WheelPhysicsControl(tire_friction=2.0, damping_rate=1.5, max_steer_angle=70.0, long_stiff_value=1000) rear_left_wheel = carla.WheelPhysicsControl(tire_friction=3.0, damping_rate=1.5, max_steer_angle=0.0, long_stiff_value=1000) rear_right_wheel = carla.WheelPhysicsControl(tire_friction=3.0, damping_rate=1.5, max_steer_angle=0.0, long_stiff_value=1000) wheels = [front_left_wheel, front_right_wheel, rear_left_wheel, rear_right_wheel] # Change Vehicle Physics Control parameters of the vehicle physics_control = vehicle.get_physics_control() physics_control.torque_curve = [carla.Vector2D(x=0, y=400), carla.Vector2D(x=1300, y=600)] physics_control.max_rpm = 10000 physics_control.moi = 1.0 physics_control.damping_rate_full_throttle = 0.0 physics_control.use_gear_autobox = True physics_control.gear_switch_time = 0.5 physics_control.clutch_strength = 10 physics_control.mass = 10000 physics_control.drag_coefficient = 0.25 physics_control.steering_curve = [carla.Vector2D(x=0, y=1), carla.Vector2D(x=100, y=1), carla.Vector2D(x=300, y=1)] physics_control.use_sweep_wheel_collision = True physics_control.wheels = wheels # Apply Vehicle Physics Control for the vehicle vehicle.apply_physics_control(physics_control) print(physics_control) if __name__ == '__main__': main()","title":"Vehicle control code example"},{"location":"tuto_G_control_vehicle_physics/#viewing-vehicle-telemetry","text":"Vehicle telemetry can be visualised by calling the Actor.enable_debug_telemetry method. This will provide graph views of several metrics on the server window as well as vehicle reference points on the simulation window. You can try the telemetry visualisation tool in the example script manual_control.py located in PythonAPI/examples . Activate the telemetry view by pressing T .","title":"Viewing vehicle telemetry"},{"location":"tuto_G_control_walker_skeletons/","text":"Walker Bone Control In this tutorial we describe how to manually control and animate the skeletons of walkers from the CARLA Python API. The reference of all classes and methods available can be found at Python API reference . Walker skeleton structure Manually control walker bones Connect to the simulator Spawn a walker Control walker skeletons Note This document assumes the user is familiar with the Python API . The user should read the first steps tutorial before reading this document. Core concepts . Walker skeleton structure All walkers have the same skeleton hierarchy and bone names. Below is an image of the skeleton hierarchy. crl_root \u2514\u2500\u2500 crl_hips__C \u251c\u2500\u2500 crl_spine__C \u2502 \u2514\u2500\u2500 crl_spine01__C \u2502 \u251c\u2500\u2500 ctrl_shoulder__L \u2502 \u2502 \u2514\u2500\u2500 crl_arm__L \u2502 \u2502 \u2514\u2500\u2500 crl_foreArm__L \u2502 \u2502 \u2514\u2500\u2500 crl_hand__L \u2502 \u2502 \u251c\u2500\u2500 crl_handThumb__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handThumbEnd__L \u2502 \u2502 \u251c\u2500\u2500 crl_handIndex__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handIndexEnd__L \u2502 \u2502 \u251c\u2500\u2500 crl_handMiddle_L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddleEnd__L \u2502 \u2502 \u251c\u2500\u2500 crl_handRing_L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handRing01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handRing02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handRingEnd__L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinky_L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinky01__L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinky02__L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinkyEnd__L \u2502 \u251c\u2500\u2500 crl_neck__C \u2502 \u2502 \u2514\u2500\u2500 crl_Head__C \u2502 \u2502 \u251c\u2500\u2500 crl_eye__L \u2502 \u2502 \u2514\u2500\u2500 crl_eye__R \u2502 \u2514\u2500\u2500 crl_shoulder__R \u2502 \u2514\u2500\u2500 crl_arm__R \u2502 \u2514\u2500\u2500 crl_foreArm__R \u2502 \u2514\u2500\u2500 crl_hand__R \u2502 \u251c\u2500\u2500 crl_handThumb__R \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handThumbEnd__R \u2502 \u251c\u2500\u2500 crl_handIndex__R \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handIndexEnd__R \u2502 \u251c\u2500\u2500 crl_handMiddle_R \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddleEnd__R \u2502 \u251c\u2500\u2500 crl_handRing_R \u2502 \u2502 \u2514\u2500\u2500 crl_handRing01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handRing02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handRingEnd__R \u2502 \u2514\u2500\u2500 crl_handPinky_R \u2502 \u2514\u2500\u2500 crl_handPinky01__R \u2502 \u2514\u2500\u2500 crl_handPinky02__R \u2502 \u2514\u2500\u2500 crl_handPinkyEnd__R \u251c\u2500\u2500 crl_thigh__L \u2502 \u2514\u2500\u2500 crl_leg__L \u2502 \u2514\u2500\u2500 crl_foot__L \u2502 \u2514\u2500\u2500 crl_toe__L \u2502 \u2514\u2500\u2500 crl_toeEnd__L \u2514\u2500\u2500 crl_thigh__R \u2514\u2500\u2500 crl_leg__R \u2514\u2500\u2500 crl_foot__R \u2514\u2500\u2500 crl_toe__R \u2514\u2500\u2500 crl_toeEnd__R Manually control walker bones Following is a detailed step-by-step example of how to change the bone transforms of a walker from the CARLA Python API Connect to the simulator Import neccessary libraries used in this example import carla import random Initialize the carla client client = carla.Client('127.0.0.1', 2000) client.set_timeout(2.0) Spawn a walker Spawn a random walker at one of the map's spawn points world = client.get_world() blueprint = random.choice(self.world.get_blueprint_library().filter('walker.*')) spawn_points = world.get_map().get_spawn_points() spawn_point = random.choice(spawn_points) if spawn_points else carla.Transform() world.try_spawn_actor(blueprint, spawn_point) Control walker skeletons A walker's skeleton can be modified by passing an instance of the WalkerBoneControl class to the walker's apply_control function. The WalkerBoneControl class contains the transforms of the bones to be modified. Its bone_transforms member is a list of tuples of value pairs where the first value is the bone name and the second value is the bone transform. The apply_control function can be called on every tick to animate a walker's skeleton. The location and rotation of each transform is relative to its parent. Therefore when a parent bone's transform is modified, the transforms of the child bones in model space will also be changed relatively. In the example below, the rotations of the walker's hands are set to be 90 degrees around the forward axis and the locations are set to the origin. control = carla.WalkerBoneControl() first_tuple = ('crl_hand__R', carla.Transform(rotation=carla.Rotation(roll=90))) second_tuple = ('crl_hand__L', carla.Transform(rotation=carla.Rotation(roll=90))) control.bone_transforms = [first_tuple, second_tuple] world.player.apply_control(control)","title":"\u63a7\u5236\u884c\u4eba\u9aa8\u9abc"},{"location":"tuto_G_control_walker_skeletons/#walker-bone-control","text":"In this tutorial we describe how to manually control and animate the skeletons of walkers from the CARLA Python API. The reference of all classes and methods available can be found at Python API reference . Walker skeleton structure Manually control walker bones Connect to the simulator Spawn a walker Control walker skeletons Note This document assumes the user is familiar with the Python API . The user should read the first steps tutorial before reading this document. Core concepts .","title":"Walker Bone Control"},{"location":"tuto_G_control_walker_skeletons/#walker-skeleton-structure","text":"All walkers have the same skeleton hierarchy and bone names. Below is an image of the skeleton hierarchy. crl_root \u2514\u2500\u2500 crl_hips__C \u251c\u2500\u2500 crl_spine__C \u2502 \u2514\u2500\u2500 crl_spine01__C \u2502 \u251c\u2500\u2500 ctrl_shoulder__L \u2502 \u2502 \u2514\u2500\u2500 crl_arm__L \u2502 \u2502 \u2514\u2500\u2500 crl_foreArm__L \u2502 \u2502 \u2514\u2500\u2500 crl_hand__L \u2502 \u2502 \u251c\u2500\u2500 crl_handThumb__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handThumbEnd__L \u2502 \u2502 \u251c\u2500\u2500 crl_handIndex__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handIndexEnd__L \u2502 \u2502 \u251c\u2500\u2500 crl_handMiddle_L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddleEnd__L \u2502 \u2502 \u251c\u2500\u2500 crl_handRing_L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handRing01__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handRing02__L \u2502 \u2502 \u2502 \u2514\u2500\u2500 crl_handRingEnd__L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinky_L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinky01__L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinky02__L \u2502 \u2502 \u2514\u2500\u2500 crl_handPinkyEnd__L \u2502 \u251c\u2500\u2500 crl_neck__C \u2502 \u2502 \u2514\u2500\u2500 crl_Head__C \u2502 \u2502 \u251c\u2500\u2500 crl_eye__L \u2502 \u2502 \u2514\u2500\u2500 crl_eye__R \u2502 \u2514\u2500\u2500 crl_shoulder__R \u2502 \u2514\u2500\u2500 crl_arm__R \u2502 \u2514\u2500\u2500 crl_foreArm__R \u2502 \u2514\u2500\u2500 crl_hand__R \u2502 \u251c\u2500\u2500 crl_handThumb__R \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handThumb02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handThumbEnd__R \u2502 \u251c\u2500\u2500 crl_handIndex__R \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handIndex02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handIndexEnd__R \u2502 \u251c\u2500\u2500 crl_handMiddle_R \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddle02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handMiddleEnd__R \u2502 \u251c\u2500\u2500 crl_handRing_R \u2502 \u2502 \u2514\u2500\u2500 crl_handRing01__R \u2502 \u2502 \u2514\u2500\u2500 crl_handRing02__R \u2502 \u2502 \u2514\u2500\u2500 crl_handRingEnd__R \u2502 \u2514\u2500\u2500 crl_handPinky_R \u2502 \u2514\u2500\u2500 crl_handPinky01__R \u2502 \u2514\u2500\u2500 crl_handPinky02__R \u2502 \u2514\u2500\u2500 crl_handPinkyEnd__R \u251c\u2500\u2500 crl_thigh__L \u2502 \u2514\u2500\u2500 crl_leg__L \u2502 \u2514\u2500\u2500 crl_foot__L \u2502 \u2514\u2500\u2500 crl_toe__L \u2502 \u2514\u2500\u2500 crl_toeEnd__L \u2514\u2500\u2500 crl_thigh__R \u2514\u2500\u2500 crl_leg__R \u2514\u2500\u2500 crl_foot__R \u2514\u2500\u2500 crl_toe__R \u2514\u2500\u2500 crl_toeEnd__R","title":"Walker skeleton structure"},{"location":"tuto_G_control_walker_skeletons/#manually-control-walker-bones","text":"Following is a detailed step-by-step example of how to change the bone transforms of a walker from the CARLA Python API","title":"Manually control walker bones"},{"location":"tuto_G_control_walker_skeletons/#connect-to-the-simulator","text":"Import neccessary libraries used in this example import carla import random Initialize the carla client client = carla.Client('127.0.0.1', 2000) client.set_timeout(2.0)","title":"Connect to the simulator"},{"location":"tuto_G_control_walker_skeletons/#spawn-a-walker","text":"Spawn a random walker at one of the map's spawn points world = client.get_world() blueprint = random.choice(self.world.get_blueprint_library().filter('walker.*')) spawn_points = world.get_map().get_spawn_points() spawn_point = random.choice(spawn_points) if spawn_points else carla.Transform() world.try_spawn_actor(blueprint, spawn_point)","title":"Spawn a walker"},{"location":"tuto_G_control_walker_skeletons/#control-walker-skeletons","text":"A walker's skeleton can be modified by passing an instance of the WalkerBoneControl class to the walker's apply_control function. The WalkerBoneControl class contains the transforms of the bones to be modified. Its bone_transforms member is a list of tuples of value pairs where the first value is the bone name and the second value is the bone transform. The apply_control function can be called on every tick to animate a walker's skeleton. The location and rotation of each transform is relative to its parent. Therefore when a parent bone's transform is modified, the transforms of the child bones in model space will also be changed relatively. In the example below, the rotations of the walker's hands are set to be 90 degrees around the forward axis and the locations are set to the origin. control = carla.WalkerBoneControl() first_tuple = ('crl_hand__R', carla.Transform(rotation=carla.Rotation(roll=90))) second_tuple = ('crl_hand__L', carla.Transform(rotation=carla.Rotation(roll=90))) control.bone_transforms = [first_tuple, second_tuple] world.player.apply_control(control)","title":"Control walker skeletons"},{"location":"tuto_G_openstreetmap/","text":"Generate maps with OpenStreetMap In this guide you will learn: How to export a map from OpenStreetMaps. The different formats of map that can be used in CARLA and each format's limitations. How to convert the native .osm format to .xodr . How to include traffic light information in the .xodr file. How to run the final map in a CARLA simulation. OpenStreetMap is an open data map of the world developed by thousands of contributors and licensed under the Open Data Commons Open Database License . Sections of the map can be exported to an XML formatted .osm file. CARLA can convert this file to an OpenDRIVE format and ingest it using the OpenDRIVE Standalone Mode . Export a map with OpenStreetMap Using OpenStreetMaps in CARLA Convert OpenStreetMap format to OpenDRIVE format Linux Windows Generate Traffic Lights Ingest into CARLA Export a map with OpenStreetMap This section explains how to export your desired map information from Open Street Map: 1. Navigate to the Open Street Map website . You will see the map view and a panel on the right side of the window where you can configure different map layers, query different features, toggle the legend, and more. 2. Search for your desired location and zoom in to a specific area. Note If you would like to use a map of a large area, for example, Paris, you may consider using CARLA's Large Map feature . 3. Click on Export on the upper left side of the window to open the Export panel. 4. Click on Manually select a different area in the Export panel. 5. Select a custom area by dragging the corners of the square area in the viewport. 6. Click the Export button in the Export panel and save the map information of the selected area as a .osm file. Using OpenStreetMaps in CARLA Open Street Map data can be used in CARLA via three different methods. The method you use will depend on if the data is in the original .osm format or if you convert the file to .xodr using the conversion method explained in the following sections. Keeping the file in .osm is the most restrictive method as it does not allow for settings customization. Options available for .xodr format: Generate the map in your own script. This method allows parameterization. Pass the file as a parameter to CARLA's config.py . This method does not allow parameterization. Options available for .osm format: Pass the file as a parameter to CARLA's config.py . This method does not allow parameterization. The following sections will provide more detail on the options listed above. Convert OpenStreetMap format to OpenDRIVE format This section demonstrates how to use the Python API to convert the .osm file we exported in the previous section to .xodr format so that it is ready for use in CARLA. The carla.Osm2OdrSettings class is used to configure conversion settings such as offset values, traffic light generation, origin coordinates, and more. The full list of configurable parameters is found in the Python API documentation . The carla.Osm2Odr class uses these settings to parse the .osm data and output it in .xodr format. In Windows, the .osm file must be encoded to UTF-8 . This is not necessary in Linux. Below are example code snippets that show how to perform the file conversion depending on your operating system: Linux # Read the .osm data f = open(\"path/to/osm/file\", 'r') osm_data = f.read() f.close() # Define the desired settings. In this case, default values. settings = carla.Osm2OdrSettings() # Set OSM road types to export to OpenDRIVE settings.set_osm_way_types([\"motorway\", \"motorway_link\", \"trunk\", \"trunk_link\", \"primary\", \"primary_link\", \"secondary\", \"secondary_link\", \"tertiary\", \"tertiary_link\", \"unclassified\", \"residential\"]) # Convert to .xodr xodr_data = carla.Osm2Odr.convert(osm_data, settings) # save opendrive file f = open(\"path/to/output/file\", 'w') f.write(xodr_data) f.close() Windows import io # Read the .osm data f = io.open(\"test\", mode=\"r\", encoding=\"utf-8\") osm_data = f.read() f.close() # Define the desired settings. In this case, default values. settings = carla.Osm2OdrSettings() # Set OSM road types to export to OpenDRIVE settings.set_osm_way_types([\"motorway\", \"motorway_link\", \"trunk\", \"trunk_link\", \"primary\", \"primary_link\", \"secondary\", \"secondary_link\", \"tertiary\", \"tertiary_link\", \"unclassified\", \"residential\"]) # Convert to .xodr xodr_data = carla.Osm2Odr.convert(osm_data, settings) # save opendrive file f = open(\"path/to/output/file\", 'w') f.write(xodr_data) f.close() Generate Traffic Lights Open Street Map data can define which junctions are controlled with traffic lights. To use this traffic light data in CARLA, you need to enable it in the OSM map settings via the Python API before converting the .osm file to .xodr format: # Define the desired settings. In this case, default values. settings = carla.Osm2OdrSettings() # enable traffic light generation from OSM data settings.generate_traffic_lights = True # Convert to .xodr xodr_data = carla.Osm2Odr.convert(osm_data, settings) Traffic light data quality can vary depending on the region from which you extract data. Some traffic light information may be missing completely. To work within these limitations, you can use the Python API to configure all junctions to be controlled with traffic lights: settings.all_junctions_with_traffic_lights = True You can also exclude certain roads, e.g., motorway links, from generating traffic lights: settings.set_traffic_light_excluded_way_types([\"motorway_link\"]) Ingest into CARLA This section explains how to use the different options available to ingest your Open Street Map information into CARLA using the OpenDRIVE Standalone Mode . There are three options available: A) Generate the map using a converted .xodr file in your own custom Python script. This method allows parameterization. B) Pass a converted .xodr file as a parameter to the CARLA config.py script. This method does not allow parameterization. C) Pass the original .osm file as a parameter to the CARLA config.py script. This method does not allow parameterization. A) Use your own script Generate the new map and block the simulation until it is ready by calling client.generate_opendrive_world() . Use the carla.OpendriveGenerationParameters class to configure the mesh generation. See below for an example: vertex_distance = 2.0 # in meters max_road_length = 500.0 # in meters wall_height = 0.0 # in meters extra_width = 0.6 # in meters world = client.generate_opendrive_world( xodr_xml, carla.OpendriveGenerationParameters( vertex_distance=vertex_distance, max_road_length=max_road_length, wall_height=wall_height, additional_width=extra_width, smooth_junctions=True, enable_mesh_visibility=True)) Note wall_height = 0.0 is strongly recommended. OpenStreetMap defines lanes in opposing directions as different roads. If walls are generated, this will result in wall overlapping and undesired collisions. B) Pass .xodr to config.py After you have started a CARLA server, run the following command in a separate terminal to load your Open Street Map: cd PythonAPI/util python3 config.py -x=/path/to/xodr/file Default parameters will be used. C) Pass .osm to config.py After you have started a CARLA server, run the following command in a separate terminal to load your Open Street Map: cd PythonAPI/util python3 config.py --osm-path=/path/to/OSM/file Default parameters will be used. Regardless of the method used, the map will be ingested into CARLA and the result should be similar to the image below: Outcome of the CARLA map generation using OpenStreetMap. Warning The roads generated end abruptly at the borders of the map. This will cause the Traffic Manager to crash when vehicles are not able to find the next waypoint. To avoid this, the OSM mode in the Traffic Manager is set to True by default ( set_osm_mode() ). This will show a warning and destroy vehicles when necessary. Any issues and doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"\u4f7f\u7528OpenStreetMap\u751f\u6210\u5730\u56fe"},{"location":"tuto_G_openstreetmap/#generate-maps-with-openstreetmap","text":"In this guide you will learn: How to export a map from OpenStreetMaps. The different formats of map that can be used in CARLA and each format's limitations. How to convert the native .osm format to .xodr . How to include traffic light information in the .xodr file. How to run the final map in a CARLA simulation. OpenStreetMap is an open data map of the world developed by thousands of contributors and licensed under the Open Data Commons Open Database License . Sections of the map can be exported to an XML formatted .osm file. CARLA can convert this file to an OpenDRIVE format and ingest it using the OpenDRIVE Standalone Mode . Export a map with OpenStreetMap Using OpenStreetMaps in CARLA Convert OpenStreetMap format to OpenDRIVE format Linux Windows Generate Traffic Lights Ingest into CARLA","title":"Generate maps with OpenStreetMap"},{"location":"tuto_G_openstreetmap/#export-a-map-with-openstreetmap","text":"This section explains how to export your desired map information from Open Street Map: 1. Navigate to the Open Street Map website . You will see the map view and a panel on the right side of the window where you can configure different map layers, query different features, toggle the legend, and more. 2. Search for your desired location and zoom in to a specific area. Note If you would like to use a map of a large area, for example, Paris, you may consider using CARLA's Large Map feature . 3. Click on Export on the upper left side of the window to open the Export panel. 4. Click on Manually select a different area in the Export panel. 5. Select a custom area by dragging the corners of the square area in the viewport. 6. Click the Export button in the Export panel and save the map information of the selected area as a .osm file.","title":"Export a map with OpenStreetMap"},{"location":"tuto_G_openstreetmap/#using-openstreetmaps-in-carla","text":"Open Street Map data can be used in CARLA via three different methods. The method you use will depend on if the data is in the original .osm format or if you convert the file to .xodr using the conversion method explained in the following sections. Keeping the file in .osm is the most restrictive method as it does not allow for settings customization. Options available for .xodr format: Generate the map in your own script. This method allows parameterization. Pass the file as a parameter to CARLA's config.py . This method does not allow parameterization. Options available for .osm format: Pass the file as a parameter to CARLA's config.py . This method does not allow parameterization. The following sections will provide more detail on the options listed above.","title":"Using OpenStreetMaps in CARLA"},{"location":"tuto_G_openstreetmap/#convert-openstreetmap-format-to-opendrive-format","text":"This section demonstrates how to use the Python API to convert the .osm file we exported in the previous section to .xodr format so that it is ready for use in CARLA. The carla.Osm2OdrSettings class is used to configure conversion settings such as offset values, traffic light generation, origin coordinates, and more. The full list of configurable parameters is found in the Python API documentation . The carla.Osm2Odr class uses these settings to parse the .osm data and output it in .xodr format. In Windows, the .osm file must be encoded to UTF-8 . This is not necessary in Linux. Below are example code snippets that show how to perform the file conversion depending on your operating system:","title":"Convert OpenStreetMap format to OpenDRIVE format"},{"location":"tuto_G_openstreetmap/#linux","text":"# Read the .osm data f = open(\"path/to/osm/file\", 'r') osm_data = f.read() f.close() # Define the desired settings. In this case, default values. settings = carla.Osm2OdrSettings() # Set OSM road types to export to OpenDRIVE settings.set_osm_way_types([\"motorway\", \"motorway_link\", \"trunk\", \"trunk_link\", \"primary\", \"primary_link\", \"secondary\", \"secondary_link\", \"tertiary\", \"tertiary_link\", \"unclassified\", \"residential\"]) # Convert to .xodr xodr_data = carla.Osm2Odr.convert(osm_data, settings) # save opendrive file f = open(\"path/to/output/file\", 'w') f.write(xodr_data) f.close()","title":"Linux"},{"location":"tuto_G_openstreetmap/#windows","text":"import io # Read the .osm data f = io.open(\"test\", mode=\"r\", encoding=\"utf-8\") osm_data = f.read() f.close() # Define the desired settings. In this case, default values. settings = carla.Osm2OdrSettings() # Set OSM road types to export to OpenDRIVE settings.set_osm_way_types([\"motorway\", \"motorway_link\", \"trunk\", \"trunk_link\", \"primary\", \"primary_link\", \"secondary\", \"secondary_link\", \"tertiary\", \"tertiary_link\", \"unclassified\", \"residential\"]) # Convert to .xodr xodr_data = carla.Osm2Odr.convert(osm_data, settings) # save opendrive file f = open(\"path/to/output/file\", 'w') f.write(xodr_data) f.close()","title":"Windows"},{"location":"tuto_G_openstreetmap/#generate-traffic-lights","text":"Open Street Map data can define which junctions are controlled with traffic lights. To use this traffic light data in CARLA, you need to enable it in the OSM map settings via the Python API before converting the .osm file to .xodr format: # Define the desired settings. In this case, default values. settings = carla.Osm2OdrSettings() # enable traffic light generation from OSM data settings.generate_traffic_lights = True # Convert to .xodr xodr_data = carla.Osm2Odr.convert(osm_data, settings) Traffic light data quality can vary depending on the region from which you extract data. Some traffic light information may be missing completely. To work within these limitations, you can use the Python API to configure all junctions to be controlled with traffic lights: settings.all_junctions_with_traffic_lights = True You can also exclude certain roads, e.g., motorway links, from generating traffic lights: settings.set_traffic_light_excluded_way_types([\"motorway_link\"])","title":"Generate Traffic Lights"},{"location":"tuto_G_openstreetmap/#ingest-into-carla","text":"This section explains how to use the different options available to ingest your Open Street Map information into CARLA using the OpenDRIVE Standalone Mode . There are three options available: A) Generate the map using a converted .xodr file in your own custom Python script. This method allows parameterization. B) Pass a converted .xodr file as a parameter to the CARLA config.py script. This method does not allow parameterization. C) Pass the original .osm file as a parameter to the CARLA config.py script. This method does not allow parameterization.","title":"Ingest into CARLA"},{"location":"tuto_G_openstreetmap/#a-use-your-own-script","text":"Generate the new map and block the simulation until it is ready by calling client.generate_opendrive_world() . Use the carla.OpendriveGenerationParameters class to configure the mesh generation. See below for an example: vertex_distance = 2.0 # in meters max_road_length = 500.0 # in meters wall_height = 0.0 # in meters extra_width = 0.6 # in meters world = client.generate_opendrive_world( xodr_xml, carla.OpendriveGenerationParameters( vertex_distance=vertex_distance, max_road_length=max_road_length, wall_height=wall_height, additional_width=extra_width, smooth_junctions=True, enable_mesh_visibility=True)) Note wall_height = 0.0 is strongly recommended. OpenStreetMap defines lanes in opposing directions as different roads. If walls are generated, this will result in wall overlapping and undesired collisions.","title":"A) Use your own script"},{"location":"tuto_G_openstreetmap/#b-pass-xodr-to-configpy","text":"After you have started a CARLA server, run the following command in a separate terminal to load your Open Street Map: cd PythonAPI/util python3 config.py -x=/path/to/xodr/file Default parameters will be used.","title":"B) Pass .xodr to config.py"},{"location":"tuto_G_openstreetmap/#c-pass-osm-to-configpy","text":"After you have started a CARLA server, run the following command in a separate terminal to load your Open Street Map: cd PythonAPI/util python3 config.py --osm-path=/path/to/OSM/file Default parameters will be used. Regardless of the method used, the map will be ingested into CARLA and the result should be similar to the image below: Outcome of the CARLA map generation using OpenStreetMap. Warning The roads generated end abruptly at the borders of the map. This will cause the Traffic Manager to crash when vehicles are not able to find the next waypoint. To avoid this, the OSM mode in the Traffic Manager is set to True by default ( set_osm_mode() ). This will show a warning and destroy vehicles when necessary. Any issues and doubts related with this topic can be posted in the CARLA forum. CARLA forum","title":"C) Pass .osm to config.py"},{"location":"tuto_G_retrieve_data/","text":"Retrieve simulation data Learning an efficient way to retrieve simulation data is essential in CARLA. This holistic tutorial is advised for both, newcomers and more experienced users. It starts from the very beginning, and gradually dives into the many options available in CARLA. First, the simulation is initialized with custom settings and traffic. An ego vehicle is set to roam around the city, optionally with some basic sensors. The simulation is recorded, so that later it can be queried to find the highlights. After that, the original simulation is played back, and exploited to the limit. New sensors can be added to retrieve consistent data. The weather conditions can be changed. The recorder can even be used to test specific scenarios with different outputs. Overview Set the simulation Map setting Weather setting Set traffic CARLA traffic and pedestrians SUMO co-simulation traffic Set the ego vehicle Spawn the ego vehicle Place the spectator Set basic sensors RGB camera Detectors Other sensors Set advanced sensors Depth camera Semantic segmentation camera LIDAR raycast sensor Radar sensor No-rendering-mode Simulate at a fast pace Manual control without rendering Record and retrieve data Start recording Capture and record Stop recording Exploit the recording Query the events Choose a fragment Retrieve more data Change the weather Try new outcomes Tutorial scripts Overview There are some common mistakes in the process of retrieving simulation data. Flooding the simulator with sensors, storing useless data, or struggling to find a specific event are some examples. However, some outlines to this process can be provided. The goal is to ensure that data can be retrieved and replicated, and the simulation can be examined and altered at will. Note This tutorial uses the CARLA 0.9.8 deb package . There may be minor changes depending on your CARLA version and installation, specially regarding paths. The tutorial presents a wide set of options for the differents steps. All along, different scripts will be mentioned. Not all of them will be used, it depends on the specific use cases. Most of them are already provided in CARLA for generic purposes. config.py changes the simulation settings. Map, rendering options, set a fixed time-step... carla/PythonAPI/util/config.py dynamic_weather.py creates interesting weather conditions. carla/PythonAPI/examples/dynamic_weather.py spawn_npc.py spawns some AI controlled vehicles and walkers. carla/PythonAPI/examples/spawn_npc.py manual_control.py spawns an ego vehicle, and provides control over it. carla/PythonAPI/examples/manual_control.py However, there are two scripts mentioned along the tutorial that cannot be found in CARLA. They contain the fragments of code cited. This serves a twofold purpose. First of all, to encourage users to build their own scripts. It is important to have full understanding of what the code is doing. In addition to this, the tutorial is only an outline that may, and should, vary a lot depending on user preferences. These two scripts are just an example. tutorial_ego.py spawns an ego vehicle with some basic sensors, and enables autopilot. The spectator is placed at the spawning position. The recorder starts at the very beginning, and stops when the script is finished. tutorial_replay.py reenacts the simulation that tutorial_ego.py recorded. There are different fragments of code to query the recording, spawn some advanced sensors, change weather conditions, and reenact fragments of the recording. The full code can be found in the last section of the tutorial. Remember these are not strict, but meant to be customized. Retrieving data in CARLA is as powerful as users want it to be. Important This tutorial requires some knowledge of Python. Set the simulation The first thing to do is set the simulation ready to a desired environment. Run CARLA. cd /opt/carla/bin ./CarlaUE.sh Map setting Choose a map for the simulation to run. Take a look at the map documentation to learn more about their specific attributes. For the sake of this tutorial, Town07 is chosen. Open a new terminal. Change the map using the config.py script. cd /opt/carla/PythonAPI/utils python3 config.py --map Town01 This script can enable different settings. Some of them will be mentioned during the tutorial, others will not. Hereunder there is a brief summary. Optional arguments in config.py -h, --help show this help message and exit --host H IP of the host CARLA Simulator (default: localhost) -p P, --port P TCP port of CARLA Simulator (default: 2000) -d, --default set default settings -m MAP, --map MAP load a new map, use --list to see available maps -r, --reload-map reload current map --delta-seconds S set fixed delta seconds, zero for variable frame rate --fps N set fixed FPS, zero for variable FPS (similar to --delta-seconds) --rendering enable rendering --no-rendering disable rendering --no-sync disable synchronous mode --weather WEATHER set weather preset, use --list to see available presets -i, --inspect inspect simulation -l, --list list available options -b FILTER, --list-blueprints FILTER list available blueprints matching FILTER (use '*' to list them all) -x XODR_FILE_PATH, --xodr-path XODR_FILE_PATH load a new map with a minimum physical road representation of the provided OpenDRIVE Aerial view of Town07 Weather setting Each town is loaded with a specific weather that fits it, however this can be set at will. There are two scripts that offer different approaches to the matter. The first one sets a dynamic weather that changes conditions over time. The other sets custom weather conditions. It is also possible to code weather conditions. This will be covered later when changing weather conditions . To set a dynamic weather . Open a new terminal and run dynamic_weather.py . This script allows to set the ratio at which the weather changes, being 1.0 the default setting. cd /opt/carla/PythonAPI/examples python3 dynamic_weather.py --speed 1.0 To set custom conditions . Use the script environment.py . There are quite a lot of possible settings. Take a look at the optional arguments, and the documentation for carla.WeatherParameters . cd /opt/carla/PythonAPI/util python3 environment.py --clouds 100 --rain 80 --wetness 100 --puddles 60 --wind 80 --fog 50 Optional arguments in environment.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) --sun SUN Sun position presets [sunset | day | night] --weather WEATHER Weather condition presets [clear | overcast | rain] --altitude A, -alt A Sun altitude [-90.0, 90.0] --azimuth A, -azm A Sun azimuth [0.0, 360.0] --clouds C, -c C Clouds amount [0.0, 100.0] --rain R, -r R Rain amount [0.0, 100.0] --puddles Pd, -pd Pd Puddles amount [0.0, 100.0] --wind W, -w W Wind intensity [0.0, 100.0] --fog F, -f F Fog intensity [0.0, 100.0] --fogdist Fd, -fd Fd Fog Distance [0.0, inf) --wetness Wet, -wet Wet Wetness intensity [0.0, 100.0] Weather changes applied Set traffic Simulating traffic is one of the best ways to bring the map to life. It is also necessary to retrieve data for urban environments. There are different options to do so in CARLA. CARLA traffic and pedestrians The CARLA traffic is managed by the Traffic Manager module. As for pedestrians, each of them has their own carla.WalkerAIController . Open a new terminal, and run spawn_npc.py to spawn vehicles and walkers. Let's just spawn 50 vehicles and the same amount of walkers. cd /opt/carla/PythonAPI/examples python3 spawn_npc.py -n 50 -w 50 --safe Optional arguments in spawn_npc.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) -n N, --number-of-vehicles N number of vehicles (default: 10) -w W, --number-of-walkers W number of walkers (default: 50) --safe avoid spawning vehicles prone to accidents --filterv PATTERN vehicles filter (default: \"vehicle.*\") --filterw PATTERN pedestrians filter (default: \"walker.pedestrian.*\") -tm_p P, --tm-port P port to communicate with TM (default: 8000) --async Asynchronous mode execution Vehicles spawned to simulate traffic. SUMO co-simulation traffic CARLA can run a co-simulation with SUMO. This allows for creating traffic in SUMO that will be propagated to CARLA. This co-simulation is bidirectional. Spawning vehicles in CARLA will do so in SUMO. Specific docs on this feature can be found here . This feature is available for CARLA 0.9.8 and later, in Town01 , Town04 , and Town05 . The first one is the most stable. Note The co-simulation will enable synchronous mode in CARLA. Read the documentation to find out more about this. First of all, install SUMO. sudo add-apt-repository ppa:sumo/stable sudo apt-get update sudo apt-get install sumo sumo-tools sumo-doc Set the environment variable SUMO_HOME. echo \"export SUMO_HOME=/usr/share/sumo\" >> ~/.bashrc && source ~/.bashrc With the CARLA server on, run the SUMO-CARLA synchrony script . cd ~/carla/Co-Simulation/Sumo python3 run_synchronization.py examples/Town01.sumocfg --sumo-gui A SUMO window should have opened. Press Play in order to start traffic in both simulations. > \"Play\" on SUMO window. The traffic generated by this script is an example created by the CARLA team. By default it spawns the same vehicles following the same routes. These can be changed by the user in SUMO. SUMO and CARLA co-simulating traffic. Warning Right now, SUMO co-simulation is a beta feature. Vehicles do not have physics nor take into account CARLA traffic lights. Set the ego vehicle From now up to the moment the recorder is stopped, there will be some fragments of code belonging to tutorial_ego.py . This script spawns the ego vehicle, optionally some sensors, and records the simulation until the user finishes the script. Spawn the ego vehicle Vehicles controlled by the user are commonly differenciated in CARLA by setting the attribute role_name to ego . Other attributes can be set, some with recommended values. Hereunder, a Tesla model is retrieved from the blueprint library , and spawned with a random recommended colour. One of the recommended spawn points by the map is chosen to place the ego vehicle. # -------------- # Spawn ego vehicle # -------------- ego_bp = world.get_blueprint_library().find('vehicle.tesla.model3') ego_bp.set_attribute('role_name','ego') print('\\nEgo role_name is set') ego_color = random.choice(ego_bp.get_attribute('color').recommended_values) ego_bp.set_attribute('color',ego_color) print('\\nEgo color is set') spawn_points = world.get_map().get_spawn_points() number_of_spawn_points = len(spawn_points) if 0 < number_of_spawn_points: random.shuffle(spawn_points) ego_transform = spawn_points[0] ego_vehicle = world.spawn_actor(ego_bp,ego_transform) print('\\nEgo is spawned') else: logging.warning('Could not found any spawn points') Place the spectator The spectator actor controls the simulation view. Moving it via script is optional, but it may facilitate finding the ego vehicle. # -------------- # Spectator on ego position # -------------- spectator = world.get_spectator() world_snapshot = world.wait_for_tick() spectator.set_transform(ego_vehicle.get_transform()) Set basic sensors The process to spawn any sensor is quite similar. 1. Use the library to find sensor blueprints. 2. Set specific attributes for the sensor. This is crucial. Attributes will shape the data retrieved. 3. Attach the sensor to the ego vehicle. The transform is relative to its parent . The carla.AttachmentType will determine how the position of the sensor is updated. 4. Add a listen() method. This is the key element. A lambda method that will be called each time the sensor listens for data. The argument is the sensor data retrieved. Having this basic guideline in mind, let's set some basic sensors for the ego vehicle. RGB camera The RGB camera generates realistic pictures of the scene. It is the sensor with more settable attributes of them all, but it is also a fundamental one. It should be understood as a real camera, with attributtes such as focal_distance , shutter_speed or gamma to determine how it would work internally. There is also a specific set of attributtes to define the lens distorsion, and lots of advanced attributes. For example, the lens_circle_multiplier can be used to achieve an effect similar to an eyefish lens. Learn more about them in the documentation . For the sake of simplicity, the script only sets the most commonly used attributes of this sensor. image_size_x and image_size_y will change the resolution of the output image. fov is the horizontal field of view of the camera. After setting the attributes, it is time to spawn the sensor. The script places the camera in the hood of the car, and pointing forward. It will capture the front view of the car. The data is retrieved as a carla.Image on every step. The listen method saves these to disk. The path can be altered at will. The name of each image is coded to be based on the simulation frame where the shot was taken. # -------------- # Spawn attached RGB camera # -------------- cam_bp = None cam_bp = world.get_blueprint_library().find('sensor.camera.rgb') cam_bp.set_attribute(\"image_size_x\",str(1920)) cam_bp.set_attribute(\"image_size_y\",str(1080)) cam_bp.set_attribute(\"fov\",str(105)) cam_location = carla.Location(2,0,1) cam_rotation = carla.Rotation(0,180,0) cam_transform = carla.Transform(cam_location,cam_rotation) ego_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) ego_cam.listen(lambda image: image.save_to_disk('tutorial/output/%.6d.jpg' % image.frame)) RGB camera output Detectors These sensors retrieve data when the object they are attached to registers a specific event. There are three type of detector sensors, each one describing one type of event. Collision detector. Retrieves collisions between its parent and other actors. Lane invasion detector. Registers when its parent crosses a lane marking. Obstacle detector. Detects possible obstacles ahead of its parent. The data they retrieve will be helpful later when deciding which part of the simulation is going to be reenacted. In fact, the collisions can be explicitely queried using the recorder. This is prepared to be printed. Only the obstacle detector blueprint has attributes to be set. Here are some important ones. sensor_tick sets the sensor to retrieve data only after x seconds pass. It is a common attribute for sensors that retrieve data on every step. distance and hit-radius shape the debug line used to detect obstacles ahead. only_dynamics determines if static objects should be taken into account or not. By default, any object is considered. The script sets the obstacle detector to only consider dynamic objects. If the vehicle collides with any static object, it will be detected by the collision sensor. # -------------- # Add collision sensor to ego vehicle. # -------------- col_bp = world.get_blueprint_library().find('sensor.other.collision') col_location = carla.Location(0,0,0) col_rotation = carla.Rotation(0,0,0) col_transform = carla.Transform(col_location,col_rotation) ego_col = world.spawn_actor(col_bp,col_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def col_callback(colli): print(\"Collision detected:\\n\"+str(colli)+'\\n') ego_col.listen(lambda colli: col_callback(colli)) # -------------- # Add Lane invasion sensor to ego vehicle. # -------------- lane_bp = world.get_blueprint_library().find('sensor.other.lane_invasion') lane_location = carla.Location(0,0,0) lane_rotation = carla.Rotation(0,0,0) lane_transform = carla.Transform(lane_location,lane_rotation) ego_lane = world.spawn_actor(lane_bp,lane_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def lane_callback(lane): print(\"Lane invasion detected:\\n\"+str(lane)+'\\n') ego_lane.listen(lambda lane: lane_callback(lane)) # -------------- # Add Obstacle sensor to ego vehicle. # -------------- obs_bp = world.get_blueprint_library().find('sensor.other.obstacle') obs_bp.set_attribute(\"only_dynamics\",str(True)) obs_location = carla.Location(0,0,0) obs_rotation = carla.Rotation(0,0,0) obs_transform = carla.Transform(obs_location,obs_rotation) ego_obs = world.spawn_actor(obs_bp,obs_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def obs_callback(obs): print(\"Obstacle detected:\\n\"+str(obs)+'\\n') ego_obs.listen(lambda obs: obs_callback(obs)) Output for detector sensors Other sensors Only two sensors of this category will be considered for the time being. GNSS sensor. Retrieves the geolocation of the sensor. IMU sensor. Comprises an accelerometer, a gyroscope, and a compass. To get general measures for the vehicle object, these two sensors are spawned centered to it. The attributes available for these sensors mostly set the mean or standard deviation parameter in the noise model of the measure. This is useful to get more realistic measures. However, in tutorial_ego.py only one attribute is set. sensor_tick . As this measures are not supposed to vary significantly between steps, it is okay to retrieve the data every so often. In this case, it is set to be printed every three seconds. # -------------- # Add GNSS sensor to ego vehicle. # -------------- gnss_bp = world.get_blueprint_library().find('sensor.other.gnss') gnss_location = carla.Location(0,0,0) gnss_rotation = carla.Rotation(0,0,0) gnss_transform = carla.Transform(gnss_location,gnss_rotation) gnss_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_gnss = world.spawn_actor(gnss_bp,gnss_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def gnss_callback(gnss): print(\"GNSS measure:\\n\"+str(gnss)+'\\n') ego_gnss.listen(lambda gnss: gnss_callback(gnss)) # -------------- # Add IMU sensor to ego vehicle. # -------------- imu_bp = world.get_blueprint_library().find('sensor.other.imu') imu_location = carla.Location(0,0,0) imu_rotation = carla.Rotation(0,0,0) imu_transform = carla.Transform(imu_location,imu_rotation) imu_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_imu = world.spawn_actor(imu_bp,imu_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def imu_callback(imu): print(\"IMU measure:\\n\"+str(imu)+'\\n') ego_imu.listen(lambda imu: imu_callback(imu)) GNSS and IMU sensors output Set advanced sensors The script tutorial_replay.py , among other things, contains definitions for more sensors. They work in the same way as the basic ones, but their comprehension may be a bit harder. Depth camera The depth camera generates pictures of the scene that map every pixel in a grayscale depth map. However, the output is not straightforward. The depth buffer of the camera is mapped using a RGB color space. This has to be translated to grayscale to be comprehensible. In order to do this, simply save the image as with the RGB camera, but apply a carla.ColorConverter to it. There are two conversions available for depth cameras. carla.ColorConverter.Depth translates the original depth with milimetric precision. carla.ColorConverter.LogarithmicDepth also has milimetric granularity, but provides better results in close distances and a little worse for further elements. The attributes for the depth camera only set elements previously stated in the RGB camera: fov , image_size_x , image_size_y and sensor_tick . The script sets this sensor to match the previous RGB camera used. # -------------- # Add a Depth camera to ego vehicle. # -------------- depth_cam = None depth_bp = world.get_blueprint_library().find('sensor.camera.depth') depth_location = carla.Location(2,0,1) depth_rotation = carla.Rotation(0,180,0) depth_transform = carla.Transform(depth_location,depth_rotation) depth_cam = world.spawn_actor(depth_bp,depth_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view depth_cam.listen(lambda image: image.save_to_disk('tutorial/new_depth_output/%.6d.jpg' % image.frame,carla.ColorConverter.LogarithmicDepth)) Depth camera output. Simple conversion on the left, logarithmic on the right. Semantic segmentation camera The semantic segmentation camera renders elements in scene with a different color depending on how these have been tagged. The tags are created by the simulator depending on the path of the asset used for spawning. For example, meshes tagged as Pedestrians are spawned with content stored in Unreal/CarlaUE4/Content/Static/Pedestrians . The output is an image, as any camera, but each pixel contains the tag encoded in the red channel. This original image must be converted using ColorConverter.CityScapesPalette . New tags can be created, read more in the documentation . The attributes available for this camera are exactly the same as the depth camera. The script also sets this to match the original RGB camera. # -------------- # Add a new semantic segmentation camera to my ego # -------------- sem_cam = None sem_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation') sem_bp.set_attribute(\"image_size_x\",str(1920)) sem_bp.set_attribute(\"image_size_y\",str(1080)) sem_bp.set_attribute(\"fov\",str(105)) sem_location = carla.Location(2,0,1) sem_rotation = carla.Rotation(0,180,0) sem_transform = carla.Transform(sem_location,sem_rotation) sem_cam = world.spawn_actor(sem_bp,sem_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view sem_cam.listen(lambda image: image.save_to_disk('tutorial/new_sem_output/%.6d.jpg' % image.frame,carla.ColorConverter.CityScapesPalette)) Semantic segmentation camera output LIDAR raycast sensor The LIDAR sensor simulates a rotating LIDAR. It creates a cloud of points that maps the scene in 3D. The LIDAR contains a set of lasers that rotate at a certain frequency. The lasers raycast the distance to impact, and store every shot as one single point. The way the array of lasers is disposed can be set using different sensor attributes. upper_fov and lower_fov the angle of the highest and the lowest laser respectively. channels sets the amount of lasers to be used. These are distributed along the desired fov . Other attributes set the way this points are calculated. They determine the amount of points that each laser calculates every step: points_per_second / (FPS * channels) . range is the maximum distance to capture. points_per_second is the amount of points that will be obtained every second. This quantity is divided between the amount of channels . rotation_frequency is the amount of times the LIDAR will rotate every second. The point cloud output is described as a [carla.LidarMeasurement]. It can be iterated as a list of [carla.Location] or saved to a .ply standart file format. # -------------- # Add a new LIDAR sensor to my ego # -------------- lidar_cam = None lidar_bp = world.get_blueprint_library().find('sensor.lidar.ray_cast') lidar_bp.set_attribute('channels',str(32)) lidar_bp.set_attribute('points_per_second',str(90000)) lidar_bp.set_attribute('rotation_frequency',str(40)) lidar_bp.set_attribute('range',str(20)) lidar_location = carla.Location(0,0,2) lidar_rotation = carla.Rotation(0,0,0) lidar_transform = carla.Transform(lidar_location,lidar_rotation) lidar_sen = world.spawn_actor(lidar_bp,lidar_transform,attach_to=ego_vehicle) lidar_sen.listen(lambda point_cloud: point_cloud.save_to_disk('tutorial/new_lidar_output/%.6d.ply' % point_cloud.frame)) The .ply output can be visualized using Meshlab . 1. Install Meshlab . sudo apt-get update -y sudo apt-get install -y meshlab 2. Open Meshlab. meshlab 3. Open one of the .ply files. File > Import mesh... LIDAR output after being processed in Meshlab. Radar sensor The radar sensor is similar to de LIDAR. It creates a conic view, and shoots lasers inside to raycast their impacts. The output is a carla.RadarMeasurement . It contains a list of the carla.RadarDetection retrieved by the lasers. These are not points in space, but detections with data regarding the sensor: azimuth , altitude , sensor and velocity . The attributes of this sensor mostly set the way the lasers are located. horizontal_fov and vertical_fov determine the amplitude of the conic view. channels sets the amount of lasers to be used. These are distributed along the desired fov . range is the maximum distance for the lasers to raycast. points_per_second sets the the amount of points to be captured, that will be divided between the channels stated. The script places the sensor on the hood of the car, and rotated a bit upwards. That way, the output will map the front view of the car. The horizontal_fov is incremented, and the vertical_fov diminished. The area of interest is specially the height where vehicles and walkers usually move on. The range is also changed from 100m to 10m, in order to retrieve data only right ahead of the vehicle. The callback is a bit more complex this time, showing more of its capabilities. It will draw the points captured by the radar on the fly. The points will be colored depending on their velocity regarding the ego vehicle. Blue for points approaching the vehicle. Read for points moving away from it. White for points static regarding the ego vehicle. # -------------- # Add a new radar sensor to my ego # -------------- rad_cam = None rad_bp = world.get_blueprint_library().find('sensor.other.radar') rad_bp.set_attribute('horizontal_fov', str(35)) rad_bp.set_attribute('vertical_fov', str(20)) rad_bp.set_attribute('range', str(20)) rad_location = carla.Location(x=2.0, z=1.0) rad_rotation = carla.Rotation(pitch=5) rad_transform = carla.Transform(rad_location,rad_rotation) rad_ego = world.spawn_actor(rad_bp,rad_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def rad_callback(radar_data): velocity_range = 7.5 # m/s current_rot = radar_data.transform.rotation for detect in radar_data: azi = math.degrees(detect.azimuth) alt = math.degrees(detect.altitude) # The 0.25 adjusts a bit the distance so the dots can # be properly seen fw_vec = carla.Vector3D(x=detect.depth - 0.25) carla.Transform( carla.Location(), carla.Rotation( pitch=current_rot.pitch + alt, yaw=current_rot.yaw + azi, roll=current_rot.roll)).transform(fw_vec) def clamp(min_v, max_v, value): return max(min_v, min(value, max_v)) norm_velocity = detect.velocity / velocity_range # range [-1, 1] r = int(clamp(0.0, 1.0, 1.0 - norm_velocity) * 255.0) g = int(clamp(0.0, 1.0, 1.0 - abs(norm_velocity)) * 255.0) b = int(abs(clamp(- 1.0, 0.0, - 1.0 - norm_velocity)) * 255.0) world.debug.draw_point( radar_data.transform.location + fw_vec, size=0.075, life_time=0.06, persistent_lines=False, color=carla.Color(r, g, b)) rad_ego.listen(lambda radar_data: rad_callback(radar_data)) Radar output. The vehicle is stopped at a traffic light, so the static elements in front of it appear in white. No-rendering mode The no-rendering mode can be useful to run an initial simulation that will be later played again to retrieve data. Especially if this simulation has some extreme conditions, such as dense traffic. Simulate at a fast pace Disabling the rendering will save up a lot of work to the simulation. As the GPU is not used, the server can work at full speed. This could be useful to simulate complex conditions at a fast pace. The best way to do so would be by setting a fixed time-step. Running an asynchronous server with a fixed time-step and no rendering, the only limitation for the simulation would be the inner logic of the server. The same config.py used to set the map can disable rendering, and set a fixed time-step. cd /opt/carla/PythonAPI/utils python3 config.py --no-rendering --delta-seconds 0.05 # Never greater than 0.1s Warning Read the documentation before messing around with with synchrony and time-step. Manual control without rendering The script PythonAPI/examples/no_rendering_mode.py provides an overview of the simulation. It creates a minimalistic aerial view with Pygame, that will follow the ego vehicle. This could be used along with manual_control.py to generate a route with barely no cost, record it, and then play it back and exploit it to gather data. cd /opt/carla/PythonAPI/examples python3 manual_control.py cd /opt/carla/PythonAPI/examples python3 no_rendering_mode.py --no-rendering Optional arguments in no_rendering_mode.py -h, --help show this help message and exit -v, --verbose print debug information --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) --res WIDTHxHEIGHT window resolution (default: 1280x720) --filter PATTERN actor filter (default: \"vehicle.*\") --map TOWN start a new episode at the given TOWN --no-rendering switch off server rendering --show-triggers show trigger boxes of traffic signs --show-connections show waypoint connections --show-spawn-points show recommended spawn points no_rendering_mode.py working in Town07 Note In this mode, GPU-based sensors will retrieve empty data. Cameras are useless, but other sensors such as detectors will work properly. Record and retrieve data Start recording The recorder can be started at anytime. The script does it at the very beginning, in order to capture everything, including the spawning of the first actors. If no path is detailed, the log will be saved into CarlaUE4/Saved . # -------------- # Start recording # -------------- client.start_recorder('~/tutorial/recorder/recording01.log') Capture and record There are many different ways to do this. Mostly it goes down as either let it roam around or control it manually. The data for the sensors spawned will be retrieved on the fly. Make sure to check it while recording, to make sure everything is set properly. Enable the autopilot. This will register the vehicle to the Traffic Manager . It will roam around the city endlessly. The script does this, and creates a loop to prevent the script from finishing. The recording will go on until the user finishes the script. Alternatively, a timer could be set to finish the script after a certain time. # -------------- # Capture data # -------------- ego_vehicle.set_autopilot(True) print('\\nEgo autopilot enabled') while True: world_snapshot = world.wait_for_tick() Manual control. Run the script PythonAPI/examples/manual_control.py in a client, and the recorder in another one. Drive the ego vehicle around to create the desired route, and stop the recorder when finished. The tutorial_ego.py script can be used to manage the recorder, but make sure to comment other fragments of code. cd /opt/carla/PythonAPI/examples python3 manual_control.py Note To avoid rendering and save up computational cost, enable no rendering mode . The script /PythonAPI/examples/no_rendering_mode.py does this while creating a simple aerial view. Stop recording The stop call is even simpler than the start call was. When the recorder is done, the recording will be saved in the path stated previously. # -------------- # Stop recording # -------------- client.stop_recorder() Exploit the recording So far, a simulation has been recorded. Now, it is time to examine the recording, find the most remarkable moments, and work with them. These steps are gathered in the script, tutorial_replay.py . The outline is structured in different segments of code commented. It is time to run a new simulation. ./CarlaUE4.sh To reenact the simulation, choose a fragment and run the script containing the code for the playback. python3 tuto_replay.py Query the events The different queries are detailed in the recorder documentation . In summary, they retrieve data for specific events or frames. Use the queries to study the recording. Find the spotlight moments, and trace what can be of interest. # -------------- # Query the recording # -------------- # Show only the most important events in the recording. print(client.show_recorder_file_info(\"~/tutorial/recorder/recording01.log\",False)) # Show actors not moving 1 meter in 10 seconds. print(client.show_recorder_actors_blocked(\"~/tutorial/recorder/recording01.log\",10,1)) # Filter collisions between vehicles 'v' and 'a' any other type of actor. print(client.show_recorder_collisions(\"~/tutorial/recorder/recording01.log\",'v','a')) Note The recorder does not need to be on, in order to do the queries. Query showing important events. This is the frame where the ego vehicle was spawned. Query showing actors blocked. In this simulation, the ego vehicle remained blocked for 100 seconds. Query showing a collision between the ego vehicle and an object of type \"other\". Note Getting detailed file info for every frame can be overwhelming. Use it after other queries to know where to look at. Choose a fragment After the queries, it may be a good idea play some moments of the simulation back, before messing around. It is very simple to do so, and it could be really helpful. Know more about the simulation. It is the best way to save time later. The method allows to choose the beginning and ending point of the playback, and an actor to follow. # -------------- # Reenact a fragment of the recording # -------------- client.replay_file(\"~/tutorial/recorder/recording01.log\",45,10,0) Here is a list of possible things to do now. Use the information from the queries. Find out the moment and the actors involved in an event, and play that again. Start the recorder a few seconds before the event. Follow different actors. Different perspectives will show new events that are not included in the queries. Rom around with a free spectator view. Set the actor_id to 0 , and get a general view of the simulation. Be wherever and whenever wanted thanks to the recording. Note When the recording stops, the simulation doesn't. Walkers will stand still, and vehicles will continue roaming around. This may happen either if the log ends, or the playback gets to the ending point stated. Retrieve more data The recorder will recreate in this simulation, the exact same conditions as the original. That ensures consistent data within different playbacks. Gather a list of the important moments, actors and events. Add sensors whenever needed and play the simulation back. The process is exactly the same as before. The script tutorial_replay.py provides different examples that have been thoroughly explained in the Set advanced sensors section. Others have been explained in the section Set basic sensors . Add as many sensors as needed, wherever they are needed. Play the simulation back as many times as desired and retrieve as much data as desired. Change the weather The recording will recreate the original weather conditions. However, these can be altered at will. This may be interesting to compare how does it affect sensors, while mantaining the rest of events the same. Get the current weather and modify it freely. Remember that carla.WeatherParameters has some presets available. The script will change the environment to a foggy sunset. # -------------- # Change weather for playback # -------------- weather = world.get_weather() weather.sun_altitude_angle = -30 weather.fog_density = 65 weather.fog_distance = 10 world.set_weather(weather) Try new outcomes The new simulation is not strictly linked to the recording. It can be modified anytime, and even when the recorder stops, the simulation goes on. This can be profitable for the user. For instance, collisions can be forced or avoided by playing back the simulation a few seconds before, and spawning or destroying an actor. Ending the recording at a specific moment can also be useful. Doing so, vehicles may take different paths. Change the conditions and mess with the simulation. There is nothing to lose, as the recorder grants that the initial simulation can always be reenacted. This is the key to exploit the full potential of CARLA. Tutorial scripts Hereunder are the two scripts gathering the fragments of code for this tutorial. Most of the code is commented, as it is meant to be modified to fit specific purposes. tutorial_ego.py import glob import os import sys import time try: sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % ( sys.version_info.major, sys.version_info.minor, 'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0]) except IndexError: pass import carla import argparse import logging import random def main(): argparser = argparse.ArgumentParser( description=__doc__) argparser.add_argument( '--host', metavar='H', default='127.0.0.1', help='IP of the host server (default: 127.0.0.1)') argparser.add_argument( '-p', '--port', metavar='P', default=2000, type=int, help='TCP port to listen to (default: 2000)') args = argparser.parse_args() logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO) client = carla.Client(args.host, args.port) client.set_timeout(10.0) try: world = client.get_world() ego_vehicle = None ego_cam = None ego_col = None ego_lane = None ego_obs = None ego_gnss = None ego_imu = None # -------------- # Start recording # -------------- \"\"\" client.start_recorder('~/tutorial/recorder/recording01.log') \"\"\" # -------------- # Spawn ego vehicle # -------------- \"\"\" ego_bp = world.get_blueprint_library().find('vehicle.tesla.model3') ego_bp.set_attribute('role_name','ego') print('\\nEgo role_name is set') ego_color = random.choice(ego_bp.get_attribute('color').recommended_values) ego_bp.set_attribute('color',ego_color) print('\\nEgo color is set') spawn_points = world.get_map().get_spawn_points() number_of_spawn_points = len(spawn_points) if 0 < number_of_spawn_points: random.shuffle(spawn_points) ego_transform = spawn_points[0] ego_vehicle = world.spawn_actor(ego_bp,ego_transform) print('\\nEgo is spawned') else: logging.warning('Could not found any spawn points') \"\"\" # -------------- # Add a RGB camera sensor to ego vehicle. # -------------- \"\"\" cam_bp = None cam_bp = world.get_blueprint_library().find('sensor.camera.rgb') cam_bp.set_attribute(\"image_size_x\",str(1920)) cam_bp.set_attribute(\"image_size_y\",str(1080)) cam_bp.set_attribute(\"fov\",str(105)) cam_location = carla.Location(2,0,1) cam_rotation = carla.Rotation(0,180,0) cam_transform = carla.Transform(cam_location,cam_rotation) ego_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) ego_cam.listen(lambda image: image.save_to_disk('~/tutorial/output/%.6d.jpg' % image.frame)) \"\"\" # -------------- # Add collision sensor to ego vehicle. # -------------- \"\"\" col_bp = world.get_blueprint_library().find('sensor.other.collision') col_location = carla.Location(0,0,0) col_rotation = carla.Rotation(0,0,0) col_transform = carla.Transform(col_location,col_rotation) ego_col = world.spawn_actor(col_bp,col_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def col_callback(colli): print(\"Collision detected:\\n\"+str(colli)+'\\n') ego_col.listen(lambda colli: col_callback(colli)) \"\"\" # -------------- # Add Lane invasion sensor to ego vehicle. # -------------- \"\"\" lane_bp = world.get_blueprint_library().find('sensor.other.lane_invasion') lane_location = carla.Location(0,0,0) lane_rotation = carla.Rotation(0,0,0) lane_transform = carla.Transform(lane_location,lane_rotation) ego_lane = world.spawn_actor(lane_bp,lane_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def lane_callback(lane): print(\"Lane invasion detected:\\n\"+str(lane)+'\\n') ego_lane.listen(lambda lane: lane_callback(lane)) \"\"\" # -------------- # Add Obstacle sensor to ego vehicle. # -------------- \"\"\" obs_bp = world.get_blueprint_library().find('sensor.other.obstacle') obs_bp.set_attribute(\"only_dynamics\",str(True)) obs_location = carla.Location(0,0,0) obs_rotation = carla.Rotation(0,0,0) obs_transform = carla.Transform(obs_location,obs_rotation) ego_obs = world.spawn_actor(obs_bp,obs_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def obs_callback(obs): print(\"Obstacle detected:\\n\"+str(obs)+'\\n') ego_obs.listen(lambda obs: obs_callback(obs)) \"\"\" # -------------- # Add GNSS sensor to ego vehicle. # -------------- \"\"\" gnss_bp = world.get_blueprint_library().find('sensor.other.gnss') gnss_location = carla.Location(0,0,0) gnss_rotation = carla.Rotation(0,0,0) gnss_transform = carla.Transform(gnss_location,gnss_rotation) gnss_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_gnss = world.spawn_actor(gnss_bp,gnss_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def gnss_callback(gnss): print(\"GNSS measure:\\n\"+str(gnss)+'\\n') ego_gnss.listen(lambda gnss: gnss_callback(gnss)) \"\"\" # -------------- # Add IMU sensor to ego vehicle. # -------------- \"\"\" imu_bp = world.get_blueprint_library().find('sensor.other.imu') imu_location = carla.Location(0,0,0) imu_rotation = carla.Rotation(0,0,0) imu_transform = carla.Transform(imu_location,imu_rotation) imu_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_imu = world.spawn_actor(imu_bp,imu_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def imu_callback(imu): print(\"IMU measure:\\n\"+str(imu)+'\\n') ego_imu.listen(lambda imu: imu_callback(imu)) \"\"\" # -------------- # Place spectator on ego spawning # -------------- \"\"\" spectator = world.get_spectator() world_snapshot = world.wait_for_tick() spectator.set_transform(ego_vehicle.get_transform()) \"\"\" # -------------- # Enable autopilot for ego vehicle # -------------- \"\"\" ego_vehicle.set_autopilot(True) \"\"\" # -------------- # Game loop. Prevents the script from finishing. # -------------- while True: world_snapshot = world.wait_for_tick() finally: # -------------- # Stop recording and destroy actors # -------------- client.stop_recorder() if ego_vehicle is not None: if ego_cam is not None: ego_cam.stop() ego_cam.destroy() if ego_col is not None: ego_col.stop() ego_col.destroy() if ego_lane is not None: ego_lane.stop() ego_lane.destroy() if ego_obs is not None: ego_obs.stop() ego_obs.destroy() if ego_gnss is not None: ego_gnss.stop() ego_gnss.destroy() if ego_imu is not None: ego_imu.stop() ego_imu.destroy() ego_vehicle.destroy() if __name__ == '__main__': try: main() except KeyboardInterrupt: pass finally: print('\\nDone with tutorial_ego.') tutorial_replay.py import glob import os import sys import time import math import weakref try: sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % ( sys.version_info.major, sys.version_info.minor, 'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0]) except IndexError: pass import carla import argparse import logging import random def main(): client = carla.Client('127.0.0.1', 2000) client.set_timeout(10.0) try: world = client.get_world() ego_vehicle = None ego_cam = None depth_cam = None depth_cam02 = None sem_cam = None rad_ego = None lidar_sen = None # -------------- # Query the recording # -------------- \"\"\" # Show the most important events in the recording. print(client.show_recorder_file_info(\"~/tutorial/recorder/recording05.log\",False)) # Show actors not moving 1 meter in 10 seconds. #print(client.show_recorder_actors_blocked(\"~/tutorial/recorder/recording04.log\",10,1)) # Show collisions between any type of actor. #print(client.show_recorder_collisions(\"~/tutorial/recorder/recording04.log\",'v','a')) \"\"\" # -------------- # Reenact a fragment of the recording # -------------- \"\"\" client.replay_file(\"~/tutorial/recorder/recording03.log\",0,30,0) \"\"\" # -------------- # Set playback simulation conditions # -------------- \"\"\" ego_vehicle = world.get_actor(322) #Store the ID from the simulation or query the recording to find out \"\"\" # -------------- # Place spectator on ego spawning # -------------- \"\"\" spectator = world.get_spectator() world_snapshot = world.wait_for_tick() spectator.set_transform(ego_vehicle.get_transform()) \"\"\" # -------------- # Change weather conditions # -------------- \"\"\" weather = world.get_weather() weather.sun_altitude_angle = -30 weather.fog_density = 65 weather.fog_distance = 10 world.set_weather(weather) \"\"\" # -------------- # Add a RGB camera to ego vehicle. # -------------- \"\"\" cam_bp = None cam_bp = world.get_blueprint_library().find('sensor.camera.rgb') cam_location = carla.Location(2,0,1) cam_rotation = carla.Rotation(0,180,0) cam_transform = carla.Transform(cam_location,cam_rotation) cam_bp.set_attribute(\"image_size_x\",str(1920)) cam_bp.set_attribute(\"image_size_y\",str(1080)) cam_bp.set_attribute(\"fov\",str(105)) ego_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) ego_cam.listen(lambda image: image.save_to_disk('~/tutorial/new_rgb_output/%.6d.jpg' % image.frame)) \"\"\" # -------------- # Add a Logarithmic Depth camera to ego vehicle. # -------------- \"\"\" depth_cam = None depth_bp = world.get_blueprint_library().find('sensor.camera.depth') depth_bp.set_attribute(\"image_size_x\",str(1920)) depth_bp.set_attribute(\"image_size_y\",str(1080)) depth_bp.set_attribute(\"fov\",str(105)) depth_location = carla.Location(2,0,1) depth_rotation = carla.Rotation(0,180,0) depth_transform = carla.Transform(depth_location,depth_rotation) depth_cam = world.spawn_actor(depth_bp,depth_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view depth_cam.listen(lambda image: image.save_to_disk('~/tutorial/de_log/%.6d.jpg' % image.frame,carla.ColorConverter.LogarithmicDepth)) \"\"\" # -------------- # Add a Depth camera to ego vehicle. # -------------- \"\"\" depth_cam02 = None depth_bp02 = world.get_blueprint_library().find('sensor.camera.depth') depth_bp02.set_attribute(\"image_size_x\",str(1920)) depth_bp02.set_attribute(\"image_size_y\",str(1080)) depth_bp02.set_attribute(\"fov\",str(105)) depth_location02 = carla.Location(2,0,1) depth_rotation02 = carla.Rotation(0,180,0) depth_transform02 = carla.Transform(depth_location02,depth_rotation02) depth_cam02 = world.spawn_actor(depth_bp02,depth_transform02,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view depth_cam02.listen(lambda image: image.save_to_disk('~/tutorial/de/%.6d.jpg' % image.frame,carla.ColorConverter.Depth)) \"\"\" # -------------- # Add a new semantic segmentation camera to ego vehicle # -------------- \"\"\" sem_cam = None sem_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation') sem_bp.set_attribute(\"image_size_x\",str(1920)) sem_bp.set_attribute(\"image_size_y\",str(1080)) sem_bp.set_attribute(\"fov\",str(105)) sem_location = carla.Location(2,0,1) sem_rotation = carla.Rotation(0,180,0) sem_transform = carla.Transform(sem_location,sem_rotation) sem_cam = world.spawn_actor(sem_bp,sem_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view sem_cam.listen(lambda image: image.save_to_disk('~/tutorial/new_sem_output/%.6d.jpg' % image.frame,carla.ColorConverter.CityScapesPalette)) \"\"\" # -------------- # Add a new radar sensor to ego vehicle # -------------- \"\"\" rad_cam = None rad_bp = world.get_blueprint_library().find('sensor.other.radar') rad_bp.set_attribute('horizontal_fov', str(35)) rad_bp.set_attribute('vertical_fov', str(20)) rad_bp.set_attribute('range', str(20)) rad_location = carla.Location(x=2.8, z=1.0) rad_rotation = carla.Rotation(pitch=5) rad_transform = carla.Transform(rad_location,rad_rotation) rad_ego = world.spawn_actor(rad_bp,rad_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def rad_callback(radar_data): velocity_range = 7.5 # m/s current_rot = radar_data.transform.rotation for detect in radar_data: azi = math.degrees(detect.azimuth) alt = math.degrees(detect.altitude) # The 0.25 adjusts a bit the distance so the dots can # be properly seen fw_vec = carla.Vector3D(x=detect.depth - 0.25) carla.Transform( carla.Location(), carla.Rotation( pitch=current_rot.pitch + alt, yaw=current_rot.yaw + azi, roll=current_rot.roll)).transform(fw_vec) def clamp(min_v, max_v, value): return max(min_v, min(value, max_v)) norm_velocity = detect.velocity / velocity_range # range [-1, 1] r = int(clamp(0.0, 1.0, 1.0 - norm_velocity) * 255.0) g = int(clamp(0.0, 1.0, 1.0 - abs(norm_velocity)) * 255.0) b = int(abs(clamp(- 1.0, 0.0, - 1.0 - norm_velocity)) * 255.0) world.debug.draw_point( radar_data.transform.location + fw_vec, size=0.075, life_time=0.06, persistent_lines=False, color=carla.Color(r, g, b)) rad_ego.listen(lambda radar_data: rad_callback(radar_data)) \"\"\" # -------------- # Add a new LIDAR sensor to ego vehicle # -------------- \"\"\" lidar_cam = None lidar_bp = world.get_blueprint_library().find('sensor.lidar.ray_cast') lidar_bp.set_attribute('channels',str(32)) lidar_bp.set_attribute('points_per_second',str(90000)) lidar_bp.set_attribute('rotation_frequency',str(40)) lidar_bp.set_attribute('range',str(20)) lidar_location = carla.Location(0,0,2) lidar_rotation = carla.Rotation(0,0,0) lidar_transform = carla.Transform(lidar_location,lidar_rotation) lidar_sen = world.spawn_actor(lidar_bp,lidar_transform,attach_to=ego_vehicle,attachment_type=carla.AttachmentType.Rigid) lidar_sen.listen(lambda point_cloud: point_cloud.save_to_disk('/home/adas/Desktop/tutorial/new_lidar_output/%.6d.ply' % point_cloud.frame)) \"\"\" # -------------- # Game loop. Prevents the script from finishing. # -------------- while True: world_snapshot = world.wait_for_tick() finally: # -------------- # Destroy actors # -------------- if ego_vehicle is not None: if ego_cam is not None: ego_cam.stop() ego_cam.destroy() if depth_cam is not None: depth_cam.stop() depth_cam.destroy() if sem_cam is not None: sem_cam.stop() sem_cam.destroy() if rad_ego is not None: rad_ego.stop() rad_ego.destroy() if lidar_sen is not None: lidar_sen.stop() lidar_sen.destroy() ego_vehicle.destroy() print('\\nNothing to be done.') if __name__ == '__main__': try: main() except KeyboardInterrupt: pass finally: print('\\nDone with tutorial_replay.') That is a wrap on how to properly retrieve data from the simulation. Make sure to play around, change the conditions of the simulator, experiment with sensor settings. The possibilities are endless. Visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum","title":"\u68c0\u7d22\u6a21\u62df\u6570\u636e"},{"location":"tuto_G_retrieve_data/#retrieve-simulation-data","text":"Learning an efficient way to retrieve simulation data is essential in CARLA. This holistic tutorial is advised for both, newcomers and more experienced users. It starts from the very beginning, and gradually dives into the many options available in CARLA. First, the simulation is initialized with custom settings and traffic. An ego vehicle is set to roam around the city, optionally with some basic sensors. The simulation is recorded, so that later it can be queried to find the highlights. After that, the original simulation is played back, and exploited to the limit. New sensors can be added to retrieve consistent data. The weather conditions can be changed. The recorder can even be used to test specific scenarios with different outputs. Overview Set the simulation Map setting Weather setting Set traffic CARLA traffic and pedestrians SUMO co-simulation traffic Set the ego vehicle Spawn the ego vehicle Place the spectator Set basic sensors RGB camera Detectors Other sensors Set advanced sensors Depth camera Semantic segmentation camera LIDAR raycast sensor Radar sensor No-rendering-mode Simulate at a fast pace Manual control without rendering Record and retrieve data Start recording Capture and record Stop recording Exploit the recording Query the events Choose a fragment Retrieve more data Change the weather Try new outcomes Tutorial scripts","title":"Retrieve simulation data"},{"location":"tuto_G_retrieve_data/#overview","text":"There are some common mistakes in the process of retrieving simulation data. Flooding the simulator with sensors, storing useless data, or struggling to find a specific event are some examples. However, some outlines to this process can be provided. The goal is to ensure that data can be retrieved and replicated, and the simulation can be examined and altered at will. Note This tutorial uses the CARLA 0.9.8 deb package . There may be minor changes depending on your CARLA version and installation, specially regarding paths. The tutorial presents a wide set of options for the differents steps. All along, different scripts will be mentioned. Not all of them will be used, it depends on the specific use cases. Most of them are already provided in CARLA for generic purposes. config.py changes the simulation settings. Map, rendering options, set a fixed time-step... carla/PythonAPI/util/config.py dynamic_weather.py creates interesting weather conditions. carla/PythonAPI/examples/dynamic_weather.py spawn_npc.py spawns some AI controlled vehicles and walkers. carla/PythonAPI/examples/spawn_npc.py manual_control.py spawns an ego vehicle, and provides control over it. carla/PythonAPI/examples/manual_control.py However, there are two scripts mentioned along the tutorial that cannot be found in CARLA. They contain the fragments of code cited. This serves a twofold purpose. First of all, to encourage users to build their own scripts. It is important to have full understanding of what the code is doing. In addition to this, the tutorial is only an outline that may, and should, vary a lot depending on user preferences. These two scripts are just an example. tutorial_ego.py spawns an ego vehicle with some basic sensors, and enables autopilot. The spectator is placed at the spawning position. The recorder starts at the very beginning, and stops when the script is finished. tutorial_replay.py reenacts the simulation that tutorial_ego.py recorded. There are different fragments of code to query the recording, spawn some advanced sensors, change weather conditions, and reenact fragments of the recording. The full code can be found in the last section of the tutorial. Remember these are not strict, but meant to be customized. Retrieving data in CARLA is as powerful as users want it to be. Important This tutorial requires some knowledge of Python.","title":"Overview"},{"location":"tuto_G_retrieve_data/#set-the-simulation","text":"The first thing to do is set the simulation ready to a desired environment. Run CARLA. cd /opt/carla/bin ./CarlaUE.sh","title":"Set the simulation"},{"location":"tuto_G_retrieve_data/#map-setting","text":"Choose a map for the simulation to run. Take a look at the map documentation to learn more about their specific attributes. For the sake of this tutorial, Town07 is chosen. Open a new terminal. Change the map using the config.py script. cd /opt/carla/PythonAPI/utils python3 config.py --map Town01 This script can enable different settings. Some of them will be mentioned during the tutorial, others will not. Hereunder there is a brief summary. Optional arguments in config.py -h, --help show this help message and exit --host H IP of the host CARLA Simulator (default: localhost) -p P, --port P TCP port of CARLA Simulator (default: 2000) -d, --default set default settings -m MAP, --map MAP load a new map, use --list to see available maps -r, --reload-map reload current map --delta-seconds S set fixed delta seconds, zero for variable frame rate --fps N set fixed FPS, zero for variable FPS (similar to --delta-seconds) --rendering enable rendering --no-rendering disable rendering --no-sync disable synchronous mode --weather WEATHER set weather preset, use --list to see available presets -i, --inspect inspect simulation -l, --list list available options -b FILTER, --list-blueprints FILTER list available blueprints matching FILTER (use '*' to list them all) -x XODR_FILE_PATH, --xodr-path XODR_FILE_PATH load a new map with a minimum physical road representation of the provided OpenDRIVE Aerial view of Town07","title":"Map setting"},{"location":"tuto_G_retrieve_data/#weather-setting","text":"Each town is loaded with a specific weather that fits it, however this can be set at will. There are two scripts that offer different approaches to the matter. The first one sets a dynamic weather that changes conditions over time. The other sets custom weather conditions. It is also possible to code weather conditions. This will be covered later when changing weather conditions . To set a dynamic weather . Open a new terminal and run dynamic_weather.py . This script allows to set the ratio at which the weather changes, being 1.0 the default setting. cd /opt/carla/PythonAPI/examples python3 dynamic_weather.py --speed 1.0 To set custom conditions . Use the script environment.py . There are quite a lot of possible settings. Take a look at the optional arguments, and the documentation for carla.WeatherParameters . cd /opt/carla/PythonAPI/util python3 environment.py --clouds 100 --rain 80 --wetness 100 --puddles 60 --wind 80 --fog 50 Optional arguments in environment.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) --sun SUN Sun position presets [sunset | day | night] --weather WEATHER Weather condition presets [clear | overcast | rain] --altitude A, -alt A Sun altitude [-90.0, 90.0] --azimuth A, -azm A Sun azimuth [0.0, 360.0] --clouds C, -c C Clouds amount [0.0, 100.0] --rain R, -r R Rain amount [0.0, 100.0] --puddles Pd, -pd Pd Puddles amount [0.0, 100.0] --wind W, -w W Wind intensity [0.0, 100.0] --fog F, -f F Fog intensity [0.0, 100.0] --fogdist Fd, -fd Fd Fog Distance [0.0, inf) --wetness Wet, -wet Wet Wetness intensity [0.0, 100.0] Weather changes applied","title":"Weather setting"},{"location":"tuto_G_retrieve_data/#set-traffic","text":"Simulating traffic is one of the best ways to bring the map to life. It is also necessary to retrieve data for urban environments. There are different options to do so in CARLA.","title":"Set traffic"},{"location":"tuto_G_retrieve_data/#carla-traffic-and-pedestrians","text":"The CARLA traffic is managed by the Traffic Manager module. As for pedestrians, each of them has their own carla.WalkerAIController . Open a new terminal, and run spawn_npc.py to spawn vehicles and walkers. Let's just spawn 50 vehicles and the same amount of walkers. cd /opt/carla/PythonAPI/examples python3 spawn_npc.py -n 50 -w 50 --safe Optional arguments in spawn_npc.py -h, --help show this help message and exit --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) -n N, --number-of-vehicles N number of vehicles (default: 10) -w W, --number-of-walkers W number of walkers (default: 50) --safe avoid spawning vehicles prone to accidents --filterv PATTERN vehicles filter (default: \"vehicle.*\") --filterw PATTERN pedestrians filter (default: \"walker.pedestrian.*\") -tm_p P, --tm-port P port to communicate with TM (default: 8000) --async Asynchronous mode execution Vehicles spawned to simulate traffic.","title":"CARLA traffic and pedestrians"},{"location":"tuto_G_retrieve_data/#sumo-co-simulation-traffic","text":"CARLA can run a co-simulation with SUMO. This allows for creating traffic in SUMO that will be propagated to CARLA. This co-simulation is bidirectional. Spawning vehicles in CARLA will do so in SUMO. Specific docs on this feature can be found here . This feature is available for CARLA 0.9.8 and later, in Town01 , Town04 , and Town05 . The first one is the most stable. Note The co-simulation will enable synchronous mode in CARLA. Read the documentation to find out more about this. First of all, install SUMO. sudo add-apt-repository ppa:sumo/stable sudo apt-get update sudo apt-get install sumo sumo-tools sumo-doc Set the environment variable SUMO_HOME. echo \"export SUMO_HOME=/usr/share/sumo\" >> ~/.bashrc && source ~/.bashrc With the CARLA server on, run the SUMO-CARLA synchrony script . cd ~/carla/Co-Simulation/Sumo python3 run_synchronization.py examples/Town01.sumocfg --sumo-gui A SUMO window should have opened. Press Play in order to start traffic in both simulations. > \"Play\" on SUMO window. The traffic generated by this script is an example created by the CARLA team. By default it spawns the same vehicles following the same routes. These can be changed by the user in SUMO. SUMO and CARLA co-simulating traffic. Warning Right now, SUMO co-simulation is a beta feature. Vehicles do not have physics nor take into account CARLA traffic lights.","title":"SUMO co-simulation traffic"},{"location":"tuto_G_retrieve_data/#set-the-ego-vehicle","text":"From now up to the moment the recorder is stopped, there will be some fragments of code belonging to tutorial_ego.py . This script spawns the ego vehicle, optionally some sensors, and records the simulation until the user finishes the script.","title":"Set the ego vehicle"},{"location":"tuto_G_retrieve_data/#spawn-the-ego-vehicle","text":"Vehicles controlled by the user are commonly differenciated in CARLA by setting the attribute role_name to ego . Other attributes can be set, some with recommended values. Hereunder, a Tesla model is retrieved from the blueprint library , and spawned with a random recommended colour. One of the recommended spawn points by the map is chosen to place the ego vehicle. # -------------- # Spawn ego vehicle # -------------- ego_bp = world.get_blueprint_library().find('vehicle.tesla.model3') ego_bp.set_attribute('role_name','ego') print('\\nEgo role_name is set') ego_color = random.choice(ego_bp.get_attribute('color').recommended_values) ego_bp.set_attribute('color',ego_color) print('\\nEgo color is set') spawn_points = world.get_map().get_spawn_points() number_of_spawn_points = len(spawn_points) if 0 < number_of_spawn_points: random.shuffle(spawn_points) ego_transform = spawn_points[0] ego_vehicle = world.spawn_actor(ego_bp,ego_transform) print('\\nEgo is spawned') else: logging.warning('Could not found any spawn points')","title":"Spawn the ego vehicle"},{"location":"tuto_G_retrieve_data/#place-the-spectator","text":"The spectator actor controls the simulation view. Moving it via script is optional, but it may facilitate finding the ego vehicle. # -------------- # Spectator on ego position # -------------- spectator = world.get_spectator() world_snapshot = world.wait_for_tick() spectator.set_transform(ego_vehicle.get_transform())","title":"Place the spectator"},{"location":"tuto_G_retrieve_data/#set-basic-sensors","text":"The process to spawn any sensor is quite similar. 1. Use the library to find sensor blueprints. 2. Set specific attributes for the sensor. This is crucial. Attributes will shape the data retrieved. 3. Attach the sensor to the ego vehicle. The transform is relative to its parent . The carla.AttachmentType will determine how the position of the sensor is updated. 4. Add a listen() method. This is the key element. A lambda method that will be called each time the sensor listens for data. The argument is the sensor data retrieved. Having this basic guideline in mind, let's set some basic sensors for the ego vehicle.","title":"Set basic sensors"},{"location":"tuto_G_retrieve_data/#rgb-camera","text":"The RGB camera generates realistic pictures of the scene. It is the sensor with more settable attributes of them all, but it is also a fundamental one. It should be understood as a real camera, with attributtes such as focal_distance , shutter_speed or gamma to determine how it would work internally. There is also a specific set of attributtes to define the lens distorsion, and lots of advanced attributes. For example, the lens_circle_multiplier can be used to achieve an effect similar to an eyefish lens. Learn more about them in the documentation . For the sake of simplicity, the script only sets the most commonly used attributes of this sensor. image_size_x and image_size_y will change the resolution of the output image. fov is the horizontal field of view of the camera. After setting the attributes, it is time to spawn the sensor. The script places the camera in the hood of the car, and pointing forward. It will capture the front view of the car. The data is retrieved as a carla.Image on every step. The listen method saves these to disk. The path can be altered at will. The name of each image is coded to be based on the simulation frame where the shot was taken. # -------------- # Spawn attached RGB camera # -------------- cam_bp = None cam_bp = world.get_blueprint_library().find('sensor.camera.rgb') cam_bp.set_attribute(\"image_size_x\",str(1920)) cam_bp.set_attribute(\"image_size_y\",str(1080)) cam_bp.set_attribute(\"fov\",str(105)) cam_location = carla.Location(2,0,1) cam_rotation = carla.Rotation(0,180,0) cam_transform = carla.Transform(cam_location,cam_rotation) ego_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) ego_cam.listen(lambda image: image.save_to_disk('tutorial/output/%.6d.jpg' % image.frame)) RGB camera output","title":"RGB camera"},{"location":"tuto_G_retrieve_data/#detectors","text":"These sensors retrieve data when the object they are attached to registers a specific event. There are three type of detector sensors, each one describing one type of event. Collision detector. Retrieves collisions between its parent and other actors. Lane invasion detector. Registers when its parent crosses a lane marking. Obstacle detector. Detects possible obstacles ahead of its parent. The data they retrieve will be helpful later when deciding which part of the simulation is going to be reenacted. In fact, the collisions can be explicitely queried using the recorder. This is prepared to be printed. Only the obstacle detector blueprint has attributes to be set. Here are some important ones. sensor_tick sets the sensor to retrieve data only after x seconds pass. It is a common attribute for sensors that retrieve data on every step. distance and hit-radius shape the debug line used to detect obstacles ahead. only_dynamics determines if static objects should be taken into account or not. By default, any object is considered. The script sets the obstacle detector to only consider dynamic objects. If the vehicle collides with any static object, it will be detected by the collision sensor. # -------------- # Add collision sensor to ego vehicle. # -------------- col_bp = world.get_blueprint_library().find('sensor.other.collision') col_location = carla.Location(0,0,0) col_rotation = carla.Rotation(0,0,0) col_transform = carla.Transform(col_location,col_rotation) ego_col = world.spawn_actor(col_bp,col_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def col_callback(colli): print(\"Collision detected:\\n\"+str(colli)+'\\n') ego_col.listen(lambda colli: col_callback(colli)) # -------------- # Add Lane invasion sensor to ego vehicle. # -------------- lane_bp = world.get_blueprint_library().find('sensor.other.lane_invasion') lane_location = carla.Location(0,0,0) lane_rotation = carla.Rotation(0,0,0) lane_transform = carla.Transform(lane_location,lane_rotation) ego_lane = world.spawn_actor(lane_bp,lane_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def lane_callback(lane): print(\"Lane invasion detected:\\n\"+str(lane)+'\\n') ego_lane.listen(lambda lane: lane_callback(lane)) # -------------- # Add Obstacle sensor to ego vehicle. # -------------- obs_bp = world.get_blueprint_library().find('sensor.other.obstacle') obs_bp.set_attribute(\"only_dynamics\",str(True)) obs_location = carla.Location(0,0,0) obs_rotation = carla.Rotation(0,0,0) obs_transform = carla.Transform(obs_location,obs_rotation) ego_obs = world.spawn_actor(obs_bp,obs_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def obs_callback(obs): print(\"Obstacle detected:\\n\"+str(obs)+'\\n') ego_obs.listen(lambda obs: obs_callback(obs)) Output for detector sensors","title":"Detectors"},{"location":"tuto_G_retrieve_data/#other-sensors","text":"Only two sensors of this category will be considered for the time being. GNSS sensor. Retrieves the geolocation of the sensor. IMU sensor. Comprises an accelerometer, a gyroscope, and a compass. To get general measures for the vehicle object, these two sensors are spawned centered to it. The attributes available for these sensors mostly set the mean or standard deviation parameter in the noise model of the measure. This is useful to get more realistic measures. However, in tutorial_ego.py only one attribute is set. sensor_tick . As this measures are not supposed to vary significantly between steps, it is okay to retrieve the data every so often. In this case, it is set to be printed every three seconds. # -------------- # Add GNSS sensor to ego vehicle. # -------------- gnss_bp = world.get_blueprint_library().find('sensor.other.gnss') gnss_location = carla.Location(0,0,0) gnss_rotation = carla.Rotation(0,0,0) gnss_transform = carla.Transform(gnss_location,gnss_rotation) gnss_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_gnss = world.spawn_actor(gnss_bp,gnss_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def gnss_callback(gnss): print(\"GNSS measure:\\n\"+str(gnss)+'\\n') ego_gnss.listen(lambda gnss: gnss_callback(gnss)) # -------------- # Add IMU sensor to ego vehicle. # -------------- imu_bp = world.get_blueprint_library().find('sensor.other.imu') imu_location = carla.Location(0,0,0) imu_rotation = carla.Rotation(0,0,0) imu_transform = carla.Transform(imu_location,imu_rotation) imu_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_imu = world.spawn_actor(imu_bp,imu_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def imu_callback(imu): print(\"IMU measure:\\n\"+str(imu)+'\\n') ego_imu.listen(lambda imu: imu_callback(imu)) GNSS and IMU sensors output","title":"Other sensors"},{"location":"tuto_G_retrieve_data/#set-advanced-sensors","text":"The script tutorial_replay.py , among other things, contains definitions for more sensors. They work in the same way as the basic ones, but their comprehension may be a bit harder.","title":"Set advanced sensors"},{"location":"tuto_G_retrieve_data/#depth-camera","text":"The depth camera generates pictures of the scene that map every pixel in a grayscale depth map. However, the output is not straightforward. The depth buffer of the camera is mapped using a RGB color space. This has to be translated to grayscale to be comprehensible. In order to do this, simply save the image as with the RGB camera, but apply a carla.ColorConverter to it. There are two conversions available for depth cameras. carla.ColorConverter.Depth translates the original depth with milimetric precision. carla.ColorConverter.LogarithmicDepth also has milimetric granularity, but provides better results in close distances and a little worse for further elements. The attributes for the depth camera only set elements previously stated in the RGB camera: fov , image_size_x , image_size_y and sensor_tick . The script sets this sensor to match the previous RGB camera used. # -------------- # Add a Depth camera to ego vehicle. # -------------- depth_cam = None depth_bp = world.get_blueprint_library().find('sensor.camera.depth') depth_location = carla.Location(2,0,1) depth_rotation = carla.Rotation(0,180,0) depth_transform = carla.Transform(depth_location,depth_rotation) depth_cam = world.spawn_actor(depth_bp,depth_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view depth_cam.listen(lambda image: image.save_to_disk('tutorial/new_depth_output/%.6d.jpg' % image.frame,carla.ColorConverter.LogarithmicDepth)) Depth camera output. Simple conversion on the left, logarithmic on the right.","title":"Depth camera"},{"location":"tuto_G_retrieve_data/#semantic-segmentation-camera","text":"The semantic segmentation camera renders elements in scene with a different color depending on how these have been tagged. The tags are created by the simulator depending on the path of the asset used for spawning. For example, meshes tagged as Pedestrians are spawned with content stored in Unreal/CarlaUE4/Content/Static/Pedestrians . The output is an image, as any camera, but each pixel contains the tag encoded in the red channel. This original image must be converted using ColorConverter.CityScapesPalette . New tags can be created, read more in the documentation . The attributes available for this camera are exactly the same as the depth camera. The script also sets this to match the original RGB camera. # -------------- # Add a new semantic segmentation camera to my ego # -------------- sem_cam = None sem_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation') sem_bp.set_attribute(\"image_size_x\",str(1920)) sem_bp.set_attribute(\"image_size_y\",str(1080)) sem_bp.set_attribute(\"fov\",str(105)) sem_location = carla.Location(2,0,1) sem_rotation = carla.Rotation(0,180,0) sem_transform = carla.Transform(sem_location,sem_rotation) sem_cam = world.spawn_actor(sem_bp,sem_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view sem_cam.listen(lambda image: image.save_to_disk('tutorial/new_sem_output/%.6d.jpg' % image.frame,carla.ColorConverter.CityScapesPalette)) Semantic segmentation camera output","title":"Semantic segmentation camera"},{"location":"tuto_G_retrieve_data/#lidar-raycast-sensor","text":"The LIDAR sensor simulates a rotating LIDAR. It creates a cloud of points that maps the scene in 3D. The LIDAR contains a set of lasers that rotate at a certain frequency. The lasers raycast the distance to impact, and store every shot as one single point. The way the array of lasers is disposed can be set using different sensor attributes. upper_fov and lower_fov the angle of the highest and the lowest laser respectively. channels sets the amount of lasers to be used. These are distributed along the desired fov . Other attributes set the way this points are calculated. They determine the amount of points that each laser calculates every step: points_per_second / (FPS * channels) . range is the maximum distance to capture. points_per_second is the amount of points that will be obtained every second. This quantity is divided between the amount of channels . rotation_frequency is the amount of times the LIDAR will rotate every second. The point cloud output is described as a [carla.LidarMeasurement]. It can be iterated as a list of [carla.Location] or saved to a .ply standart file format. # -------------- # Add a new LIDAR sensor to my ego # -------------- lidar_cam = None lidar_bp = world.get_blueprint_library().find('sensor.lidar.ray_cast') lidar_bp.set_attribute('channels',str(32)) lidar_bp.set_attribute('points_per_second',str(90000)) lidar_bp.set_attribute('rotation_frequency',str(40)) lidar_bp.set_attribute('range',str(20)) lidar_location = carla.Location(0,0,2) lidar_rotation = carla.Rotation(0,0,0) lidar_transform = carla.Transform(lidar_location,lidar_rotation) lidar_sen = world.spawn_actor(lidar_bp,lidar_transform,attach_to=ego_vehicle) lidar_sen.listen(lambda point_cloud: point_cloud.save_to_disk('tutorial/new_lidar_output/%.6d.ply' % point_cloud.frame)) The .ply output can be visualized using Meshlab . 1. Install Meshlab . sudo apt-get update -y sudo apt-get install -y meshlab 2. Open Meshlab. meshlab 3. Open one of the .ply files. File > Import mesh... LIDAR output after being processed in Meshlab.","title":"LIDAR raycast sensor"},{"location":"tuto_G_retrieve_data/#radar-sensor","text":"The radar sensor is similar to de LIDAR. It creates a conic view, and shoots lasers inside to raycast their impacts. The output is a carla.RadarMeasurement . It contains a list of the carla.RadarDetection retrieved by the lasers. These are not points in space, but detections with data regarding the sensor: azimuth , altitude , sensor and velocity . The attributes of this sensor mostly set the way the lasers are located. horizontal_fov and vertical_fov determine the amplitude of the conic view. channels sets the amount of lasers to be used. These are distributed along the desired fov . range is the maximum distance for the lasers to raycast. points_per_second sets the the amount of points to be captured, that will be divided between the channels stated. The script places the sensor on the hood of the car, and rotated a bit upwards. That way, the output will map the front view of the car. The horizontal_fov is incremented, and the vertical_fov diminished. The area of interest is specially the height where vehicles and walkers usually move on. The range is also changed from 100m to 10m, in order to retrieve data only right ahead of the vehicle. The callback is a bit more complex this time, showing more of its capabilities. It will draw the points captured by the radar on the fly. The points will be colored depending on their velocity regarding the ego vehicle. Blue for points approaching the vehicle. Read for points moving away from it. White for points static regarding the ego vehicle. # -------------- # Add a new radar sensor to my ego # -------------- rad_cam = None rad_bp = world.get_blueprint_library().find('sensor.other.radar') rad_bp.set_attribute('horizontal_fov', str(35)) rad_bp.set_attribute('vertical_fov', str(20)) rad_bp.set_attribute('range', str(20)) rad_location = carla.Location(x=2.0, z=1.0) rad_rotation = carla.Rotation(pitch=5) rad_transform = carla.Transform(rad_location,rad_rotation) rad_ego = world.spawn_actor(rad_bp,rad_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def rad_callback(radar_data): velocity_range = 7.5 # m/s current_rot = radar_data.transform.rotation for detect in radar_data: azi = math.degrees(detect.azimuth) alt = math.degrees(detect.altitude) # The 0.25 adjusts a bit the distance so the dots can # be properly seen fw_vec = carla.Vector3D(x=detect.depth - 0.25) carla.Transform( carla.Location(), carla.Rotation( pitch=current_rot.pitch + alt, yaw=current_rot.yaw + azi, roll=current_rot.roll)).transform(fw_vec) def clamp(min_v, max_v, value): return max(min_v, min(value, max_v)) norm_velocity = detect.velocity / velocity_range # range [-1, 1] r = int(clamp(0.0, 1.0, 1.0 - norm_velocity) * 255.0) g = int(clamp(0.0, 1.0, 1.0 - abs(norm_velocity)) * 255.0) b = int(abs(clamp(- 1.0, 0.0, - 1.0 - norm_velocity)) * 255.0) world.debug.draw_point( radar_data.transform.location + fw_vec, size=0.075, life_time=0.06, persistent_lines=False, color=carla.Color(r, g, b)) rad_ego.listen(lambda radar_data: rad_callback(radar_data)) Radar output. The vehicle is stopped at a traffic light, so the static elements in front of it appear in white.","title":"Radar sensor"},{"location":"tuto_G_retrieve_data/#no-rendering-mode","text":"The no-rendering mode can be useful to run an initial simulation that will be later played again to retrieve data. Especially if this simulation has some extreme conditions, such as dense traffic.","title":"No-rendering mode"},{"location":"tuto_G_retrieve_data/#simulate-at-a-fast-pace","text":"Disabling the rendering will save up a lot of work to the simulation. As the GPU is not used, the server can work at full speed. This could be useful to simulate complex conditions at a fast pace. The best way to do so would be by setting a fixed time-step. Running an asynchronous server with a fixed time-step and no rendering, the only limitation for the simulation would be the inner logic of the server. The same config.py used to set the map can disable rendering, and set a fixed time-step. cd /opt/carla/PythonAPI/utils python3 config.py --no-rendering --delta-seconds 0.05 # Never greater than 0.1s Warning Read the documentation before messing around with with synchrony and time-step.","title":"Simulate at a fast pace"},{"location":"tuto_G_retrieve_data/#manual-control-without-rendering","text":"The script PythonAPI/examples/no_rendering_mode.py provides an overview of the simulation. It creates a minimalistic aerial view with Pygame, that will follow the ego vehicle. This could be used along with manual_control.py to generate a route with barely no cost, record it, and then play it back and exploit it to gather data. cd /opt/carla/PythonAPI/examples python3 manual_control.py cd /opt/carla/PythonAPI/examples python3 no_rendering_mode.py --no-rendering Optional arguments in no_rendering_mode.py -h, --help show this help message and exit -v, --verbose print debug information --host H IP of the host server (default: 127.0.0.1) -p P, --port P TCP port to listen to (default: 2000) --res WIDTHxHEIGHT window resolution (default: 1280x720) --filter PATTERN actor filter (default: \"vehicle.*\") --map TOWN start a new episode at the given TOWN --no-rendering switch off server rendering --show-triggers show trigger boxes of traffic signs --show-connections show waypoint connections --show-spawn-points show recommended spawn points no_rendering_mode.py working in Town07 Note In this mode, GPU-based sensors will retrieve empty data. Cameras are useless, but other sensors such as detectors will work properly.","title":"Manual control without rendering"},{"location":"tuto_G_retrieve_data/#record-and-retrieve-data","text":"","title":"Record and retrieve data"},{"location":"tuto_G_retrieve_data/#start-recording","text":"The recorder can be started at anytime. The script does it at the very beginning, in order to capture everything, including the spawning of the first actors. If no path is detailed, the log will be saved into CarlaUE4/Saved . # -------------- # Start recording # -------------- client.start_recorder('~/tutorial/recorder/recording01.log')","title":"Start recording"},{"location":"tuto_G_retrieve_data/#capture-and-record","text":"There are many different ways to do this. Mostly it goes down as either let it roam around or control it manually. The data for the sensors spawned will be retrieved on the fly. Make sure to check it while recording, to make sure everything is set properly. Enable the autopilot. This will register the vehicle to the Traffic Manager . It will roam around the city endlessly. The script does this, and creates a loop to prevent the script from finishing. The recording will go on until the user finishes the script. Alternatively, a timer could be set to finish the script after a certain time. # -------------- # Capture data # -------------- ego_vehicle.set_autopilot(True) print('\\nEgo autopilot enabled') while True: world_snapshot = world.wait_for_tick() Manual control. Run the script PythonAPI/examples/manual_control.py in a client, and the recorder in another one. Drive the ego vehicle around to create the desired route, and stop the recorder when finished. The tutorial_ego.py script can be used to manage the recorder, but make sure to comment other fragments of code. cd /opt/carla/PythonAPI/examples python3 manual_control.py Note To avoid rendering and save up computational cost, enable no rendering mode . The script /PythonAPI/examples/no_rendering_mode.py does this while creating a simple aerial view.","title":"Capture and record"},{"location":"tuto_G_retrieve_data/#stop-recording","text":"The stop call is even simpler than the start call was. When the recorder is done, the recording will be saved in the path stated previously. # -------------- # Stop recording # -------------- client.stop_recorder()","title":"Stop recording"},{"location":"tuto_G_retrieve_data/#exploit-the-recording","text":"So far, a simulation has been recorded. Now, it is time to examine the recording, find the most remarkable moments, and work with them. These steps are gathered in the script, tutorial_replay.py . The outline is structured in different segments of code commented. It is time to run a new simulation. ./CarlaUE4.sh To reenact the simulation, choose a fragment and run the script containing the code for the playback. python3 tuto_replay.py","title":"Exploit the recording"},{"location":"tuto_G_retrieve_data/#query-the-events","text":"The different queries are detailed in the recorder documentation . In summary, they retrieve data for specific events or frames. Use the queries to study the recording. Find the spotlight moments, and trace what can be of interest. # -------------- # Query the recording # -------------- # Show only the most important events in the recording. print(client.show_recorder_file_info(\"~/tutorial/recorder/recording01.log\",False)) # Show actors not moving 1 meter in 10 seconds. print(client.show_recorder_actors_blocked(\"~/tutorial/recorder/recording01.log\",10,1)) # Filter collisions between vehicles 'v' and 'a' any other type of actor. print(client.show_recorder_collisions(\"~/tutorial/recorder/recording01.log\",'v','a')) Note The recorder does not need to be on, in order to do the queries. Query showing important events. This is the frame where the ego vehicle was spawned. Query showing actors blocked. In this simulation, the ego vehicle remained blocked for 100 seconds. Query showing a collision between the ego vehicle and an object of type \"other\". Note Getting detailed file info for every frame can be overwhelming. Use it after other queries to know where to look at.","title":"Query the events"},{"location":"tuto_G_retrieve_data/#choose-a-fragment","text":"After the queries, it may be a good idea play some moments of the simulation back, before messing around. It is very simple to do so, and it could be really helpful. Know more about the simulation. It is the best way to save time later. The method allows to choose the beginning and ending point of the playback, and an actor to follow. # -------------- # Reenact a fragment of the recording # -------------- client.replay_file(\"~/tutorial/recorder/recording01.log\",45,10,0) Here is a list of possible things to do now. Use the information from the queries. Find out the moment and the actors involved in an event, and play that again. Start the recorder a few seconds before the event. Follow different actors. Different perspectives will show new events that are not included in the queries. Rom around with a free spectator view. Set the actor_id to 0 , and get a general view of the simulation. Be wherever and whenever wanted thanks to the recording. Note When the recording stops, the simulation doesn't. Walkers will stand still, and vehicles will continue roaming around. This may happen either if the log ends, or the playback gets to the ending point stated.","title":"Choose a fragment"},{"location":"tuto_G_retrieve_data/#retrieve-more-data","text":"The recorder will recreate in this simulation, the exact same conditions as the original. That ensures consistent data within different playbacks. Gather a list of the important moments, actors and events. Add sensors whenever needed and play the simulation back. The process is exactly the same as before. The script tutorial_replay.py provides different examples that have been thoroughly explained in the Set advanced sensors section. Others have been explained in the section Set basic sensors . Add as many sensors as needed, wherever they are needed. Play the simulation back as many times as desired and retrieve as much data as desired.","title":"Retrieve more data"},{"location":"tuto_G_retrieve_data/#change-the-weather","text":"The recording will recreate the original weather conditions. However, these can be altered at will. This may be interesting to compare how does it affect sensors, while mantaining the rest of events the same. Get the current weather and modify it freely. Remember that carla.WeatherParameters has some presets available. The script will change the environment to a foggy sunset. # -------------- # Change weather for playback # -------------- weather = world.get_weather() weather.sun_altitude_angle = -30 weather.fog_density = 65 weather.fog_distance = 10 world.set_weather(weather)","title":"Change the weather"},{"location":"tuto_G_retrieve_data/#try-new-outcomes","text":"The new simulation is not strictly linked to the recording. It can be modified anytime, and even when the recorder stops, the simulation goes on. This can be profitable for the user. For instance, collisions can be forced or avoided by playing back the simulation a few seconds before, and spawning or destroying an actor. Ending the recording at a specific moment can also be useful. Doing so, vehicles may take different paths. Change the conditions and mess with the simulation. There is nothing to lose, as the recorder grants that the initial simulation can always be reenacted. This is the key to exploit the full potential of CARLA.","title":"Try new outcomes"},{"location":"tuto_G_retrieve_data/#tutorial-scripts","text":"Hereunder are the two scripts gathering the fragments of code for this tutorial. Most of the code is commented, as it is meant to be modified to fit specific purposes. tutorial_ego.py import glob import os import sys import time try: sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % ( sys.version_info.major, sys.version_info.minor, 'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0]) except IndexError: pass import carla import argparse import logging import random def main(): argparser = argparse.ArgumentParser( description=__doc__) argparser.add_argument( '--host', metavar='H', default='127.0.0.1', help='IP of the host server (default: 127.0.0.1)') argparser.add_argument( '-p', '--port', metavar='P', default=2000, type=int, help='TCP port to listen to (default: 2000)') args = argparser.parse_args() logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO) client = carla.Client(args.host, args.port) client.set_timeout(10.0) try: world = client.get_world() ego_vehicle = None ego_cam = None ego_col = None ego_lane = None ego_obs = None ego_gnss = None ego_imu = None # -------------- # Start recording # -------------- \"\"\" client.start_recorder('~/tutorial/recorder/recording01.log') \"\"\" # -------------- # Spawn ego vehicle # -------------- \"\"\" ego_bp = world.get_blueprint_library().find('vehicle.tesla.model3') ego_bp.set_attribute('role_name','ego') print('\\nEgo role_name is set') ego_color = random.choice(ego_bp.get_attribute('color').recommended_values) ego_bp.set_attribute('color',ego_color) print('\\nEgo color is set') spawn_points = world.get_map().get_spawn_points() number_of_spawn_points = len(spawn_points) if 0 < number_of_spawn_points: random.shuffle(spawn_points) ego_transform = spawn_points[0] ego_vehicle = world.spawn_actor(ego_bp,ego_transform) print('\\nEgo is spawned') else: logging.warning('Could not found any spawn points') \"\"\" # -------------- # Add a RGB camera sensor to ego vehicle. # -------------- \"\"\" cam_bp = None cam_bp = world.get_blueprint_library().find('sensor.camera.rgb') cam_bp.set_attribute(\"image_size_x\",str(1920)) cam_bp.set_attribute(\"image_size_y\",str(1080)) cam_bp.set_attribute(\"fov\",str(105)) cam_location = carla.Location(2,0,1) cam_rotation = carla.Rotation(0,180,0) cam_transform = carla.Transform(cam_location,cam_rotation) ego_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) ego_cam.listen(lambda image: image.save_to_disk('~/tutorial/output/%.6d.jpg' % image.frame)) \"\"\" # -------------- # Add collision sensor to ego vehicle. # -------------- \"\"\" col_bp = world.get_blueprint_library().find('sensor.other.collision') col_location = carla.Location(0,0,0) col_rotation = carla.Rotation(0,0,0) col_transform = carla.Transform(col_location,col_rotation) ego_col = world.spawn_actor(col_bp,col_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def col_callback(colli): print(\"Collision detected:\\n\"+str(colli)+'\\n') ego_col.listen(lambda colli: col_callback(colli)) \"\"\" # -------------- # Add Lane invasion sensor to ego vehicle. # -------------- \"\"\" lane_bp = world.get_blueprint_library().find('sensor.other.lane_invasion') lane_location = carla.Location(0,0,0) lane_rotation = carla.Rotation(0,0,0) lane_transform = carla.Transform(lane_location,lane_rotation) ego_lane = world.spawn_actor(lane_bp,lane_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def lane_callback(lane): print(\"Lane invasion detected:\\n\"+str(lane)+'\\n') ego_lane.listen(lambda lane: lane_callback(lane)) \"\"\" # -------------- # Add Obstacle sensor to ego vehicle. # -------------- \"\"\" obs_bp = world.get_blueprint_library().find('sensor.other.obstacle') obs_bp.set_attribute(\"only_dynamics\",str(True)) obs_location = carla.Location(0,0,0) obs_rotation = carla.Rotation(0,0,0) obs_transform = carla.Transform(obs_location,obs_rotation) ego_obs = world.spawn_actor(obs_bp,obs_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def obs_callback(obs): print(\"Obstacle detected:\\n\"+str(obs)+'\\n') ego_obs.listen(lambda obs: obs_callback(obs)) \"\"\" # -------------- # Add GNSS sensor to ego vehicle. # -------------- \"\"\" gnss_bp = world.get_blueprint_library().find('sensor.other.gnss') gnss_location = carla.Location(0,0,0) gnss_rotation = carla.Rotation(0,0,0) gnss_transform = carla.Transform(gnss_location,gnss_rotation) gnss_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_gnss = world.spawn_actor(gnss_bp,gnss_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def gnss_callback(gnss): print(\"GNSS measure:\\n\"+str(gnss)+'\\n') ego_gnss.listen(lambda gnss: gnss_callback(gnss)) \"\"\" # -------------- # Add IMU sensor to ego vehicle. # -------------- \"\"\" imu_bp = world.get_blueprint_library().find('sensor.other.imu') imu_location = carla.Location(0,0,0) imu_rotation = carla.Rotation(0,0,0) imu_transform = carla.Transform(imu_location,imu_rotation) imu_bp.set_attribute(\"sensor_tick\",str(3.0)) ego_imu = world.spawn_actor(imu_bp,imu_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def imu_callback(imu): print(\"IMU measure:\\n\"+str(imu)+'\\n') ego_imu.listen(lambda imu: imu_callback(imu)) \"\"\" # -------------- # Place spectator on ego spawning # -------------- \"\"\" spectator = world.get_spectator() world_snapshot = world.wait_for_tick() spectator.set_transform(ego_vehicle.get_transform()) \"\"\" # -------------- # Enable autopilot for ego vehicle # -------------- \"\"\" ego_vehicle.set_autopilot(True) \"\"\" # -------------- # Game loop. Prevents the script from finishing. # -------------- while True: world_snapshot = world.wait_for_tick() finally: # -------------- # Stop recording and destroy actors # -------------- client.stop_recorder() if ego_vehicle is not None: if ego_cam is not None: ego_cam.stop() ego_cam.destroy() if ego_col is not None: ego_col.stop() ego_col.destroy() if ego_lane is not None: ego_lane.stop() ego_lane.destroy() if ego_obs is not None: ego_obs.stop() ego_obs.destroy() if ego_gnss is not None: ego_gnss.stop() ego_gnss.destroy() if ego_imu is not None: ego_imu.stop() ego_imu.destroy() ego_vehicle.destroy() if __name__ == '__main__': try: main() except KeyboardInterrupt: pass finally: print('\\nDone with tutorial_ego.') tutorial_replay.py import glob import os import sys import time import math import weakref try: sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % ( sys.version_info.major, sys.version_info.minor, 'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0]) except IndexError: pass import carla import argparse import logging import random def main(): client = carla.Client('127.0.0.1', 2000) client.set_timeout(10.0) try: world = client.get_world() ego_vehicle = None ego_cam = None depth_cam = None depth_cam02 = None sem_cam = None rad_ego = None lidar_sen = None # -------------- # Query the recording # -------------- \"\"\" # Show the most important events in the recording. print(client.show_recorder_file_info(\"~/tutorial/recorder/recording05.log\",False)) # Show actors not moving 1 meter in 10 seconds. #print(client.show_recorder_actors_blocked(\"~/tutorial/recorder/recording04.log\",10,1)) # Show collisions between any type of actor. #print(client.show_recorder_collisions(\"~/tutorial/recorder/recording04.log\",'v','a')) \"\"\" # -------------- # Reenact a fragment of the recording # -------------- \"\"\" client.replay_file(\"~/tutorial/recorder/recording03.log\",0,30,0) \"\"\" # -------------- # Set playback simulation conditions # -------------- \"\"\" ego_vehicle = world.get_actor(322) #Store the ID from the simulation or query the recording to find out \"\"\" # -------------- # Place spectator on ego spawning # -------------- \"\"\" spectator = world.get_spectator() world_snapshot = world.wait_for_tick() spectator.set_transform(ego_vehicle.get_transform()) \"\"\" # -------------- # Change weather conditions # -------------- \"\"\" weather = world.get_weather() weather.sun_altitude_angle = -30 weather.fog_density = 65 weather.fog_distance = 10 world.set_weather(weather) \"\"\" # -------------- # Add a RGB camera to ego vehicle. # -------------- \"\"\" cam_bp = None cam_bp = world.get_blueprint_library().find('sensor.camera.rgb') cam_location = carla.Location(2,0,1) cam_rotation = carla.Rotation(0,180,0) cam_transform = carla.Transform(cam_location,cam_rotation) cam_bp.set_attribute(\"image_size_x\",str(1920)) cam_bp.set_attribute(\"image_size_y\",str(1080)) cam_bp.set_attribute(\"fov\",str(105)) ego_cam = world.spawn_actor(cam_bp,cam_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) ego_cam.listen(lambda image: image.save_to_disk('~/tutorial/new_rgb_output/%.6d.jpg' % image.frame)) \"\"\" # -------------- # Add a Logarithmic Depth camera to ego vehicle. # -------------- \"\"\" depth_cam = None depth_bp = world.get_blueprint_library().find('sensor.camera.depth') depth_bp.set_attribute(\"image_size_x\",str(1920)) depth_bp.set_attribute(\"image_size_y\",str(1080)) depth_bp.set_attribute(\"fov\",str(105)) depth_location = carla.Location(2,0,1) depth_rotation = carla.Rotation(0,180,0) depth_transform = carla.Transform(depth_location,depth_rotation) depth_cam = world.spawn_actor(depth_bp,depth_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view depth_cam.listen(lambda image: image.save_to_disk('~/tutorial/de_log/%.6d.jpg' % image.frame,carla.ColorConverter.LogarithmicDepth)) \"\"\" # -------------- # Add a Depth camera to ego vehicle. # -------------- \"\"\" depth_cam02 = None depth_bp02 = world.get_blueprint_library().find('sensor.camera.depth') depth_bp02.set_attribute(\"image_size_x\",str(1920)) depth_bp02.set_attribute(\"image_size_y\",str(1080)) depth_bp02.set_attribute(\"fov\",str(105)) depth_location02 = carla.Location(2,0,1) depth_rotation02 = carla.Rotation(0,180,0) depth_transform02 = carla.Transform(depth_location02,depth_rotation02) depth_cam02 = world.spawn_actor(depth_bp02,depth_transform02,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view depth_cam02.listen(lambda image: image.save_to_disk('~/tutorial/de/%.6d.jpg' % image.frame,carla.ColorConverter.Depth)) \"\"\" # -------------- # Add a new semantic segmentation camera to ego vehicle # -------------- \"\"\" sem_cam = None sem_bp = world.get_blueprint_library().find('sensor.camera.semantic_segmentation') sem_bp.set_attribute(\"image_size_x\",str(1920)) sem_bp.set_attribute(\"image_size_y\",str(1080)) sem_bp.set_attribute(\"fov\",str(105)) sem_location = carla.Location(2,0,1) sem_rotation = carla.Rotation(0,180,0) sem_transform = carla.Transform(sem_location,sem_rotation) sem_cam = world.spawn_actor(sem_bp,sem_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) # This time, a color converter is applied to the image, to get the semantic segmentation view sem_cam.listen(lambda image: image.save_to_disk('~/tutorial/new_sem_output/%.6d.jpg' % image.frame,carla.ColorConverter.CityScapesPalette)) \"\"\" # -------------- # Add a new radar sensor to ego vehicle # -------------- \"\"\" rad_cam = None rad_bp = world.get_blueprint_library().find('sensor.other.radar') rad_bp.set_attribute('horizontal_fov', str(35)) rad_bp.set_attribute('vertical_fov', str(20)) rad_bp.set_attribute('range', str(20)) rad_location = carla.Location(x=2.8, z=1.0) rad_rotation = carla.Rotation(pitch=5) rad_transform = carla.Transform(rad_location,rad_rotation) rad_ego = world.spawn_actor(rad_bp,rad_transform,attach_to=ego_vehicle, attachment_type=carla.AttachmentType.Rigid) def rad_callback(radar_data): velocity_range = 7.5 # m/s current_rot = radar_data.transform.rotation for detect in radar_data: azi = math.degrees(detect.azimuth) alt = math.degrees(detect.altitude) # The 0.25 adjusts a bit the distance so the dots can # be properly seen fw_vec = carla.Vector3D(x=detect.depth - 0.25) carla.Transform( carla.Location(), carla.Rotation( pitch=current_rot.pitch + alt, yaw=current_rot.yaw + azi, roll=current_rot.roll)).transform(fw_vec) def clamp(min_v, max_v, value): return max(min_v, min(value, max_v)) norm_velocity = detect.velocity / velocity_range # range [-1, 1] r = int(clamp(0.0, 1.0, 1.0 - norm_velocity) * 255.0) g = int(clamp(0.0, 1.0, 1.0 - abs(norm_velocity)) * 255.0) b = int(abs(clamp(- 1.0, 0.0, - 1.0 - norm_velocity)) * 255.0) world.debug.draw_point( radar_data.transform.location + fw_vec, size=0.075, life_time=0.06, persistent_lines=False, color=carla.Color(r, g, b)) rad_ego.listen(lambda radar_data: rad_callback(radar_data)) \"\"\" # -------------- # Add a new LIDAR sensor to ego vehicle # -------------- \"\"\" lidar_cam = None lidar_bp = world.get_blueprint_library().find('sensor.lidar.ray_cast') lidar_bp.set_attribute('channels',str(32)) lidar_bp.set_attribute('points_per_second',str(90000)) lidar_bp.set_attribute('rotation_frequency',str(40)) lidar_bp.set_attribute('range',str(20)) lidar_location = carla.Location(0,0,2) lidar_rotation = carla.Rotation(0,0,0) lidar_transform = carla.Transform(lidar_location,lidar_rotation) lidar_sen = world.spawn_actor(lidar_bp,lidar_transform,attach_to=ego_vehicle,attachment_type=carla.AttachmentType.Rigid) lidar_sen.listen(lambda point_cloud: point_cloud.save_to_disk('/home/adas/Desktop/tutorial/new_lidar_output/%.6d.ply' % point_cloud.frame)) \"\"\" # -------------- # Game loop. Prevents the script from finishing. # -------------- while True: world_snapshot = world.wait_for_tick() finally: # -------------- # Destroy actors # -------------- if ego_vehicle is not None: if ego_cam is not None: ego_cam.stop() ego_cam.destroy() if depth_cam is not None: depth_cam.stop() depth_cam.destroy() if sem_cam is not None: sem_cam.stop() sem_cam.destroy() if rad_ego is not None: rad_ego.stop() rad_ego.destroy() if lidar_sen is not None: lidar_sen.stop() lidar_sen.destroy() ego_vehicle.destroy() print('\\nNothing to be done.') if __name__ == '__main__': try: main() except KeyboardInterrupt: pass finally: print('\\nDone with tutorial_replay.') That is a wrap on how to properly retrieve data from the simulation. Make sure to play around, change the conditions of the simulator, experiment with sensor settings. The possibilities are endless. Visit the forum to post any doubts or suggestions that have come to mind during this reading. CARLA forum","title":"Tutorial scripts"},{"location":"tuto_G_rllib_integration/","text":"RLlib Integration The RLlib integration brings support between the Ray/RLlib library and CARLA, allowing the easy use of the CARLA environment for training and inference purposes. Ray is an open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library. The RLlib integration allows users to create and use CARLA as an environment of Ray and use that environment for training and inference purposes. The integration is ready to use both locally and in the cloud using AWS. In this guide we will outline the requirements needed for running the RLlib integration both locally and on AWS, the structure of the integration repository, an overview of how to use the library and then an example of how to set up a Ray experiment using CARLA as an environment. Before you begin Requirements for running locally Requirements for running on AWS Cloud RLlib repository structure Creating your own experiment The experiment class The environment configuration The training and inference scripts DQN example Running on AWS Configure AWS Create the training AMI Configure the cluster Run the training Running the DQN example on AWS Before you begin Download the RLlib integration from GitHub or clone the repository directly: git clone https://github.com/carla-simulator/rllib-integration.git Requirements vary depending on if you are running locally or on AWS: Requirements for running locally Install a package version of CARLA and import the additional assets . The recommended version is CARLA 0.9.11 as the integration was designed and tested with this version. Other versions may be compatible but have not been fully tested, so use these at your own discretion. Navigate into the root folder of the RLlib integration repository and install the Python requirements: pip3 install -r requirements.txt Set an environment variable to locate the CARLA package by running the command below or add CARLA_ROOT=path/to/carla to your .bashrc file: export CARLA_ROOT=path/to/carla Requirements for running on AWS Cloud The requirements for running on AWS are taken care of automatically in an install script found in the RLlib integration repository. Find more details in the section \"Running on AWS\" . RLlib repository structure The repository is divided into three directories: rllib_integration contains all the infrastructure related to CARLA and how to set up the CARLA server, clients and actors. This provides the basic structure that all training and testing experiments must follow. aws has the files needed to run in an AWS instance. aws_helper.py provides several functionalities that ease the management of EC2 instances, including instance creation and sending and receiving data. dqn_example and the dqn_* files in the root directory provide an easy-to-understand example on how to set up a Ray experiment using CARLA as its environment. Creating your own experiment This section provides a general overview on how to create your own experiment. For a more specific example, see the next section \"DQN example\" . You will need to create at least four files: The experiment class The environment configuration The training and inference scripts 1. The experiment class To use the CARLA environment you need to define a training experiment. Ray requires environments to return a series of specific information. You can see details on the CARLA environment in rllib-integration/rllib_integration/carla_env.py . The information required by Ray is dependent on your specific experiment so all experiments should inherit from BaseExperiment . This class contains all the functions that need to be overwritten for your own experiment. These are all functions related to the actions, observations and rewards of the training. 2. The environment configuration The experiment should be configured through a .yaml file. Any settings passed through the configuration file will override the default settings. The locations of the different default settings are explained below. The configuration file has three main uses: Sets up most of the CARLA server and client settings, such as timeout or map quality. See the default values here . Sets up variables specific to your experiment as well as specifying town conditions and the spawning of the ego vehicle and its sensors. The default settings are found here and provide an example of how to set up sensors. Configures settings specific to Ray's training . These settings are related to the specific trainer used. If you are using a built-in model, you can apply settings for it here. 3. The training and inference scripts The last step is to create your own training and inference scripts. This part is completely up to you and is dependent on the Ray API. If you want to create your own specific model, check out Ray's custom model documentation . DQN example This section builds upon the previous section to show a specific example on how to work with the RLlib integration using the BirdView pseudosensor and Ray's DQNTrainer . The structure of the DQN example is as follows: The experiment class : DQNExperiment , which overwrites the methods of the BaseExperiment class. The configuration file : dqn_example/dqn_config.yaml The training file : dqn_train.py The inference file : With Ray : dqn_inference_ray.py Without Ray : dqn_inference.py To run the example locally: Install pytorch: pip3 install -r dqn_example/dqn_requirements.txt Run the training file: python3 dqn_train.py dqn_example/dqn_config.yaml --name dqn Note The default configuration uses 1 GPU and 12 CPUs, so if your local machine doesn't have that capacity, lower the numbers in the configuration file . If you experience out of memory problems, consider reducing the buffer_size parameter. Running on AWS This section explains how to use the RLlib integration to automatically run training and inference on AWS EC2 instances. To handle the scaling of instances we use the Ray autoscaler API . Configure AWS You will need to configure your boto3 environment correctly. Check here for more information. Create the training AMI Use the provided aws_helper.py script to automatically create the image needed for training by running the command below, passing in the name of the base image and the installation script install.sh found in rllib-integration/aws/install : python3 aws_helper.py create-image --name <AMI-name> --installation-scripts <installation-scripts> --instance-type <instance-type> --volume-size <volume-size> Configure the cluster Once the image is created, there will be an output with image information. To use the Ray autoscaler, update the <ImageId> and <SecurityGroupIds> settings in your autoscaler configuration file with the information from the output. Run the training With the image created, you can use Ray's API to run the training on the cluster: Initialize the cluster: ray up <autoscaler_configuration_file> (Optional) If the local code has been modified after the cluster initialization, run this command to update it: ray rsync-up <autoscaler_configuration_file> <path_to_local_folder> <path_to_remote_folder> Run the training: ray submit <autoscaler_configuration_file> <training_file> (Optional) Monitor the cluster status: ray attach <autoscaler_configuration_file> watch -n 1 ray status Shutdown the cluster: ray down <autoscaler_configuration_file> Running the DQN example on AWS To run the DQN example on AWS: Create the image by passing the dqn_example/dqn_autoscaler.yaml configuration to the following command: python3 aws_helper.py create-image --name <AMI-name> --installation-scripts install/install.sh --instance-type <instance-type> --volume-size <volume-size> Update the <ImageId> and <SecurityGroupIds> settings in dqn_autoscaler.yaml with the information provided by the previous command. Initialize the cluster: ray up dqn_example/dqn_autoscaler.yaml (Optional) Update remote files with local changes: ray rsync-up dqn_example/dqn_autoscaler.yaml dqn_example . ray rsync-up dqn_example/dqn_autoscaler.yaml rllib_integration . Run the training: ray submit dqn_example/dqn_autoscaler.yaml dqn_train.py -- dqn_example/dqn_config.yaml --auto (Optional) Monitor the cluster status: ray attach dqn_example/dqn_autoscaler.yaml watch -n 1 ray status Shutdown the cluster: ray down dqn_example/dqn_autoscaler.yaml This guide has outlined how to install and run the RLlib integration on AWS and on a local machine. If you have any questions or ran into any issues working through the guide, feel free to post in the forum or raise an issue on GitHub .","title":"RLlib \u96c6\u6210"},{"location":"tuto_G_rllib_integration/#rllib-integration","text":"The RLlib integration brings support between the Ray/RLlib library and CARLA, allowing the easy use of the CARLA environment for training and inference purposes. Ray is an open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library. The RLlib integration allows users to create and use CARLA as an environment of Ray and use that environment for training and inference purposes. The integration is ready to use both locally and in the cloud using AWS. In this guide we will outline the requirements needed for running the RLlib integration both locally and on AWS, the structure of the integration repository, an overview of how to use the library and then an example of how to set up a Ray experiment using CARLA as an environment. Before you begin Requirements for running locally Requirements for running on AWS Cloud RLlib repository structure Creating your own experiment The experiment class The environment configuration The training and inference scripts DQN example Running on AWS Configure AWS Create the training AMI Configure the cluster Run the training Running the DQN example on AWS","title":"RLlib Integration"},{"location":"tuto_G_rllib_integration/#before-you-begin","text":"Download the RLlib integration from GitHub or clone the repository directly: git clone https://github.com/carla-simulator/rllib-integration.git Requirements vary depending on if you are running locally or on AWS:","title":"Before you begin"},{"location":"tuto_G_rllib_integration/#requirements-for-running-locally","text":"Install a package version of CARLA and import the additional assets . The recommended version is CARLA 0.9.11 as the integration was designed and tested with this version. Other versions may be compatible but have not been fully tested, so use these at your own discretion. Navigate into the root folder of the RLlib integration repository and install the Python requirements: pip3 install -r requirements.txt Set an environment variable to locate the CARLA package by running the command below or add CARLA_ROOT=path/to/carla to your .bashrc file: export CARLA_ROOT=path/to/carla","title":"Requirements for running locally"},{"location":"tuto_G_rllib_integration/#requirements-for-running-on-aws-cloud","text":"The requirements for running on AWS are taken care of automatically in an install script found in the RLlib integration repository. Find more details in the section \"Running on AWS\" .","title":"Requirements for running on AWS Cloud"},{"location":"tuto_G_rllib_integration/#rllib-repository-structure","text":"The repository is divided into three directories: rllib_integration contains all the infrastructure related to CARLA and how to set up the CARLA server, clients and actors. This provides the basic structure that all training and testing experiments must follow. aws has the files needed to run in an AWS instance. aws_helper.py provides several functionalities that ease the management of EC2 instances, including instance creation and sending and receiving data. dqn_example and the dqn_* files in the root directory provide an easy-to-understand example on how to set up a Ray experiment using CARLA as its environment.","title":"RLlib repository structure"},{"location":"tuto_G_rllib_integration/#creating-your-own-experiment","text":"This section provides a general overview on how to create your own experiment. For a more specific example, see the next section \"DQN example\" . You will need to create at least four files: The experiment class The environment configuration The training and inference scripts","title":"Creating your own experiment"},{"location":"tuto_G_rllib_integration/#1-the-experiment-class","text":"To use the CARLA environment you need to define a training experiment. Ray requires environments to return a series of specific information. You can see details on the CARLA environment in rllib-integration/rllib_integration/carla_env.py . The information required by Ray is dependent on your specific experiment so all experiments should inherit from BaseExperiment . This class contains all the functions that need to be overwritten for your own experiment. These are all functions related to the actions, observations and rewards of the training.","title":"1. The experiment class"},{"location":"tuto_G_rllib_integration/#2-the-environment-configuration","text":"The experiment should be configured through a .yaml file. Any settings passed through the configuration file will override the default settings. The locations of the different default settings are explained below. The configuration file has three main uses: Sets up most of the CARLA server and client settings, such as timeout or map quality. See the default values here . Sets up variables specific to your experiment as well as specifying town conditions and the spawning of the ego vehicle and its sensors. The default settings are found here and provide an example of how to set up sensors. Configures settings specific to Ray's training . These settings are related to the specific trainer used. If you are using a built-in model, you can apply settings for it here.","title":"2. The environment configuration"},{"location":"tuto_G_rllib_integration/#3-the-training-and-inference-scripts","text":"The last step is to create your own training and inference scripts. This part is completely up to you and is dependent on the Ray API. If you want to create your own specific model, check out Ray's custom model documentation .","title":"3. The training and inference scripts"},{"location":"tuto_G_rllib_integration/#dqn-example","text":"This section builds upon the previous section to show a specific example on how to work with the RLlib integration using the BirdView pseudosensor and Ray's DQNTrainer . The structure of the DQN example is as follows: The experiment class : DQNExperiment , which overwrites the methods of the BaseExperiment class. The configuration file : dqn_example/dqn_config.yaml The training file : dqn_train.py The inference file : With Ray : dqn_inference_ray.py Without Ray : dqn_inference.py To run the example locally: Install pytorch: pip3 install -r dqn_example/dqn_requirements.txt Run the training file: python3 dqn_train.py dqn_example/dqn_config.yaml --name dqn Note The default configuration uses 1 GPU and 12 CPUs, so if your local machine doesn't have that capacity, lower the numbers in the configuration file . If you experience out of memory problems, consider reducing the buffer_size parameter.","title":"DQN example"},{"location":"tuto_G_rllib_integration/#running-on-aws","text":"This section explains how to use the RLlib integration to automatically run training and inference on AWS EC2 instances. To handle the scaling of instances we use the Ray autoscaler API .","title":"Running on AWS"},{"location":"tuto_G_rllib_integration/#configure-aws","text":"You will need to configure your boto3 environment correctly. Check here for more information.","title":"Configure AWS"},{"location":"tuto_G_rllib_integration/#create-the-training-ami","text":"Use the provided aws_helper.py script to automatically create the image needed for training by running the command below, passing in the name of the base image and the installation script install.sh found in rllib-integration/aws/install : python3 aws_helper.py create-image --name <AMI-name> --installation-scripts <installation-scripts> --instance-type <instance-type> --volume-size <volume-size>","title":"Create the training AMI"},{"location":"tuto_G_rllib_integration/#configure-the-cluster","text":"Once the image is created, there will be an output with image information. To use the Ray autoscaler, update the <ImageId> and <SecurityGroupIds> settings in your autoscaler configuration file with the information from the output.","title":"Configure the cluster"},{"location":"tuto_G_rllib_integration/#run-the-training","text":"With the image created, you can use Ray's API to run the training on the cluster: Initialize the cluster: ray up <autoscaler_configuration_file> (Optional) If the local code has been modified after the cluster initialization, run this command to update it: ray rsync-up <autoscaler_configuration_file> <path_to_local_folder> <path_to_remote_folder> Run the training: ray submit <autoscaler_configuration_file> <training_file> (Optional) Monitor the cluster status: ray attach <autoscaler_configuration_file> watch -n 1 ray status Shutdown the cluster: ray down <autoscaler_configuration_file>","title":"Run the training"},{"location":"tuto_G_rllib_integration/#running-the-dqn-example-on-aws","text":"To run the DQN example on AWS: Create the image by passing the dqn_example/dqn_autoscaler.yaml configuration to the following command: python3 aws_helper.py create-image --name <AMI-name> --installation-scripts install/install.sh --instance-type <instance-type> --volume-size <volume-size> Update the <ImageId> and <SecurityGroupIds> settings in dqn_autoscaler.yaml with the information provided by the previous command. Initialize the cluster: ray up dqn_example/dqn_autoscaler.yaml (Optional) Update remote files with local changes: ray rsync-up dqn_example/dqn_autoscaler.yaml dqn_example . ray rsync-up dqn_example/dqn_autoscaler.yaml rllib_integration . Run the training: ray submit dqn_example/dqn_autoscaler.yaml dqn_train.py -- dqn_example/dqn_config.yaml --auto (Optional) Monitor the cluster status: ray attach dqn_example/dqn_autoscaler.yaml watch -n 1 ray status Shutdown the cluster: ray down dqn_example/dqn_autoscaler.yaml This guide has outlined how to install and run the RLlib integration on AWS and on a local machine. If you have any questions or ran into any issues working through the guide, feel free to post in the forum or raise an issue on GitHub .","title":"Running the DQN example on AWS"},{"location":"tuto_G_scenic/","text":"Scenic This guide provides an overview of how to use Scenic with CARLA to generate multiple, diverse scenarios with a single scenario definition. It assumes that users have prior knowledge of the Scenic syntax. If you need to learn more about Scenic, then read their \"Getting Started with Scenic\" guide and have a look at their tutorials for creating static and dynamic scenarios. By the end of the guide you will know: The minimum requirements needed to run a Scenic script on CARLA. How to write a simple scenario definition to generate a multitude of scenario simulations. How to run a Scenic script on CARLA. Parameters used to configure Scenic simulations on CARLA. Before you begin Scenic domains Creating a Scenic scenario to use with CARLA Run the scenario Additional parameters Before you begin Before using Scenic with CARLA, you will need to fulfill the following requirements: Install Python 3.8 or higher. Install Scenic . Scenic Domains Scenic has a general driving domain which allows users to define scenarios that can be run on any driving simulator. In addition, it has other domains that are specific to each simulator. Check here for more information on Scenic domains. Of particular importance within each domain are the behaviour and actions definitions. Check the links below for reference material to behaviours and actions from the Scenic driving domain and the CARLA domain: Behaviours in the Scenic driving domain Behaviours in the CARLA domain Actions in the Scenic driving domain Actions in the CARLA domain Creating a Scenic scenario to use with CARLA This section walks through how to write a basic Scenic script in which a leading vehicle decelerates suddenly due to an obstacle in the road. An ego vehicle then needs to brake suddenly to avoid a collison with the leading vehicle. The full script is found in the Scenic repository along with other examples involving more complex road networks. 1. Set the map parameters and declare the model to be used in the scenario: An .xodr file should be set as the value for the map parameter, this will be used later to generate road network information. The parameter carla_map refers to the name of the CARLA map you would like to use in the simulation. If this is defined then Scenic will load all the assets of the map (buildings, trees, etc.), and if not, then the OpenDRIVE standalone mode will be used. The model includes all the utilities specific to running scenarios on CARLA. This should be defined in all the scripts you want to run on CARLA. ## SET MAP AND MODEL param map = localPath('../../../tests/formats/opendrive/maps/CARLA/Town01.xodr') param carla_map = 'Town01' model scenic.simulators.carla.model 2. Define the constants to be used in the scenario: The scenario involves two vehicles, the leading vehicle and the ego vehicle. We will define the ego vehicle model, the speeds of both cars, the distance threshold for braking and the amount of brake to apply. ## CONSTANTS EGO_MODEL = \"vehicle.lincoln.mkz_2017\" EGO_SPEED = 10 EGO_BRAKING_THRESHOLD = 12 LEAD_CAR_SPEED = 10 LEADCAR_BRAKING_THRESHOLD = 10 BRAKE_ACTION = 1.0 3 . Define the scenario behaviours: In this scenario we will use the Scenic behaviour library to instruct the ego vehicle to follow the lane at the predefined speed and then brake hard when it gets within a certain distance of another vehicle. The leading vehicle will also follow the lane at the predefined speed and brake hard within a certain distance of any objects: ## DEFINING BEHAVIORS # EGO BEHAVIOR: Follow lane, and brake after passing a threshold distance to the leading car behavior EgoBehavior(speed=10): try: do FollowLaneBehavior(speed) interrupt when withinDistanceToAnyCars(self, EGO_BRAKING_THRESHOLD): take SetBrakeAction(BRAKE_ACTION) # LEAD CAR BEHAVIOR: Follow lane, and brake after passing a threshold distance to obstacle behavior LeadingCarBehavior(speed=10): try: do FollowLaneBehavior(speed) interrupt when withinDistanceToAnyObjs(self, LEADCAR_BRAKING_THRESHOLD): take SetBrakeAction(BRAKE_ACTION) 4. Generate the road network: The Scenic roads library is used to generate the road network geometry and traffic information. The road network is represented by an instance of the Network class and is generated from the .xodr file defined at the beginning of the script. ## DEFINING SPATIAL RELATIONS # make sure to put '*' to uniformly randomly select from all elements of the list, 'lanes' lane = Uniform(*network.lanes) 5. Set the scene: We will now define the starting positions for the vehicles and placement of objects. Place a trash can in the middle of the lane: obstacle = Trash on lane.centerline Place the leading car driving at the predefined speed along the road at a distance of between 50 and 30 meters behind the obstacle: leadCar = Car following roadDirection from obstacle for Range(-50, -30), with behavior LeadingCarBehavior(LEAD_CAR_SPEED) Place the ego vehicle driving at the predefined speed along the road at a distance of between 15 to 10 meters behind the leading vehicle: ego = Car following roadDirection from leadCar for Range(-15, -10), with blueprint EGO_MODEL, with behavior EgoBehavior(EGO_SPEED) Make it a requirement that the scene takes place more than 80 meters from an intersection: require (distance to intersection) > 80 6. Set an end point so the script knows when the scene is finished: The scenario will end when the speed of the ego vehicle goes below 0.1 meters per second and is situated less than 30 meters from the obstacle. terminate when ego.speed < 0.1 and (distance to obstacle) < 30 Run the scenario To run the Scenic scenario: 1. Start the CARLA server. 2. Run the following command: scenic path/to/scenic/script.scenic --simulate A pygame window will appear and the scenario will play out repeatedly, each time generating a unique scenario within the bounds of the restrictions set in the script. To stop the scenario generation, press ctrl + C in the terminal. Additional parameters The CARLA model provides several global parameters than can be overridden in scenarios using the param statement or via the command line using the --param option . Below is a table of configurable parameters in the CARLA model: Name Value Description carla_map str Name of the CARLA map to use (e.g. 'Town01'). If set to None , CARLA will attempt to create a world in the OpenDRIVE standalone mode using the .xodr file defined in the map parameter. timestep float Timestep to use for simulations (how frequently Scenic interrupts CARLA to run behaviors, check requirements, etc.) in seconds. Default is 0.1 seconds. weather str or dict Weather to use for the simulation. Can be either a string identifying one of the CARLA weather presets (e.g. 'ClearSunset') or a dictionary specifying all the weather parameters ). Default is a uniform distribution over all the weather presets. address str IP address to connect to CARLA. Default is localhost (127.0.0.1). port int Port to connect to CARLA. Default is 2000. timeout float Maximum time in seconds to wait when attempting to connect to CARLA. Default is 10. render int Whether or not to have CARLA create a window showing the simulations from the point of view of the ego object: 1 for yes, 0 for no. Default 1 . record str If nonempty, folder in which to save CARLA record files for replaying simulations.","title":"Scenic"},{"location":"tuto_G_scenic/#scenic","text":"This guide provides an overview of how to use Scenic with CARLA to generate multiple, diverse scenarios with a single scenario definition. It assumes that users have prior knowledge of the Scenic syntax. If you need to learn more about Scenic, then read their \"Getting Started with Scenic\" guide and have a look at their tutorials for creating static and dynamic scenarios. By the end of the guide you will know: The minimum requirements needed to run a Scenic script on CARLA. How to write a simple scenario definition to generate a multitude of scenario simulations. How to run a Scenic script on CARLA. Parameters used to configure Scenic simulations on CARLA. Before you begin Scenic domains Creating a Scenic scenario to use with CARLA Run the scenario Additional parameters","title":"Scenic"},{"location":"tuto_G_scenic/#before-you-begin","text":"Before using Scenic with CARLA, you will need to fulfill the following requirements: Install Python 3.8 or higher. Install Scenic .","title":"Before you begin"},{"location":"tuto_G_scenic/#scenic-domains","text":"Scenic has a general driving domain which allows users to define scenarios that can be run on any driving simulator. In addition, it has other domains that are specific to each simulator. Check here for more information on Scenic domains. Of particular importance within each domain are the behaviour and actions definitions. Check the links below for reference material to behaviours and actions from the Scenic driving domain and the CARLA domain: Behaviours in the Scenic driving domain Behaviours in the CARLA domain Actions in the Scenic driving domain Actions in the CARLA domain","title":"Scenic Domains"},{"location":"tuto_G_scenic/#creating-a-scenic-scenario-to-use-with-carla","text":"This section walks through how to write a basic Scenic script in which a leading vehicle decelerates suddenly due to an obstacle in the road. An ego vehicle then needs to brake suddenly to avoid a collison with the leading vehicle. The full script is found in the Scenic repository along with other examples involving more complex road networks. 1. Set the map parameters and declare the model to be used in the scenario: An .xodr file should be set as the value for the map parameter, this will be used later to generate road network information. The parameter carla_map refers to the name of the CARLA map you would like to use in the simulation. If this is defined then Scenic will load all the assets of the map (buildings, trees, etc.), and if not, then the OpenDRIVE standalone mode will be used. The model includes all the utilities specific to running scenarios on CARLA. This should be defined in all the scripts you want to run on CARLA. ## SET MAP AND MODEL param map = localPath('../../../tests/formats/opendrive/maps/CARLA/Town01.xodr') param carla_map = 'Town01' model scenic.simulators.carla.model 2. Define the constants to be used in the scenario: The scenario involves two vehicles, the leading vehicle and the ego vehicle. We will define the ego vehicle model, the speeds of both cars, the distance threshold for braking and the amount of brake to apply. ## CONSTANTS EGO_MODEL = \"vehicle.lincoln.mkz_2017\" EGO_SPEED = 10 EGO_BRAKING_THRESHOLD = 12 LEAD_CAR_SPEED = 10 LEADCAR_BRAKING_THRESHOLD = 10 BRAKE_ACTION = 1.0 3 . Define the scenario behaviours: In this scenario we will use the Scenic behaviour library to instruct the ego vehicle to follow the lane at the predefined speed and then brake hard when it gets within a certain distance of another vehicle. The leading vehicle will also follow the lane at the predefined speed and brake hard within a certain distance of any objects: ## DEFINING BEHAVIORS # EGO BEHAVIOR: Follow lane, and brake after passing a threshold distance to the leading car behavior EgoBehavior(speed=10): try: do FollowLaneBehavior(speed) interrupt when withinDistanceToAnyCars(self, EGO_BRAKING_THRESHOLD): take SetBrakeAction(BRAKE_ACTION) # LEAD CAR BEHAVIOR: Follow lane, and brake after passing a threshold distance to obstacle behavior LeadingCarBehavior(speed=10): try: do FollowLaneBehavior(speed) interrupt when withinDistanceToAnyObjs(self, LEADCAR_BRAKING_THRESHOLD): take SetBrakeAction(BRAKE_ACTION) 4. Generate the road network: The Scenic roads library is used to generate the road network geometry and traffic information. The road network is represented by an instance of the Network class and is generated from the .xodr file defined at the beginning of the script. ## DEFINING SPATIAL RELATIONS # make sure to put '*' to uniformly randomly select from all elements of the list, 'lanes' lane = Uniform(*network.lanes) 5. Set the scene: We will now define the starting positions for the vehicles and placement of objects. Place a trash can in the middle of the lane: obstacle = Trash on lane.centerline Place the leading car driving at the predefined speed along the road at a distance of between 50 and 30 meters behind the obstacle: leadCar = Car following roadDirection from obstacle for Range(-50, -30), with behavior LeadingCarBehavior(LEAD_CAR_SPEED) Place the ego vehicle driving at the predefined speed along the road at a distance of between 15 to 10 meters behind the leading vehicle: ego = Car following roadDirection from leadCar for Range(-15, -10), with blueprint EGO_MODEL, with behavior EgoBehavior(EGO_SPEED) Make it a requirement that the scene takes place more than 80 meters from an intersection: require (distance to intersection) > 80 6. Set an end point so the script knows when the scene is finished: The scenario will end when the speed of the ego vehicle goes below 0.1 meters per second and is situated less than 30 meters from the obstacle. terminate when ego.speed < 0.1 and (distance to obstacle) < 30","title":"Creating a Scenic scenario to use with CARLA"},{"location":"tuto_G_scenic/#run-the-scenario","text":"To run the Scenic scenario: 1. Start the CARLA server. 2. Run the following command: scenic path/to/scenic/script.scenic --simulate A pygame window will appear and the scenario will play out repeatedly, each time generating a unique scenario within the bounds of the restrictions set in the script. To stop the scenario generation, press ctrl + C in the terminal.","title":"Run the scenario"},{"location":"tuto_G_scenic/#additional-parameters","text":"The CARLA model provides several global parameters than can be overridden in scenarios using the param statement or via the command line using the --param option . Below is a table of configurable parameters in the CARLA model: Name Value Description carla_map str Name of the CARLA map to use (e.g. 'Town01'). If set to None , CARLA will attempt to create a world in the OpenDRIVE standalone mode using the .xodr file defined in the map parameter. timestep float Timestep to use for simulations (how frequently Scenic interrupts CARLA to run behaviors, check requirements, etc.) in seconds. Default is 0.1 seconds. weather str or dict Weather to use for the simulation. Can be either a string identifying one of the CARLA weather presets (e.g. 'ClearSunset') or a dictionary specifying all the weather parameters ). Default is a uniform distribution over all the weather presets. address str IP address to connect to CARLA. Default is localhost (127.0.0.1). port int Port to connect to CARLA. Default is 2000. timeout float Maximum time in seconds to wait when attempting to connect to CARLA. Default is 10. render int Whether or not to have CARLA create a window showing the simulations from the point of view of the ego object: 1 for yes, 0 for no. Default 1 . record str If nonempty, folder in which to save CARLA record files for replaying simulations.","title":"Additional parameters"},{"location":"tuto_M_add_map_alternative/","text":"Alternative methods to import maps This guide describes alternative methods to import maps into CARLA. These methods involve more manual steps than the processes described in the package and source import guides. First we will describe the RoadRuner plugin and then the manual import method. RoadRunner plugin import Manual import RoadRunner plugin import The RoadRunner software from MathWorks provides plugins for Unreal Engine to help ease the import process of maps into CARLA. Plugin installation 1. The plugins are available for download from the MathWorks website . MathWorks also has a full tutorial , similar to this one, on how to import maps to CARLA using the plugins. 2. Extract the contents of the downloaded folder and move the folders RoadRunnerImporter , RoadRunnerCarlaIntegration and RoadRunnerMaterials to <carla>/Unreal/CarlaUE4/Plugins/ . 3. Rebuild the plugin following the instructions below: On Windows. Right-click the .uproject file in <carla>/Unreal/CarlaUE4 and select Generate Visual Studio project files . In the root folder of CARLA, run the command: make launch On Linux. Run the following command: UE4_ROOT/GenerateProjectFiles.sh -project=\"carla/Unreal/CarlaUE4/CarlaUE4.uproject\" -game -engine 4. In the Unreal Engine window, make sure the checkbox is selected for both plugins Edit > Plugins . Import map 1. Import the <mapName>.fbx file to a new folder under /Content/Carla/Maps with the Import button. 2. Set Scene > Hierarchy Type to Create One Blueprint Asset (selected by default). 3. Set Static Meshes > Normal Import Method to Import Normals . 4. Click Import . 5. Save the current level File -> Save Current As... -> <mapname> . The new map should now appear next to the others in the Unreal Engine Content Browser . Note The tags for semantic segmentation will be assigned according to the name of the asset. The asset will be moved to the corresponding folder in Content/Carla/PackageName/Static . To change these, move them manually after importing. Manual import This method of importing maps can be used with generic .fbx and .xodr files. If you are using RoadRunner, you should use the export method Firebox (.fbx) , OpenDRIVE (.xodr) or Unreal (.fbx + .xml) . Do not use the Carla Exporter option because you will run into compatibility issues with the .fbx file. To import a map manually to Unreal Engine: 1. In your system's file explorer, copy the .xodr file to <carla-root>/Unreal/CarlaUE4/Content/Carla/Maps/OpenDrive . 2. Open the Unreal Engine editor by running make launch in the carla root directory. In the Content Browser of the editor, navigate to Content/Carla/Maps/BaseMap and duplicate the BaseMap . This will provide a blank map with the default sky and lighting objects. 3. Create a new folder with the name of your map package in the Content/Carla/Maps directory and save the duplicated map there with the same name as your .fbx and .xodr files. 4. In the Content Browser of the Unreal Engine editor, navigate back to Content/Carla/Maps . Right click in the grey area and select Import to /Game/Carla/Maps... under the heading Import Asset . 5. In the configuration window that pops up, make sure: These options are unchecked: Auto Generate Collision Combine Meshes Force Front xAxis In the following drop downs, the corresponding options are selected: Normal Import Method - Import Normals Material Import Method - Create New Materials These options are checked: Convert Scene Unit Import Textures 6. Click Import . 7. The meshes will appear in the Content Browser . Select the meshes and drag them into the scene. 8. Center the meshes at 0,0,0. 9. In the Content Browser , select all the meshes that need to have colliders. This refers to any meshes that will interact with pedestrians or vehicles. The colliders prevent them from falling into the abyss. Right-click the selected meshes and select Asset Actions > Bulk Edit via Property Matrix... . 10. Search for collision in the search box. 11. Change Collision Complexity from Project Default to Use Complex Collision As Simple and close the window. 12. Confirm the collision setting has been applied correctly by pressing Alt + c . You will see a black web over the meshes. 13. To create the ground truth for the semantic segmentation sensor, move the static meshes to the corresponding Carla/Static/<segment> folder following the structure below: Content \u2514\u2500\u2500 Carla \u251c\u2500\u2500 Blueprints \u251c\u2500\u2500 Config \u251c\u2500\u2500 Exported Maps \u251c\u2500\u2500 HDMaps \u251c\u2500\u2500 Maps \u2514\u2500\u2500 Static \u251c\u2500\u2500 Terrain \u2502 \u2514\u2500\u2500 mapname \u2502 \u2514\u2500\u2500 Static Meshes \u2502 \u251c\u2500\u2500 Road \u2502 \u2514\u2500\u2500 mapname \u2502 \u2514\u2500\u2500 Static Meshes \u2502 \u251c\u2500\u2500 RoadLines | \u2514\u2500\u2500 mapname | \u2514\u2500\u2500 Static Meshes \u2514\u2500\u2500 Sidewalks \u2514\u2500\u2500 mapname \u2514\u2500\u2500 Static Meshes 14. In the Modes panel, search for the Open Drive Actor and drag it into the scene. 15. In the Details panel, check Add Spawners and then click on the box beside Generate Routes . This will find the .xodr file with the same map name in the <carla-root>/Unreal/CarlaUE4/Content/Carla/Maps/OpenDrive directory and use it to generate a series of RoutePlanner and VehicleSpawnPoint actors. Next steps You will now be able to open your map in the Unreal Editor and run simulations. From here, you will be able to customize the map and generate the pedestrian navigation data. We recommend generating the pedestrian navigation after all customization has finished, so there is no chance of obstacles blocking the pedestrian paths. CARLA provides several tools and guides to help with the customization of your maps: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . It is recommended to use the automated processes for importing maps detailed in the guides for CARLA packages and CARLA source build , however the methods listed in this section can be used if required. If you encounter any issues with the alternative methods, feel free to post in the forum .","title":"\u5bfc\u5165\u5730\u56fe\u7684\u66ff\u4ee3\u65b9\u6cd5"},{"location":"tuto_M_add_map_alternative/#alternative-methods-to-import-maps","text":"This guide describes alternative methods to import maps into CARLA. These methods involve more manual steps than the processes described in the package and source import guides. First we will describe the RoadRuner plugin and then the manual import method. RoadRunner plugin import Manual import","title":"Alternative methods to import maps"},{"location":"tuto_M_add_map_alternative/#roadrunner-plugin-import","text":"The RoadRunner software from MathWorks provides plugins for Unreal Engine to help ease the import process of maps into CARLA.","title":"RoadRunner plugin import"},{"location":"tuto_M_add_map_alternative/#plugin-installation","text":"1. The plugins are available for download from the MathWorks website . MathWorks also has a full tutorial , similar to this one, on how to import maps to CARLA using the plugins. 2. Extract the contents of the downloaded folder and move the folders RoadRunnerImporter , RoadRunnerCarlaIntegration and RoadRunnerMaterials to <carla>/Unreal/CarlaUE4/Plugins/ . 3. Rebuild the plugin following the instructions below: On Windows. Right-click the .uproject file in <carla>/Unreal/CarlaUE4 and select Generate Visual Studio project files . In the root folder of CARLA, run the command: make launch On Linux. Run the following command: UE4_ROOT/GenerateProjectFiles.sh -project=\"carla/Unreal/CarlaUE4/CarlaUE4.uproject\" -game -engine 4. In the Unreal Engine window, make sure the checkbox is selected for both plugins Edit > Plugins .","title":"Plugin installation"},{"location":"tuto_M_add_map_alternative/#import-map","text":"1. Import the <mapName>.fbx file to a new folder under /Content/Carla/Maps with the Import button. 2. Set Scene > Hierarchy Type to Create One Blueprint Asset (selected by default). 3. Set Static Meshes > Normal Import Method to Import Normals . 4. Click Import . 5. Save the current level File -> Save Current As... -> <mapname> . The new map should now appear next to the others in the Unreal Engine Content Browser . Note The tags for semantic segmentation will be assigned according to the name of the asset. The asset will be moved to the corresponding folder in Content/Carla/PackageName/Static . To change these, move them manually after importing.","title":"Import map"},{"location":"tuto_M_add_map_alternative/#manual-import","text":"This method of importing maps can be used with generic .fbx and .xodr files. If you are using RoadRunner, you should use the export method Firebox (.fbx) , OpenDRIVE (.xodr) or Unreal (.fbx + .xml) . Do not use the Carla Exporter option because you will run into compatibility issues with the .fbx file. To import a map manually to Unreal Engine: 1. In your system's file explorer, copy the .xodr file to <carla-root>/Unreal/CarlaUE4/Content/Carla/Maps/OpenDrive . 2. Open the Unreal Engine editor by running make launch in the carla root directory. In the Content Browser of the editor, navigate to Content/Carla/Maps/BaseMap and duplicate the BaseMap . This will provide a blank map with the default sky and lighting objects. 3. Create a new folder with the name of your map package in the Content/Carla/Maps directory and save the duplicated map there with the same name as your .fbx and .xodr files. 4. In the Content Browser of the Unreal Engine editor, navigate back to Content/Carla/Maps . Right click in the grey area and select Import to /Game/Carla/Maps... under the heading Import Asset . 5. In the configuration window that pops up, make sure: These options are unchecked: Auto Generate Collision Combine Meshes Force Front xAxis In the following drop downs, the corresponding options are selected: Normal Import Method - Import Normals Material Import Method - Create New Materials These options are checked: Convert Scene Unit Import Textures 6. Click Import . 7. The meshes will appear in the Content Browser . Select the meshes and drag them into the scene. 8. Center the meshes at 0,0,0. 9. In the Content Browser , select all the meshes that need to have colliders. This refers to any meshes that will interact with pedestrians or vehicles. The colliders prevent them from falling into the abyss. Right-click the selected meshes and select Asset Actions > Bulk Edit via Property Matrix... . 10. Search for collision in the search box. 11. Change Collision Complexity from Project Default to Use Complex Collision As Simple and close the window. 12. Confirm the collision setting has been applied correctly by pressing Alt + c . You will see a black web over the meshes. 13. To create the ground truth for the semantic segmentation sensor, move the static meshes to the corresponding Carla/Static/<segment> folder following the structure below: Content \u2514\u2500\u2500 Carla \u251c\u2500\u2500 Blueprints \u251c\u2500\u2500 Config \u251c\u2500\u2500 Exported Maps \u251c\u2500\u2500 HDMaps \u251c\u2500\u2500 Maps \u2514\u2500\u2500 Static \u251c\u2500\u2500 Terrain \u2502 \u2514\u2500\u2500 mapname \u2502 \u2514\u2500\u2500 Static Meshes \u2502 \u251c\u2500\u2500 Road \u2502 \u2514\u2500\u2500 mapname \u2502 \u2514\u2500\u2500 Static Meshes \u2502 \u251c\u2500\u2500 RoadLines | \u2514\u2500\u2500 mapname | \u2514\u2500\u2500 Static Meshes \u2514\u2500\u2500 Sidewalks \u2514\u2500\u2500 mapname \u2514\u2500\u2500 Static Meshes 14. In the Modes panel, search for the Open Drive Actor and drag it into the scene. 15. In the Details panel, check Add Spawners and then click on the box beside Generate Routes . This will find the .xodr file with the same map name in the <carla-root>/Unreal/CarlaUE4/Content/Carla/Maps/OpenDrive directory and use it to generate a series of RoutePlanner and VehicleSpawnPoint actors.","title":"Manual import"},{"location":"tuto_M_add_map_alternative/#next-steps","text":"You will now be able to open your map in the Unreal Editor and run simulations. From here, you will be able to customize the map and generate the pedestrian navigation data. We recommend generating the pedestrian navigation after all customization has finished, so there is no chance of obstacles blocking the pedestrian paths. CARLA provides several tools and guides to help with the customization of your maps: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . It is recommended to use the automated processes for importing maps detailed in the guides for CARLA packages and CARLA source build , however the methods listed in this section can be used if required. If you encounter any issues with the alternative methods, feel free to post in the forum .","title":"Next steps"},{"location":"tuto_M_add_map_package/","text":"Ingesting Maps in a CARLA package This section describes the process of ingesting maps into a package (binary) version of CARLA . If you are using a version of CARLA that has been built from source to ingest maps then follow the guidelines here instead. This process is only available for Linux systems. The import process involves running a Docker image of Unreal Engine to import the relevant files and then export them as a standalone package which can then be configured to be used in CARLA. The Docker image takes around 4h and 600-700 GB to be built. This is only needed the first time the image is built. Before you begin Map ingestion in a CARLA package Before you begin You will need to fulfill the following system requirements: 64-bit version of Docker in Ubuntu 16.04+ Minimum 8GB of RAM Minimum 700 GB available disk space for building container images Git version control Ensure you are using a package (binary) version of CARLA. If you are using a version of CARLA that has been built from source to ingest maps then follow the guidelines here instead. You should have at least two files, <mapName>.xodr and <mapName>.fbx that have been generated from a map editor such as RoadRunner. These files should have the same value for <mapName> in order to be recognised as the same map. Map ingestion in a CARLA package 1. CARLA provides all the utilities to build Unreal Engine in a Docker image and to compile CARLA using that image. The tools are found in the source code available in GitHub. Clone the repository using the following command: git clone https://github.com/carla-simulator/carla 2. Build the Docker image of Unreal Engine by following these instructions . 3. Create an input_folder . This is where you will put the files to be imported. Docker will automatically create a .json file describing the package folder structure. Change permissions on the input_folder for this to be created successfully: #Go to the parent folder, where the input folder is contained chmod 777 input_folder Note This is not necessary if the package is prepared manually , and contains a .json file already. 4. Create an output_folder . This is where the Docker image will write the output files after it has cooked the map. 5. Navigate to ~/carla/Util/Docker . This is where the ingestion script is located. The script requires the path for the input_folder and output_folder and the name of the package to be ingested. If a .json file is provided, the name of that file is the package name, if no .json is provided, the name must be map_package : python3 docker_tools.py --input ~/path_to_input_folder --output ~/path_to_output_folder --packages map_package Warning If the argument --packages map_package is not provided, the Docker image will make a package of CARLA. 6. The package will be generated in the output_folder as <map_package>.tar.gz . This is the standalone package that is now ready to be imported into CARLA. Move the package to the Import folder in the CARLA root directory (of the package/binary version where you will be using the map), and run the following script from the root directory to import it: ./ImportAssets.sh 7. To run a simulation with the new map, run CARLA and then change the map using the config.py file: cd PythonAPI/util python3 config.py --map <mapName> Your map is now ready to run simulations in CARLA. If you have any questions about the process then you can ask in the forum or you can try running some of our example scripts on your new map to test it out.","title":"\u5728CARLA\u5305\u5bfc\u5165\u5730\u56fe"},{"location":"tuto_M_add_map_package/#ingesting-maps-in-a-carla-package","text":"This section describes the process of ingesting maps into a package (binary) version of CARLA . If you are using a version of CARLA that has been built from source to ingest maps then follow the guidelines here instead. This process is only available for Linux systems. The import process involves running a Docker image of Unreal Engine to import the relevant files and then export them as a standalone package which can then be configured to be used in CARLA. The Docker image takes around 4h and 600-700 GB to be built. This is only needed the first time the image is built. Before you begin Map ingestion in a CARLA package","title":"Ingesting Maps in a CARLA package"},{"location":"tuto_M_add_map_package/#before-you-begin","text":"You will need to fulfill the following system requirements: 64-bit version of Docker in Ubuntu 16.04+ Minimum 8GB of RAM Minimum 700 GB available disk space for building container images Git version control Ensure you are using a package (binary) version of CARLA. If you are using a version of CARLA that has been built from source to ingest maps then follow the guidelines here instead. You should have at least two files, <mapName>.xodr and <mapName>.fbx that have been generated from a map editor such as RoadRunner. These files should have the same value for <mapName> in order to be recognised as the same map.","title":"Before you begin"},{"location":"tuto_M_add_map_package/#map-ingestion-in-a-carla-package","text":"1. CARLA provides all the utilities to build Unreal Engine in a Docker image and to compile CARLA using that image. The tools are found in the source code available in GitHub. Clone the repository using the following command: git clone https://github.com/carla-simulator/carla 2. Build the Docker image of Unreal Engine by following these instructions . 3. Create an input_folder . This is where you will put the files to be imported. Docker will automatically create a .json file describing the package folder structure. Change permissions on the input_folder for this to be created successfully: #Go to the parent folder, where the input folder is contained chmod 777 input_folder Note This is not necessary if the package is prepared manually , and contains a .json file already. 4. Create an output_folder . This is where the Docker image will write the output files after it has cooked the map. 5. Navigate to ~/carla/Util/Docker . This is where the ingestion script is located. The script requires the path for the input_folder and output_folder and the name of the package to be ingested. If a .json file is provided, the name of that file is the package name, if no .json is provided, the name must be map_package : python3 docker_tools.py --input ~/path_to_input_folder --output ~/path_to_output_folder --packages map_package Warning If the argument --packages map_package is not provided, the Docker image will make a package of CARLA. 6. The package will be generated in the output_folder as <map_package>.tar.gz . This is the standalone package that is now ready to be imported into CARLA. Move the package to the Import folder in the CARLA root directory (of the package/binary version where you will be using the map), and run the following script from the root directory to import it: ./ImportAssets.sh 7. To run a simulation with the new map, run CARLA and then change the map using the config.py file: cd PythonAPI/util python3 config.py --map <mapName> Your map is now ready to run simulations in CARLA. If you have any questions about the process then you can ask in the forum or you can try running some of our example scripts on your new map to test it out.","title":"Map ingestion in a CARLA package"},{"location":"tuto_M_add_map_source/","text":"Ingesting Maps in CARLA Built From Source This section describes the process of ingesting maps into CARLA that has been built from source . If you are using a package (binary) version of CARLA to ingest maps then follow the guidelines here instead. The ingestion process involves importing the relevant map files by compiling them into a package. This package can then be opened in the Unreal Engine editor and customized before generating the pedestrian navigation file and finally adding it to the package. Before you begin Map ingestion Next steps Before you begin Ensure you are using a version of CARLA that has been built from source. If you are using a packaged (binary) version of CARLA then follow the tutorial here . You should have at least two files, <mapName>.xodr and <mapName>.fbx that have been generated from a map editor such as RoadRunner. These files should have the same value for <mapName> in order to be recognised as the same map. You can ingest multiple maps into the same package. Each map should have a unique name. Map ingestion 1. Place the map files to be imported in the Import folder found in the CARLA root directory. 2. Run the command below to ingest the files: make import Note that there are two optional parameter flags that can be set : --package=<package_name> specifies the name of the package. By default, this is set to map_package . Two packages cannot have the same name, so using the default value will lead to errors on a subsequent ingestion. It is highly recommended to change the name of the package . Use this flag by running the command: make import ARGS=\"--package=<package_name>\" --no-carla-materials specifies that you do not want to use the default CARLA materials (road textures etc). You will use the RoadRunner materials instead. This flag is only required if you are not providing your own .json file . Any value in the .json file will override this flag. Use this flag by running the command: make import ARGS=\"--no-carla-materials\" A folder will be created in Unreal/CarlaUE4/Content with the name of your map package. It will contain config files, overdrive information, static asset information and navigation information. Next steps You will now be able to open your map in the Unreal Editor and run simulations. From here, you will be able to customize the map and generate the pedestrian navigation data. We recommend generating the pedestrian navigation after all customization has finished, so there is no chance of obstacles blocking the pedestrian paths. CARLA provides several tools and guides to help with the customization of your maps: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum .","title":"\u5728 CARLA \u6e90\u6784\u5efa\u4e2d\u5bfc\u5165\u5730\u56fe"},{"location":"tuto_M_add_map_source/#ingesting-maps-in-carla-built-from-source","text":"This section describes the process of ingesting maps into CARLA that has been built from source . If you are using a package (binary) version of CARLA to ingest maps then follow the guidelines here instead. The ingestion process involves importing the relevant map files by compiling them into a package. This package can then be opened in the Unreal Engine editor and customized before generating the pedestrian navigation file and finally adding it to the package. Before you begin Map ingestion Next steps","title":"Ingesting Maps in CARLA Built From Source"},{"location":"tuto_M_add_map_source/#before-you-begin","text":"Ensure you are using a version of CARLA that has been built from source. If you are using a packaged (binary) version of CARLA then follow the tutorial here . You should have at least two files, <mapName>.xodr and <mapName>.fbx that have been generated from a map editor such as RoadRunner. These files should have the same value for <mapName> in order to be recognised as the same map. You can ingest multiple maps into the same package. Each map should have a unique name.","title":"Before you begin"},{"location":"tuto_M_add_map_source/#map-ingestion","text":"1. Place the map files to be imported in the Import folder found in the CARLA root directory. 2. Run the command below to ingest the files: make import Note that there are two optional parameter flags that can be set : --package=<package_name> specifies the name of the package. By default, this is set to map_package . Two packages cannot have the same name, so using the default value will lead to errors on a subsequent ingestion. It is highly recommended to change the name of the package . Use this flag by running the command: make import ARGS=\"--package=<package_name>\" --no-carla-materials specifies that you do not want to use the default CARLA materials (road textures etc). You will use the RoadRunner materials instead. This flag is only required if you are not providing your own .json file . Any value in the .json file will override this flag. Use this flag by running the command: make import ARGS=\"--no-carla-materials\" A folder will be created in Unreal/CarlaUE4/Content with the name of your map package. It will contain config files, overdrive information, static asset information and navigation information.","title":"Map ingestion"},{"location":"tuto_M_add_map_source/#next-steps","text":"You will now be able to open your map in the Unreal Editor and run simulations. From here, you will be able to customize the map and generate the pedestrian navigation data. We recommend generating the pedestrian navigation after all customization has finished, so there is no chance of obstacles blocking the pedestrian paths. CARLA provides several tools and guides to help with the customization of your maps: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum .","title":"Next steps"},{"location":"tuto_M_custom_add_tl/","text":"Customizing maps: Traffic Lights and Signs This guide explains how to add traffic lights and signs to your custom map, configure the area of influence of each one, and how to configure traffic lights as a group at junctions. This option is only available to users who have access to the Unreal Engine editor. Traffic Lights Traffic signs Next steps Traffic lights To add traffic lights to your new map: 1. From the Content Browser , navigate to Content/Carla/Static/TrafficLight/StreetLights_01 . You will find several different traffic light blueprints to choose from. 2. Drag the traffic lights into the scene and position them in the desired location. Press the space bar on your keyboard to toggle between positioning, rotation, and scaling tools. 3. Adjust the trigger volume for each traffic light by selecting the BoxTrigger component in the Details panel and adjusting the values in the Transform section. This will determine the traffic light's area of influence. 4. For junctions, drag the BP_TrafficLightGroup actor into the level. Assign all the traffic lights in the junction to the traffic light group by adding them to the Traffic Lights array in the Details panel. 5. Traffic light timing is only configurable through the Python API. See the documentation here for more information. Example: Traffic Signs, Traffic lights and Turn based stop. Traffic signs To add traffic lights to your new map: 1. From the Content Browser , navigate to Content/Carla/Static/TrafficSign . You will find several different traffic light blueprints to choose from. 2. Drag the traffic lights into the scene and position them in the desired location. Press the space bar on your keyboard to toggle between positioning, rotation, and scaling tools. 3. Adjust the trigger volume for each traffic sign by selecting the BoxTrigger component in the Details panel and adjusting the values in the Transform section. This will determine the traffic light's area of influence. Not all traffic signs have a trigger volume. Those that do, include the yield, stop and speed limit signs. Next steps Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process then you can ask in the forum .","title":"\u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u7ea2\u7eff\u706f\u548c\u6807\u5fd7"},{"location":"tuto_M_custom_add_tl/#customizing-maps-traffic-lights-and-signs","text":"This guide explains how to add traffic lights and signs to your custom map, configure the area of influence of each one, and how to configure traffic lights as a group at junctions. This option is only available to users who have access to the Unreal Engine editor. Traffic Lights Traffic signs Next steps","title":"Customizing maps: Traffic Lights and Signs"},{"location":"tuto_M_custom_add_tl/#traffic-lights","text":"To add traffic lights to your new map: 1. From the Content Browser , navigate to Content/Carla/Static/TrafficLight/StreetLights_01 . You will find several different traffic light blueprints to choose from. 2. Drag the traffic lights into the scene and position them in the desired location. Press the space bar on your keyboard to toggle between positioning, rotation, and scaling tools. 3. Adjust the trigger volume for each traffic light by selecting the BoxTrigger component in the Details panel and adjusting the values in the Transform section. This will determine the traffic light's area of influence. 4. For junctions, drag the BP_TrafficLightGroup actor into the level. Assign all the traffic lights in the junction to the traffic light group by adding them to the Traffic Lights array in the Details panel. 5. Traffic light timing is only configurable through the Python API. See the documentation here for more information. Example: Traffic Signs, Traffic lights and Turn based stop.","title":"Traffic lights"},{"location":"tuto_M_custom_add_tl/#traffic-signs","text":"To add traffic lights to your new map: 1. From the Content Browser , navigate to Content/Carla/Static/TrafficSign . You will find several different traffic light blueprints to choose from. 2. Drag the traffic lights into the scene and position them in the desired location. Press the space bar on your keyboard to toggle between positioning, rotation, and scaling tools. 3. Adjust the trigger volume for each traffic sign by selecting the BoxTrigger component in the Details panel and adjusting the values in the Transform section. This will determine the traffic light's area of influence. Not all traffic signs have a trigger volume. Those that do, include the yield, stop and speed limit signs.","title":"Traffic signs"},{"location":"tuto_M_custom_add_tl/#next-steps","text":"Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process then you can ask in the forum .","title":"Next steps"},{"location":"tuto_M_custom_buildings/","text":"Customizing Maps: Procedural Buildings Procedural buildings Building structure Structure modifications Next steps Procedural buildings The procedural building tool allows you to create rectangular buildings composed of different levels. Each level is built using a configurable array of meshes or a single blueprint. If an array of meshes is used, each mesh will be repeated along the level at random to provide variety. The meshes are created once and each repition will be an instance of that mesh. This improves performance of your map. Building structure To get started on your building: In the Content Browser of the Unreal Engine editor, navigate to Content/Carla/Blueprints/LevelDesign . Drag the BP_Procedural_Building into the scene. In the Details panel, you will see all the options available to customize your building. Every time a change is made here, the building will disappear from the scene view, as the key meshes are updated. Click on Create Building to see the new result, or enable Create automatically to avoid having to repeat this step. The key meshes are pieces of the building's structure. They fall into four categories: Base: The ground floor. Body: The middle floors. Top: The highest floor. Roof: The roof that covers the top floor. For each of them, except the Roof , there is a mesh to fill the center of the floor, and a Corner mesh that will be placed on the sides of the floor. The following picture represents the global structure. Visualization of the building structure. The Base parameters set the dimensions. Num Floors: Floors of the building. Repetitions of the Body meshes. Length X and Length Y: Length and breadth of the building. Repetitions of the central meshes for each side of the building. Example of BP_Procedural_Building. Structure modifications There are some additional options to modify the general structure of the building. Disable corners: If selected, no corner meshes will be used. Use full blocks: If selected, the structure of the building will use only one mesh per floor. No corners nor repetitions will appear in each floor. Doors: Meshes that appear in the ground floor, right in front of the central meshes. The amount of doors and their location can be set. 0 is the initial position, 1 the next base repetition, and so on. Walls: Meshes that substitute one or more sides of the building. For example, a plane mesh can be used to paint one side of the building. On the left, a building with no cornes and one door. On the right, a building with a wall applied to one side of the building. The wall is a texture with no fire escape. Next steps Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add and configure traffic lights and signs. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u7a0b\u5e8f\u5efa\u7b51"},{"location":"tuto_M_custom_buildings/#customizing-maps-procedural-buildings","text":"Procedural buildings Building structure Structure modifications Next steps","title":"Customizing Maps: Procedural Buildings"},{"location":"tuto_M_custom_buildings/#procedural-buildings","text":"The procedural building tool allows you to create rectangular buildings composed of different levels. Each level is built using a configurable array of meshes or a single blueprint. If an array of meshes is used, each mesh will be repeated along the level at random to provide variety. The meshes are created once and each repition will be an instance of that mesh. This improves performance of your map.","title":"Procedural buildings"},{"location":"tuto_M_custom_buildings/#building-structure","text":"To get started on your building: In the Content Browser of the Unreal Engine editor, navigate to Content/Carla/Blueprints/LevelDesign . Drag the BP_Procedural_Building into the scene. In the Details panel, you will see all the options available to customize your building. Every time a change is made here, the building will disappear from the scene view, as the key meshes are updated. Click on Create Building to see the new result, or enable Create automatically to avoid having to repeat this step. The key meshes are pieces of the building's structure. They fall into four categories: Base: The ground floor. Body: The middle floors. Top: The highest floor. Roof: The roof that covers the top floor. For each of them, except the Roof , there is a mesh to fill the center of the floor, and a Corner mesh that will be placed on the sides of the floor. The following picture represents the global structure. Visualization of the building structure. The Base parameters set the dimensions. Num Floors: Floors of the building. Repetitions of the Body meshes. Length X and Length Y: Length and breadth of the building. Repetitions of the central meshes for each side of the building. Example of BP_Procedural_Building.","title":"Building structure"},{"location":"tuto_M_custom_buildings/#structure-modifications","text":"There are some additional options to modify the general structure of the building. Disable corners: If selected, no corner meshes will be used. Use full blocks: If selected, the structure of the building will use only one mesh per floor. No corners nor repetitions will appear in each floor. Doors: Meshes that appear in the ground floor, right in front of the central meshes. The amount of doors and their location can be set. 0 is the initial position, 1 the next base repetition, and so on. Walls: Meshes that substitute one or more sides of the building. For example, a plane mesh can be used to paint one side of the building. On the left, a building with no cornes and one door. On the right, a building with a wall applied to one side of the building. The wall is a texture with no fire escape.","title":"Structure modifications"},{"location":"tuto_M_custom_buildings/#next-steps","text":"Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add and configure traffic lights and signs. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Next steps"},{"location":"tuto_M_custom_layers/","text":"Customizing Maps: Layered Maps Utilizing levels in your custom map enables multiple people to work on a single map concurrently. It also allows you to use the Python API to load and unload layers on your map during a simulation, just like the layered CARLA maps . This guide will explain how to add a new level, how to add assets to a level, and how to configure a level to be always loaded or not. Add a new level Add assets to a level Configure level loading options Next steps Add a new level All new levels in your map will be nested within the parent level, known as the Persistent Level . To create a new level: 1. Open the levels panel. In the Unreal Engine editor, open Window from the menu bar. Click on Levels . 2. Create a new level. In the Levels panel, click on Levels and select Create New... . Choose Empty Level . Save the level in Content/Carla/Maps/Sublevels/<map_name>/ . To integrate the level with the CARLA Python API, use the naming convention <map_name>_<layer_name> , e.g., TutorialMap_Buildings . For a list of available layers, check here . Add assets to a level 1. Select the level to which you want to add assets . In the Levels panel, double-click the level to which you would like to add assets. Make sure the level is unlocked by toggling the lock icon. 2. Select the assets to add. Select all the assets you would like to add to the level. Right-click and go to Level . Click on Move Selection to Current Level . 3. Save the level. If a level has pending changes to save, you will see a pencil icon next to it in the Levels panel. Click this to save the changes. Configure level loading options Levels can be configured to be able to be toggled or to be always loaded. To configure the level for either option: Right-click the level in the Levels panel and go to Change Streaming Method . Choose the desired setting: Always Loaded : The level will not be able to be toggled via the Python API. Blueprint : The level will be able to be toggled via the Python API. A blue dot will appear beside the level name. Regardless of the setting, you will still be able to toggle the level in the editor by pressing the eye icon. Next steps Continue customizing your map using the tools and guides below: Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u5206\u5c42\u5730\u56fe: Layered maps"},{"location":"tuto_M_custom_layers/#customizing-maps-layered-maps","text":"Utilizing levels in your custom map enables multiple people to work on a single map concurrently. It also allows you to use the Python API to load and unload layers on your map during a simulation, just like the layered CARLA maps . This guide will explain how to add a new level, how to add assets to a level, and how to configure a level to be always loaded or not. Add a new level Add assets to a level Configure level loading options Next steps","title":"Customizing Maps: Layered Maps"},{"location":"tuto_M_custom_layers/#add-a-new-level","text":"All new levels in your map will be nested within the parent level, known as the Persistent Level . To create a new level: 1. Open the levels panel. In the Unreal Engine editor, open Window from the menu bar. Click on Levels . 2. Create a new level. In the Levels panel, click on Levels and select Create New... . Choose Empty Level . Save the level in Content/Carla/Maps/Sublevels/<map_name>/ . To integrate the level with the CARLA Python API, use the naming convention <map_name>_<layer_name> , e.g., TutorialMap_Buildings . For a list of available layers, check here .","title":"Add a new level"},{"location":"tuto_M_custom_layers/#add-assets-to-a-level","text":"1. Select the level to which you want to add assets . In the Levels panel, double-click the level to which you would like to add assets. Make sure the level is unlocked by toggling the lock icon. 2. Select the assets to add. Select all the assets you would like to add to the level. Right-click and go to Level . Click on Move Selection to Current Level . 3. Save the level. If a level has pending changes to save, you will see a pencil icon next to it in the Levels panel. Click this to save the changes.","title":"Add assets to a level"},{"location":"tuto_M_custom_layers/#configure-level-loading-options","text":"Levels can be configured to be able to be toggled or to be always loaded. To configure the level for either option: Right-click the level in the Levels panel and go to Change Streaming Method . Choose the desired setting: Always Loaded : The level will not be able to be toggled via the Python API. Blueprint : The level will be able to be toggled via the Python API. A blue dot will appear beside the level name. Regardless of the setting, you will still be able to toggle the level in the editor by pressing the eye icon.","title":"Configure level loading options"},{"location":"tuto_M_custom_layers/#next-steps","text":"Continue customizing your map using the tools and guides below: Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Next steps"},{"location":"tuto_M_custom_map_overview/","text":"Add a new map Users of CARLA can create custom maps and use them to run simulations. There are several ways to import custom maps in CARLA. The method to be used will depend on whether you are using a packaged version of CARLA or a version built from source. This section gives an overview of what you need to start the process, the different options available to import, and customization and pedestrian navigation tools available. Overview Generation Importation Customization Generate pedestrian navigation Overview Using custom maps in CARLA involves four main processes: Generation Importation Customization Pedestrian Navigation Read on further for additional general information on each process. Generation CARLA requires map geometry information in .fbx format and OpenDRIVE information in .xodr format. The current recommended software to generate these files is RoadRunner. This guide explains how to use RoadRunner to generate the map information. Importation There are several ways to import your map into CARLA. If you are using a package version of CARLA, you will import your map using Docker. This option is only available in Linux, and you will not have the ability to customize the map using the Unreal Editor. You will find the guide here . If you are using a source build version of CARLA, there are three methods available to import your map: Using the automatic make import process (recommended). You will find the guide here . Using the RoadRunner plugin. You will find the guide here . Manually importing the map into Unreal Engine. You will find the guide here . The following video explains some of the methods available to import maps into CARLA: Customization As well as hundreds of static meshes ready to be added to the landscape, CARLA provides several tools and guides to help you customize your map: Add sub-levels: Sub-levels will allow multiple people to work on the same map at the same time. They will also allow you to toggle layers of your map with the Python API, just like the CARLA layered maps. You will find the guide here . Set default weather: Experiment with different weather presets, and when you find the right combination, set the default weather for your map. You will find the guide here . Populate landscape: Use blueprints to populate the landscape with repeating meshes such as street lights, power lines, and walls. You will find the guide here . Paint the roads: Paint the roads with a master material that blends different textures. Add decals and meshes such as fallen leaves, cracks, or manholes. You will find the guide here . Add procedural buildings: Add buildings with a custom size, amount of floors, and variable mesh combinations using the procedural building blueprint. You will find the guide here . Add traffic lights and signs: Add traffic lights and signs and configure their area of influence. Group traffic lights at junctions. You will find the guide here . Generate pedestrian navigation For pedestrians to be spawned and navigate the map, you need to generate the pedestrian navigation information using the tool provided by CARLA. Pedestrian navigation should be generated after you complete the customization of your map so that obstacles are not created over the top of navigation paths. You can find the guide here . If you have any questions about the above process, feel free to post these in the forum . CARLA forum","title":"CARLA \u4e2d\u81ea\u5b9a\u4e49\u5730\u56fe\u7684\u6982\u8ff0"},{"location":"tuto_M_custom_map_overview/#add-a-new-map","text":"Users of CARLA can create custom maps and use them to run simulations. There are several ways to import custom maps in CARLA. The method to be used will depend on whether you are using a packaged version of CARLA or a version built from source. This section gives an overview of what you need to start the process, the different options available to import, and customization and pedestrian navigation tools available. Overview Generation Importation Customization Generate pedestrian navigation","title":"Add a new map"},{"location":"tuto_M_custom_map_overview/#overview","text":"Using custom maps in CARLA involves four main processes: Generation Importation Customization Pedestrian Navigation Read on further for additional general information on each process.","title":"Overview"},{"location":"tuto_M_custom_map_overview/#generation","text":"CARLA requires map geometry information in .fbx format and OpenDRIVE information in .xodr format. The current recommended software to generate these files is RoadRunner. This guide explains how to use RoadRunner to generate the map information.","title":"Generation"},{"location":"tuto_M_custom_map_overview/#importation","text":"There are several ways to import your map into CARLA. If you are using a package version of CARLA, you will import your map using Docker. This option is only available in Linux, and you will not have the ability to customize the map using the Unreal Editor. You will find the guide here . If you are using a source build version of CARLA, there are three methods available to import your map: Using the automatic make import process (recommended). You will find the guide here . Using the RoadRunner plugin. You will find the guide here . Manually importing the map into Unreal Engine. You will find the guide here . The following video explains some of the methods available to import maps into CARLA:","title":"Importation"},{"location":"tuto_M_custom_map_overview/#customization","text":"As well as hundreds of static meshes ready to be added to the landscape, CARLA provides several tools and guides to help you customize your map: Add sub-levels: Sub-levels will allow multiple people to work on the same map at the same time. They will also allow you to toggle layers of your map with the Python API, just like the CARLA layered maps. You will find the guide here . Set default weather: Experiment with different weather presets, and when you find the right combination, set the default weather for your map. You will find the guide here . Populate landscape: Use blueprints to populate the landscape with repeating meshes such as street lights, power lines, and walls. You will find the guide here . Paint the roads: Paint the roads with a master material that blends different textures. Add decals and meshes such as fallen leaves, cracks, or manholes. You will find the guide here . Add procedural buildings: Add buildings with a custom size, amount of floors, and variable mesh combinations using the procedural building blueprint. You will find the guide here . Add traffic lights and signs: Add traffic lights and signs and configure their area of influence. Group traffic lights at junctions. You will find the guide here .","title":"Customization"},{"location":"tuto_M_custom_map_overview/#generate-pedestrian-navigation","text":"For pedestrians to be spawned and navigate the map, you need to generate the pedestrian navigation information using the tool provided by CARLA. Pedestrian navigation should be generated after you complete the customization of your map so that obstacles are not created over the top of navigation paths. You can find the guide here . If you have any questions about the above process, feel free to post these in the forum . CARLA forum","title":"Generate pedestrian navigation"},{"location":"tuto_M_custom_road_painter/","text":"Customizing Maps: Road Painter This guide explains what the road painter tool is, how to use it to customize the appearance of the road by combining different textures, how to add decals and meshes and how to update the appearance of lane markings according to the road texture. What is the road painter? Before you begin Establish the road painter, master material and render target Prepare the master material Paint the road Update the appearance of lane markings Next steps What is the road painter? The Road Painter tool is a blueprint that uses OpenDRIVE information to paint roads quickly. It takes a master material and applies it to a render target of the road to use as a canvas. The master material is made up of a collection of materials that can be blended using brushes and applied as masks. There is no need to apply photometry techniques nor consider the UVs of the geometry. Before you begin The road painter uses the OpenDRIVE information to paint the roads. Make sure that your .xodr file has the same name as your map for this to work correctly. Establish the road painter, master material and render target 1. Create the RoadPainter actor. In the Content Browser , navigate to Content/Carla/Blueprints/LevelDesign . Drag the RoadPainter into the scene. 2. Create the Render Target. In the Content Browser , navigate to Content/Carla/Blueprints/LevelDesign/RoadPainterAssets . Right-click on the RenderTarget file and select Duplicate . Rename to Tutorial_RenderTarget . 3. Create the master material instance. In the Content Browser , navigate to Game/Carla/Static/GenericMaterials/RoadPainterMaterials . Right-click on M_RoadMaster and select Create Material Instance . Rename to Tutorial_RoadMaster . 4. Re-calibrate the Map Size (Cm) so that it is equal to the actual size of the map. Select the RoadPainter actor in the scene. Go to the Details panel and press the Z-Size button. You will see the value in Map Size (Cm) change. 5. Synchronize the map size between the RoadPainter and Tutorial_RoadMaster . In the Content Browser , open Tutorial_RoadMaster . Copy the value Map Size (Cm) from the previous step and paste it to Global Scalar Parameter Values -> Map units (CM) in the Tutorial_RoadMaster window. Press save. 6. Create the communication link between the road painter and the master material. The Tutorial_RenderTarget will be the communication link between the road painter and Tutorial_RoadMaster . In the Tutorial_RoadMaster window, apply the Tutorial_RenderTarget to Global Texture Parameter Values -> Texture Mask . Save and close. In the main editor window, select the road painter actor, go to the Details panel and apply the Tutorial_RenderTarget to Paint -> Render Target . Prepare the master material The Tutorial_RoadMaster material you created holds the base material, extra material information, and parameters that will be applied via your Tutorial_RenderTarget . You can configure one base material and up to three additional materials. To configure the materials, double-click the Tutorial_RoadMaster file. In the window that appears, you can select and adjust the following values for each material according to your needs: Brightness Hue Saturation AO Intensity NormalMap Intensity Roughness Contrast Roughness Intensity You can change the textures for each material by selecting the following values and searching for a texture in the search box: Diffuse Normal ORMH Explore some of the CARLA textures available in Game/Carla/Static/GenericMaterials/Asphalt/Textures . Paint the road 1. Create the link between the road painter and the roads. In the main editor window, search for Road_Road in the World Outliner search box. Press Ctrl + A to select all the roads. In the Details panel, go to the Materials section and apply Tutorial_RoadMaster to Element 0 , Element 1 , Element 2 , and Element 3 . 2. Choose the material to customize. Each of the materials we added to Tutorial_RoadMaster are applied to the roads separately and application is configured with the Brush tool. To apply and customize a material: Select the road painter actor In the Details panel, select the material to work with in the Mask Color dropdown menu. 3. Set the brush and stencil parameters. There are a variety of stencils to choose from in GenericMaterials/RoadStencil/Alphas . The stencil is used to paint the road according to your needs and can be adjusted using the following values: Stencil size \u2014 Size of the brush. Brush strength \u2014 Roughness of the outline. Spacebeween Brushes \u2014 Distance between strokes. Max Jitter \u2014 Size variation of the brush between strokes. Stencil \u2014 The brush to use. Rotation \u2014 Rotation applied to the stroke. Brush panel. Different types of brushes. 4. Apply each material to the desired portions of the road. Choose where to apply the selected material via the buttons in the Default section of the Details panel: Paint all roads \u2014 Paint all the roads. Paint by actor \u2014 Paint a specific, selected actor. Paint over circle \u2014 Paint using a circular pattern, useful to provide variation. Paint over square \u2014 Paint using a square pattern, useful to provide variation. This section also contains options to erase the applied changes. Clear all \u2014 Erase all the painted material. Clear materials \u2014 Remove the currently active materials. Clear material by actor \u2014 Remove the material closest to the selected actor. Different painting and erasing options. 5. Add decals and meshes. You can explore the available decals and meshes in Content/Carla/Static/Decals and Content/Carla/Static . Add them to road painter by extending and adding to the Decals Spawn and Meshes Spawn arrays. For each one you can configure the following parameters: Number of Decals/Meshes - The amount of each decal or mesh to paint. Decal/Mesh Scale \u2014 Scale of the decal/mesh per axis. Fixed Decal/Mesh Offset \u2014 Deviation from the center of the lane per axis. Random Offset \u2014 Max deviation from the center of the lane per axis. Decal/Mesh Random Yaw \u2014 Max random yaw rotation. Decal/Mesh Min Scale \u2014 Minimum random scale applied to the decal/mesh. Decal/Mesh Max Scale \u2014 Max random scale applied to the decal/mesh. Decals and Meshes panels. Once you have configured your meshes and decals, spawn them by pressing Spawn decals and Spawn meshes . Note Make sure that meshes and decals do not have collisions enabled that can interfere with cars on the road and lower any bounding boxes to the level of the road. 7. Experiment to get your desired appearance. Experiment with different materials, textures, settings, decals, and meshes to get your desired look. Below are some example images of how the appearance of the road changes during the process of painting each material. Example of base road material. Example after material 1 is applied. Example after material 2 is applied. Example after material 3 is applied. Example after decals are applied. Example after meshes are applied. Update the appearance of lane markings After you have painted the roads, you can update the appearance of the road markings by following these steps: 1. Make a copy of the master material. In the Content Browser , navigate to Game/Carla/Static/GenericMaterials/RoadPainterMaterials . Right-click on Tutorial_RoadMaster and select Create Material Instance . Rename to Tutorial_LaneMarkings . 2. Configure the lane marking material. In the Content Browser , double-click on Tutorial_LaneMarkings . In the Details panel, go to the Global Static Switch Parameter Values section and check the boxes on the left and right of LaneMark . Go to the Texture section and check the boxes for LaneColor and Uv Size . Choose your preferred color for the lane markings in LaneColor . Save and close. 3. Select the road marking meshes. Drag the material onto the lane markings you wish to color. Repeat the whole process for different colors of lane markings if required. Next steps Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u81ea\u5b9a\u4e49\u5730\u56fe\uff1aRoad painter"},{"location":"tuto_M_custom_road_painter/#customizing-maps-road-painter","text":"This guide explains what the road painter tool is, how to use it to customize the appearance of the road by combining different textures, how to add decals and meshes and how to update the appearance of lane markings according to the road texture. What is the road painter? Before you begin Establish the road painter, master material and render target Prepare the master material Paint the road Update the appearance of lane markings Next steps","title":"Customizing Maps: Road Painter"},{"location":"tuto_M_custom_road_painter/#what-is-the-road-painter","text":"The Road Painter tool is a blueprint that uses OpenDRIVE information to paint roads quickly. It takes a master material and applies it to a render target of the road to use as a canvas. The master material is made up of a collection of materials that can be blended using brushes and applied as masks. There is no need to apply photometry techniques nor consider the UVs of the geometry.","title":"What is the road painter?"},{"location":"tuto_M_custom_road_painter/#before-you-begin","text":"The road painter uses the OpenDRIVE information to paint the roads. Make sure that your .xodr file has the same name as your map for this to work correctly.","title":"Before you begin"},{"location":"tuto_M_custom_road_painter/#establish-the-road-painter-master-material-and-render-target","text":"1. Create the RoadPainter actor. In the Content Browser , navigate to Content/Carla/Blueprints/LevelDesign . Drag the RoadPainter into the scene. 2. Create the Render Target. In the Content Browser , navigate to Content/Carla/Blueprints/LevelDesign/RoadPainterAssets . Right-click on the RenderTarget file and select Duplicate . Rename to Tutorial_RenderTarget . 3. Create the master material instance. In the Content Browser , navigate to Game/Carla/Static/GenericMaterials/RoadPainterMaterials . Right-click on M_RoadMaster and select Create Material Instance . Rename to Tutorial_RoadMaster . 4. Re-calibrate the Map Size (Cm) so that it is equal to the actual size of the map. Select the RoadPainter actor in the scene. Go to the Details panel and press the Z-Size button. You will see the value in Map Size (Cm) change. 5. Synchronize the map size between the RoadPainter and Tutorial_RoadMaster . In the Content Browser , open Tutorial_RoadMaster . Copy the value Map Size (Cm) from the previous step and paste it to Global Scalar Parameter Values -> Map units (CM) in the Tutorial_RoadMaster window. Press save. 6. Create the communication link between the road painter and the master material. The Tutorial_RenderTarget will be the communication link between the road painter and Tutorial_RoadMaster . In the Tutorial_RoadMaster window, apply the Tutorial_RenderTarget to Global Texture Parameter Values -> Texture Mask . Save and close. In the main editor window, select the road painter actor, go to the Details panel and apply the Tutorial_RenderTarget to Paint -> Render Target .","title":"Establish the road painter, master material and render target"},{"location":"tuto_M_custom_road_painter/#prepare-the-master-material","text":"The Tutorial_RoadMaster material you created holds the base material, extra material information, and parameters that will be applied via your Tutorial_RenderTarget . You can configure one base material and up to three additional materials. To configure the materials, double-click the Tutorial_RoadMaster file. In the window that appears, you can select and adjust the following values for each material according to your needs: Brightness Hue Saturation AO Intensity NormalMap Intensity Roughness Contrast Roughness Intensity You can change the textures for each material by selecting the following values and searching for a texture in the search box: Diffuse Normal ORMH Explore some of the CARLA textures available in Game/Carla/Static/GenericMaterials/Asphalt/Textures .","title":"Prepare the master material"},{"location":"tuto_M_custom_road_painter/#paint-the-road","text":"1. Create the link between the road painter and the roads. In the main editor window, search for Road_Road in the World Outliner search box. Press Ctrl + A to select all the roads. In the Details panel, go to the Materials section and apply Tutorial_RoadMaster to Element 0 , Element 1 , Element 2 , and Element 3 . 2. Choose the material to customize. Each of the materials we added to Tutorial_RoadMaster are applied to the roads separately and application is configured with the Brush tool. To apply and customize a material: Select the road painter actor In the Details panel, select the material to work with in the Mask Color dropdown menu. 3. Set the brush and stencil parameters. There are a variety of stencils to choose from in GenericMaterials/RoadStencil/Alphas . The stencil is used to paint the road according to your needs and can be adjusted using the following values: Stencil size \u2014 Size of the brush. Brush strength \u2014 Roughness of the outline. Spacebeween Brushes \u2014 Distance between strokes. Max Jitter \u2014 Size variation of the brush between strokes. Stencil \u2014 The brush to use. Rotation \u2014 Rotation applied to the stroke. Brush panel. Different types of brushes. 4. Apply each material to the desired portions of the road. Choose where to apply the selected material via the buttons in the Default section of the Details panel: Paint all roads \u2014 Paint all the roads. Paint by actor \u2014 Paint a specific, selected actor. Paint over circle \u2014 Paint using a circular pattern, useful to provide variation. Paint over square \u2014 Paint using a square pattern, useful to provide variation. This section also contains options to erase the applied changes. Clear all \u2014 Erase all the painted material. Clear materials \u2014 Remove the currently active materials. Clear material by actor \u2014 Remove the material closest to the selected actor. Different painting and erasing options. 5. Add decals and meshes. You can explore the available decals and meshes in Content/Carla/Static/Decals and Content/Carla/Static . Add them to road painter by extending and adding to the Decals Spawn and Meshes Spawn arrays. For each one you can configure the following parameters: Number of Decals/Meshes - The amount of each decal or mesh to paint. Decal/Mesh Scale \u2014 Scale of the decal/mesh per axis. Fixed Decal/Mesh Offset \u2014 Deviation from the center of the lane per axis. Random Offset \u2014 Max deviation from the center of the lane per axis. Decal/Mesh Random Yaw \u2014 Max random yaw rotation. Decal/Mesh Min Scale \u2014 Minimum random scale applied to the decal/mesh. Decal/Mesh Max Scale \u2014 Max random scale applied to the decal/mesh. Decals and Meshes panels. Once you have configured your meshes and decals, spawn them by pressing Spawn decals and Spawn meshes . Note Make sure that meshes and decals do not have collisions enabled that can interfere with cars on the road and lower any bounding boxes to the level of the road. 7. Experiment to get your desired appearance. Experiment with different materials, textures, settings, decals, and meshes to get your desired look. Below are some example images of how the appearance of the road changes during the process of painting each material. Example of base road material. Example after material 1 is applied. Example after material 2 is applied. Example after material 3 is applied. Example after decals are applied. Example after meshes are applied.","title":"Paint the road"},{"location":"tuto_M_custom_road_painter/#update-the-appearance-of-lane-markings","text":"After you have painted the roads, you can update the appearance of the road markings by following these steps: 1. Make a copy of the master material. In the Content Browser , navigate to Game/Carla/Static/GenericMaterials/RoadPainterMaterials . Right-click on Tutorial_RoadMaster and select Create Material Instance . Rename to Tutorial_LaneMarkings . 2. Configure the lane marking material. In the Content Browser , double-click on Tutorial_LaneMarkings . In the Details panel, go to the Global Static Switch Parameter Values section and check the boxes on the left and right of LaneMark . Go to the Texture section and check the boxes for LaneColor and Uv Size . Choose your preferred color for the lane markings in LaneColor . Save and close. 3. Select the road marking meshes. Drag the material onto the lane markings you wish to color. Repeat the whole process for different colors of lane markings if required.","title":"Update the appearance of lane markings"},{"location":"tuto_M_custom_road_painter/#next-steps","text":"Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the weather Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Next steps"},{"location":"tuto_M_custom_weather_landscape/","text":"Customizing maps: Weather and Landscape CARLA provides several blueprints to help ease the creation of default weather settings for your maps and to populate the lanscape with serial meshes such as street lights, power lines, etc. This guide will explain where each one of these blueprints are located and how to use and configure them. Weather customization BP_Sky BP_Weather Serial meshes BP_RepSpline BP_Spline BP_Wall BP_SplinePoweLine Next steps Important This tutorial only applies to users that work with a build from source, and have access to the Unreal Editor. Weather customization This section explains how to experiment with different weather parameters before setting your map's default weather, and once you are happy with the settings, how to configure the default weather parameters for your map. BP_Sky The BP_Sky blueprint is neccessary to bring light and weather to your map. It can also be used to test different weather configurations before deciding on your default weather parameters. It is likely the BP_Sky blueprint will already be loaded in your map. If not you can add it by dragging it into the scene from Content/Carla/Blueprints/Weather . To try out different weather parameters, go to the Details panel of the BP_Sky actor, and play with the values in the Parameters section. Important If more than one BP_Sky blueprint is loaded into the scene, the weather will be duplicated with undesirable results, e.g, having two suns. BP_Weather The default weather for your map is defined in the BP_Weather blueprint. This blueprint allows you to set the same parameters as are available through the Python API. These parameters are described here . To set the default weather for your map: 1. Open the BP_Weather blueprint. In the Content Browser , navigate to Content/Carla/Blueprints/Weather and double-click on BP_Weather . 2. Add your town. In the Details panel of the BP_Weather window, go to the Weather section and add your town to the Default Weathers array. 3. Configure your default weather parameters. For each weather parameter, set your desired value. When you are finished, press Compile then Save and close. Array containing default weather parameters for every CARLA map. Town01 opened. Add serial meshes There are four blueprints available to add props aligned in one direction, e.g., walls, powerlines, street lights. These blueprints use a series of meshes distributed along a Bezier curve. Each one is initialized in the same way: 1. Initialize the series. Drag the blueprint into the scene. You will see one element standing at the starting point of a Bezier curve with two nodes marking the beginning and ending. 2. Define the path. Select the direction arrow of the element and press Alt while dragging the element in the direction you want to go. This will create a new element which can be used to define the curve. As you drag, a new mesh will appear either on every node of the curve or every time you press Alt while dragging, depending on the blueprint. 3. Customize the pattern. The following sections will describe the different customization parameters available to each blueprint. BP_RepSpline The BP_RepSpline blueprint is found in Carla/Blueprints/LevelDesign . It is used to add individual elements along a path defined by a Bezier curve. The serialization is customized via the following values: Distance between \u2014 Set the distance between elements. Offset rotation \u2014 Set a fixed rotation for the different axis. Random rotation \u2014 Set a range of random rotations for the different axis. Offset translation \u2014 Set a range of random locations along the different axis. Max Number of Meshes \u2014 Set the maximum amount of elements that will be place between nodes of the curve. World aligned ZY \u2014 If selected, the elements will be vertically aligned regarding the world axis. EndPoint \u2014 If selected, an element will be added at the end node of the curve. Collision enabled \u2014 Set the type of collisions enabled for the meshes. BP_RepSpline example. BP_Spline The BP_Spline blueprint is found in Carla/Blueprints/LevelDesign . It adds connected elements that strictly follow a path defined by a Bezier curve. The mesh will be warped to fit the path created. The blueprint can be customized using the following value: Gap distance \u2014 Add a separation between elements. BP_Spline example. BP_Wall The BP_Wall blueprint is found in Carla/Blueprints/LevelDesign . It adds connected elements along a path defined by a Bezier curve. The mesh will not be warped to fit the curve, but the nodes will be respected. Distance between \u2014 Set the distance between elements. Vertically aligned \u2014 If selected, the elements will be vertically aligned regarding the world axis. Scale offset \u2014 Scale the length of the mesh to round out the connection between elements. BP_Wall example. BP_SplinePoweLine The BP_SplinePoweLine blueprint is found in Carla/Static/Pole/PoweLine . It adds electricity poles along a path defined by a Bezier curve and connects them with power lines . To provide variety, you can provide the blueprint with an array of powerline meshes to populate the path. To do this: Double-click the BP_SplinePoweLine blueprint in the Content Browser . In the Details panel, go to the Default section. Expand the Array Meshes and add to or change it according to your needs. Press Compile , then save and close the window. BP_SplinePowerLine example. To alter the line tension of the power lines: Select the blueprint actor in the editor scene and go to the Details panel. Go to the Default section. Adjust the value in Tension . 0 indicates that the lines will be straight. To increase the amount of wires: In the Content Browser , double-click on one of the pole meshes. Go to the Socket Manager panel. Configure existing sockets or add new ones by clicking Create Socket . Sockets are empty meshes that represent the connection points of the power line. A wire is created form socket to socket between poles. Visualization of the sockets for BP_SplinePowerLine. Important The amount of sockets and their names should be consistent between poles. Otherwise, visualization issues may arise. Next steps Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u81ea\u5b9a\u4e49\u5730\u56fe\uff1a\u5929\u6c14\u548c\u666f\u89c2"},{"location":"tuto_M_custom_weather_landscape/#customizing-maps-weather-and-landscape","text":"CARLA provides several blueprints to help ease the creation of default weather settings for your maps and to populate the lanscape with serial meshes such as street lights, power lines, etc. This guide will explain where each one of these blueprints are located and how to use and configure them. Weather customization BP_Sky BP_Weather Serial meshes BP_RepSpline BP_Spline BP_Wall BP_SplinePoweLine Next steps Important This tutorial only applies to users that work with a build from source, and have access to the Unreal Editor.","title":"Customizing maps: Weather and Landscape"},{"location":"tuto_M_custom_weather_landscape/#weather-customization","text":"This section explains how to experiment with different weather parameters before setting your map's default weather, and once you are happy with the settings, how to configure the default weather parameters for your map.","title":"Weather customization"},{"location":"tuto_M_custom_weather_landscape/#bp_sky","text":"The BP_Sky blueprint is neccessary to bring light and weather to your map. It can also be used to test different weather configurations before deciding on your default weather parameters. It is likely the BP_Sky blueprint will already be loaded in your map. If not you can add it by dragging it into the scene from Content/Carla/Blueprints/Weather . To try out different weather parameters, go to the Details panel of the BP_Sky actor, and play with the values in the Parameters section. Important If more than one BP_Sky blueprint is loaded into the scene, the weather will be duplicated with undesirable results, e.g, having two suns.","title":"BP_Sky"},{"location":"tuto_M_custom_weather_landscape/#bp_weather","text":"The default weather for your map is defined in the BP_Weather blueprint. This blueprint allows you to set the same parameters as are available through the Python API. These parameters are described here . To set the default weather for your map: 1. Open the BP_Weather blueprint. In the Content Browser , navigate to Content/Carla/Blueprints/Weather and double-click on BP_Weather . 2. Add your town. In the Details panel of the BP_Weather window, go to the Weather section and add your town to the Default Weathers array. 3. Configure your default weather parameters. For each weather parameter, set your desired value. When you are finished, press Compile then Save and close. Array containing default weather parameters for every CARLA map. Town01 opened.","title":"BP_Weather"},{"location":"tuto_M_custom_weather_landscape/#add-serial-meshes","text":"There are four blueprints available to add props aligned in one direction, e.g., walls, powerlines, street lights. These blueprints use a series of meshes distributed along a Bezier curve. Each one is initialized in the same way: 1. Initialize the series. Drag the blueprint into the scene. You will see one element standing at the starting point of a Bezier curve with two nodes marking the beginning and ending. 2. Define the path. Select the direction arrow of the element and press Alt while dragging the element in the direction you want to go. This will create a new element which can be used to define the curve. As you drag, a new mesh will appear either on every node of the curve or every time you press Alt while dragging, depending on the blueprint. 3. Customize the pattern. The following sections will describe the different customization parameters available to each blueprint.","title":"Add serial meshes"},{"location":"tuto_M_custom_weather_landscape/#bp_repspline","text":"The BP_RepSpline blueprint is found in Carla/Blueprints/LevelDesign . It is used to add individual elements along a path defined by a Bezier curve. The serialization is customized via the following values: Distance between \u2014 Set the distance between elements. Offset rotation \u2014 Set a fixed rotation for the different axis. Random rotation \u2014 Set a range of random rotations for the different axis. Offset translation \u2014 Set a range of random locations along the different axis. Max Number of Meshes \u2014 Set the maximum amount of elements that will be place between nodes of the curve. World aligned ZY \u2014 If selected, the elements will be vertically aligned regarding the world axis. EndPoint \u2014 If selected, an element will be added at the end node of the curve. Collision enabled \u2014 Set the type of collisions enabled for the meshes. BP_RepSpline example.","title":"BP_RepSpline"},{"location":"tuto_M_custom_weather_landscape/#bp_spline","text":"The BP_Spline blueprint is found in Carla/Blueprints/LevelDesign . It adds connected elements that strictly follow a path defined by a Bezier curve. The mesh will be warped to fit the path created. The blueprint can be customized using the following value: Gap distance \u2014 Add a separation between elements. BP_Spline example.","title":"BP_Spline"},{"location":"tuto_M_custom_weather_landscape/#bp_wall","text":"The BP_Wall blueprint is found in Carla/Blueprints/LevelDesign . It adds connected elements along a path defined by a Bezier curve. The mesh will not be warped to fit the curve, but the nodes will be respected. Distance between \u2014 Set the distance between elements. Vertically aligned \u2014 If selected, the elements will be vertically aligned regarding the world axis. Scale offset \u2014 Scale the length of the mesh to round out the connection between elements. BP_Wall example.","title":"BP_Wall"},{"location":"tuto_M_custom_weather_landscape/#bp_splinepoweline","text":"The BP_SplinePoweLine blueprint is found in Carla/Static/Pole/PoweLine . It adds electricity poles along a path defined by a Bezier curve and connects them with power lines . To provide variety, you can provide the blueprint with an array of powerline meshes to populate the path. To do this: Double-click the BP_SplinePoweLine blueprint in the Content Browser . In the Details panel, go to the Default section. Expand the Array Meshes and add to or change it according to your needs. Press Compile , then save and close the window. BP_SplinePowerLine example. To alter the line tension of the power lines: Select the blueprint actor in the editor scene and go to the Details panel. Go to the Default section. Adjust the value in Tension . 0 indicates that the lines will be straight. To increase the amount of wires: In the Content Browser , double-click on one of the pole meshes. Go to the Socket Manager panel. Configure existing sockets or add new ones by clicking Create Socket . Sockets are empty meshes that represent the connection points of the power line. A wire is created form socket to socket between poles. Visualization of the sockets for BP_SplinePowerLine. Important The amount of sockets and their names should be consistent between poles. Otherwise, visualization issues may arise.","title":"BP_SplinePoweLine"},{"location":"tuto_M_custom_weather_landscape/#next-steps","text":"Continue customizing your map using the tools and guides below: Implement sub-levels in your map. Add and configure traffic lights and signs. Add buildings with the procedural building tool. Customize the road with the road painter tool. Customize the landscape with serial meshes. Once you have finished with the customization, you can generate the pedestrian navigation information . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Next steps"},{"location":"tuto_M_generate_map/","text":"Generating Maps in RoadRunner RoadRunner is the recommended software to create maps to be imported into CARLA. This guide outlines what RoadRunner is, things to consider when building the map and how to export custom maps ready for importing into CARLA. Introduction to RoadRunner Before you start Build a map in RoadRunner Export a map in RoadRunner Next steps Introduction to RoadRunner RoadRunner is an interactive editor that lets you design 3D scenes for simulating and testing automated driving systems. It can be used to create road layouts and accompanying OpenDRIVE and geometry information. Find out more about RoadRunner here . RoadRunner is part of the MATLAB Campus-Wide Licenses, so many universities can provide unlimited academic access. Check if your university has access. Reach out to automated-driving@mathworks.com for any questions or troubles regarding accessibility. There is also a trial version available. A license for RoadRunner is also available to everyone participating in the CARLA Leaderboard. Click here for more information. Before you start You will need to install RoadRunner. You can follow the installation guide at the Mathworks website. Build a map in RoadRunner The specifics of how to build a map in RoadRunner go beyond the scope of this guide, however, there are video tutorials available in the RoadRunner documentation . Keep in mind that a map heavy with props can slow the import process significantly. This is because Unreal Engine needs to convert every mesh to an Unreal asset. If you plan to import your map into a source build version of CARLA, we highly recommend that you only create the road layout in RoadRunner and leave any customization until after the map has been imported into Unreal Engine. CARLA provides several tools that you can use in the Unreal Engine editor to simplify the customization process. Export a map in RoadRunner Below is a basic guideline to export your custom map from RoadRunner. You can find more detailed information about how to export to CARLA in MathWorks' documentation . Once you have made your map in RoadRunner you will be able to export it. Be aware that the road layout cannot be modified after it has been exported. Before exporting, ensure that: The map is centered at (0,0) to ensure the map can be visualized correctly in Unreal Engine. The map definition is correct. The map validation is correct, paying close attention to connections and geometries. Once the map is ready, click on the OpenDRIVE Preview Tool button to visualize the OpenDRIVE road network and give everything one last check. Note OpenDrive Preview Tool makes it easier to test the integrity of the map. If there are any errors with junctions, click on Maneuver Tool , and Rebuild Maneuver Roads . When you are ready to export: 1. Export the scene using the CARLA option: In the main toolbar, select File -> Export -> CARLA (.fbx, .xodr, .rrdata.xml) 2. In the window that pops up: Check the following options: Split by Segmentation : Divides the mesh by semantic segmentation. Power of Two Texture Dimensions : Improves performance. Embed Textures : Ensures textures are embedded in the mesh. Export to Tiles : Choose the size of the tile or leave unchecked for only one piece. Leave unchecked: Export Individual Tiles : Generates one .fbx file with all map pieces. 3. Choose the directory where you want to export your files and click Export . This will generate <mapName>.fbx and <mapName>.xodr files among others. Warning Make sure that the .xodr and the .fbx files have the same name. Next steps You are now ready to import your map into CARLA. The next step will depend upon the kind of CARLA installation you are using: For users of CARLA built from source , follow the guide here . For users of a packaged (binary) version of CARLA , follow the guide here . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u5728 RoadRunner \u4e2d\u521b\u5efa\u5730\u56fe"},{"location":"tuto_M_generate_map/#generating-maps-in-roadrunner","text":"RoadRunner is the recommended software to create maps to be imported into CARLA. This guide outlines what RoadRunner is, things to consider when building the map and how to export custom maps ready for importing into CARLA. Introduction to RoadRunner Before you start Build a map in RoadRunner Export a map in RoadRunner Next steps","title":"Generating Maps in RoadRunner"},{"location":"tuto_M_generate_map/#introduction-to-roadrunner","text":"RoadRunner is an interactive editor that lets you design 3D scenes for simulating and testing automated driving systems. It can be used to create road layouts and accompanying OpenDRIVE and geometry information. Find out more about RoadRunner here . RoadRunner is part of the MATLAB Campus-Wide Licenses, so many universities can provide unlimited academic access. Check if your university has access. Reach out to automated-driving@mathworks.com for any questions or troubles regarding accessibility. There is also a trial version available. A license for RoadRunner is also available to everyone participating in the CARLA Leaderboard. Click here for more information.","title":"Introduction to RoadRunner"},{"location":"tuto_M_generate_map/#before-you-start","text":"You will need to install RoadRunner. You can follow the installation guide at the Mathworks website.","title":"Before you start"},{"location":"tuto_M_generate_map/#build-a-map-in-roadrunner","text":"The specifics of how to build a map in RoadRunner go beyond the scope of this guide, however, there are video tutorials available in the RoadRunner documentation . Keep in mind that a map heavy with props can slow the import process significantly. This is because Unreal Engine needs to convert every mesh to an Unreal asset. If you plan to import your map into a source build version of CARLA, we highly recommend that you only create the road layout in RoadRunner and leave any customization until after the map has been imported into Unreal Engine. CARLA provides several tools that you can use in the Unreal Engine editor to simplify the customization process.","title":"Build a map in RoadRunner"},{"location":"tuto_M_generate_map/#export-a-map-in-roadrunner","text":"Below is a basic guideline to export your custom map from RoadRunner. You can find more detailed information about how to export to CARLA in MathWorks' documentation . Once you have made your map in RoadRunner you will be able to export it. Be aware that the road layout cannot be modified after it has been exported. Before exporting, ensure that: The map is centered at (0,0) to ensure the map can be visualized correctly in Unreal Engine. The map definition is correct. The map validation is correct, paying close attention to connections and geometries. Once the map is ready, click on the OpenDRIVE Preview Tool button to visualize the OpenDRIVE road network and give everything one last check. Note OpenDrive Preview Tool makes it easier to test the integrity of the map. If there are any errors with junctions, click on Maneuver Tool , and Rebuild Maneuver Roads . When you are ready to export: 1. Export the scene using the CARLA option: In the main toolbar, select File -> Export -> CARLA (.fbx, .xodr, .rrdata.xml) 2. In the window that pops up: Check the following options: Split by Segmentation : Divides the mesh by semantic segmentation. Power of Two Texture Dimensions : Improves performance. Embed Textures : Ensures textures are embedded in the mesh. Export to Tiles : Choose the size of the tile or leave unchecked for only one piece. Leave unchecked: Export Individual Tiles : Generates one .fbx file with all map pieces. 3. Choose the directory where you want to export your files and click Export . This will generate <mapName>.fbx and <mapName>.xodr files among others. Warning Make sure that the .xodr and the .fbx files have the same name.","title":"Export a map in RoadRunner"},{"location":"tuto_M_generate_map/#next-steps","text":"You are now ready to import your map into CARLA. The next step will depend upon the kind of CARLA installation you are using: For users of CARLA built from source , follow the guide here . For users of a packaged (binary) version of CARLA , follow the guide here . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Next steps"},{"location":"tuto_M_generate_pedestrian_navigation/","text":"Generate Pedestrian Navigation To allow pedestrians to navigate a map, you will need to generate a pedestrian navigation file. This guide details what meshes to use and how to generate the file. Before you begin Pedestrian navigable meshes Optional pedestrian navigation options Generate the pedestrian navigation Before you begin Map customization (adding buildings, painting the road, adding landscape features, etc.) should be completed before generating the pedestrian navigation in order to avoid interference or collisions between the two, resulting in the need to generate the pedestrian navigation a second time. Pedestrian navigable meshes Pedestrians can only navigate specific meshes. You need to name the meshes you want to include in pedestrian navigation according to the nomenclature in the table below: Type Name includes Description Ground Road_Sidewalk or Roads_Sidewalk Pedestrians will walk over these meshes freely. Crosswalk Road_Crosswalk or Roads_Crosswalk Pedestrians will walk over these meshes as a second option if no ground is found. Grass Road_Grass or Roads_Grass Pedestrians won't walk on this mesh unless you specify a percentage of them to do so. Road Road_Road or Roads_Road Road_Curb or Roads_Curb Road_Gutter or Roads_Gutter Road_Marking or Roads_Marking Pedestrians will only cross roads through these meshes. Optional pedestrian navigation options The following step is not necessary for generating a pedestrian navigation, but allows you to customize pedestrian activity to a certain extent. Generate new crosswalks . Avoid doing this if the crosswalk is already defined the .xodr file as this will lead to duplication: Create a plane mesh that extends a bit over two sidewalks that you want to connect. Place the mesh overlapping the ground and disable it's physics and rendering. Change the name of the mesh to Road_Crosswalk or Roads_Crosswalk . Generate the pedestrian navigation 1. To prevent the map being too large to export, select the BP_Sky object and add a tag NoExport to it. If you have any other particularly large meshes that are not involved in the pedestrian navigation, add the NoExport tag to them as well. 2. Double check your mesh names. Mesh names should start with any of the appropriate formats listed below in order to be recognized as areas where pedestrians can walk. By default, pedestrians will be able to walk over sidewalks, crosswalks, and grass (with minor influence over the rest): Sidewalk = Road_Sidewalk or Roads_Sidewalk Crosswalk = Road_Crosswalk or Roads_Crosswalk Grass = Road_Grass or Roads_Grass 3. Press ctrl + A to select everything and export the map by selecting File -> Carla Exporter . A <mapName>.obj file will be created in Unreal/CarlaUE4/Saved . 4. Move the <mapName>.obj and the <mapName>.xodr to Util/DockerUtils/dist . 5. Run the following command to generate the navigation file: Windows build.bat <mapName> # <mapName> has no extension Linux ./build.sh <mapName> # <mapName> has no extension 6. A <mapName>.bin file will be created. This file contains the information for pedestrian navigation on your map. Move this file to the Nav folder of the package that contains the map. 7. Test the pedestrian navigation by starting a simulation and running the example script generate_traffic.py in PythonAPI/examples . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u751f\u6210\u884c\u4eba\u5bfc\u822a"},{"location":"tuto_M_generate_pedestrian_navigation/#generate-pedestrian-navigation","text":"To allow pedestrians to navigate a map, you will need to generate a pedestrian navigation file. This guide details what meshes to use and how to generate the file. Before you begin Pedestrian navigable meshes Optional pedestrian navigation options Generate the pedestrian navigation","title":"Generate Pedestrian Navigation"},{"location":"tuto_M_generate_pedestrian_navigation/#before-you-begin","text":"Map customization (adding buildings, painting the road, adding landscape features, etc.) should be completed before generating the pedestrian navigation in order to avoid interference or collisions between the two, resulting in the need to generate the pedestrian navigation a second time.","title":"Before you begin"},{"location":"tuto_M_generate_pedestrian_navigation/#pedestrian-navigable-meshes","text":"Pedestrians can only navigate specific meshes. You need to name the meshes you want to include in pedestrian navigation according to the nomenclature in the table below: Type Name includes Description Ground Road_Sidewalk or Roads_Sidewalk Pedestrians will walk over these meshes freely. Crosswalk Road_Crosswalk or Roads_Crosswalk Pedestrians will walk over these meshes as a second option if no ground is found. Grass Road_Grass or Roads_Grass Pedestrians won't walk on this mesh unless you specify a percentage of them to do so. Road Road_Road or Roads_Road Road_Curb or Roads_Curb Road_Gutter or Roads_Gutter Road_Marking or Roads_Marking Pedestrians will only cross roads through these meshes.","title":"Pedestrian navigable meshes"},{"location":"tuto_M_generate_pedestrian_navigation/#optional-pedestrian-navigation-options","text":"The following step is not necessary for generating a pedestrian navigation, but allows you to customize pedestrian activity to a certain extent. Generate new crosswalks . Avoid doing this if the crosswalk is already defined the .xodr file as this will lead to duplication: Create a plane mesh that extends a bit over two sidewalks that you want to connect. Place the mesh overlapping the ground and disable it's physics and rendering. Change the name of the mesh to Road_Crosswalk or Roads_Crosswalk .","title":"Optional pedestrian navigation options"},{"location":"tuto_M_generate_pedestrian_navigation/#generate-the-pedestrian-navigation","text":"1. To prevent the map being too large to export, select the BP_Sky object and add a tag NoExport to it. If you have any other particularly large meshes that are not involved in the pedestrian navigation, add the NoExport tag to them as well. 2. Double check your mesh names. Mesh names should start with any of the appropriate formats listed below in order to be recognized as areas where pedestrians can walk. By default, pedestrians will be able to walk over sidewalks, crosswalks, and grass (with minor influence over the rest): Sidewalk = Road_Sidewalk or Roads_Sidewalk Crosswalk = Road_Crosswalk or Roads_Crosswalk Grass = Road_Grass or Roads_Grass 3. Press ctrl + A to select everything and export the map by selecting File -> Carla Exporter . A <mapName>.obj file will be created in Unreal/CarlaUE4/Saved . 4. Move the <mapName>.obj and the <mapName>.xodr to Util/DockerUtils/dist . 5. Run the following command to generate the navigation file: Windows build.bat <mapName> # <mapName> has no extension Linux ./build.sh <mapName> # <mapName> has no extension 6. A <mapName>.bin file will be created. This file contains the information for pedestrian navigation on your map. Move this file to the Nav folder of the package that contains the map. 7. Test the pedestrian navigation by starting a simulation and running the example script generate_traffic.py in PythonAPI/examples . If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Generate the pedestrian navigation"},{"location":"tuto_M_manual_map_package/","text":"Manual package preparation A map package follows a certain folder structure and must contain a .json file describing that structure. Our automatic map import processes create this .json file automatically, but you also have the option to prepare it yourself. Including your own .json file will overwrite any arguments passed to the make import command. Standard Maps Create the folder structure for the standard maps Create the JSON description for the standard maps Large Maps Create the folder structure for the large maps Create the JSON description for the large maps Standard maps Create the folder structure for the standard maps 1. Create a folder inside carla/Import . The name of the folder is not important. 2. Create different subfolders for each map to be imported. 3. Move the files of each map to the corresponding subfolder. A subfolder will contain a specific set of elements: The mesh of the map in a .fbx file. The OpenDRIVE definition in a .xodr file. Optionally, the textures required by the asset. For instance, an Import folder with one package containing two maps should have a structure similar to the one below. Import \u2502 \u2514\u2500\u2500 Package01 \u251c\u2500\u2500 Package01.json \u251c\u2500\u2500 Map01 \u2502 \u251c\u2500\u2500 Asphalt1_Diff.jpg \u2502 \u251c\u2500\u2500 Asphalt1_Norm.jpg \u2502 \u251c\u2500\u2500 Asphalt1_Spec.jpg \u2502 \u251c\u2500\u2500 Grass1_Diff.jpg \u2502 \u251c\u2500\u2500 Grass1_Norm.jpg \u2502 \u251c\u2500\u2500 Grass1_Spec.jpg \u2502 \u251c\u2500\u2500 LaneMarking1_Diff.jpg \u2502 \u251c\u2500\u2500 LaneMarking1_Norm.jpg \u2502 \u251c\u2500\u2500 LaneMarking1_Spec.jpg \u2502 \u251c\u2500\u2500 Map01.fbx \u2502 \u2514\u2500\u2500 Map01.xodr \u2514\u2500\u2500 Map02 \u2514\u2500\u2500 Map02.fbx Create the JSON description for the standard maps Create a .json file in the root folder of the package. Name the file after the package. Note that this will be the distribution name. The content of the file will describe a JSON array of maps and props with basic information for each of them. Maps need the following parameters: name of the map. This must be the same as the .fbx and .xodr files. source path to the .fbx file. use_carla_materials . If True , the map will use CARLA materials. Otherwise, it will use RoadRunner materials. xodr Path to the .xodr file. Props are not part of this tutorial. The field will be left empty. There is another tutorial on how to add new props . The resulting .json file should resemble the following: { \"maps\": [ { \"name\": \"Map01\", \"source\": \"./Map01/Map01.fbx\", \"use_carla_materials\": true, \"xodr\": \"./Map01/Map01.xodr\" }, { \"name\": \"Map02\", \"source\": \"./Map02/Map02.fbx\", \"use_carla_materials\": false, \"xodr\": \"./Map02/Map02.xodr\" } ], \"props\": [ ] } If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"\u624b\u52a8\u51c6\u5907\u5730\u56fe\u5305"},{"location":"tuto_M_manual_map_package/#manual-package-preparation","text":"A map package follows a certain folder structure and must contain a .json file describing that structure. Our automatic map import processes create this .json file automatically, but you also have the option to prepare it yourself. Including your own .json file will overwrite any arguments passed to the make import command. Standard Maps Create the folder structure for the standard maps Create the JSON description for the standard maps Large Maps Create the folder structure for the large maps Create the JSON description for the large maps","title":"Manual package preparation"},{"location":"tuto_M_manual_map_package/#standard-maps","text":"","title":"Standard maps"},{"location":"tuto_M_manual_map_package/#create-the-folder-structure-for-the-standard-maps","text":"1. Create a folder inside carla/Import . The name of the folder is not important. 2. Create different subfolders for each map to be imported. 3. Move the files of each map to the corresponding subfolder. A subfolder will contain a specific set of elements: The mesh of the map in a .fbx file. The OpenDRIVE definition in a .xodr file. Optionally, the textures required by the asset. For instance, an Import folder with one package containing two maps should have a structure similar to the one below. Import \u2502 \u2514\u2500\u2500 Package01 \u251c\u2500\u2500 Package01.json \u251c\u2500\u2500 Map01 \u2502 \u251c\u2500\u2500 Asphalt1_Diff.jpg \u2502 \u251c\u2500\u2500 Asphalt1_Norm.jpg \u2502 \u251c\u2500\u2500 Asphalt1_Spec.jpg \u2502 \u251c\u2500\u2500 Grass1_Diff.jpg \u2502 \u251c\u2500\u2500 Grass1_Norm.jpg \u2502 \u251c\u2500\u2500 Grass1_Spec.jpg \u2502 \u251c\u2500\u2500 LaneMarking1_Diff.jpg \u2502 \u251c\u2500\u2500 LaneMarking1_Norm.jpg \u2502 \u251c\u2500\u2500 LaneMarking1_Spec.jpg \u2502 \u251c\u2500\u2500 Map01.fbx \u2502 \u2514\u2500\u2500 Map01.xodr \u2514\u2500\u2500 Map02 \u2514\u2500\u2500 Map02.fbx","title":"Create the folder structure for the standard maps"},{"location":"tuto_M_manual_map_package/#create-the-json-description-for-the-standard-maps","text":"Create a .json file in the root folder of the package. Name the file after the package. Note that this will be the distribution name. The content of the file will describe a JSON array of maps and props with basic information for each of them. Maps need the following parameters: name of the map. This must be the same as the .fbx and .xodr files. source path to the .fbx file. use_carla_materials . If True , the map will use CARLA materials. Otherwise, it will use RoadRunner materials. xodr Path to the .xodr file. Props are not part of this tutorial. The field will be left empty. There is another tutorial on how to add new props . The resulting .json file should resemble the following: { \"maps\": [ { \"name\": \"Map01\", \"source\": \"./Map01/Map01.fbx\", \"use_carla_materials\": true, \"xodr\": \"./Map01/Map01.xodr\" }, { \"name\": \"Map02\", \"source\": \"./Map02/Map02.fbx\", \"use_carla_materials\": false, \"xodr\": \"./Map02/Map02.xodr\" } ], \"props\": [ ] } If you have any questions about the process, then you can ask in the forum . CARLA forum","title":"Create the JSON description for the standard maps"}]}